TY  - JOUR
T1  - A three-phase approach to document clustering based on topic significance degree
JO  - Expert Systems with Applications
VL  - 41
IS  - 18
SP  - 8203
EP  - 8210
PY  - 2014/12/15/
T2  - 
AU  - Ma, Yinglong
AU  - Wang, Yao
AU  - Jin, Beihong
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2014.07.014
UR  - http://www.sciencedirect.com/science/article/pii/S0957417414004126
KW  - Document clustering
KW  - Topic model
KW  - K-means
KW  - K-means++
AB  - Abstract
Topic model can project documents into a topic space which facilitates effective document clustering. Selecting a good topic model and improving clustering performance are two highly correlated problems for topic based document clustering. In this paper, we propose a three-phase approach to topic based document clustering. In the first phase, we determine the best topic model and present a formal concept about significance degree of topics and some topic selection criteria, through which we can find the best number of the most suitable topics from the original topic model discovered by LDA. Then, we choose the initial clustering centers by using the k-means++ algorithm. In the third phase, we take the obtained initial clustering centers and use the k-means algorithm for document clustering. Three clustering solutions based on the three phase approach are used for document clustering. The related experiments of the three solutions are made for comparing and illustrating the effectiveness and efficiency of our approach.
ER  - 

TY  - JOUR
T1  - Document clustering method using dimension reduction and support vector clustering to overcome sparseness
JO  - Expert Systems with Applications
VL  - 41
IS  - 7
SP  - 3204
EP  - 3212
PY  - 2014/6/1/
T2  - 
AU  - Jun, Sunghae
AU  - Park, Sang-Sung
AU  - Jang, Dong-Sik
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2013.11.018
UR  - http://www.sciencedirect.com/science/article/pii/S0957417413009305
KW  - Document clustering
KW  - Sparseness problem
KW  - Patent clustering
KW  - Dimension reduction
KW  - K-means clustering based on support vector clustering
KW  - Silhouette measure
AB  - Abstract
Many studies on developing technologies have been published as articles, papers, or patents. We use and analyze these documents to find scientific and technological trends. In this paper, we consider document clustering as a method of document data analysis. In general, we have trouble analyzing documents directly because document data are not suitable for statistical and machine learning methods of analysis. Therefore, we have to transform document data into structured data for analytical purposes. For this process, we use text mining techniques. The structured data are very sparse, and hence, it is difficult to analyze them. This study proposes a new method to overcome the sparsity problem of document clustering. We build a combined clustering method using dimension reduction and K-means clustering based on support vector clustering and Silhouette measure. In particular, we attempt to overcome the sparseness in patent document clustering. To verify the efficacy of our work, we first conduct an experiment using news data from the machine learning repository of the University of California at Irvine. Second, using patent documents retrieved from the United States Patent and Trademark Office, we carry out patent clustering for technology forecasting.
ER  - 

TY  - JOUR
T1  - An Intelligent Document Clustering Approach to Detect Crime Patterns
JO  - Procedia Technology
VL  - 11
IS  - 
SP  - 1181
EP  - 1187
PY  - 2013///
T2  - 4th International Conference on Electrical Engineering and Informatics, ICEEI 2013
AU  - Bsoul, Qusay
AU  - Salim, Juhana
AU  - Zakaria, Lailatul Qadri
SN  - 2212-0173
DO  - http://dx.doi.org/10.1016/j.protcy.2013.12.311
UR  - http://www.sciencedirect.com/science/article/pii/S2212017313004659
KW  - Intelligent Clustering
KW  - K-means
KW  - Affinity Propagation algorithm
KW  - Lemmatization Algorithm
KW  - Crime Detection
AB  - Abstract
A wide number of reports and news on crimes, increasingly conducted almost every day, have resulted in making detection of such crimes more difficult if not complex. Therefore, the need for detecting and identifying such crimes emerges as a necessary way of detecting and identifying such crime patterns on the news. Document Clustering have been increasingly becoming an important task for obtaining good results with the unsupervised learning methods. It aims to automatically group similar documents in one cluster using different types of extractions and cluster algorithms. There are ongoing works done to improve Document Clustering techniques such as Extractions and Clustering approaches to overcome the difficulty in designing a general purpose document clustering for crime investigation and the ill posed problem of extraction and clustering. This paper discusses two major sequential stages in Document Clustering “Extraction Features and Clustering Algorithms” as well as the major challenges and the key issues in designing extraction features and clustering algorithms. In addition, the following approach assists the law enforcement officers and detectives to enhance performance and speed up the process of solving crimes.
ER  - 

TY  - JOUR
T1  - Probability based document clustering and image clustering using content-based image retrieval
JO  - Applied Soft Computing
VL  - 13
IS  - 2
SP  - 959
EP  - 966
PY  - 2013/2//
T2  - 
AU  - Karthikeyan, M.
AU  - Aruna, P.
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2012.09.013
UR  - http://www.sciencedirect.com/science/article/pii/S1568494612004334
KW  - Document clustering
KW  - Word frequency
KW  - Content-based image retrieval
KW  - Major colour set
KW  - Global colour signature
KW  - Distribution block signature
KW  - Hue saturation value
KW  - Region of Interest
KW  - RGB histogram-based image retrieval
AB  - Clustering of related or similar objects has long been regarded as a potentially useful contribution of helping users to navigate an information space such as a document collection. Many clustering algorithms and techniques have been developed and implemented but as the sizes of document collections have grown these techniques have not been scaled to large collections because of their computational overhead. To solve this problem, the proposed system concentrates on an interactive text clustering methodology, probability based topic oriented and semi-supervised document clustering. Recently, as web and various documents contain both text and large number of images, the proposed system concentrates on content-based image retrieval (CBIR) for image clustering to give additional effect to the document clustering approach. It suggests two kinds of indexing keys, major colour sets (MCS) and distribution block signature (DBS) to prune away the irrelevant images to given query image. Major colour sets are related with colour information while distribution block signatures are related with spatial information. After successively applying these filters to a large database, only small amount of high potential candidates that are somewhat similar to that of query image are identified. Then, the system uses quad modelling method (QM) to set the initial weight of two-dimensional cells in query image according to each major colour and retrieve more similar images through similarity association function associated with the weights. The proposed system evaluates the system efficiency by implementing and testing the clustering results with Dbscan and K-means clustering algorithms. Experiment shows that the proposed document clustering algorithm performs with an average efficiency of 94.4% for various document categories.
ER  - 

TY  - JOUR
T1  - An Evolutionary Approach for Document Clustering
JO  - IERI Procedia
VL  - 4
IS  - 
SP  - 370
EP  - 375
PY  - 2013///
T2  - 2013 International Conference on Electronic Engineering and Computer Science (EECS 2013)
AU  - Akter, Ruksana
AU  - Chung, Yoojin
SN  - 2212-6678
DO  - http://dx.doi.org/10.1016/j.ieri.2013.11.053
UR  - http://www.sciencedirect.com/science/article/pii/S2212667813000567
KW  - Document clustering
KW  - Genetic Algorithm
KW  - Local minima
KW  - Cluster Evaluation
AB  - Abstract
We propose an evolutionary approach based on genetic algorithm for text document clustering. Instead of applying genetic algorithm on the whole dataset, we partition the dataset into some groups and apply genetic algorithm to each of the partitions separately. Finally, we apply another genetic algorithm phase on the outcomes of the earlier ones. This allows to get rid of the local minima, which is one of the major problems of using genetic algorithms. Another good feature of our proposal is that we do not require specifying the total clusters to be made in advance as most of the available methods. Experimental results also show the superior performance of our approach as compared to the previous approaches.
ER  - 

TY  - JOUR
T1  - A similarity assessment technique for effective grouping of documents
JO  - Information Sciences
VL  - 311
IS  - 
SP  - 149
EP  - 162
PY  - 2015/8/1/
T2  - 
AU  - Basu, Tanmay
AU  - Murthy, C.A.
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2015.03.038
UR  - http://www.sciencedirect.com/science/article/pii/S0020025515002030
KW  - Document clustering
KW  - Text mining
KW  - Applied data mining
AB  - Abstract
Document clustering refers to the task of grouping similar documents and segregating dissimilar documents. It is very useful to find meaningful categories from a large corpus. In practice, the task to categorize a corpus is not so easy, since it generally contains huge documents and the document vectors are high dimensional. This paper introduces a hybrid document clustering technique by combining a new hierarchical and the traditional k-means clustering techniques. A distance function is proposed to find the distance between the hierarchical clusters. Initially the algorithm constructs some clusters by the hierarchical clustering technique using the new distance function. Then k-means algorithm is performed by using the centroids of the hierarchical clusters to group the documents that are not included in the hierarchical clusters. The major advantage of the proposed distance function is that it is able to find the nature of the corpora by varying a similarity threshold. Thus the proposed clustering technique does not require the number of clusters prior to executing the algorithm. In this way the initial random selection of k centroids for k-means algorithm is not needed for the proposed method. The experimental evaluation using Reuter, Ohsumed and various TREC data sets shows that the proposed method performs significantly better than several other document clustering techniques. F-measure and normalized mutual information are used to show that the proposed method is effectively grouping the text data sets.
ER  - 

TY  - JOUR
T1  - CDIM: Document Clustering by Discrimination Information Maximization
JO  - Information Sciences
VL  - 316
IS  - 
SP  - 87
EP  - 106
PY  - 2015/9/20/
T2  - Nature-Inspired Algorithms for Large Scale Global Optimization
AU  - Hassan, Malik Tahir
AU  - Karim, Asim
AU  - Kim, Jeong-Bae
AU  - Jeon, Moongu
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2015.04.009
UR  - http://www.sciencedirect.com/science/article/pii/S0020025515002777
KW  - Document clustering
KW  - Discrimination information
KW  - Semantic relatedness
KW  - Relative risk
KW  - Cluster understanding
AB  - Abstract
Ideally, document clustering methods should produce clusters that are semantically relevant and readily understandable as collections of documents belonging to particular contexts or topics. However, existing popular document clustering methods often ignore term-document corpus-based semantics while relying upon generic measures of similarity. In this paper, we present CDIM, an algorithmic framework for partitional clustering of documents that maximizes the sum of the discrimination information provided by documents. CDIM exploits the semantic that term discrimination information provides better understanding of contextual topics than term-to-term relatedness to yield clusters that are describable by their highly discriminating terms. We evaluate the proposed clustering algorithm using well-known discrimination/semantic measures including Relative Risk (RR), Measurement of Discrimination Information (MDI), Domain Relevance (DR), and Domain Consensus (DC) on twelve data sets to prove that CDIM produces high-quality clusters comparable to the best methods. We also illustrate the understandability and efficiency of CDIM, suggesting its suitability for practical document clustering.
ER  - 

TY  - JOUR
T1  - Using a new relational concept to improve the clustering performance of search engines
JO  - Information Processing & Management
VL  - 47
IS  - 2
SP  - 287
EP  - 299
PY  - 2011/3//
T2  - 
AU  - Chen, Lin-Chih
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2010.04.001
UR  - http://www.sciencedirect.com/science/article/pii/S0306457310000373
KW  - Document clustering
KW  - Semantic relation
KW  - Relational concept
KW  - Web search engines
KW  - Web documents
AB  - In this paper, we present a novel clustering algorithm to generate a number of candidate clusters from other web search results. The candidate clusters generate a connective relation among the clusters and the relation is semantic. Moreover, the algorithm also contains the following attractive properties: (1) it can be applied to multilingual web documents, (2) it improves the clustering performance of any search engine, (3) its unsupervised learning can automatically identify potentially relevant knowledge without using any corpus, and (4) clustering results are generated on the fly and fitted into search engines.
ER  - 

TY  - JOUR
T1  - Semi-supervised concept factorization for document clustering
JO  - Information Sciences
VL  - 331
IS  - 
SP  - 86
EP  - 98
PY  - 2016/2/20/
T2  - 
AU  - Lu, Mei
AU  - Zhao, Xiang-Jun
AU  - Zhang, Li
AU  - Li, Fan-Zhang
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2015.10.038
UR  - http://www.sciencedirect.com/science/article/pii/S0020025515007720
KW  - Concept factorization
KW  - Locally consistent concept factorization
KW  - Semi-supervised document clustering
AB  - Abstract
Nonnegative Matrix Factorization (NMF) and Concept Factorization (CF) are two popular methods for finding the low-rank approximation of nonnegative matrix. Different from NMF, CF can be applied not only to the matrix containing negative values but also to the kernel space. Based on NMF and CF, many methods, such as Graph regularized Nonnegative Matrix Factorization (GNMF) and Locally Consistent Clustering Factorization (LCCF) can significantly improve the performance of clustering. Unfortunately, these are unsupervised learning methods. In order to enhance the clustering performance with the supervisory information, a Semi-Supervised Concept Factorization (SSCF) is proposed in this paper by incorporating the pairwise constraints into CF as the reward and penalty terms, which can guarantee that the data points belonging to a cluster in the original space are still in the same cluster in the transformed space. By comparing with the state-of-the-arts algorithms (KM, NMF, CF, LCCF, GNMF, PCCF), experimental results on document clustering show that the proposed algorithm has better performance in terms of accuracy and mutual information.
ER  - 

TY  - JOUR
T1  - Learning latent features by nonnegative matrix factorization combining similarity judgments
JO  - Neurocomputing
VL  - 155
IS  - 
SP  - 43
EP  - 52
PY  - 2015/5/1/
T2  - 
AU  - Zhang, Jiang-She
AU  - Wang, Chang-Peng
AU  - Yang, Yu-Qian
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2014.12.050
UR  - http://www.sciencedirect.com/science/article/pii/S0925231214017147
KW  - Nonnegative matrix factorization
KW  - Additive clustering
KW  - Feature extraction
KW  - Face recognition
KW  - Document clustering
AB  - Abstract
Nonnegative matrix factorization (NMF) is a popular method for learning low-rank approximation of nonnegative matrix. However, aiming at seeking the low-rank approximation from the viewpoint of data reconstruction, NMF may produce unfavorable performances in classification and clustering tasks. In this paper, we develop a novel modification of NMF (called NMFCSJ) by incorporating the similarity judgments of data points into NMF, and then performs a collective factorization on the data matrix and a weighted similarity matrix with a closely related factor matrix. With the superiority of additive clustering, the proposed method NMFCSJ exploits the latent features hidden in the original data. Experiments show that NMFCSJ improves the classification performance on two face databases and achieves better clustering accuracy for semi-supervised or unsupervised document clustering on 9 documents datasets from CLUTO toolkit.
ER  - 

TY  - JOUR
T1  - Improving document clustering in a learned concept space
JO  - Information Processing & Management
VL  - 46
IS  - 2
SP  - 180
EP  - 192
PY  - 2010/3//
T2  - 
AU  - Pessiot, Jean-François
AU  - Kim, Young-Min
AU  - Amini, Massih R.
AU  - Gallinari, Patrick
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2009.09.007
UR  - http://www.sciencedirect.com/science/article/pii/S0306457309001095
KW  - Document clustering
KW  - Aspect models
KW  - Concept learning
AB  - Most document clustering algorithms operate in a high dimensional bag-of-words space. The inherent presence of noise in such representation obviously degrades the performance of most of these approaches. In this paper we investigate an unsupervised dimensionality reduction technique for document clustering. This technique is based upon the assumption that terms co-occurring in the same context with the same frequencies are semantically related. On the basis of this assumption we first find term clusters using a classification version of the EM algorithm. Documents are then represented in the space of these term clusters and a multinomial mixture model (MM) is used to build document clusters. We empirically show on four document collections, Reuters-21578, Reuters RCV2-French, 20Newsgroups and WebKB, that this new text representation noticeably increases the performance of the MM model. By relating the proposed approach to the Probabilistic Latent Semantic Analysis (PLSA) model we further propose an extension of the latter in which an extra latent variable allows the model to co-cluster documents and terms simultaneously. We show on these four datasets that the proposed extended version of the PLSA model produces statistically significant improvements with respect to two clustering measures over all variants of the original PLSA and the MM models.
ER  - 

TY  - JOUR
T1  - Clustering tagged documents with labeled and unlabeled documents
JO  - Information Processing & Management
VL  - 49
IS  - 3
SP  - 596
EP  - 606
PY  - 2013/5//
T2  - Personalization and Recommendation in Information Access
AU  - Liu, Chien-Liang
AU  - Hsaio, Wen-Hoar
AU  - Lee, Chia-Hoang
AU  - Chen, Chun-Hsien
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2012.12.004
UR  - http://www.sciencedirect.com/science/article/pii/S0306457312001422
KW  - Text mining
KW  - Document clustering
KW  - Semi-supervised clustering
KW  - Tagged document clustering
AB  - This study employs our proposed semi-supervised clustering method called Constrained-PLSA to cluster tagged documents with a small amount of labeled documents and uses two data sets for system performance evaluations. The first data set is a document set whose boundaries among the clusters are not clear; while the second one has clear boundaries among clusters. This study employs abstracts of papers and the tags annotated by users to cluster documents. Four combinations of tags and words are used for feature representations. The experimental results indicate that almost all of the methods can benefit from tags. However, unsupervised learning methods fail to function properly in the data set with noisy information, but Constrained-PLSA functions properly. In many real applications, background knowledge is ready, making it appropriate to employ background knowledge in the clustering process to make the learning more fast and effective.
ER  - 

TY  - JOUR
T1  - Exploring the E-science Knowledge Base through Co-citation Analysis
JO  - Procedia Computer Science
VL  - 19
IS  - 
SP  - 586
EP  - 593
PY  - 2013///
T2  - The 4th International Conference on Ambient Systems, Networks and Technologies (ANT 2013), the 3rd International Conference on Sustainable Energy Information Technology (SEIT-2013)
AU  - Mustafee, Navonil
AU  - Bessis, Nik
AU  - Taylor, Simon J.E.
AU  - Sotiriadis, Stelios
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2013.06.078
UR  - http://www.sciencedirect.com/science/article/pii/S1877050913006868
KW  - e-Science
KW  - co-citation analysis
KW  - grid computing
KW  - desktop grid computing
KW  - cloud computing
AB  - Abstract
E-Science is the “science of this age”; it is realized through collaborative scientific enquiry which requires utilization of non-trivial amounts of computing resources and massive data sets. In this paper we explore the e-Science knowledge base through co-citation analysis of extant literature. Our objective is to use the knowledge domain visualization software CiteSpace to identifying the turning point articles and authors. In other words, our analysis is not solely based on tabulating the frequency of co-cited articles and authors, but the identification of landmark articles and authors irrespective of their co-citation count. The dataset for this analysis is downloaded from the ISI Web of Science and includes approx. 1000 articles. It is expected that this paper will be an important source of reference for academics and researchers working in the area of e-Science and its three technology enablers - grid computing, desktop grids and cloud computing.
ER  - 

TY  - JOUR
T1  - ICE – Intelligent Clustering Engine: A clustering gadget for Google Desktop
JO  - Expert Systems with Applications
VL  - 39
IS  - 10
SP  - 9524
EP  - 9533
PY  - 2012/8//
T2  - 
AU  - Carlantonio, Lando M. di
AU  - Osiek, Bruno A.
AU  - Xexéo, Geraldo B.
AU  - Costa, Rosa Maria E.M. da
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2012.02.101
UR  - http://www.sciencedirect.com/science/article/pii/S0957417412003648
KW  - Information retrieval
KW  - Text mining
KW  - Document clustering
KW  - Genetic Algorithms
AB  - In light of the increased capacity and lower prices of computer hard drives, a new universe to be explored emerges, the microcosm of personal files. Although search and information retrieval techniques are already widely used in the Internet, its application in personal computers is still incipient. This paper describes a new tool for document clustering in the desktop, whose effectiveness in obtaining groups with similar documents is evidenced by the experimental results.
ER  - 

TY  - JOUR
T1  - Performance Evaluation of Semantic Based and Ontology Based Text Document Clustering Techniques
JO  - Procedia Engineering
VL  - 30
IS  - 
SP  - 100
EP  - 106
PY  - 2012///
T2  - International Conference on Communication Technology and System Design 2011
AU  - Punitha, S.C.
AU  - Punithavalli, M.
SN  - 1877-7058
DO  - http://dx.doi.org/10.1016/j.proeng.2012.01.839
UR  - http://www.sciencedirect.com/science/article/pii/S1877705812008491
KW  - Dataming ;Document clustering
KW  - HSTC
KW  - Feature Selection ;TCFSmethod
AB  - The amount of digital information is created and used is steadily growing along with the development of sophisticated hardware and software. This has increased the need for powerful algorithms that can interpret and extract interesting knowledge from these data. Data mining is a technique that has been successfully exploited for this purpose. Text mining, a category of data mining, considers only digital documents or text. Text Clustering is the process of grouping text or documents such that the document in the same cluster are similar and are dissimilar from the one in other clusters. This paper studies the working of two sophisticated algorithms. The first work is a hybrid method that combines pattern recognition process with semantic driven methods for clustering documents, while the second uses an ontology-based approach to cluster documents. Through experiments, the performance of both the selected algorithms is analyzed in terms of clustering efficiency and speed of clustering.
ER  - 

TY  - JOUR
T1  - Mining fuzzy frequent itemsets for hierarchical document clustering
JO  - Information Processing & Management
VL  - 46
IS  - 2
SP  - 193
EP  - 211
PY  - 2010/3//
T2  - 
AU  - Chen, Chun-Ling
AU  - Tseng, Frank S.C.
AU  - Liang, Tyne
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2009.09.009
UR  - http://www.sciencedirect.com/science/article/pii/S0306457309001113
KW  - Fuzzy association rule mining
KW  - Text mining
KW  - Hierarchical document clustering
KW  - Frequent itemsets
AB  - As text documents are explosively increasing in the Internet, the process of hierarchical document clustering has been proven to be useful for grouping similar documents for versatile applications. However, most document clustering methods still suffer from challenges in dealing with the problems of high dimensionality, scalability, accuracy, and meaningful cluster labels. In this paper, we will present an effective Fuzzy Frequent Itemset-Based Hierarchical Clustering (F2IHC) approach, which uses fuzzy association rule mining algorithm to improve the clustering accuracy of Frequent Itemset-Based Hierarchical Clustering (FIHC) method. In our approach, the key terms will be extracted from the document set, and each document is pre-processed into the designated representation for the following mining process. Then, a fuzzy association rule mining algorithm for text is employed to discover a set of highly-related fuzzy frequent itemsets, which contain key terms to be regarded as the labels of the candidate clusters. Finally, these documents will be clustered into a hierarchical cluster tree by referring to these candidate clusters. We have conducted experiments to evaluate the performance based on Classic4, Hitech, Re0, Reuters, and Wap datasets. The experimental results show that our approach not only absolutely retains the merits of FIHC, but also improves the accuracy quality of FIHC.
ER  - 

TY  - JOUR
T1  - Orthogonal nonnegative matrix tri-factorization for co-clustering: Multiplicative updates on Stiefel manifolds
JO  - Information Processing & Management
VL  - 46
IS  - 5
SP  - 559
EP  - 570
PY  - 2010/9//
T2  - 
AU  - Yoo, Jiho
AU  - Choi, Seungjin
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2009.12.007
UR  - http://www.sciencedirect.com/science/article/pii/S0306457310000038
KW  - Co-clustering
KW  - Document clustering
KW  - Multiplicative updates
KW  - Nonnegative matrix factorization
KW  - Stiefel manifolds
AB  - Matrix factorization-based methods become popular in dyadic data analysis, where a fundamental problem, for example, is to perform document clustering or co-clustering words and documents given a term-document matrix. Nonnegative matrix tri-factorization (NMTF) emerges as a promising tool for co-clustering, seeking a 3-factor decomposition X ≈ USV ⊤ with all factor matrices restricted to be nonnegative, i.e., U ⩾ 0 , S ⩾ 0 , V ⩾ 0 . In this paper we develop multiplicative updates for orthogonal NMTF where X ≈ USV ⊤ is pursued with orthogonality constraints, U ⊤ U = I , and V ⊤ V = I , exploiting true gradients on Stiefel manifolds. Experiments on various document data sets demonstrate that our method works well for document clustering and is useful in revealing polysemous words via co-clustering words and documents.
ER  - 

TY  - JOUR
T1  - Data-intensive document clustering on graphics processing unit (GPU) clusters
JO  - Journal of Parallel and Distributed Computing
VL  - 71
IS  - 2
SP  - 211
EP  - 224
PY  - 2011/2//
T2  - Data Intensive Computing
AU  - Zhang, Yongpeng
AU  - Mueller, Frank
AU  - Cui, Xiaohui
AU  - Potok, Thomas
SN  - 0743-7315
DO  - http://dx.doi.org/10.1016/j.jpdc.2010.08.002
UR  - http://www.sciencedirect.com/science/article/pii/S0743731510001383
KW  - High-performance computing
KW  - Accelerators
KW  - Data-intensive computing
AB  - Document clustering is a central method to mine massive amounts of data. Due to the explosion of raw documents generated on the Internet and the necessity to analyze them efficiently in various intelligent information systems, clustering techniques have reached their limitations on single processors. Instead of single processors, general-purpose multi-core chips are increasingly deployed in response to diminishing returns in single-processor speedup due to the frequency wall, but multi-core benefits only provide linear speedups while the number of documents in the Internet is growing exponentially. Accelerating hardware devices represent a novel promise for improving the performance for data-intensive problems such as document clustering. They offer more radical designs with a higher level of parallelism but adaptation to novel programming environments.

In this paper, we assess the benefits of exploiting the computational power of graphics processing units (GPUs) to study two fundamental problems in document mining, namely to calculate the term frequency–inverse document frequency (TF–IDF) and cluster a large set of documents. We transform traditional algorithms into accelerated parallel counterparts that can be efficiently executed on many-core GPU architectures. We assess our implementations on various platforms, ranging from stand-alone GPU desktops to Beowulf-like clusters equipped with contemporary GPU cards. We observe at least one order of magnitude speedups over CPU-only desktops and clusters. This demonstrates the potential of exploiting GPU clusters to efficiently solve massive document mining problems. Such speedups combined with the scalability potential and accelerator-based parallelization are unique in the domain of document-based data mining, to the best of our knowledge.
ER  - 

TY  - JOUR
T1  - RPLSA: A novel updating scheme for Probabilistic Latent Semantic Analysis
JO  - Computer Speech & Language
VL  - 25
IS  - 4
SP  - 741
EP  - 760
PY  - 2011/10//
T2  - 
AU  - Bassiou, N.
AU  - Kotropoulos, C.
SN  - 0885-2308
DO  - http://dx.doi.org/10.1016/j.csl.2010.12.002
UR  - http://www.sciencedirect.com/science/article/pii/S0885230811000027
KW  - PLSA
KW  - PLSA updating
KW  - Document clustering
KW  - Information retrieval
KW  - Adjusted Rand
KW  - Expectation Maximization
AB  - A novel updating method for Probabilistic Latent Semantic Analysis (PLSA), called Recursive PLSA (RPLSA), is proposed. The updating of conditional probabilities is derived from first principles for both the asymmetric and the symmetric PLSA formulations. The performance of RPLSA for both formulations is compared to that of the PLSA folding-in, the PLSA rerun from the breakpoint, and well-known LSA updating methods, such as the singular value decomposition (SVD) folding-in and the SVD-updating. The experimental results demonstrate that the RPLSA outperforms the other updating methods under study with respect to the maximization of the average log-likelihood and the minimization of the average absolute error between the probabilities estimated by the updating methods and those derived by applying the non-adaptive PLSA from scratch. A comparison in terms of CPU run time is conducted as well. Finally, in document clustering using the Adjusted Rand index, it is demonstrated that the clusters generated by the RPLSA are: (a) similar to those generated by the PLSA applied from scratch; (b) closer to the ground truth than those created by the other PLSA or LSA updating methods.
ER  - 

TY  - JOUR
T1  - An integration of WordNet and fuzzy association rule mining for multi-label document clustering
JO  - Data & Knowledge Engineering
VL  - 69
IS  - 11
SP  - 1208
EP  - 1226
PY  - 2010/11//
T2  - Special issue on contribution of ontologies in designing advanced information systems
AU  - Chen, Chun-Ling
AU  - Tseng, Frank S.C.
AU  - Liang, Tyne
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2010.08.003
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X10000972
KW  - Fuzzy association rule mining
KW  - Text mining
KW  - Document clustering
KW  - WordNet
KW  - Frequent itemsets
AB  - With the rapid growth of text documents, document clustering has become one of the main techniques for organizing large amount of documents into a small number of meaningful clusters. However, there still exist several challenges for document clustering, such as high dimensionality, scalability, accuracy, meaningful cluster labels, overlapping clusters, and extracting semantics from texts. In order to improve the quality of document clustering results, we propose an effective Fuzzy-based Multi-label Document Clustering (FMDC) approach that integrates fuzzy association rule mining with an existing ontology WordNet to alleviate these problems. In our approach, the key terms will be extracted from the document set, and the initial representation of all documents is further enriched by using hypernyms of WordNet in order to exploit the semantic relations between terms. Then, a fuzzy association rule mining algorithm for texts is employed to discover a set of highly-related fuzzy frequent itemsets, which contain key terms to be regarded as the labels of the candidate clusters. Finally, each document is dispatched into more than one target cluster by referring to these candidate clusters, and then the highly similar target clusters are merged. We conducted experiments to evaluate the performance based on Classic, Re0, R8, and WebKB datasets. The experimental results proved that our approach outperforms the influential document clustering methods with higher accuracy. Therefore, our approach not only provides more general and meaningful labels for documents, but also effectively generates overlapping clusters.
ER  - 

TY  - JOUR
T1  - Heuristic Frequent Term-Based Clustering of News Headlines
JO  - Procedia Technology
VL  - 6
IS  - 
SP  - 436
EP  - 443
PY  - 2012///
T2  - 2nd International Conference on Communication, Computing &amp;amp; Security [ICCCS-2012]
AU  - Bora, Nibir Nayan
AU  - Mishra, Bhabani Shankar Prasad
AU  - Dehuri, Satchidananda
SN  - 2212-0173
DO  - http://dx.doi.org/10.1016/j.protcy.2012.10.052
UR  - http://www.sciencedirect.com/science/article/pii/S221201731200597X
KW  - Document clustering
KW  - Cluster evaluation
KW  - Frequent term clustering
KW  - k-means
AB  - Document clustering deals with assigning documents to groups (called clusters) in accordance with the general clustering rule, ‘high intra-cluster document similarity and low inter-cluster document similarity’. In this study, we propose a novel heuristics for clustering news headlines. News headlines are grammatically and semantically different from larger bodies of text, like blog posts and reviews. Based on the heuristics, we implemented versions of the frequent term-based and frequent noun-based clustering algorithms. Both these algorithms, along with k-means, regular frequent term and frequent noun clustering were evaluated using five datasets -Reuters343, Reuters2388 (news headlines), CICLing-2002, Hep-ex and KnCr (scientific abstracts). On interpreting the results based on common external cluster quality evaluation measures (purity, entropy and F measure), it was found that the heuristics performed at par with, or even better than, traditional clustering algorithms and few other intuitive algorithms, when tested using the datasets comprising of news headlines. However, on using the datasets comprising of scientific abstracts, the results were not favorable.
ER  - 

TY  - JOUR
T1  - Generic title labeling for clustered documents
JO  - Expert Systems with Applications
VL  - 37
IS  - 3
SP  - 2247
EP  - 2254
PY  - 2010/3/15/
T2  - 
AU  - Tseng, Yuen-Hsien
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2009.07.048
UR  - http://www.sciencedirect.com/science/article/pii/S0957417409007167
KW  - Hypernym search
KW  - Clustering labeling
KW  - WordNet
KW  - Correlation coefficient
KW  - Topic identification
AB  - Document clustering is a powerful technique to detect topics and their relations for information browsing, analysis, and organization. However, clustered documents require post-assignment of descriptive titles to help users interpret the results. Existing techniques often assign labels to clusters based only on the terms that the clustered documents contain, which may not be sufficient for some applications. To solve this problem, a cluster labeling algorithm for creating generic titles, based on external resources such as WordNet, is proposed. Our method first extracts category-specific terms as cluster descriptors. These descriptors are then mapped to generic terms based on a hypernym search algorithm. The proposed method has been evaluated on a patent document collection and a subset of the Reuters-21578 collection. Experimental results revealed that our method performs as anticipated. Real-case applications of these generic terms show promising in assisting humans in interpreting the clustered topics. Our method is general enough such that it can be easily extended to use other hierarchical resources for adaptable label generation.
ER  - 

TY  - JOUR
T1  - An improved bee colony optimization algorithm with an application to document clustering
JO  - Neurocomputing
VL  - 159
IS  - 
SP  - 9
EP  - 26
PY  - 2015/7/2/
T2  - 
AU  - Forsati, Rana
AU  - Keikha, Andisheh
AU  - Shamsfard, Mehrnoush
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2015.02.048
UR  - http://www.sciencedirect.com/science/article/pii/S092523121500212X
KW  - Swarm intelligence
KW  - Bee colony optimization
KW  - Document clustering
AB  - Abstract
The bee colony optimization (BCO) algorithm is proved to be one of the fast, robust and efficient global search heuristics in tackling different practical problems. Considering BCO algorithm in this paper, we utilize it for the data clustering, a fundamental problem that frequently arises in many applications. However, we discovered some obstacles in directly applying the ancient BCO to address the clustering problem and managed to change some basic behaviors of this swarm algorithm. In particular, we present an improved bee colony optimization algorithm, dubbed IBCO, by introducing cloning and fairness concepts into the BCO algorithm and make it more efficient for data clustering. These features give BCO very powerful and balanced exploration and exploitation capabilities to effectively guide the search process toward the proximity of the high quality solutions. In particular, the cloning feature allows it to take advantage of experiences gained from previous generations when generating new solutions. The problem of getting stuck in local optima still laid bare in the proposed improved version. As a result, to overcome the shortage of this swarm algorithm in searching locally, we hybridize it with the k-means algorithm to take advantage of fine tuning power of the widely used k-means algorithm which demonstrates good result in local searches. We propose four different hybridized algorithms based on IBCO and k-means algorithms and investigate the clustering results and convergence behavior of them. We empirically demonstrate that our hybrid algorithms alleviate the problem of sticking in a local solution even for large and high dimensional data sets such as document clustering. The results show that proposed algorithms are robust enough to be used in many applications compared to k-means and other recently proposed evolutionary based clustering algorithms including genetic, particle swarm optimization, ant colony, and bee based algorithms.
ER  - 

TY  - JOUR
T1  - Clustering Software Components for Program Restructuring and Component Reuse Using Hybrid XOR Similarity Function
JO  - AASRI Procedia
VL  - 4
IS  - 
SP  - 319
EP  - 328
PY  - 2013///
T2  - 2013 AASRI Conference on Intelligent Systems and Control
AU  - Srinivas, Chintakindi
AU  - Radhakrishna, Vangipuram
AU  - Guru Rao, C.V.
SN  - 2212-6716
DO  - http://dx.doi.org/10.1016/j.aasri.2013.10.047
UR  - http://www.sciencedirect.com/science/article/pii/S2212671613000486
KW  - Clustering
KW  - hybrid XOR ;frequent itemsets
KW  - mining ;classification,components
AB  - Abstract
Component based software development has gained a lot of practical importance in the field of software engineering from several researchers and also from industry perspective. Finding components for efficient software reuse is one of the important problems aimed by researchers. Clustering reduces the search space of components by grouping similar entities together thus ensuring reduced time complexity as it reduces the search time for component retrieval. In this research, we instigate a new a generalized approach for clustering a given set of documents or text files or components by defining a new similarity function called hybrid XOR function for the purpose of finding degree of similarity between two document sets or software components. We construct a matrix called similarity matrix of the order n-1 by n for a given set of n documents or components or patterns by applying hybrid XOR function. We define and design the algorithm for component or document clustering which has the input as similarity matrix and output being set of clusters formed dynamically as compared to other clustering algorithms that predefine the count of clusters. The output is a set of highly cohesive pattern groups or documents. The approach can be justified as it carries out very simple computational logic and efficient in terms of processing with reduced search space and can be also be used in general for document clustering or software component clustering.
ER  - 

TY  - JOUR
T1  - Review: Important contributions in development and improvement of the heat integration techniques
JO  - Computers & Chemical Engineering
VL  - 34
IS  - 8
SP  - 1171
EP  - 1179
PY  - 2010/8/9/
T2  - 
AU  - Morar, Mihaela
AU  - Agachi, Paul Serban
SN  - 0098-1354
DO  - http://dx.doi.org/10.1016/j.compchemeng.2010.02.038
UR  - http://www.sciencedirect.com/science/article/pii/S009813541000089X
KW  - Heat integration
KW  - Pinch analysis
KW  - Mathematical programming
KW  - Knowledge domain visualization
AB  - The chemical processes and utility industries are central issues to modern living standards. The society evolution dictates that chemical processes will need continuous development and the advantages obtained of using process integration techniques consist in process improvement, increased productivity, energy conservation, pollution prevention, and capital and operating costs reductions of chemical plants.

Therefore, the aim of this paper is to present in a comprehensive review the development through the years (1975–2008) of the heat integration and heat exchanger network synthesis (HENS) as a technique of process integration. From an impressive amount of studies related to this topic, a selection with the studies representing the turning points and the emerging trends in developing and improving of heat integration and HENS methods was made.

The relationships between domains, authors, and journals, related with the field of research, are presented in an easy understanding visual format through the diagrams provided by CiteSpace II software.
ER  - 

TY  - JOUR
T1  - A fast divisive clustering algorithm using an improved discrete particle swarm optimizer
JO  - Pattern Recognition Letters
VL  - 31
IS  - 11
SP  - 1216
EP  - 1225
PY  - 2010/8/1/
T2  - 
AU  - Feng, Liang
AU  - Qiu, Ming-Hui
AU  - Wang, Yu-Xuan
AU  - Xiang, Qiao-Liang
AU  - Yang, Yin-Fei
AU  - Liu, Kai
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2010.04.001
UR  - http://www.sciencedirect.com/science/article/pii/S0167865510001133
KW  - Hierarchical clustering
KW  - Divisive clustering
KW  - Particle swarm optimizer
AB  - As an important technique for data analysis, clustering has been employed in many applications such as image segmentation, document clustering and vector quantization. Divisive clustering, which is a branch of hierarchical clustering, has been studied and widely used due to its computational efficiency. Generally, which cluster should be split and how to split the selected cluster are two major principles that should be taken into account when a divisive clustering algorithm is used. However, one disadvantage of the divisive clustering is its degraded performance compared to the partitional clustering, thus making it hard to achieve a good trade-off between computational time and clustering performance. To tackle this problem, we propose a novel divisive clustering algorithm by integrating an improved discrete particle swarm optimizer into a divisive clustering framework. Experiments on several synthetic data sets, real-world data sets and two real-world applications (document clustering and vector quantization) show some promising results. Firstly, the proposed algorithm performs better or at least comparable to the other representative clustering algorithms in terms of clustering quality and robustness. Secondly, the proposed algorithm runs much faster than the other competing algorithms on all the benchmark sets. At last, the good time-quality trade-off is still achievable when the size of the problem instance is increased.
ER  - 

TY  - JOUR
T1  - A fuzzy document clustering approach based on domain-specified ontology
JO  - Data & Knowledge Engineering
VL  - 100, Part A
IS  - 
SP  - 148
EP  - 166
PY  - 2015/11//
T2  - 
AU  - Yue, Lin
AU  - Zuo, Wanli
AU  - Peng, Tao
AU  - Wang, Ying
AU  - Han, Xuming
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2015.04.008
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X15000191
KW  - Domain-specified ontology
KW  - Document clustering
KW  - Feature selection
KW  - Singular value decomposition (SVD)
KW  - Fuzzy equivalence relation
AB  - Abstract
Document clustering techniques include automatic document organization, topic extraction, fast information retrieval or filtering, etc. Numerous methods have been developed for document clustering research. Despite the advances achieved, however, document clustering still presents certain challenges such as optimizing feature selection for low-dimensional document representation and incorporating mutual information between the documents into a clustering algorithm. This paper mainly focuses on these two questions. First, we construct a domain-specific ontology that provides the controlled vocabulary describing the hazards related to dairy products. Synonyms of the controlled vocabulary in document set are considered to be relatively prevalent and fundamentally important for feature selection. Second, in combination with the vector space model (VSM), we perform singular value decomposition (SVD) to translate all of the term-document vectors into a concept space. We then obtain the mutual information between documents by calculating the similarity of every two document vectors in the orthogonal matrix of right singular vectors. As the mutual information matrix is also a fuzzy compatible relation, a fuzzy equivalence can be derived by calculating max–min transitive closure. Finally, based on the fuzzy equivalence relation, all of the data sequences are easily allocated into clusters under the guidance of a cluster validation index. Our method both reduces the dimensionality of the original data and considers the correlation between the terms. The experimental results show that encoding the ontologies in the aggregation process could provide better clustering results. Moreover, the proposed work has been applied to food safety supervision which is beneficial for government and society.
ER  - 

TY  - JOUR
T1  - Computing text semantic relatedness using the contents and links of a hypertext encyclopedia
JO  - Artificial Intelligence
VL  - 194
IS  - 
SP  - 176
EP  - 202
PY  - 2013/1//
T2  - Artificial Intelligence, Wikipedia and Semi-Structured Resources
AU  - Yazdani, Majid
AU  - Popescu-Belis, Andrei
SN  - 0004-3702
DO  - http://dx.doi.org/10.1016/j.artint.2012.06.004
UR  - http://www.sciencedirect.com/science/article/pii/S0004370212000744
KW  - Text semantic relatedness
KW  - Distance metric learning
KW  - Learning to rank
KW  - Random walk
KW  - Text classification
KW  - Text similarity
KW  - Document clustering
KW  - Information retrieval
KW  - Word similarity
AB  - We propose a method for computing semantic relatedness between words or texts by using knowledge from hypertext encyclopedias such as Wikipedia. A network of concepts is built by filtering the encyclopediaʼs articles, each concept corresponding to an article. Two types of weighted links between concepts are considered: one based on hyperlinks between the texts of the articles, and another one based on the lexical similarity between them. We propose and implement an efficient random walk algorithm that computes the distance between nodes, and then between sets of nodes, using the visiting probability from one (set of) node(s) to another. Moreover, to make the algorithm tractable, we propose and validate empirically two truncation methods, and then use an embedding space to learn an approximation of visiting probability. To evaluate the proposed distance, we apply our method to four important tasks in natural language processing: word similarity, document similarity, document clustering and classification, and ranking in information retrieval. The performance of the method is state-of-the-art or close to it for each task, thus demonstrating the generality of the knowledge resource. Moreover, using both hyperlinks and lexical similarity links improves the scores with respect to a method using only one of them, because hyperlinks bring additional real-world knowledge not captured by lexical similarity.
ER  - 

TY  - JOUR
T1  - Text clustering using frequent itemsets
JO  - Knowledge-Based Systems
VL  - 23
IS  - 5
SP  - 379
EP  - 388
PY  - 2010/7//
T2  - 
AU  - Zhang, Wen
AU  - Yoshida, Taketoshi
AU  - Tang, Xijin
AU  - Wang, Qing
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2010.01.011
UR  - http://www.sciencedirect.com/science/article/pii/S0950705110000134
KW  - Document clustering
KW  - Frequent itemsets
KW  - Maximum Capturing
KW  - Similarity measure
KW  - Competitive learning
AB  - Frequent itemset originates from association rule mining. Recently, it has been applied in text mining such as document categorization, clustering, etc. In this paper, we conduct a study on text clustering using frequent itemsets. The main contribution of this paper is three manifolds. First, we present a review on existing methods of document clustering using frequent patterns. Second, a new method called Maximum Capturing is proposed for document clustering. Maximum Capturing includes two procedures: constructing document clusters and assigning cluster topics. We develop three versions of Maximum Capturing based on three similarity measures. We propose a normalization process based on frequency sensitive competitive learning for Maximum Capturing to merge cluster candidates into predefined number of clusters. Third, experiments are carried out to evaluate the proposed method in comparison with CFWS, CMS, FTC and FIHC methods. Experiment results show that in clustering, Maximum Capturing has better performances than other methods mentioned above. Particularly, Maximum Capturing with representation using individual words and similarity measure using asymmetrical binary similarity achieves the best performance. Moreover, topics produced by Maximum Capturing distinguished clusters from each other and can be used as labels of document clusters.
ER  - 

TY  - JOUR
T1  - Knowledge dissemination patterns in the information retrieval industry: A case study for automatic classification techniques
JO  - World Patent Information
VL  - 39
IS  - 
SP  - 50
EP  - 57
PY  - 2014/12//
T2  - 
AU  - Eito-Brun, Ricardo
SN  - 0172-2190
DO  - http://dx.doi.org/10.1016/j.wpi.2014.06.003
UR  - http://www.sciencedirect.com/science/article/pii/S0172219014000957
KW  - Citation analysis
KW  - Automatic document classification
KW  - Document clustering
KW  - Bibliometric indicators
KW  - Innovation capability assessment
AB  - Abstract
Patents provide valuable information to identify flows in the transfer of technical knowledge and assess the innovation capabilities of the actors involved in different industries. Patent citations are also recognized as a valid tool to measure the impact of innovations and to identify key influencers in diverse activity sectors.

This study analyzes a collection of U.S. patents granted in the period between 1990 and 2012 for the subject “automatic document clustering and classification”, a key technology within the Information Retrieval and Text Mining disciplines. The purpose of this research is to identify – using citation analysis – the most productive and influential companies and journals, and the patterns followed in the transfer and sharing of technical knowledge. The paper identifies the most productive organizations (those that have been granted a higher number of patents) and those with a higher impact (organizations whose patents have received a major number of citations), and compares the generated rankings with those obtained using traditional bibliometric indicators. The conclusions provide an overview of the innovation landscape in the area of study, and suggest to which extent bibliometric indicators match the conclusions obtained after analyzing productivity and impact using patent citation.
ER  - 

TY  - JOUR
T1  - Efficient stochastic algorithms for document clustering
JO  - Information Sciences
VL  - 220
IS  - 
SP  - 269
EP  - 291
PY  - 2013/1/20/
T2  - Online Fuzzy Machine Learning and Data Mining
AU  - Forsati, Rana
AU  - Mahdavi, Mehrdad
AU  - Shamsfard, Mehrnoush
AU  - Reza Meybodi, Mohammad
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2012.07.025
UR  - http://www.sciencedirect.com/science/article/pii/S0020025512004975
KW  - Document clustering
KW  - Stochastic optimization
KW  - Harmony search
KW  - K-means
KW  - Hybridization
AB  - Clustering has become an increasingly important and highly complicated research area for targeting useful and relevant information in modern application domains such as the World Wide Web. Recent studies have shown that the most commonly used partitioning-based clustering algorithm, the K-means algorithm, is more suitable for large datasets. However, the K-means algorithm may generate a local optimal clustering. In this paper, we present novel document clustering algorithms based on the Harmony Search (HS) optimization method. By modeling clustering as an optimization problem, we first propose a pure HS based clustering algorithm that finds near-optimal clusters within a reasonable time. Then, harmony clustering is integrated with the K-means algorithm in three ways to achieve better clustering by combining the explorative power of HS with the refining power of the K-means. Contrary to the localized searching property of K-means algorithm, the proposed algorithms perform a globalized search in the entire solution space. Additionally, the proposed algorithms improve K-means by making it less dependent on the initial parameters such as randomly chosen initial cluster centers, therefore, making it more stable. The behavior of the proposed algorithm is theoretically analyzed by modeling its population variance as a Markov chain. We also conduct an empirical study to determine the impacts of various parameters on the quality of clusters and convergence behavior of the algorithms. In the experiments, we apply the proposed algorithms along with K-means and a Genetic Algorithm (GA) based clustering algorithm on five different document datasets. Experimental results reveal that the proposed algorithms can find better clusters and the quality of clusters is comparable based on F-measure, Entropy, Purity, and Average Distance of Documents to the Cluster Centroid (ADDC).
ER  - 

TY  - JOUR
T1  - Clustering of web search results based on the cuckoo search algorithm and Balanced Bayesian Information Criterion
JO  - Information Sciences
VL  - 281
IS  - 
SP  - 248
EP  - 264
PY  - 2014/10/10/
T2  - Multimedia Modeling
AU  - Cobos, Carlos
AU  - Muñoz-Collazos, Henry
AU  - Urbano-Muñoz, Richar
AU  - Mendoza, Martha
AU  - León, Elizabeth
AU  - Herrera-Viedma, Enrique
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2014.05.047
UR  - http://www.sciencedirect.com/science/article/pii/S0020025514006100
KW  - Cuckoo search algorithm
KW  - Clustering of web result
KW  - Web document clustering
KW  - Balanced Bayesian Information Criterion
KW  - k-Mean
AB  - Abstract
The clustering of web search results – or web document clustering – has become a very interesting research area among academic and scientific communities involved in information retrieval. Web search result clustering systems, also called Web Clustering Engines, seek to increase the coverage of documents presented for the user to review, while reducing the time spent reviewing them. Several algorithms for clustering web results already exist, but results show room for more to be done. This paper introduces a new description-centric algorithm for the clustering of web results, called WDC-CSK, which is based on the cuckoo search meta-heuristic algorithm, k-means algorithm, Balanced Bayesian Information Criterion, split and merge methods on clusters, and frequent phrases approach for cluster labeling. The cuckoo search meta-heuristic provides a combined global and local search strategy in the solution space. Split and merge methods replace the original Lévy flights operation and try to improve existing solutions (nests), so they can be considered as local search methods. WDC-CSK includes an abandon operation that provides diversity and prevents the population nests from converging too quickly. Balanced Bayesian Information Criterion is used as a fitness function and allows defining the number of clusters automatically. WDC-CSK was tested with four data sets (DMOZ-50, AMBIENT, MORESQUE and ODP-239) over 447 queries. The algorithm was also compared against other established web document clustering algorithms, including Suffix Tree Clustering (STC), Lingo, and Bisecting k-means. The results show a considerable improvement upon the other algorithms as measured by recall, F-measure, fall-out, accuracy and SSLk.
ER  - 

TY  - JOUR
T1  - Distributionally Extended Network-based Word Sense Disambiguation in Semantic Clustering of Polish Texts
JO  - IERI Procedia
VL  - 10
IS  - 
SP  - 38
EP  - 44
PY  - 2014///
T2  - International Conference on Future Information Engineering (FIE 2014)
AU  - Kędzia, Paweł
AU  - Piasecki, Maciej
AU  - Kocoń, Jan
AU  - Indyka-Piasecka, Agnieszka
SN  - 2212-6678
DO  - http://dx.doi.org/10.1016/j.ieri.2014.09.073
UR  - http://www.sciencedirect.com/science/article/pii/S221266781400121X
KW  - Word Sense Disambiguation
KW  - wordnet
KW  - text classification
KW  - plWordNet
AB  - Abstract
In the paper we present an extended version of the graph-based unsupervised Word Sense Disambiguation algorithm. The algorithm is based on the spreading activation scheme applied to the graphs dynamically built on the basis of the text words and a large wordnet. The algorithm, originally proposed for English and Princeton WordNet, was adapted to Polish and plWordNet. An extension based on the knowledge acquired from the corpus-derived Measure of Semantic Relatedness was proposed. The extended algorithm was evaluated against the manually disambiguated corpus. We observed improvement in the case of the disambiguation performed for shorter text contexts. In addition the algorithm application expressed improvement in document clustering task.
ER  - 

TY  - JOUR
T1  - Ontology-based semantic retrieval for engineering domain knowledge
JO  - Neurocomputing
VL  - 116
IS  - 
SP  - 382
EP  - 391
PY  - 2013/9/20/
T2  - Advanced Theory and Methodology in Intelligent ComputingSelected Papers from the Seventh International Conference on Intelligent Computing (ICIC 2011).
AU  - Zhang, Xutang
AU  - Hou, Xin
AU  - Chen, Xiaofeng
AU  - Zhuang, Ting
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2011.12.057
UR  - http://www.sciencedirect.com/science/article/pii/S0925231212006935
KW  - Ontology
KW  - Knowledge retrieval
KW  - Latent semantic analysis
KW  - Document clustering
AB  - The semantic retrieval of the engineering domain knowledge is critical in many engineering activities, e.g., product design and process planning. To address the problems with existing keyword-based and semantic-enable methods, we propose an ontology-based semantic retrieval scheme for knowledge search and retrieval from domain documents. In our scheme, domain ontology is first constructed using the graph-based approach to automating construction of domain ontology GRAONTO proposed by our group, and query semantic extension and retrieval are then adopted for semantic-based knowledge retrieval. For query semantic extension, latent semantic analysis is adopted to discover the latent semantic relationships between queries and ontology semantic features, and ontology semantic graph is used to represent the query. For semantic retrieval, a graph-based k-means method is proposed to partition the domain documents into several clusters, and a hierarchical searching strategy is employed for document retrieval. Finally, experimental results on the fixture design corpus verify the benefits of the proposed scheme.
ER  - 

TY  - JOUR
T1  - Enhancing meta-portals using dynamic user context personalization techniques
JO  - Journal of Network and Computer Applications
VL  - 35
IS  - 5
SP  - 1446
EP  - 1453
PY  - 2012/9//
T2  - Service Delivery Management in Broadband Networks
AU  - Bouras, Christos
AU  - Poulopoulos, Vassilis
SN  - 1084-8045
DO  - http://dx.doi.org/10.1016/j.jnca.2011.10.005
UR  - http://www.sciencedirect.com/science/article/pii/S1084804511001925
KW  - Personalization
KW  - Web personalization
KW  - On-line document grouping
KW  - User profiling
KW  - Meta-portal
AB  - The Internet is flooded with information and the last decade its size has grown so many times that information search and presentation have become tedious tasks even for experienced users. Minor changes to existing resources can alter the situation and lead to major changes to the end user experience. In this manuscript we present the dynamic web personalization and document grouping infrastructure for meta-portals and the evaluation of our mechanism on a meta-portal. A meta-portal is an informational node where articles from different sources are collected and presented in a categorized and personalized manner. The web personalization mechanism is based on dynamic creation and update of user profiles according to the users preferences when browsing. In parallel a user's profile is affected by user grouping details, which are constructed by users with similar profiles. Assuming that required information, such as article tagging, keywords to categories matching and articles to categories relation is already part of the meta-portal we present a novel mechanism that can build and maintain a user profile which is formed without disturbing the user. Furthermore, we describe the real-time user-centred document grouping mechanism that is implemented to support the web personalization system and present the experimental evaluation of the whole system.
ER  - 

TY  - JOUR
T1  - Towards a New Approach of Support Innovation Guided by Knowledge Management: Application on FERTIAL
JO  - Procedia - Social and Behavioral Sciences
VL  - 210
IS  - 
SP  - 260
EP  - 269
PY  - 2015/12/2/
T2  - Proceedings of the 4th International Conference on Leadership, Technology, Innovation and Business Management (ICLTIBM-2014)
AU  - Menaouer, Brahami
AU  - Khalissa, Semaoune
AU  - Abdelbaki, Benziane
AU  - Abdelhamid, Touati
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2015.11.366
UR  - http://www.sciencedirect.com/science/article/pii/S1877042815057134
KW  - Knowledge management
KW  - Knowledge mapping
KW  - Knowledge capitalization
KW  - Innovation process
KW  - MASK method
KW  - TRIZ method
AB  - Abstract
In the context current industrial, the companies consider the knowledge as an important resource and strategic for innovation. For it, a good understanding of intellectual patrimony of the company and its environment promotes the emergence of the new ideas. In this paper, we present a new approach to support innovation which builds on the one hand, on the critical knowledge mapping, respecting the principle of the method MASK, and on the other hand on the exploitation of these capitalized knowledge (mapped) for innovate the production processes using the method TRIZ.
ER  - 

TY  - JOUR
T1  - An Approach of Support Innovation Guided by Knowledge Capitalization: Application on FERTIAL
JO  - Procedia - Social and Behavioral Sciences
VL  - 181
IS  - 
SP  - 197
EP  - 206
PY  - 2015/5/11/
T2  - PROCEEDINGS OF THE 3rd INTERNATIONAL CONFERENCE ON LEADERSHIP, TECHNOLOGY AND INNOVATION MANAGEMENT
AU  - Menaouer, Brahami
AU  - Khalissa, Semaoune
AU  - Abdelbaki, Benziane
AU  - Abdelhamid, Touati
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2015.04.881
UR  - http://www.sciencedirect.com/science/article/pii/S1877042815031742
KW  - Knowledge management
KW  - Knowledge mapping
KW  - Knowledge capitalization
KW  - Innovation process
KW  - MASK method
KW  - TRIZ method
AB  - Abstract
In the context current industrial, the companies consider the knowledge as an important resource and strategic for innovation. For it, a good understanding of intellectual patrimony of the company and its environment promotes the emergence of the new ideas. In this paper, we present a new approach to support innovation which builds on the one hand, on the critical knowledge mapping, respecting the principle of the method MASK, and on the other hand on the exploitation of these capitalized knowledge (mapped) for innovate the production processes using the method TRIZ.
ER  - 

TY  - JOUR
T1  - Document Clustering Using Hybrid XOR Similarity Function for Efficient Software Component Reuse
JO  - Procedia Computer Science
VL  - 17
IS  - 
SP  - 121
EP  - 128
PY  - 2013///
T2  - First International Conference on Information Technology and Quantitative Management
AU  - Radhakrishna, Vangipuram
AU  - Srinivas, C.
AU  - Rao, C.V.Guru
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2013.05.017
UR  - http://www.sciencedirect.com/science/article/pii/S1877050913001506
KW  - hybrid xor ;clustering
KW  - frequent itemsets
KW  - cluster
AB  - Abstract
In this paper a generalized approach is proposed for clustering a set of given documents or text files or software components for reuse based on the new similarity function called hybrid XOR function defined for the purpose of finding degree of similarity among two document sets or any two software components. We construct a matrix called similarity matrix of order n-1 by n for n document sets or software components by applying hybrid XOR function for each pair of document sets. We define and design the clustering algorithm which has its input as similarity matrix and output as a set of clusters formed dynamically as compared to other clustering algorithms that predefine the count of clusters and documents being fit to one of those clusters or classes finally. The approach carried out uses simple computations.
ER  - 

TY  - JOUR
T1  - Knowledge mapping of hospitality research − A visual analysis using CiteSpace
JO  - International Journal of Hospitality Management
VL  - 60
IS  - 
SP  - 77
EP  - 93
PY  - 2017/1//
T2  - 
AU  - Li, Xinjian
AU  - Ma, Emily
AU  - Qu, Hailin
SN  - 0278-4319
DO  - http://dx.doi.org/10.1016/j.ijhm.2016.10.006
UR  - http://www.sciencedirect.com/science/article/pii/S0278431916303152
KW  - Hospitality
KW  - Knowledge mapping
KW  - CiteSpace
KW  - Visual analysis
AB  - Abstract
Hospitality literature constitutes a considerable accumulation of data for follow-up studies. This study used CiteSpace to analyze investigations published in three top journals of hospitality research: International Journal of Hospitality Management (2008–2014), Cornell Hospitality Quarterly (2008–2014), and International Journal of Contemporary Hospitality Management (2009–2014). This application resulted in comprehensive knowledge maps of hospitality research. The study identified major disciplines that provide knowledge and theories for the hospitality discipline as well as contemporary research topics and most influential researchers.
ER  - 

TY  - JOUR
T1  - Using patent data for technology forecasting: China RFID patent analysis
JO  - Advanced Engineering Informatics
VL  - 25
IS  - 1
SP  - 53
EP  - 64
PY  - 2011/1//
T2  - RFID and sustainable value chains
AU  - Trappey, Charles V.
AU  - Wu, Hsin-Ying
AU  - Taghaboni-Dutta, Fataneh
AU  - Trappey, Amy J.C.
SN  - 1474-0346
DO  - http://dx.doi.org/10.1016/j.aei.2010.05.007
UR  - http://www.sciencedirect.com/science/article/pii/S1474034610000340
KW  - Radio Frequency Identification (RFID)
KW  - Clustering
KW  - Patent analysis
KW  - China patents
KW  - Patent mapping
AB  - China is one of the world’s largest manufacturers and consumers of Radio Frequency Identification (RFID) applications. Current estimates show that China will need over 3 billion RFID tags to satisfy demand in the year 2009. The applications for RFID patents have spread across a very diverse range of inventions and in the future it is likely that most products manufactured in China will contain an RFID tag. China’s RFID industry has grown along with the demand and researchers are making significant technological advances. In this research, patent data from the State Intellectual Property Office of the People’s Republic of China (SIPO) have been used to explore RFID technology development and its trends. Patent abstracts containing the keyword and phrase “RFID” and “Radio Frequency Identification” were collected for analysis, content extraction, and clustering. In total, 1389 patents from the SIPO database covering the years 1995–2008 were retrieved and archived for analysis. Patents provide exclusive rights and legal protection for inventors, play an important role in the development and fair diffusion of technology, and contain detailed specifications necessary to define and protect the boundaries of an invention. Through patent analysis, companies monitor the development of technology and evaluate the position of potential competitors in the market. This research introduce a methodology which combines patent content clustering and technology life cycle forecasting to find a niche space of RFID technology development in China.

A patent content clustering method is used to cluster different patent documents into homogenous groups, and then technology forecasting is applied to evaluate possible market opportunities for future inventors and investors. The results suggest that the cluster called RFID wireless communication devices has entered the saturation stage and thus provides limited opportunity for development. Four other clusters; RFID concepts and applications, RFID architecture, RFID tracking implementation, and RFID transmission apparatus, have entered the mature stage. The RFID frequency and waves cluster appears to be in early growth stage with good development potential. Since the technology related to basic RFID concepts and devices has reached a mature stage in China, the research and development seems to be targeting the improvement of the RFID frequencies and waves as a means to develop more reliable RFID systems and applications.
ER  - 

TY  - JOUR
T1  - Hard and fuzzy diagonal co-clustering for document-term partitioning
JO  - Neurocomputing
VL  - 193
IS  - 
SP  - 133
EP  - 147
PY  - 2016/6/12/
T2  - 
AU  - Laclau, Charlotte
AU  - Nadif, Mohamed
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2016.02.003
UR  - http://www.sciencedirect.com/science/article/pii/S0925231216001818
KW  - Co-clustering
KW  - Fuzzy co-clustering
KW  - Document clustering
AB  - Abstract
We propose a hard and a fuzzy diagonal co-clustering algorithms built upon the double K-means to address the problem of document-term co-clustering. At each iteration, the proposed algorithms seek a diagonal block structure of the data by minimizing a criterion based on both the variance within the class and the centroid effect. In addition to be easy-to-interpret and effective on sparse binary and continuous data, the proposed algorithms, Hard Diagonal Double K-means (DDKM) and Fuzzy Diagonal Double K-means (F-DDKM), are also faster than other state-of-the-art clustering algorithms. We evaluate our contribution using synthetic data sets, and real data sets commonly used in document clustering.
ER  - 

TY  - JOUR
T1  - Improving the text classification using clustering and a novel HMM to reduce the dimensionality
JO  - Computer Methods and Programs in Biomedicine
VL  - 136
IS  - 
SP  - 119
EP  - 130
PY  - 2016/11//
T2  - 
AU  - Seara Vieira, A.
AU  - Borrajo, L.
AU  - Iglesias, E.L.
SN  - 0169-2607
DO  - http://dx.doi.org/10.1016/j.cmpb.2016.08.018
UR  - http://www.sciencedirect.com/science/article/pii/S016926071530050X
KW  - KeywordsHidden Markov Model
KW  - Text classification
KW  - Dimensionality reduction
KW  - Document clustering
KW  - Similarity-based classification
AB  - Abstract
In text classification problems, the representation of a document has a strong impact on the performance of learning systems. The high dimensionality of the classical structured representations can lead to burdensome computations due to the great size of real-world data. Consequently, there is a need for reducing the quantity of handled information to improve the classification process. In this paper, we propose a method to reduce the dimensionality of a classical text representation based on a clustering technique to group documents, and a previously developed Hidden Markov Model to represent them. We have applied tests with the k-NN and SVM classifiers on the OHSUMED and TREC benchmark text corpora using the proposed dimensionality reduction technique. The experimental results obtained are very satisfactory compared to commonly used techniques like InfoGain and the statistical tests performed demonstrate the suitability of the proposed technique for the preprocessing step in a text classification task.
ER  - 

TY  - JOUR
T1  - Knowledge mapping for rapidly evolving domains: A design science approach
JO  - Decision Support Systems
VL  - 50
IS  - 2
SP  - 415
EP  - 427
PY  - 2011/1//
T2  - 
AU  - Dang, Yan
AU  - Zhang, Yulei
AU  - Hu, Paul Jen-Hwa
AU  - Brown, Susan A.
AU  - Chen, Hsinchun
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2010.10.003
UR  - http://www.sciencedirect.com/science/article/pii/S0167923610001806
KW  - Knowledge mapping
KW  - Design science
KW  - Information systems
AB  - Knowledge mapping can provide comprehensive depictions of rapidly evolving scientific domains. Taking the design science approach, we developed a Web-based knowledge mapping system (i.e., Nano Mapper) that provides interactive search and analysis on various scientific document sources in nanotechnology. We conducted multiple studies to evaluate Nano Mapper's search and analysis functionality respectively. The search functionality appears more effective than that of the benchmark systems. Subjects exhibit favorable satisfaction with the analysis functionality. Our study addresses several gaps in knowledge mapping for nanotechnology and illustrates desirability of using the design science approach to design, implement, and evaluate an advanced information system.
ER  - 

TY  - JOUR
T1  - A weighted common structure based clustering technique for XML documents
JO  - Journal of Systems and Software
VL  - 83
IS  - 7
SP  - 1267
EP  - 1274
PY  - 2010/7//
T2  - SPLC 2008
AU  - Hwang, Jeong Hee
AU  - Ryu, Keun Ho
SN  - 0164-1212
DO  - http://dx.doi.org/10.1016/j.jss.2010.02.004
UR  - http://www.sciencedirect.com/science/article/pii/S0164121210000397
KW  - Data mining
KW  - XML mining
KW  - Document clustering
KW  - XML clustering
AB  - XML has recently become very popular as a means of representing semistructured data and as a standard for data exchange over the Web, because of its varied applicability in numerous applications. Therefore, XML documents constitute an important data mining domain. In this paper, we propose a new method of XML document clustering by a global criterion function, considering the weight of common structures. Our approach initially extracts representative structures of frequent patterns from schemaless XML documents using a sequential pattern mining algorithm. Then, we perform clustering of an XML document by the weight of common structures, without a measure of pairwise similarity, assuming that an XML document is a transaction and frequent structures extracted from documents are items of the transaction. We conducted experiments to compare our method with previous methods. The experimental results show the effectiveness of our approach.
ER  - 

TY  - JOUR
T1  - Power law based foundation for the measurement of discrimination information for human knowledge representation
JO  - Future Generation Computer Systems
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Xu, Zheng
AU  - Luo, Xiangfeng
AU  - Liu, Yunhuai
AU  - Mei, Lin
AU  - Hu, Chuanping
SN  - 0167-739X
DO  - http://dx.doi.org/10.1016/j.future.2016.10.021
UR  - http://www.sciencedirect.com/science/article/pii/S0167739X16304447
KW  - Algorithms
KW  - Design
KW  - Theory
KW  - Discrimination information
KW  - Power law
KW  - Information theory
AB  - Abstract
The discrimination information (DI) of keyword plays an important role in information retrieval and data mining. However, the measurement of DI is still a challenge because the existing methods cannot leverage the contradiction between accuracy and complexity. In this paper, a new model is proposed, does not need any prior knowledge and the computing complexity is O ( n m ) for a collection of m documents with n keywords. Firstly, we define three types of keywords according to the document frequency spectrum, which divides the spectrum of keywords into two monotonically spectrums that can give a qualitative analysis of DI. Secondly, in order to decrease the complexity, the power law function of keywords’ document frequencies is built. Thirdly, we propose an algorithm to classify keywords by using the distances between the adjacent points on the linear regression line. Finally, a piecewise function is used for computing DI according to the monotonically spectrums, which transforms DI into a scalable value to be used directly, thereby reducing the computing complexity of DI significantly. Moreover, a new weighting scheme of keywords based on DI is employed for document clustering, which shows that DI has a good prospect on the information retrieval area.
ER  - 

TY  - JOUR
T1  - Semantic smoothing for text clustering
JO  - Knowledge-Based Systems
VL  - 54
IS  - 
SP  - 216
EP  - 229
PY  - 2013/12//
T2  - 
AU  - Nasir, Jamal A.
AU  - Varlamis, Iraklis
AU  - Karim, Asim
AU  - Tsatsaronis, George
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2013.09.012
UR  - http://www.sciencedirect.com/science/article/pii/S0950705113002906
KW  - Text clustering
KW  - Semantic smoothing kernels
KW  - WordNet
KW  - Wikipedia
KW  - Generalized vector space model kernel
AB  - Abstract
In this paper we present a new semantic smoothing vector space kernel (S-VSM) for text documents clustering. In the suggested approach semantic relatedness between words is used to smooth the similarity and the representation of text documents. The basic hypothesis examined is that considering semantic relatedness between two text documents may improve the performance of the text document clustering task. For our experimental evaluation we analyze the performance of several semantic relatedness measures when embedded in the proposed (S-VSM) and present results with respect to different experimental conditions, such as: (i) the datasets used, (ii) the underlying knowledge sources of the utilized measures, and (iii) the clustering algorithms employed. To the best of our knowledge, the current study is the first to systematically compare, analyze and evaluate the impact of semantic smoothing in text clustering based on ‘wisdom of linguists’, e.g., WordNets, ‘wisdom of crowds’, e.g., Wikipedia, and ‘wisdom of corpora’, e.g., large text corpora represented with the traditional Bag of Words (BoW) model. Three semantic relatedness measures for text are considered; two knowledge-based (Omiotis [1] that uses WordNet, and WLM [2] that uses Wikipedia), and one corpus-based (PMI [3] trained on a semantically tagged SemCor version). For the comparison of different experimental conditions we use the BCubed F-Measure evaluation metric which satisfies all formal constraints of good quality cluster. The experimental results show that the clustering performance based on the S-VSM is better compared to the traditional VSM model and compares favorably against the standard GVSM kernel which uses word co-occurrences to compute the latent similarities between document terms.
ER  - 

TY  - JOUR
T1  - A document clustering algorithm for discovering and describing topics
JO  - Pattern Recognition Letters
VL  - 31
IS  - 6
SP  - 502
EP  - 510
PY  - 2010/4/15/
T2  - CIARP 2008: Robust and Efficient Analysis of Signals and Images
AU  - Anaya-Sánchez, Henry
AU  - Pons-Porrata, Aurora
AU  - Berlanga-Llavori, Rafael
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2009.11.013
UR  - http://www.sciencedirect.com/science/article/pii/S0167865509003249
KW  - Document clustering
KW  - Topic discovery
KW  - Topic description
AB  - In this paper, we introduce a new clustering algorithm for discovering and describing the topics comprised in a text collection. Our proposal relies on both the most probable term pairs generated from the collection and the estimation of the topic homogeneity associated to these pairs. Topics and their descriptions are generated from those term pairs whose support sets are homogeneous enough for representing collection topics. Experimental results obtained over three benchmark text collections demonstrate the effectiveness and utility of this new approach.
ER  - 

TY  - JOUR
T1  - Clustering Software Components for Program Restructuring and Component Reuse Using Hybrid XNOR Similarity Function
JO  - Procedia Technology
VL  - 12
IS  - 
SP  - 246
EP  - 254
PY  - 2014///
T2  - The 7th International Conference Interdisciplinarity in Engineering, INTER-ENG 2013, 10-11 October 2013, Petru Maior University of Tirgu Mures, Romania
AU  - Srinivas, Chintakindi
AU  - Radhakrishna, Vangipuram
AU  - Rao, C.V. Guru
SN  - 2212-0173
DO  - http://dx.doi.org/10.1016/j.protcy.2013.12.482
UR  - http://www.sciencedirect.com/science/article/pii/S2212017313006671
KW  - clustering
KW  - similarity
KW  - frequent item
KW  - mining
KW  - classification
KW  - component
AB  - Abstract
Component based software development has gained a lot of practical importance in the field of software engineering from academic researchers and also from industry perspective. Finding components for efficient software reuse is one of the important problems aimed by researchers. Clustering reduces the search space of components by grouping similar entities together thus ensuring reduced time complexity as it reduces the search time for component retrieval. In this research, we instigate a generalized approach for clustering a given set of documents or software components by defining a similarity function called hybrid XNOR function to find degree of similarity between two document sets or software components. A similarity matrix is obtained for a given set of documents or components by applying hybrid XNOR function. We define and design the algorithm for component or document clustering which has the input as similarity matrix and output being set of clusters. The output is a set of highly cohesive pattern groups or components.
ER  - 

TY  - JOUR
T1  - Constrained Laplacian Eigenmap for dimensionality reduction
JO  - Neurocomputing
VL  - 73
IS  - 4–6
SP  - 951
EP  - 958
PY  - 2010/1//
T2  - Bayesian Networks / Design and Application of Neural Networks and Intelligent Learning Systems (KES 2008 / Bio-inspired Computing: Theories and Applications (BIC-TA 2007)
AU  - Chen, Chun
AU  - Zhang, Lijun
AU  - Bu, Jiajun
AU  - Wang, Can
AU  - Chen, Wei
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2009.08.021
UR  - http://www.sciencedirect.com/science/article/pii/S0925231209003798
KW  - Dimensionality reduction
KW  - Graph embedding
KW  - Laplacian Eigenmap
KW  - Document clustering
AB  - Dimensionality reduction is a commonly used tool in machine learning, especially when dealing with high dimensional data. We consider semi-supervised graph based dimensionality reduction in this paper, and a novel dimensionality reduction algorithm called constrained Laplacian Eigenmap (CLE) is proposed. Suppose the data set contains r classes, and for each class we have some labeled points. CLE maps each data point into r different lines, and each map i tries to separate points belonging to class i from others by using label information. CLE constrains the solution space of Laplacian Eigenmap only to contain embedding results that are consistent with the labels. Then, each point is represented as a r-dimensional vector. Labeled points belonging to the same class are merged together, labeled points belonging to different classes are separated, and similar points are close to one another. We perform semi-supervised document clustering using CLE on two standard corpora. Experimental results show that CLE is very effective.
ER  - 

TY  - JOUR
T1  - Visualising a knowledge mapping of information systems investment evaluation
JO  - Expert Systems with Applications
VL  - 41
IS  - 1
SP  - 105
EP  - 125
PY  - 2014/1//
T2  - 21st Century Logistics and Supply Chain Management
AU  - Irani, Zahir
AU  - Sharif, Amir
AU  - Kamal, Muhammad Mustafa
AU  - Love, Peter E.D.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2013.07.015
UR  - http://www.sciencedirect.com/science/article/pii/S0957417413004922
KW  - Knowledge management
KW  - Knowledge mapping
KW  - Knowledge components
KW  - Supply chain management
KW  - IS investment evaluation
KW  - Expert Systems
AB  - Abstract
Information systems (IS) facilitate organisations to increase responsiveness and reduce the costs of their supply chain. This paper seeks to make a contribution through exploring and visualising knowledge mapping from the perspective of IS investment evaluation. The evaluation of IS is regarded as a challenging and complex process, which becomes even more difficult with the increased complexity of IS. The intricacy of IS evaluation, however, is due to numerous interrelated factors (e.g. costs, benefits and risks) that have human or organisational dimensions. With this in mind, there appears to be an increasing need to assess investment decision-making processes, to better understand the often far-reaching implications associated with technology adoption and interrelated knowledge components (KC). Through the identification and extrapolation of key learning issues from the literature and empirical findings, organisations can better improve their business processes and thereby their effectiveness and efficiency, while preventing others from making costly oversights that may not necessarily be only financial. In seeking to enlighten the often obscure evaluation of IS investments, this paper attempts to inductively emphasise the dissemination of knowledge and learning through the application of a fuzzy Expert System (ES) based knowledge mapping technique (i.e. Fuzzy Cognitive Map [FCM]). The rationale for exploring knowledge and IS investment evaluation is that a knowledge map will materialise for others to exploit during their specific technology evaluation. This is realised through conceptualising the explicit and tacit investment drivers. Among the several findings drawn from this research, the key resulting knowledge mapping through FCM demonstrated the complex, multifaceted and emergent behaviour of causal relationships within the knowledge area. The principal relationships and knowledge within IS investment evaluation are illustrated as being determined by a blend of managerial and user perspectives.
ER  - 

TY  - JOUR
T1  - XNDDF: Towards a Framework for Flexible Near-Duplicate Document Detection Using Supervised and Unsupervised Learning
JO  - Procedia Computer Science
VL  - 48
IS  - 
SP  - 228
EP  - 235
PY  - 2015///
T2  - International Conference on Computer, Communication and Convergence (ICCC 2015)
AU  - Pamulaparty, Lavanya
AU  - Guru Rao, C.V.
AU  - Rao, M. Sreenivasa
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.04.175
UR  - http://www.sciencedirect.com/science/article/pii/S1877050915006845
KW  - Web search
KW  - Document clustering
KW  - Near duplicate detection
KW  - Offline processing
AB  - Abstract
The WWW has witnessed the exponential growth of web documents. People of all walks of life depend on the electronic superhighway, Internet, for retrieving information. Search engines retrieve data. Detecting near duplicate documents and handling them can help search engines to improve performance. In this paper, we proposed two algorithms. The first algorithm is meant for unsupervised probabilistic clustering of documents while the second algorithm is to detect near duplicates that can handle in offline processing of search engines. The clustered documents can avoid unnecessary comparisons while near duplicate detection algorithm involve local feature selection in are given document based on weights assigned to terms. A classifier is built to have supervised learning for discriminating documents. We proposed a framework named eXtensible Near Duplicate Detection Framework (XNDDF) which provides various components that provide room for flexible duplicate detection solutions besides showing offline and online processing required by a search engine. Our future work is to implement the framework components through a prototype application.
ER  - 

TY  - JOUR
T1  - A probabilistic relational approach for web document clustering
JO  - Information Processing & Management
VL  - 46
IS  - 2
SP  - 117
EP  - 130
PY  - 2010/3//
T2  - 
AU  - Fersini, E.
AU  - Messina, E.
AU  - Archetti, F.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2009.08.003
UR  - http://www.sciencedirect.com/science/article/pii/S0306457309000892
KW  - Relational document clustering
KW  - Relational web structure estimation
AB  - The exponential growth of information available on the World Wide Web, and retrievable by search engines, has implied the necessity to develop efficient and effective methods for organizing relevant contents. In this field document clustering plays an important role and remains an interesting and challenging problem in the field of web computing. In this paper we present a document clustering method, which takes into account both contents information and hyperlink structure of web page collection, where a document is viewed as a set of semantic units. We exploit this representation to determine the strength of a relation between two linked pages and to define a relational clustering algorithm based on a probabilistic graph representation. The experimental results show that the proposed approach, called RED-clustering, outperforms two of the most well known clustering algorithm as k-Means and Expectation Maximization.
ER  - 

TY  - JOUR
T1  - Clustering documents with labeled and unlabeled documents using fuzzy semi-Kmeans
JO  - Fuzzy Sets and Systems
VL  - 221
IS  - 
SP  - 48
EP  - 64
PY  - 2013/6/16/
T2  - Theme: Clustering
AU  - Liu, Chien-Liang
AU  - Chang, Tao-Hsing
AU  - Li, Hsuan-Hsun
SN  - 0165-0114
DO  - http://dx.doi.org/10.1016/j.fss.2013.01.004
UR  - http://www.sciencedirect.com/science/article/pii/S0165011413000213
KW  - Fuzzy clustering
KW  - Semi-supervised learning
KW  - Text mining
KW  - Fuzzy semi-Kmeans
AB  - While focusing on document clustering, this work presents a fuzzy semi-supervised clustering algorithm called fuzzy semi-Kmeans. The fuzzy semi-Kmeans is an extension of K-means clustering model, and it is inspired by an EM algorithm and a Gaussian mixture model. Additionally, the fuzzy semi-Kmeans provides the flexibility to employ different fuzzy membership functions to measure the distance between data. This work employs Gaussian weighting function to conduct experiments, but cosine similarity function can be used as well. This work conducts experiments on three data sets and compares fuzzy semi-Kmeans with several methods. The experimental results indicate that fuzzy semi-Kmeans can generally outperform the other methods.
ER  - 

TY  - JOUR
T1  - Pairwise-adaptive dissimilarity measure for document clustering
JO  - Information Sciences
VL  - 180
IS  - 12
SP  - 2341
EP  - 2358
PY  - 2010/6/15/
T2  - 
AU  - D’hondt, Joris
AU  - Vertommen, Joris
AU  - Verhaegen, Paul-Armand
AU  - Cattrysse, Dirk
AU  - Duflou, Joost R.
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2010.02.021
UR  - http://www.sciencedirect.com/science/article/pii/S002002551000099X
KW  - Distance measure
KW  - Document clustering
KW  - Cluster quality
KW  - Text mining
AB  - This paper introduces a novel pairwise-adaptive dissimilarity measure for large high dimensional document datasets that improves the unsupervised clustering quality and speed compared to the original cosine dissimilarity measure. This measure dynamically selects a number of important features of the compared pair of document vectors. Two approaches for selecting the number of features in the application of the measure are discussed. The proposed feature selection process makes this dissimilarity measure especially applicable in large, high dimensional document collections. Its performance is validated on several test sets originating from standardized datasets. The dissimilarity measure is compared to the well-known cosine dissimilarity measure using the average F-measures of the hierarchical agglomerative clustering result. This new dissimilarity measure results in an improved clustering result obtained with a lower required computational time.
ER  - 

TY  - JOUR
T1  - Mining Concepts from Texts
JO  - Procedia Computer Science
VL  - 9
IS  - 
SP  - 27
EP  - 36
PY  - 2012///
T2  - Proceedings of the International Conference on Computational Science, ICCS 2012
AU  - Ventura, João
AU  - Silva, Joaquim
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2012.04.004
UR  - http://www.sciencedirect.com/science/article/pii/S1877050912001251
KW  - Text Mining
KW  - Term Extraction
KW  - Relevant Expression
KW  - Information Extraction
KW  - Statistical Extractor
AB  - The extraction of multi-word relevant expressions has been an increasingly hot topic in the last few years. Relevant expressions are applicable in diverse areas such as Information Retrieval, document clustering, or classiﬁcation and indexing of documents. However, relevant single-words, which represent much of the knowledge in texts, have been a relatively dormant ﬁeld. In this paper we present a statistical language-independent approach to extract concepts formed by relevant single and multi-word units. By achieving promising precision/recall values, it can be an alternative both to language dependent approaches and to extractors that deal exclusively with multi-words.
ER  - 

TY  - JOUR
T1  - Analyses of research on the health of college students based on a perspective of knowledge mapping
JO  - Public Health
VL  - 137
IS  - 
SP  - 188
EP  - 191
PY  - 2016/8//
T2  - 
AU  - Zhang, C.
AU  - Zhang, J.
AU  - Long, C.
AU  - Zheng, J.
AU  - Su, C.
AU  - Hu, W.
AU  - Duan, Z.
SN  - 0033-3506
DO  - http://dx.doi.org/10.1016/j.puhe.2015.11.002
UR  - http://www.sciencedirect.com/science/article/pii/S0033350615004503
ER  - 

TY  - JOUR
T1  - Dynamic hierarchical algorithms for document clustering
JO  - Pattern Recognition Letters
VL  - 31
IS  - 6
SP  - 469
EP  - 477
PY  - 2010/4/15/
T2  - CIARP 2008: Robust and Efficient Analysis of Signals and Images
AU  - Gil-García, Reynaldo
AU  - Pons-Porrata, Aurora
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2009.11.011
UR  - http://www.sciencedirect.com/science/article/pii/S0167865509003225
KW  - Hierarchical clustering
KW  - Dynamic clustering
KW  - Overlapped clustering
AB  - In this paper, two clustering algorithms called dynamic hierarchical compact and dynamic hierarchical star are presented. Both methods aim to construct a cluster hierarchy, dealing with dynamic data sets. The first creates disjoint hierarchies of clusters, while the second obtains overlapped hierarchies. The experimental results on several benchmark text collections show that these methods not only are suitable for producing hierarchical clustering solutions in dynamic environments effectively and efficiently, but also offer hierarchies easier to browse than traditional algorithms. Therefore, we advocate its use for tasks that require dynamic clustering, such as information organization, creation of document taxonomies and hierarchical topic detection.
ER  - 

TY  - JOUR
T1  - Subject-based semantic document clustering for digital forensic investigations
JO  - Data & Knowledge Engineering
VL  - 86
IS  - 
SP  - 224
EP  - 241
PY  - 2013/7//
T2  - 
AU  - Dagher, Gaby G.
AU  - Fung, Benjamin C.M.
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2013.03.005
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X13000360
KW  - Clustering
KW  - Classification
KW  - Data mining
KW  - Information retrieval
KW  - Forensic analysis
KW  - Crime investigation
AB  - Abstract
Computers are increasingly used as tools to commit crimes such as unauthorized access (hacking), drug trafficking, and child pornography. The proliferation of crimes involving computers has created a demand for special forensic tools that allow investigators to look for evidence on a suspect's computer by analyzing communications and data on the computer's storage devices. Motivated by the forensic process at Sûreté du Québec (SQ), the Québec provincial police, we propose a new subject-based semantic document clustering model that allows an investigator to cluster documents stored on a suspect's computer by grouping them into a set of overlapping clusters, each corresponding to a subject of interest initially defined by the investigator.
ER  - 

TY  - JOUR
T1  - Fuzzy evolutionary optimization modeling and its applications to unsupervised categorization and extractive summarization
JO  - Expert Systems with Applications
VL  - 38
IS  - 8
SP  - 9112
EP  - 9121
PY  - 2011/8//
T2  - 
AU  - Song, Wei
AU  - Cheon Choi, Lim
AU  - Cheol Park, Soon
AU  - Feng Ding, Xiao
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2010.12.102
UR  - http://www.sciencedirect.com/science/article/pii/S095741741001465X
KW  - Extractive summarization
KW  - Topics estimation
KW  - Unsupervised categorization
KW  - Fuzzy evolutionary optimization
KW  - Normalized Google distance
AB  - Modern information retrieval (IR) systems consist of many challenging components, e.g. clustering, summarization, etc. Nowadays, without browsing the whole volume of datasets, IR systems present users with clusters of documents they are interested in, and summarize each document briefly which facilitates the task of finding the desired documents. This paper proposes a fuzzy evolutionary optimization modeling (FEOM) and its applications to unsupervised categorization and extractive summarization. In view of the nature of biological evolution, we take advantage of several fuzzy control parameters to adaptively regulate the behaviors of the evolutionary optimization, which can effectively prevent premature convergence to a local optimal solution. As a portable, modular and extensively executable model, FEOM is firstly implemented for clustering text documents. The searching capability of FEOM is exploited to explore appropriate partitions of documents such that the similarity metric of the resulting clusters is optimized. In order to further investigate its effectiveness as a generic data clustering model, FEOM is then applied to sentence clustering based extractive document summarization. It selects the most important sentence from each cluster to represent the overall meaning of document. We demonstrate the improved performance by a series of experiments using standard test sets, e.g. Reuter document collection, 20-newsgroup corpus, DUC01 and DUC02, as evaluated by some commonly used metrics, i.e. F-measure and ROUGE. The experimental results show that FEOM achieves performance as good as or better than state of arts of clustering and summarizing systems.
ER  - 

TY  - JOUR
T1  - Visualization of co-readership patterns from an online reference management system
JO  - Journal of Informetrics
VL  - 9
IS  - 1
SP  - 169
EP  - 182
PY  - 2015/1//
T2  - 
AU  - Kraker, Peter
AU  - Schlögl, Christian
AU  - Jack, Kris
AU  - Lindstaedt, Stefanie
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2014.12.003
UR  - http://www.sciencedirect.com/science/article/pii/S1751157714001151
KW  - Relational scientometrics
KW  - Topical distribution
KW  - Knowledge domain visualization
KW  - Mapping
KW  - Altmetrics
KW  - Readership statistics
AB  - Abstract
In this paper, we analyze the adequacy and applicability of readership statistics recorded in social reference management systems for creating knowledge domain visualizations. First, we investigate the distribution of subject areas in user libraries of educational technology researchers on Mendeley. The results show that around 69% of the publications in an average user library can be attributed to a single subject area. Then, we use co-readership patterns to map the field of educational technology. The resulting visualization prototype, based on the most read publications in this field on Mendeley, reveals 13 topic areas of educational technology research. The visualization is a recent representation of the field: 80% of the publications included were published within ten years of data collection. The characteristics of the readers, however, introduce certain biases to the visualization. Knowledge domain visualizations based on readership statistics are therefore multifaceted and timely, but it is important that the characteristics of the underlying sample are made transparent.
ER  - 

TY  - JOUR
T1  - A link-based approach to semantic relation analysis
JO  - Neurocomputing
VL  - 154
IS  - 
SP  - 127
EP  - 138
PY  - 2015/4/22/
T2  - 
AU  - Cheng, Xin
AU  - Miao, Duoqian
AU  - Wang, Can
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2014.12.011
UR  - http://www.sciencedirect.com/science/article/pii/S0925231214016750
KW  - Semantic relation analysis
KW  - Co-occurrence statistics
KW  - Neighbor information
KW  - Link-based relation
AB  - Abstract
The semantic relation analysis is an interesting issue in natural language processing. To capture the semantic relation between terms (words or phrases), various approaches have been proposed by using the co-occurrence statistics within corpus. However, it is still a challenging task to build a robust relation measure due to the complexity of the natural language. In this paper, we present a novel approach for the semantic relation analysis, which takes account of both the pairwise relation and the link-based relation within terms. The pairwise relation captures the relation between terms from the local view, which conveys the co-occurrence pattern between terms to measure their relation. The link-based relation involves the global information into the relation measure, which derives the relation between terms from the similarity of their context information. The combination of these two relations creates a model for robust and accurate semantic relation analysis. Experimental evaluation indicates that our proposed approach leads to much improved result in document clustering over the existed methods.
ER  - 

TY  - JOUR
T1  - Enhancements to knowledge discovery framework of SOPHIA textual case-based reasoning
JO  - Egyptian Informatics Journal
VL  - 15
IS  - 3
SP  - 211
EP  - 220
PY  - 2014/11//
T2  - 
AU  - Elhalwany, Islam
AU  - Mohammed, Ammar
AU  - Wassif, Khaled T.
AU  - Hefny, Hesham A.
SN  - 1110-8665
DO  - http://dx.doi.org/10.1016/j.eij.2014.10.002
UR  - http://www.sciencedirect.com/science/article/pii/S1110866514000346
KW  - Case based reasoning
KW  - Textual case based reasoning
KW  - Questions answering systems
KW  - Text classification
KW  - Text clustering
KW  - Knowledge discovery
AB  - Abstract
Many approaches were presented recently for developing Textual Case-Based Reasoning (TCBR) applications. One of the successful approaches is SOPHisticated Information Analysis (SOPHIA), which is distinguished by its ability to work without prior knowledge engineering, without domain dependency and without language dependency. SOPHIA is based on the distributional document clustering approach, which facilitates an advanced and rich knowledge discovery framework for case-based retrieval.

This paper contributes to propose enhancements to SOPHIA approach that aims to enhance the retrieval efficiency and increase the precision degree. It also aimed to grantee that all results will have the same subject of the user query. The enhancements include performing an automatic classification to the case-base before the clustering step in the indexing stage, and include performing an automatic classification to the user query before the retrieval stage. Moreover, proofing that SOPHIA approach is a domain and language independent by applying it in the domain of Islamic jurisprudence in Arabic language.
ER  - 

TY  - JOUR
T1  - Selection criteria for text mining approaches
JO  - Computers in Human Behavior
VL  - 51, Part B
IS  - 
SP  - 729
EP  - 733
PY  - 2015/10//
T2  - Computing for Human Learning, Behaviour and Collaboration in the Social and Mobile Networks Era
AU  - Hashimi, Hussein
AU  - Hafez, Alaaeldin
AU  - Mathkour, Hassan
SN  - 0747-5632
DO  - http://dx.doi.org/10.1016/j.chb.2014.10.062
UR  - http://www.sciencedirect.com/science/article/pii/S0747563214007201
KW  - Text mining approaches
KW  - Classification
KW  - Clustering
KW  - Selection criteria
AB  - Abstract
Text mining techniques include categorization of text, summarization, topic detection, concept extraction, search and retrieval, document clustering, etc. Each of these techniques can be used in finding some non-trivial information from a collection of documents. Text mining can also be employed to detect a document’s main topic/theme which is useful in creating taxonomy from the document collection. Areas of applications for text mining include publishing, media, telecommunications, marketing, research, healthcare, medicine, etc. Text mining has also been applied on many applications on the World Wide Web for developing recommendation systems. We propose here a set of criteria to evaluate the effectiveness of text mining techniques in an attempt to facilitate the selection of appropriate technique.
ER  - 

TY  - JOUR
T1  - Knowledge management mapping and gap analysis in renewable energy: Towards a sustainable framework in developing countries
JO  - Renewable and Sustainable Energy Reviews
VL  - 20
IS  - 
SP  - 576
EP  - 584
PY  - 2013/4//
T2  - 
AU  - El Fadel, M.
AU  - Rachid, G.
AU  - El-Samra, R.
AU  - Bou Boutros, G.
AU  - Hashisho, J.
SN  - 1364-0321
DO  - http://dx.doi.org/10.1016/j.rser.2012.11.071
UR  - http://www.sciencedirect.com/science/article/pii/S1364032112006855
KW  - Renewable energy knowledge
KW  - Barriers
KW  - Gaps
KW  - SWOT analysis
AB  - This paper presents a mapping of knowledge management in renewable energy (RE) promoted through international and regional organizations with emphasis on gap analysis for the purpose of increasing RE deployment in developing countries. The knowledge mapping showed that most efforts are focused on RE information sharing and awareness raising, followed by policy assistance and technology transfer. Priorities seem vague with minimal close implementation, coordination, and evaluation whereby technology transfer and capacity building efforts do not always cater to the needs of benefiting countries with a lack of specialized RE financial mechanisms that provide incentives for countries to invest in RE. Equally significant, limited efforts are discerned about joint research initiatives with a slow progress towards standardization and certification of RE technologies. A general framework is proposed with a definition of short, medium and long-term undertakings towards increased RE penetration in developing countries. The profile of well-positioned organizations to adopt such a framework is identified on the basis of a SWOT analysis.
ER  - 

TY  - JOUR
T1  - A New Visualization-oriented Knowledge Service Platform
JO  - Procedia Engineering
VL  - 15
IS  - 
SP  - 1859
EP  - 1863
PY  - 2011///
T2  - CEIS 2011
AU  - Li, Guangzheng
AU  - Song, Xingang
SN  - 1877-7058
DO  - http://dx.doi.org/10.1016/j.proeng.2011.08.346
UR  - http://www.sciencedirect.com/science/article/pii/S1877705811018479
KW  - knowledge service
KW  - knowledge visualization
KW  - visual navigation
AB  - With the rapid growth of knowledge resources and increasing individual demands of users, the problem of how to spend less effort finding knowledge they need has been becoming more and more important. The visualization-oriented knowledge service platform is presented, which includes knowledge acquisition, knowledge categories, knowledge processing, knowledge storage and knowledge visualization. The platform aims to further transfer insights, experiences, attitudes, values, expectations, perspectives, opinions, and predictions by using various complementary visualizations. That is, by using knowledge mapping techniques a large and complex set of knowledge resources can be assimilated and navigated more easily. A prototype system of visual knowledge service has been implemented and applied to the massive knowledge organization, management and service for education.
ER  - 

TY  - JOUR
T1  - GPU enhanced parallel computing for large scale data clustering
JO  - Future Generation Computer Systems
VL  - 29
IS  - 7
SP  - 1736
EP  - 1741
PY  - 2013/9//
T2  - Including Special sections: Cyber-enabled Distributed Computing for Ubiquitous Cloud and Network Services &amp; Cloud Computing and Scientific Applications — Big Data, Scalable Analytics, and Beyond
AU  - Cui, Xiaohui
AU  - Charles, Jesse St.
AU  - Potok, Thomas
SN  - 0167-739X
DO  - http://dx.doi.org/10.1016/j.future.2012.07.009
UR  - http://www.sciencedirect.com/science/article/pii/S0167739X12001707
KW  - GPU
KW  - Swarm intelligence
KW  - Data clustering
KW  - CUDA
AB  - Analyzing and clustering large scale data set is a complex problem. One explored method of solving this problem borrows from nature, imitating the flocking behavior of birds. One limitation of this method of data clustering is its complexity O ( n 2 ) . As the number of data and feature dimensions grows, it becomes increasingly difficult to generate results in a reasonable amount of time. In the last few years, the graphics processing unit (GPU) has received attention for its ability to solve highly-parallel and semi-parallel problems much faster than the traditional sequential processor. In this paper, we have conducted research to exploit this architecture and apply its strengths to the flocking based high dimension data clustering problem. Using the CUDA platform from NVIDIA, we developed a Multiple Species Data Flocking implementation to be run on the NVIDIA GPU. Performance gains ranged from 30 to 60 times improvement of the GPU over the 3GHz CPU implementation.
ER  - 

TY  - JOUR
T1  - A subspace co-training framework for multi-view clustering
JO  - Pattern Recognition Letters
VL  - 41
IS  - 
SP  - 73
EP  - 82
PY  - 2014/5/1/
T2  - Supervised and Unsupervised Classification Techniques and their Applications
AU  - Zhao, Xuran
AU  - Evans, Nicholas
AU  - Dugelay, Jean-Luc
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2013.12.003
UR  - http://www.sciencedirect.com/science/article/pii/S0167865513004686
KW  - Multi-view clustering
KW  - Subspace clustering
KW  - Co-training
AB  - Abstract
This paper addresses the problem of unsupervised clustering with multi-view data of high dimensionality. We propose a new algorithm which learns discriminative subspaces in an unsupervised fashion based upon the assumption that a reliable clustering should assign same-class samples to the same cluster in each view. The framework combines the simplicity of k-means clustering and Linear Discriminant Analysis (LDA) within a co-training scheme which exploits labels learned automatically in one view to learn discriminative subspaces in another. The effectiveness of the proposed algorithm is demonstrated empirically under scenarios where the conditional independence assumption is either fully satisfied (audio-visual speaker clustering) or only partially satisfied (handwritten digit clustering and document clustering). Significant improvements over alternative multi-view clustering approaches are reported in both cases. The new algorithm is flexible and can be readily adapted to use different distance measures, semi-supervised learning, and non-linear problems.
ER  - 

TY  - JOUR
T1  - Caracterización de la base intelectual de la fisioterapia a través del análisis de cocitación de documentos
JO  - Fisioterapia
VL  - 36
IS  - 4
SP  - 167
EP  - 176
PY  - 2014/7//
Y2  - 2014/9//
T2  - 
AU  - Martínez-Fuentes, J.
AU  - Ríos-Díaz, J.
AU  - Meroño-Gallut, A.J.
AU  - Martínez-Payá, J.J.
AU  - del-Baño-Aledo, M.E.
SN  - 0211-5638
DO  - http://dx.doi.org/10.1016/j.ft.2013.10.001
UR  - http://www.sciencedirect.com/science/article/pii/S0211563813001417
KW  - Bibliometría
KW  - Cienciometría
KW  - Método de visualización de dominios de conocimiento
KW  - Modalidades de fisioterapia
KW  - Especialidad en fisioterapia
KW  - Bibliometrics
KW  - Scientometrics
KW  - Knowledge domain visualization method
KW  - Physiotherapy modalities
KW  - Physiotherapy specialty
AB  - ResumenAntecedentes
Los análisis de cocitación permiten la visualización de miles de documentos citantes y de referencias citadas, que pueden representar la base intelectual de una disciplina. El objetivo del estudio fue identificar la base intelectual de la fisioterapia.
Material y método
Análisis de cocitación de documentos en 3 revistas internacionales (Physical Therapy, Physiotherapy, Australian Journal of Physiotherapy) de impacto en el área de fisioterapia entre los años 2000-2011. Se recuperaron 2.795 artículos con 77.894 citaciones desde SCIex con Citespace II-v.2.2.R9 en subperíodos de un año.
Resultados
Se localizaron un total de 237 documentos citados con una media ± desviación estándar de citas recibidas de 16,1 ± 13,72 citas). El año de publicación medio se situó en 1997 ± 8,1 años. El 42,8% (89) de los documentos citados pertenecían a revistas de fisioterapia con 73 (82%) documentos citados de Physical Therapy, seguida de 7 (7,9%) documentos citados de Australian Journal of Physiotherapy. El modelo de grafo detectado se ajusta a un modelo de potencia donde existe una gran masa de documentos con pocas citaciones y una pequeña masa de documentos que acumulan la mayor parte de las citaciones. Estos documentos son de índole metodológica o de guía de práctica clínica.
Conclusión
La base intelectual de la fisioterapia muestra que es una disciplina joven que se apoya en otras áreas de conocimiento con un área de interés especialmente orientada hacia la «práctica basada en pruebas».
AbstractBackground
Co-citation analyses make it possible to visualize thousands of citing documents and cited references that may represent the intellectual basis of a discipline. This study has aimed to identify the intellectual basis of physiotherapy.
Material and method
Document co-citation analysis in three international impact journals (Physical Therapy, Physiotherapy, Australian Journal of Physiotherapy) in the area of physiotherapy between 2000-2011. 2583 Items recovered included 77894 citations from SCIex with Citespace II-v.2.2.R9 in sub-periods of one year.
Results
A total of 237 documents cited were located with an average of 16.1 citations received (S.D. 13.72 citations). Mean year of publication was 1997 (S.D.: 8.1 years). Of the documents cited, 42.8% (89) belonged to physiotherapy journals with 73% (82) cited documents from Physical Therapy and 7 (7.9%) from Australian Journal of Physiotherapy. The graph model detected adjusts to a power model in which there is a large number of documents with few citations and a small number of documents that accumulate the most citations. These documents can be classified as methodological or clinical practice guideline type.
Conclusion
The intellectual basis of physiotherapy analyzed through document co-citation shows that it is a young discipline that relies on other areas of knowledge with an area of interest oriented towards the evidence-based practice.
ER  - 

TY  - JOUR
T1  - Efficient incremental density-based algorithm for clustering large datasets
JO  - Alexandria Engineering Journal
VL  - 54
IS  - 4
SP  - 1147
EP  - 1154
PY  - 2015/12//
T2  - 
AU  - Bakr, Ahmad M.
AU  - Ghanem, Nagia M.
AU  - Ismail, Mohamed A.
SN  - 1110-0168
DO  - http://dx.doi.org/10.1016/j.aej.2015.08.009
UR  - http://www.sciencedirect.com/science/article/pii/S1110016815001489
KW  - Incremental clustering
KW  - Density-based clustering
KW  - Document clustering
KW  - Information retrieval
AB  - Abstract
In dynamic information environments such as the web, the amount of information is rapidly increasing. Thus, the need to organize such information in an efficient manner is more important than ever. With such dynamic nature, incremental clustering algorithms are always preferred compared to traditional static algorithms. In this paper, an enhanced version of the incremental DBSCAN algorithm is introduced for incrementally building and updating arbitrary shaped clusters in large datasets. The proposed algorithm enhances the incremental clustering process by limiting the search space to partitions rather than the whole dataset which results in significant improvements in the performance compared to relevant incremental clustering algorithms. Experimental results with datasets of different sizes and dimensions show that the proposed algorithm speeds up the incremental clustering process by factor up to 3.2 compared to existing incremental algorithms.
ER  - 

TY  - JOUR
T1  - Document clustering using synthetic cluster prototypes
JO  - Data & Knowledge Engineering
VL  - 70
IS  - 3
SP  - 284
EP  - 306
PY  - 2011/3//
T2  - 
AU  - Kalogeratos, Argyris
AU  - Likas, Aristidis
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2010.12.002
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X10001515
KW  - Clustering methods
KW  - Document clustering
KW  - Text mining
KW  - Term selection
KW  - Subspace clustering
AB  - The use of centroids as prototypes for clustering text documents with the k-means family of methods is not always the best choice for representing text clusters due to the high dimensionality, sparsity, and low quality of text data. Especially for the cases where we seek clusters with small number of objects, the use of centroids may lead to poor solutions near the bad initial conditions. To overcome this problem, we propose the idea of synthetic cluster prototype that is computed by first selecting a subset of cluster objects (instances), then computing the representative of these objects and finally selecting important features. In this spirit, we introduce the MedoidKNN synthetic prototype that favors the representation of the dominant class in a cluster. These synthetic cluster prototypes are incorporated into the generic spherical k-means procedure leading to a robust clustering method called k-synthetic prototypes (k-sp). Comparative experimental evaluation demonstrates the robustness of the approach especially for small datasets and clusters overlapping in many dimensions and its superior performance against traditional and subspace clustering methods.
ER  - 

TY  - JOUR
T1  - Subtractive clustering for seeding non-negative matrix factorizations
JO  - Information Sciences
VL  - 257
IS  - 
SP  - 369
EP  - 387
PY  - 2014/2/1/
T2  - 
AU  - Casalino, Gabriella
AU  - Del Buono, Nicoletta
AU  - Mencar, Corrado
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2013.05.038
UR  - http://www.sciencedirect.com/science/article/pii/S0020025513004349
KW  - Non-negative matrix factorization
KW  - Subtractive clustering
KW  - Initialization method
AB  - Abstract
Non-negative matrix factorization is a multivariate analysis method which is proven to be useful in many areas such as bio-informatics, molecular pattern discovery, pattern recognition, document clustering and so on. It seeks a reduced representation of a multivariate data matrix into the product of basis and encoding matrices possessing only non-negative elements, in order to learn the so called part-based representations of data. All algorithms for computing non-negative matrix factorization are iterative, therefore particular emphasis must be placed on a proper initialization of NMF because of its local convergence. The problem of selecting appropriate starting matrices becomes more complex when data possess special meaning as in document clustering. In this paper, we propose the adoption of the subtractive clustering algorithm as a scheme to generate initial matrices for non-negative matrix factorization algorithms. Comparisons with other commonly adopted initializations of non-negative matrix factorization algorithms have been performed and the proposed scheme reveals to be a good trade-off between effectiveness and speed. Moreover, the effectiveness of the proposed initialization to suggest a number of basis for NMF, when data distances are estimated, is illustrated when NMF is used for solving clustering problems where the number of groups in which the data are grouped is not known a priori. The influence of a proper rank factor on the interpretability and the effectiveness of the results are also discussed.
ER  - 

TY  - JOUR
T1  - Fuzzy control GA with a novel hybrid semantic similarity strategy for text clustering
JO  - Information Sciences
VL  - 273
IS  - 
SP  - 156
EP  - 170
PY  - 2014/7/20/
T2  - 
AU  - Song, Wei
AU  - Liang, Jiu Zhen
AU  - Park, Soon Cheol
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2014.03.024
UR  - http://www.sciencedirect.com/science/article/pii/S0020025514003089
KW  - Clustering
KW  - WordNet
KW  - Hybrid semantic similarity
KW  - Fuzzy control
KW  - Evolutionary computation
KW  - Genetic algorithm
AB  - Abstract
This paper proposes a fuzzy control genetic algorithm (GA) in conjunction with a novel hybrid semantic similarity measure for document clustering. Since the common clustering algorithms use vector space model (VSM) to represent document, the conceptual relationships between related terms being ignored, we use semantic similarity measures to solve this problem. In general, the semantic similarity measures can be extensively categorized into two kinds: thesaurus-based methods and corpus-based methods. However, in practice the corpus-based method is rather complicated to tackle. We propose and demonstrate a semantic space model (SSM) as the corpus-based method, where the appropriately reduced dimensions in SSM can capture the true relationship between documents in terms of concepts, rather than specific terms. Thus, the thesaurus-based method is combined with our SSM as a hybrid strategy to represent the semantic similarity measure. In GA field, the balance between the capability to converge to an optimum and the capacity to explore new solutions affects the success of search for the global optimum. We utilize a fuzzy control GA to adaptively adjust the influence between these two factors. Two textual data sets from Reuter document collection and 20-newsgroup corpus are tested in our experiments, and the results show that our fuzzy control GA combined with the hybrid semantic similarity strategy apparently outperforms the conventional GA, FCM and K-means with the traditional cosine similarity in VSM. Moreover, the superiorities of the fuzzy control GA and our hybrid semantic strategy are demonstrated by their better performance, in comparison with conventional GA with the same similarity measures.
ER  - 

TY  - JOUR
T1  - A clustering technique for news articles using WordNet
JO  - Knowledge-Based Systems
VL  - 36
IS  - 
SP  - 115
EP  - 128
PY  - 2012/12//
T2  - 
AU  - Bouras, Christos
AU  - Tsogkas, Vassilis
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2012.06.015
UR  - http://www.sciencedirect.com/science/article/pii/S0950705112001864
KW  - News clustering
KW  - k-Means
KW  - W-k means
KW  - Cluster labeling
KW  - Partitional clustering
AB  - The Web is overcrowded with news articles, an overwhelming information source both with its amount and diversity. Document clustering is a powerful technique that has been widely used for organizing data into smaller and manageable information kernels. Several approaches have been proposed which, however, suffer from problems like synonymy, ambiguity and lack of a descriptive content marking of the generated clusters. In this work, we are investigating the application of a great spectrum of clustering algorithms, as well as similarity measures, to news articles that originate from the Web. Also, we are proposing the enhancement of standard k-means algorithm using the external knowledge from WordNet hypernyms in a twofold manner: enriching the “bag of words” used prior to the clustering process and assisting the label generation procedure following it. Furthermore, we are examining the effect that text preprocessing has on clustering. Operating on a corpus of news articles derived from major news portals, our comparison of the existing clustering methodologies revealed that k-means, gives better aggregate results when it comes to efficiency. This is amplified when the algorithm is accompanied with preliminary steps for data cleaning and normalizing, despite its simple nature. Moreover, the proposed WordNet-enabled W-k means clustering algorithm significantly improves standard k-means generating also useful and high quality cluster tags by using the presented cluster labeling process.
ER  - 

TY  - JOUR
T1  - Reducing explicit semantic representation vectors using Latent Dirichlet Allocation
JO  - Knowledge-Based Systems
VL  - 100
IS  - 
SP  - 145
EP  - 159
PY  - 2016/5/15/
T2  - 
AU  - Saif, Abdulgabbar
AU  - Ab Aziz, Mohd Juzaiddin
AU  - Omar, Nazlia
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2016.03.002
UR  - http://www.sciencedirect.com/science/article/pii/S0950705116001155
KW  - Semantic representation
KW  - Explicit Semantic Analysis
KW  - Topic modeling
KW  - Knowledge-based method
AB  - Abstract
Explicit Semantic Analysis (ESA) is a knowledge-based method which builds the semantic representation of the words depending on the textual description of the concepts in the certain knowledge source. Due to its simplicity and success, ESA has received wide attention from researchers in the computational linguistics and information retrieval. However, the representation vectors formed by ESA method are generally very excessive, high dimensional, and may contain many redundant concepts. In this paper, we introduce a reduced semantic representation method that constructs the semantic interpretation of the words as the vectors over the latent topics from the original ESA representation vectors. For modeling the latent topics, the Latent Dirichlet Allocation (LDA) is adapted to the ESA vectors for extracting the topics as the probability distributions over the concepts rather than the words in the traditional model. The proposed method is applied to the wide knowledge sources used in the computational semantic analysis: WordNet and Wikipedia. For evaluation, we use the proposed method in two natural language processing tasks: measuring the semantic relatedness between words/texts and text clustering. The experimental results indicate that the proposed method overcomes the limitations of the representation of the ESA method.
ER  - 

TY  - JOUR
T1  - Applying text and data mining techniques to forecasting the trend of petitions filed to e-People
JO  - Expert Systems with Applications
VL  - 37
IS  - 10
SP  - 7255
EP  - 7268
PY  - 2010/10//
T2  - 
AU  - Suh, Jong Hwan
AU  - Park, Chung Hoon
AU  - Jeon, Si Hyun
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2010.04.002
UR  - http://www.sciencedirect.com/science/article/pii/S0957417410002733
KW  - Text mining
KW  - Data mining
KW  - Petition
KW  - Keyword extracting
KW  - Document clustering
KW  - Forecasting
KW  - e-Government
KW  - Open Innovation
KW  - e-People
AB  - As the Internet has been the virtual place where citizens are united and their opinions are promptly shifted into the action, two way communications between the government sector and the citizen have been more important among activities of e-Government. Hence, Anti-corruption and Civil Rights Commission (ACRC) in the Republic of Korea has constructed the online petition portal system named e-People. In addition, the nation’s Open Innovation through e-People has gained increasing attention. That is because e-People can be applied for the virtual space where citizens participate in improving the national law and policy by simply filing petitions to e-People as the voice of the nation. However, currently there are problems and challenging issues to be solved until e-People can function as the virtual space for the nation’s Open Innovation based on petitions collected from citizens. First, there is no objective and systematic method for analyzing a large number of petitions filed to e-People without a lot of manual works of petition inspectors. Second, e-People is required to forecast the trend of petitions filed to e-People more accurately and quickly than petition inspectors for making a better decision on the national law and policy strategy. Therefore, in this paper, we propose the framework of applying text and data mining techniques not only to analyze a large number of petitions filed to e-People but also to predict the trend of petitions. In detail, we apply text mining techniques to unstructured data of petitions to elicit keywords from petitions and identify groups of petitions with the elicited keywords. Moreover, we apply data mining techniques to structured data of the identified petition groups on purpose to forecast the trend of petitions. Our approach based on applying text and data mining techniques decreases time-consuming manual works on reading and classifying a large number of petitions, and contributes to increasing accuracy in evaluating the trend of petitions. Eventually, it helps petition inspectors to give more attention on detecting and tracking important groups of petitions that possibly grow as nationwide problems. Further, the petitions ordered by their petition groups’ trend values can be used as the baseline for making a better decision on the national law and policy strategy.
ER  - 

TY  - JOUR
T1  - Didactic Ideational Knowledge that Student Teachers Learn in a Single Supervisory Conference
JO  - Procedia - Social and Behavioral Sciences
VL  - 46
IS  - 
SP  - 1257
EP  - 1262
PY  - 2012///
T2  - 4th WORLD CONFERENCE ON EDUCATIONAL SCIENCES (WCES-2012) 02-05 February 2012 Barcelona, Spain
AU  - Shor, Loret M.
AU  - Hoz, Ron
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2012.05.285
UR  - http://www.sciencedirect.com/science/article/pii/S1877042812014140
KW  - Pre-service education
KW  - supervision
KW  - ideational knowledge mapping
KW  - learning
AB  - Preservice teachers are supposed to learn didactical ideational knowledge in their supervisory conferences. This study identified sources of such ideas and assessed the learning of 8 dimensions of knowledge. We found that the sources of substantial portions of the learned new ideas were not the supervisory conference, and most students’ didactical ideational knowledge expanded as well as the self creation of substantial aspects of these ideas, namely, complexity, abstractness, and generality. Implications for supervisory conferences were drawn from these findings.
ER  - 

TY  - JOUR
T1  - Software Engineering Competence Evaluation Portal
JO  - Procedia Computer Science
VL  - 43
IS  - 
SP  - 11
EP  - 17
PY  - 2015///
T2  - ICTE in Regional Development, December 2014, Valmiera, Latvia
AU  - Misnevs, Boriss
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2014.12.003
UR  - http://www.sciencedirect.com/science/article/pii/S1877050914015713
KW  - Competance evaluation
KW  - Web portal
KW  - Knowledge mapping
KW  - Testing
KW  - SWEBOK
AB  - Abstract
This paper presents the results of the initial research phase of Software Engineering Competence Evaluation Portal design and implementation. The web portal will be dedicated to joint master program training content and supervision synchronization between several Baltic universities. The functionality of the portal will provide a common support service for learning outcomes information exchange, referring to a graduate's knowledge, skills and competence upon completion of the Master of Science in Software Engineering (Information Technology) Programs.
ER  - 

TY  - JOUR
T1  - A novel approach for initializing the spherical K-means clustering algorithm
JO  - Simulation Modelling Practice and Theory
VL  - 54
IS  - 
SP  - 49
EP  - 63
PY  - 2015/5//
T2  - 
AU  - Duwairi, Rehab
AU  - Abu-Rahmeh, Mohammed
SN  - 1569-190X
DO  - http://dx.doi.org/10.1016/j.simpat.2015.03.007
UR  - http://www.sciencedirect.com/science/article/pii/S1569190X15000489
KW  - Spherical K-means clustering
KW  - K-means initialization
KW  - Intra-cluster similarity
KW  - Cluster compactness
AB  - Abstract
In this paper, a novel approach for initializing the spherical K-means algorithm is proposed. It is based on calculating well distributed seeds across the input space. Also, a new measure for calculating vectors’ directional variance is formulated, to be used as a measure of clusters’ compactness. The proposed initialization scheme is compared with the classical K-means – where initial seeds are specified randomly or arbitrarily – on two datasets. The assessment was based on three measures: an objective function that measures intra cluster similarity, cluster compactness and time to converge. The proposed algorithm (called initialized K-means) outperforms the classical (random) K-means when intra cluster similarity and cluster compactness were considered for several values of k (number of clusters). As far as convergence time is concerned, the initialized K-means converges faster than the random K-means for small number of clusters. For a large number of clusters the time necessary to calculate the initial clusters’ seeds start to outweigh the convergence criterion in time. The exact number of clusters at which the proposed algorithm starts to change behavior is data dependent (=11 for dataset1 and = 15 for dataset2).
ER  - 

TY  - JOUR
T1  - Enhanced clustering of biomedical documents using ensemble non-negative matrix factorization
JO  - Information Sciences
VL  - 181
IS  - 11
SP  - 2293
EP  - 2302
PY  - 2011/6/1/
T2  - 
AU  - Huang, Xiaodi
AU  - Zheng, Xiaodong
AU  - Yuan, Wei
AU  - Wang, Fei
AU  - Zhu, Shanfeng
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2011.01.029
UR  - http://www.sciencedirect.com/science/article/pii/S002002551100048X
KW  - Biomedical document clustering
KW  - Non-negative matrix factorization
KW  - Ensemble clustering
AB  - Searching and mining biomedical literature databases are common ways of generating scientific hypotheses by biomedical researchers. Clustering can assist researchers to form hypotheses by seeking valuable information from grouped documents effectively. Although a large number of clustering algorithms are available, this paper attempts to answer the question as to which algorithm is best suited to accurately cluster biomedical documents. Non-negative matrix factorization (NMF) has been widely applied to clustering general text documents. However, the clustering results are sensitive to the initial values of the parameters of NMF. In order to overcome this drawback, we present the ensemble NMF for clustering biomedical documents in this paper. The performance of ensemble NMF was evaluated on numerous datasets generated from the TREC Genomics track dataset. With respect to most datasets, the experimental results have demonstrated that the ensemble NMF significantly outperforms classical clustering algorithms of bisecting K-means, and hierarchical clustering. We compared four different methods for constructing an ensemble NMF. For clustering biomedical documents, this research is the first to compare ensemble NMF with typical classical clustering algorithms, and validates ensemble NMF constructed from different graph-based ensemble algorithms. This is also the first work on ensemble NMF with Hybrid Bipartite Graph Formulation for clustering biomedical documents.
ER  - 

TY  - JOUR
T1  - 25 years at Knowledge-Based Systems: A bibliometric analysis
JO  - Knowledge-Based Systems
VL  - 80
IS  - 
SP  - 3
EP  - 13
PY  - 2015/5//
T2  - 25th anniversary of Knowledge-Based Systems
AU  - Cobo, M.J.
AU  - Martínez, M.A.
AU  - Gutiérrez-Salcedo, M.
AU  - Fujita, H.
AU  - Herrera-Viedma, E.
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2014.12.035
UR  - http://www.sciencedirect.com/science/article/pii/S0950705115000076
KW  - Bibliometrics
KW  - Science mapping
KW  - Citations
KW  - Co-word analysis
KW  - h-index
AB  - Abstract
In commemoration of the Anniversary 25th of KnoSys we present a bibliometric analysis of the scientific content of the journal during the period 1991–2014. This analysis shows the conceptual evolution of the journal and some of its performance bibliometric indicators based on citations, as the evolution of its impact factor, its h-index, and its most cited authors/documents.
ER  - 

TY  - JOUR
T1  - A bibliometric analysis of 20 years of research on software product lines
JO  - Information and Software Technology
VL  - 72
IS  - 
SP  - 1
EP  - 15
PY  - 2016/4//
T2  - 
AU  - Heradio, Ruben
AU  - Perez-Morago, Hector
AU  - Fernandez-Amoros, David
AU  - Javier Cabrerizo, Francisco
AU  - Herrera-Viedma, Enrique
SN  - 0950-5849
DO  - http://dx.doi.org/10.1016/j.infsof.2015.11.004
UR  - http://www.sciencedirect.com/science/article/pii/S0950584915001883
KW  - Software product lines
KW  - Bibliometrics
KW  - Science mapping
KW  - Performance analysis
AB  - Abstract
Context: Software product line engineering has proven to be an efficient paradigm to developing families of similar software systems at lower costs, in shorter time, and with higher quality.

Objective: This paper analyzes the literature on product lines from 1995 to 2014, identifying the most influential publications, the most researched topics, and how the interest in those topics has evolved along the way.

Method: Bibliographic data have been gathered from ISI Web of Science and Scopus. The data have been examined using two prominent bibliometric approaches: science mapping and performance analysis.

Results: According to the study carried out, (i) software architecture was the initial motor of research in SPL; (ii) work on systematic software reuse has been essential for the development of the area; and (iii) feature modeling has been the most important topic for the last fifteen years, having the best evolution behavior in terms of number of published papers and received citations.

Conclusion: Science mapping has been used to identify the main researched topics, the evolution of the interest in those topics and the relationships among topics. Performance analysis has been used to recognize the most influential papers, the journals and conferences that have published most papers, how numerous is the literature on product lines and what is its distribution over time.
ER  - 

TY  - JOUR
T1  - Knowledge maps: A systematic literature review and directions for future research
JO  - International Journal of Information Management
VL  - 36
IS  - 3
SP  - 451
EP  - 475
PY  - 2016/6//
T2  - 
AU  - Balaid, Ali
AU  - Abd Rozan, Mohd Zaidi
AU  - Hikmi, Syed Norris
AU  - Memon, Jamshed
SN  - 0268-4012
DO  - http://dx.doi.org/10.1016/j.ijinfomgt.2016.02.005
UR  - http://www.sciencedirect.com/science/article/pii/S0268401216000098
KW  - Knowledge maps
KW  - Knowledge management
KW  - Systematic literature review
AB  - AbstractContext
Nowadays the concept of knowledge mapping has attracted increased attention from scientists in a variety of academic disciplines and professional practice areas. Among the most important attributes of a knowledge map is its ability to increase communication and share common practices across an entire organisation. However, despite being a promising area for research, the knowledge maps community lacks a widespread understanding of the current state of the art.
Objective
The objective of this article is to explore the world of knowledge mapping by reviewing and analysing the current state of research and providing an overview of knowledge mapping’s concepts, benefits, techniques, classifications and methodologies, which are precisely reviewed, and their features are highlighted. In addition, we offer directions for future research.
Method
Based on the systematic literature review method this study collects, synthesises, and analyses numerous articles on a variety of topics closely related to a knowledge map published from January 2000 to December 2013 on six electronic databases by following a pre-defined review protocol. The articles have been retrieved through a combination of automatic and manual search, hence extensive quantitative and qualitative results of the research are provided.
Results
From the review study, we identified 132 articles addressing knowledge maps that have been reviewed in order to extract relevant information on a set of research questions. We found a generally increasing level of activity during this 5-year period. We noted that while existing research covers a large number of studies on some disciplines, such as systems and tools development, it contains very few studies on other disciplines, such as knowledge maps adoption. To aid this situation, we offer directions for future research.
Conclusions
The results demonstrated that a knowledge map is an imperative strategy for increasing organisations’ effectiveness. In addition, there is a need for more knowledge maps research.
ER  - 

TY  - JOUR
T1  - Text segmentation in degraded historical document images
JO  - Egyptian Informatics Journal
VL  - 17
IS  - 2
SP  - 189
EP  - 197
PY  - 2016/7//
T2  - 
AU  - Kavitha, A.S.
AU  - Shivakumara, P.
AU  - Kumar, G.H.
AU  - Lu, Tong
SN  - 1110-8665
DO  - http://dx.doi.org/10.1016/j.eij.2015.11.003
UR  - http://www.sciencedirect.com/science/article/pii/S111086651500064X
KW  - Text enhancement
KW  - Sobel and Laplacian operations
KW  - Indus document
KW  - Clustering
KW  - Text line segmentation
AB  - Abstract
Text segmentation from degraded Historical Indus script images helps Optical Character Recognizer (OCR) to achieve good recognition rates for Hindus scripts; however, it is challenging due to complex background in such images. In this paper, we present a new method for segmenting text and non-text in Indus documents based on the fact that text components are less cursive compared to non-text ones. To achieve this, we propose a new combination of Sobel and Laplacian for enhancing degraded low contrast pixels. Then the proposed method generates skeletons for text components in enhanced images to reduce computational burdens, which in turn helps in studying component structures efficiently. We propose to study the cursiveness of components based on branch information to remove false text components. The proposed method introduces the nearest neighbor criterion for grouping components in the same line, which results in clusters. Furthermore, the proposed method classifies these clusters into text and non-text cluster based on characteristics of text components. We evaluate the proposed method on a large dataset containing varieties of images. The results are compared with the existing methods to show that the proposed method is effective in terms of recall and precision.
ER  - 

TY  - JOUR
T1  - Enhancing sentence-level clustering with ranking-based clustering framework for theme-based summarization
JO  - Information Sciences
VL  - 260
IS  - 
SP  - 37
EP  - 50
PY  - 2014/3/1/
T2  - 
AU  - Yang, Libin
AU  - Cai, Xiaoyan
AU  - Zhang, Yang
AU  - Shi, Peng
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2013.11.026
UR  - http://www.sciencedirect.com/science/article/pii/S0020025513008347
KW  - Ranking-based clustering
KW  - Sentence clustering
KW  - Theme-based summarization
AB  - Abstract
Sentence clustering plays a pivotal role in theme-based summarization, which discovers topic themes defined as the clusters of highly related sentences in order to avoid redundancy and cover more diverse information. As the length of sentences is short and the content it contains is limited, the bag-of-words cosine similarity traditionally used for document clustering is no longer reasonably suitable. Special treatment for measuring sentence similarity is necessary. In this paper, we propose a ranking-based clustering framework that utilizes ranking distribution of documents and terms to help generate high quality sentence clusters. The effectiveness of the proposed framework is demonstrated by both the cluster quality analysis and the summarization evaluation conducted on the DUC 2004 and DUC2007 datasets.
ER  - 

TY  - JOUR
T1  - Paraphrase Extraction using fuzzy hierarchical clustering
JO  - Applied Soft Computing
VL  - 34
IS  - 
SP  - 426
EP  - 437
PY  - 2015/9//
T2  - 
AU  - Chitra, A.
AU  - Rajkumar, Anupriya
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2015.05.017
UR  - http://www.sciencedirect.com/science/article/pii/S1568494615003178
KW  - Fuzzy Agglomerative Clustering
KW  - Divisive clustering
KW  - Paraphrase Recognition
AB  - Abstract
Paraphrase Extraction involves the discovery of equivalent text segments from large corpora and finds application in tasks such as multi-document summarization and document clustering. Semantic similarity identification is a challenging problem which is further compounded by the large size of the corpus. In this paper a two-stage approach which involves clustering followed by Paraphrase Recognition has been proposed for extraction of sentence-level paraphrases from text collections. In order to handle the ambiguity and inherent variability of natural language a fuzzy hierarchical clustering approach which combines agglomeration based on verbs and division on nouns has been used. Sentences within each resultant cluster are then processed by a machine-learning based Paraphrase Recognizer to discover the paraphrases. The two-stage approach has been applied on the Microsoft Research Paraphrase Corpus and a subset of the Microsoft Research Video Description Corpus. The performance has been evaluated against an existing k-means clustering approach as well as cosine-similarity technique and Fuzzy C-Means clustering and the two-stage system has consistently demonstrated better performance.
ER  - 

TY  - JOUR
T1  - Arabic web pages clustering and annotation using semantic class features
JO  - Journal of King Saud University - Computer and Information Sciences
VL  - 26
IS  - 4
SP  - 388
EP  - 397
PY  - 2014/12//
T2  - Special Issue on Arabic NLP
AU  - Alghamdi, Hanan M.
AU  - Selamat, Ali
AU  - Abdul Karim, Nor Shahriza
SN  - 1319-1578
DO  - http://dx.doi.org/10.1016/j.jksuci.2014.06.002
UR  - http://www.sciencedirect.com/science/article/pii/S1319157814000263
KW  - k-Means
KW  - Semantic similarity
KW  - Text clustering
KW  - Arabic webpage
AB  - Abstract
To effectively manage the great amount of data on Arabic web pages and to enable the classification of relevant information are very important research problems. Studies on sentiment text mining have been very limited in the Arabic language because they need to involve deep semantic processing. Therefore, in this paper, we aim to retrieve machine-understandable data with the help of a Web content mining technique to detect covert knowledge within these data. We propose an approach to achieve clustering with semantic similarities. This approach comprises integrating k-means document clustering with semantic feature extraction and document vectorization to group Arabic web pages according to semantic similarities and then show the semantic annotation. The document vectorization helps to transform text documents into a semantic class probability distribution or semantic class density. To reach semantic similarities, the approach extracts the semantic class features and integrates them into the similarity weighting schema. The quality of the clustering result has evaluated the use of the purity and the mean intra-cluster distance (MICD) evaluation measures. We have evaluated the proposed approach on a set of common Arabic news web pages. We have acquired favorable clustering results that are effective in minimizing the MICD, expanding the purity and lowering the runtime.
ER  - 

TY  - JOUR
T1  - The Relations Between Elementary Teacher's Didactic Knowledge and their Preservice Specialization, Seniority in Teaching, and School System
JO  - Procedia - Social and Behavioral Sciences
VL  - 46
IS  - 
SP  - 1051
EP  - 1055
PY  - 2012///
T2  - 4th WORLD CONFERENCE ON EDUCATIONAL SCIENCES (WCES-2012) 02-05 February 2012 Barcelona, Spain
AU  - Atawne, Ahmad
AU  - Hoz, Ron
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2012.05.247
UR  - http://www.sciencedirect.com/science/article/pii/S1877042812013766
KW  - Didactics
KW  - ideational knowledge mapping
KW  - language teaching
KW  - seniority
KW  - school system
AB  - The relations between the ideational didactical knowledge of Israeli elementary language teachers and 3 professional variables were examined and the findings were that their preservice preparation to teach first language to 1st and 2nd graders had no effect on their knowledge, their school system (Jewish or Arabic) was unrelated to their knowledge, and on most dimensions of the didactical ideational knowledge teachers with high seniority has higher values than those with low seniority. Implications for supervisory conferences were drawn from these findings
ER  - 

TY  - JOUR
T1  - Group Profiling Automation for Crime and Terrorism (GPACT)
JO  - Procedia Manufacturing
VL  - 3
IS  - 
SP  - 3933
EP  - 3940
PY  - 2015///
T2  - 6th International Conference on Applied Human Factors and Ergonomics (AHFE 2015) and the Affiliated Conferences, AHFE 2015
AU  - Lautenschlager, Jennifer
AU  - Ruvinsky, Alicia
AU  - Warfield, Ian
AU  - Kettler, Brian
SN  - 2351-9789
DO  - http://dx.doi.org/10.1016/j.promfg.2015.07.922
UR  - http://www.sciencedirect.com/science/article/pii/S2351978915009233
KW  - Group profiling
KW  - Natural Language Processing (NLP)
KW  - Data analytics
KW  - Event data
KW  - Event clustering
KW  - Event trending
KW  - Narrative generation
AB  - Abstract
The U.S. State Department Bureau of Counterterrorism officially lists 59 foreign terrorist organizations, while the current Terrorism Research &amp; Analysis Consortium (TRAC) database contains over 3,800 groups. The number of actual groups is constantly changing as new groups emerge and existing groups are redefined, thus motivating a need to automate the rapid generation of multi-faceted group profiles to provide on-demand support for analyst understanding. Robust, automated profiles can be generated for these groups by leveraging current Natural Language Processing (NLP) techniques and large-scale analytics over relevant text (e.g., news stories, social media). Information on key individuals, attack history, group interactions, and more can be extracted and assembled into a dynamic organizational profile. Lockheed Martin Advanced Technology Labs (LM ATL) has developed a prototype system for creating such profiles, based on the publicly released Integrated Crisis Early Warning System (ICEWS) Coded Event Data, a set of over 13 million automatically generated events extracted from public news stories. This set of data has proven valuable for situational awareness and event forecasting, and a more actor-centric view of the data can yield rich details about a group's history and modus operandi. Profile generation, then, is based on the following capabilities: (1) event clustering, (2) event trending, and (3) narrative generation. In this paper, we describe both the framework and analytical components of the Group Profiling Automation for Crime and Terrorism (GPACT) prototype that generates terrorist and criminal group profiles. After describing the overall framework we focus on three analytical capabilities. First, event clustering operates over the set of event data to identify clusters of related events relevant to a particular topic of interest (e.g., interactions with other groups, past attack history), similar to how topic and document clustering operates. The second, event trend analysis, performs analytics over event data focusing on clustered topics to provide awareness of aggregate patterns detectable in the data. Third, narrative generation uses a template-based approach to natural language generation to construct a textual overview of the organization. Our results are analyzed, and ideas for potential future research identified.
ER  - 

TY  - JOUR
T1  - Visualization analysis of ecological assets/values research by knowledge mapping
JO  - Acta Ecologica Sinica
VL  - 35
IS  - 5
SP  - 142
EP  - 154
PY  - 2015/10//
T2  - 
AU  - Lin, Zhuo
AU  - Wu, Chengzhen
AU  - Hong, Wei
SN  - 1872-2032
DO  - http://dx.doi.org/10.1016/j.chnaes.2015.07.005
UR  - http://www.sciencedirect.com/science/article/pii/S187220321500044X
KW  - CiteSpace
KW  - Ecological assets
KW  - Ecological values
KW  - Knowledge mapping
KW  - Visualization
AB  - Abstract
Using knowledge mapping tools (CiteSpace), we conducted the visualization analysis on both of international and domestic literatures in relation to ecological assets/values from the Web of Science (WoS) databases and China National Knowledge Infrastructure (CNKI) databases. By combination of the statistical data and visualization mapping, we studied on the research relationship networks and status for the co-authors' institutions, co-authors, co-citation literatures and co-occurring keywords of ecological assets/values based on the sample data from literatures. In the aspects of research on ecological values, our results showed that: (i) main countries of researches on ecological values were the United States, Australia, Canada and China in order, especially the US had the most plenty of literatures in relation to ecological values, and at the same time, literatures from China in this field are in the upper level; (ii) the hotspots of researches on ecological values from the global literatures covered various fields including biodiversity, species richness, ecosystem services, landscape, climate change and dynamic simulation; (iii) as a result of the multidisciplinary integration, the hotspots of researches on ecological values emerge endlessly, so that many high yielding authors and relevant international institutions constantly expanded the research scopes and fields, which promoted the combination of theories and made the significant contribution to themselves; (iv) the mass domestic researches on ecological values began in 1992. The number of posting paper increased obviously and the scopes in relation to ecological value expanded gradually, particularly involved with ecology, economy, even legal and ideology, which illustrated that concepts of “ecological values” had not been only confined to the researches on the traditional science, but also been widely used in many fields of humanity and social science. In the aspect of research on ecological assets, our results showed that: (i) domestic researches on ecological assets had many points in common with ecological values research. In fact, driven from ecological values, researches on ecological assets became gradually characteristic, such as assessment of forest ecological asset, ecological industry and fair value measurement of ecological assets, all of which contained lots of considerable consequences; (ii) the Chinese Academy of Sciences was in the dominant position of domestic research on ecological assets. Other colleges and universities like Beijing Normal University and Nanjing Forestry University were also effective and productive in this field. Their achievements were already improving Chinese academic level; (iii) domestic research teams also changed from different discipline backgrounds to enrich the research scopes of ecological assets. Based on analysis of typical literatures from our results, in the similarity and difference of the concept of “ecological asset” between foreign and domestic literatures, we summarized key points that we should pay attention to: (i) ecological assets included natural resources and ecosystem services; (ii) ecological assets consisted of tangible and intangible parts; (iii) ecological assets were of profitability and public welfare at the same time. Finally, we elucidated that future trend of research on ecological assets would pay more attention to the internal mechanism of changes of ecological assets, determination of the bearing capacity of the ecological environment by such changes, and discovery of accumulation of ecological assets for a stable and sustainable development of the ecosystem, and for harmony between humans and environment.
ER  - 

TY  - JOUR
T1  - Exploratory analysis of textual data streams
JO  - Future Generation Computer Systems
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Castano, Silvana
AU  - Ferrara, Alfio
AU  - Montanelli, Stefano
SN  - 0167-739X
DO  - http://dx.doi.org/10.1016/j.future.2016.07.005
UR  - http://www.sciencedirect.com/science/article/pii/S0167739X16302357
KW  - Clustering
KW  - Textual data stream
KW  - Exploratory analysis
KW  - Topic evolution
KW  - Detection of emergent topics
AB  - Abstract
In this paper, we address exploratory analysis of textual data streams and we propose a bootstrapping process based on a combination of keyword similarity and clustering techniques to: i) classify documents into fine-grained similarity clusters, based on keyword commonalities; ii) aggregate similar clusters into larger document collections sharing a richer, more user-prominent keyword set that we call topic; iii) assimilate newly extracted topics of current bootstrapping cycle with existing topics resulting from previous bootstrapping cycles, by linking similar topics of different time periods, if any, to highlight topic trends and evolution. An analysis framework is also defined enabling the topic-based exploration of the underlying textual data stream according to a thematic perspective and a temporal perspective. The bootstrapping process is evaluated on a real data stream of about 330.000 newspaper articles about politics published by the New York Times from Jan 1st 1900 to Dec 31st 2015.
ER  - 

TY  - JOUR
T1  - Improving retrievability with improved cluster-based pseudo-relevance feedback selection
JO  - Expert Systems with Applications
VL  - 39
IS  - 8
SP  - 7495
EP  - 7502
PY  - 2012/6/15/
T2  - 
AU  - Bashir, Shariq
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2012.01.041
UR  - http://www.sciencedirect.com/science/article/pii/S0957417412000541
KW  - Retrievability in information retrieval
KW  - Recall-oriented retrieval
KW  - Query expansion
KW  - Cluster based pseudo relevance feedback selection
KW  - Prior-art search
AB  - High findability of documents within a certain cut-off rank is considered an important factor in recall-oriented application domains such as patent or legal document retrieval. Findability is hindered by two aspects, namely the inherent bias favoring some types of documents over others introduced by the retrieval model, and the failure to correctly capture and interpret the context of conventionally rather short queries. In this paper, we analyze the bias impact of different retrieval models and query expansion strategies. We furthermore propose a novel query expansion strategy based on document clustering to identify dominant relevant documents. This helps to overcome limitations of conventional query expansion strategies that suffer strongly from the noise introduced by imperfect initial query results for pseudo-relevance feedback documents selection. Experiments with different collections of patent documents suggest that clustering based document selection for pseudo-relevance feedback is an effective approach for increasing the findability of individual documents and decreasing the bias of a retrieval system.
ER  - 

TY  - JOUR
T1  - Constructing a dental implant ontology for domain specific clustering and life span analysis
JO  - Advanced Engineering Informatics
VL  - 27
IS  - 3
SP  - 346
EP  - 357
PY  - 2013/8//
T2  - 
AU  - Trappey, Charles V.
AU  - Wang, Tong-Mei
AU  - Hoang, Sean
AU  - Trappey, Amy J.C.
SN  - 1474-0346
DO  - http://dx.doi.org/10.1016/j.aei.2013.04.003
UR  - http://www.sciencedirect.com/science/article/pii/S1474034613000475
KW  - Clustering
KW  - Key phrase extraction
KW  - Dental implant ontology
KW  - Life span analysis
AB  - Abstract
Dental implant and prosthetics is a growing industry that follows the increasing aged populations that incur a higher percentage of tooth loss [1]. The dental implant sector is one of the most technical oriented fields in dentistry with many new techniques, devices, and materials being invented and put to clinical trials. Most innovations and technologies tend to be protected by intellectual property rights (IPRs) through patents. Thus, this research identifies the life spans of dental implant (DI) key technologies using patent analysis. Key patents and their frequently appearing phrases are analyzed for the construction of the DI ontology. Afterward, the life spans of DI technical clusters are defined based on the ontology schema. This research demonstrates the feasibility of using text mining and data mining techniques to extract key phrases from a set of DI patents with different patent classifications (e.g., UPC, IPC) as the basis for building a domain-specific ontology. The case study of ontological sub-clustering for dental implants demonstrates life span mapping of the technology and the ability to use clusters to represent stages of development and maturity in specific technology life cycles.
ER  - 

TY  - JOUR
T1  - The competency levels of school principals in implementing knowledge management strategies The views of principals and teachers according to gender variable
JO  - Procedia - Social and Behavioral Sciences
VL  - 2
IS  - 2
SP  - 5370
EP  - 5376
PY  - 2010///
T2  - Innovation and Creativity in Education
AU  - Ozmen, Fatma
AU  - Muratoglu, Vecihe
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2010.03.875
UR  - http://www.sciencedirect.com/science/article/pii/S1877042810009158
KW  - Knowledge management
KW  - principals
KW  - strategies
KW  - schools
AB  - The technological developments and changes which have been experienced in the last decades, have affected significantly the management of organizations. Especially the issue of knowledge management has begun to play a crucial role in ensuring the competitive advantages of the organizations. Therefore, schools, which are already knowledge based organizations, have to develop their knowledge management strategies in order to achieve effective education that meet the requirements of the age. In that context school principalship has received the utmost importance since it is seen as leading authority for accomplishing the educational aims.The main goal of this research is, based on the views of teachers and principals, to determine the competency level of the school principals in implementing some predetermined knowledge management strategies at schools with regard to gender variable. In this study, the views of the subjects have been gathered by a Likert type questionnaire developed by the researchers themselves. The questionnaire consisted of eight dimensions such as Active Knowledge Management, Formation of a Knowledge Team, Formation of a Knowledge Database, Knowledge Mapping, Benchmarking, Formation of a Knowledge Network, Formation of a Knowledge Centre, and Designation of an Executive Responsible for Implementations. The obtained results have revealed that schools generally have some insufficiencies in implementing knowledge management strategies.
ER  - 

TY  - JOUR
T1  - Chinese–Tibetan bilingual clustering based on random walk
JO  - Neurocomputing
VL  - 158
IS  - 
SP  - 32
EP  - 41
PY  - 2015/6/22/
T2  - 
AU  - Ye, Cheng-Xu
AU  - Wen, Wu-Shao
AU  - Wang, Chang-Dong
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2015.02.003
UR  - http://www.sciencedirect.com/science/article/pii/S0925231215001460
KW  - Multi-source clustering
KW  - Bilingual clustering
KW  - Chinese–Tibetan
KW  - Bilingual graph
KW  - Random walk
AB  - Abstract
In recent years, multi-source clustering has received a significant amount of attention. Several multi-source clustering methods have been developed from different perspectives. In this paper, aiming at addressing the problem of Chinese–Tibetan bilingual document clustering, a novel bilingual clustering scheme is proposed, which can well capture both the intralingua document structures and interlingua document relations. The proposed scheme consists of three major phases. Firstly, to properly combine the feature structures of documents in different languages, a bilingual graph is constructed. In the second phase, two bilingual similarity matrices are computed based on the random walk performed in the bilingual graph. Finally, the similarity based clustering methods are performed on the two bilingual similarity matrices so as to generate cluster structures for documents in each language respectively, which lead to the corresponding bilingual clustering methods. Extensive experiments conducted on two Chinese–Tibetan bilingual document sets have confirmed the effectiveness of the proposed methods.
ER  - 

TY  - JOUR
T1  - Adaptive Concept Resolution for document representation and its applications in text mining
JO  - Knowledge-Based Systems
VL  - 74
IS  - 
SP  - 1
EP  - 13
PY  - 2015/1//
T2  - 
AU  - Bing, Lidong
AU  - Jiang, Shan
AU  - Lam, Wai
AU  - Zhang, Yan
AU  - Jameel, Shoaib
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2014.10.003
UR  - http://www.sciencedirect.com/science/article/pii/S0950705114003700
KW  - Adaptive Concept Resolution
KW  - Ontology
KW  - WordNet
KW  - Wikipedia
KW  - WordNet-Plus
AB  - Abstract
It is well-known that synonymous and polysemous terms often bring in some noise when we calculate the similarity between documents. Existing ontology-based document representation methods are static so that the selected semantic concepts for representing a document have a fixed resolution. Therefore, they are not adaptable to the characteristics of document collection and the text mining problem in hand. We propose an Adaptive Concept Resolution (ACR) model to overcome this problem. ACR can learn a concept border from an ontology taking into the consideration of the characteristics of the particular document collection. Then, this border provides a tailor-made semantic concept representation for a document coming from the same domain. Another advantage of ACR is that it is applicable in both classification task where the groups are given in the training document set and clustering task where no group information is available. The experimental results show that ACR outperforms an existing static method in almost all cases. We also present a method to integrate Wikipedia entities into an expert-edited ontology, namely WordNet, to generate an enhanced ontology named WordNet-Plus, and its performance is also examined under the ACR model. Due to the high coverage, WordNet-Plus can outperform WordNet on data sets having more fresh documents in classification.
ER  - 

TY  - JOUR
T1  - Mining group-based knowledge flows for sharing task knowledge
JO  - Decision Support Systems
VL  - 50
IS  - 2
SP  - 370
EP  - 386
PY  - 2011/1//
T2  - 
AU  - Liu, Duen-Ren
AU  - Lai, Chin-Hui
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2010.09.004
UR  - http://www.sciencedirect.com/science/article/pii/S0167923610001739
KW  - Knowledge flow
KW  - Group-based knowledge flow
KW  - Knowledge graph
KW  - Knowledge sharing
KW  - Data mining
KW  - Topic
KW  - Task
AB  - In an organization, knowledge is the most important resource in the creation of core competitive advantages. It is circulated and accumulated by knowledge flows (KFs) in the organization to support workers' task needs. Because workers accumulate knowledge of different domains, they may cooperate and participate in several task-based groups to satisfy their needs. In this paper, we propose algorithms that integrate information retrieval and data mining techniques to mine and construct group-based KFs (GKFs) for task-based groups. A GKF is expressed as a directed knowledge graph which represents the knowledge referencing behavior, or knowledge flow, of a group of workers with similar task needs. Task-related knowledge topics and their relationships (flows) can be identified from the knowledge graph so as to fulfill workers' task needs and promote knowledge sharing for collaboration of group members. Moreover, the frequent knowledge referencing path can be identified from the knowledge graph to indicate the frequent knowledge flow of the workers. To demonstrate the efficacy of the proposed methods, we implement a prototype of the GKF mining system. Our GKF mining methods can enhance organizational learning and facilitate knowledge management, sharing, and reuse in an environment where collaboration and teamwork are essential.
ER  - 

TY  - JOUR
T1  - Applying an automatic approach for showing up the hidden themes in financial marketing research (1961–2010)
JO  - Expert Systems with Applications
VL  - 39
IS  - 12
SP  - 11055
EP  - 11065
PY  - 2012/9/15/
T2  - 
AU  - Muñoz-Leiva, Francisco
AU  - Sánchez-Fernández, Juan
AU  - Liébana-Cabanillas, Francisco J.
AU  - López-Herrera, Antonio Gabriel
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2012.03.017
UR  - http://www.sciencedirect.com/science/article/pii/S0957417412004873
KW  - Bibliometric study
KW  - Conceptual evolution
KW  - Emerging trends
KW  - Co-word analysis
KW  - Financial marketing research
KW  - Bank marketing
AB  - This paper analyses the academic research conducted in financial marketing from 1961 to 2010. To do so, an automatic approach for detecting and visualising the hidden themes is applied. This automatic approach, based on co-word analysis, combines performance analysis and science mapping. It permits visualising the division of the financial marketing research (FMR) into several subfields, and indicate the relationships between them. These outcomes are completed with a systematic review, where a content analysis is used to explore the type of methodologies and topics most frequently used.

The results allow us to identifying trends that will presumably be developed in FMR in coming years. In addition, these results also help both experts and novices to understand the current state of the art of FMR and to predict where future research could lead.
ER  - 

TY  - JOUR
T1  - Combining multiple clusterings using similarity graph
JO  - Pattern Recognition
VL  - 44
IS  - 3
SP  - 694
EP  - 703
PY  - 2011/3//
T2  - 
AU  - Mimaroglu, Selim
AU  - Erdil, Ertunc
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2010.09.008
UR  - http://www.sciencedirect.com/science/article/pii/S0031320310004486
KW  - Clustering
KW  - Combining clustering partitions
KW  - Cluster ensemble
KW  - Evidence accumulation
KW  - Robust clustering
KW  - Mutual information
AB  - Multiple clusterings are produced for various needs and reasons in both distributed and local environments. Combining multiple clusterings into a final clustering which has better overall quality has gained importance recently. It is also expected that the final clustering is novel, robust, and scalable. In order to solve this challenging problem we introduce a new graph-based method. Our method uses the evidence accumulated in the previously obtained clusterings, and produces a very good quality final clustering. The number of clusters in the final clustering is obtained automatically; this is another important advantage of our technique. Experimental test results on real and synthetically generated data sets demonstrate the effectiveness of our new method.
ER  - 

TY  - JOUR
T1  - Labeling clusters from both linguistic and statistical perspectives: A hybrid approach
JO  - Knowledge-Based Systems
VL  - 76
IS  - 
SP  - 219
EP  - 227
PY  - 2015/3//
T2  - 
AU  - Li, Zhixing
AU  - Li, Juanzi
AU  - Liao, Yi
AU  - Wen, Siqiang
AU  - Tang, Jie
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2014.12.019
UR  - http://www.sciencedirect.com/science/article/pii/S0950705114004572
KW  - Cluster labeling
KW  - Dependency parsing
KW  - Context sensitive scoring
KW  - Rule learning
KW  - Phrase extraction
AB  - Abstract
Document clustering refers to grouping similar documents together automatically. Labels of the clusters, usually edited manually, are helpful for users to quickly grasp the major meaning of the grouped documents. Therefore, high quality labels are desired in many user-facing applications. However, assigning the labels manually is time consuming and tedious. In this paper a hybrid approach is proposed to automate the labeling process. First, linguistic knowledge are used to ensure candidate labels’ readability and information quantity by exploring the dependencies between words. Second, a statistical generative model is proposed to select representative labels. It scores a label w.r.t. a cluster by estimating how likely the cluster is generated by the label. The proposed approach is evaluated on two data sets in both English and Chinese. Experimental results show that the proposed approach produces high quality labels and outperforms existing state-of-art methods on both manual and automatic evaluations.
ER  - 

TY  - JOUR
T1  - Building a term suggestion and ranking system based on a probabilistic analysis model and a semantic analysis graph
JO  - Decision Support Systems
VL  - 53
IS  - 1
SP  - 257
EP  - 266
PY  - 2012/4//
T2  - 
AU  - Chen, Lin-Chih
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2012.02.001
UR  - http://www.sciencedirect.com/science/article/pii/S0167923612000450
KW  - Probabilistic analysis model
KW  - Semantic analysis graph
KW  - Probability parameters
KW  - Expectation maximization algorithm
KW  - Euclidean distance
AB  - Term suggestion is a kind of information retrieval technique that attempts to suggest relevant terms to help users formulate more effective queries and reduce unnecessary search steps. In this paper, we apply two semantic analysis methods, the probabilistic analysis model and semantic analysis graph, to design a term suggestion system that can effectively deal with the problems of synonymy and polysemy.

The main contributions of this paper are the following. First, we apply two semantic analysis methods to design a high-performance term suggestion system. Second, we design an intelligent mechanism that can effectively balance cost and performance to minimize the number of iterations required for our system.
ER  - 

TY  - JOUR
T1  - A hybrid evolutionary computation approach with its application for optimizing text document clustering
JO  - Expert Systems with Applications
VL  - 42
IS  - 5
SP  - 2517
EP  - 2524
PY  - 2015/4/1/
T2  - 
AU  - Song, Wei
AU  - Qiao, Yingying
AU  - Park, Soon Cheol
AU  - Qian, Xuezhong
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2014.11.003
UR  - http://www.sciencedirect.com/science/article/pii/S0957417414006861
KW  - Knowledge discovery and management
KW  - Evolutionary computation
KW  - Particle swarm optimization
KW  - Quantum-behaved particle swarm optimization
AB  - Abstract
Quantum-behaved particle swarm optimization (QPSO) is a promising global optimization algorithm inspired by concepts of quantum mechanics and particle swarm optimization (PSO). Since the particles are initialized randomly in QPSO, the blindness of initializing particles affects its capacity for complicated optimization. In this paper, we make full use of a hybrid evolutionary computation approach to resolve such an issue. In specific, the robust global search ability of genetic algorithm (GA) improves the initial strategy of particles in QPSO. What is more, the original position update approach of QPSO without the restriction of its upper bound may generate some abrupt features and cause the issue of overstepping boundary, which affects its performance for search of optimum. In this study, a new position update approach is tested to normalize the search range of particles in a proper space. Such an approach enhances its probability to find the optimal solution. Since the clustering problem can be regarded as the centers searching process by using evolutionary optimization approach, the evolutionary process of chromosomes or particles encoded by centers simulates the process of solving clustering problem. In order to testify the clustering performance of our approach, we conduct the experiments on 4 subsets of standard Reuter-21578 and 20Newsgroup datasets. Experimental results show that our method performs better than the state of art clustering algorithms in the light of the evaluations of fitness and F-measure.
ER  - 

TY  - JOUR
T1  - Coupling learning of complex interactions
JO  - Information Processing & Management
VL  - 51
IS  - 2
SP  - 167
EP  - 186
PY  - 2015/3//
T2  - 
AU  - Cao, Longbing
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2014.08.007
UR  - http://www.sciencedirect.com/science/article/pii/S0306457314000855
KW  - Coupling learning
KW  - Coupling relationship
KW  - Interaction learning
KW  - Non-IIDness learning
KW  - Invisibility learning
AB  - Abstract
Complex applications such as big data analytics involve different forms of coupling relationships that reflect interactions between factors related to technical, business (domain-specific) and environmental (including socio-cultural and economic) aspects. There are diverse forms of couplings embedded in poor-structured and ill-structured data. Such couplings are ubiquitous, implicit and/or explicit, objective and/or subjective, heterogeneous and/or homogeneous, presenting complexities to existing learning systems in statistics, mathematics and computer sciences, such as typical dependency, association and correlation relationships. Modeling and learning such couplings thus is fundamental but challenging. This paper discusses the concept of coupling learning, focusing on the involvement of coupling relationships in learning systems. Coupling learning has great potential for building a deep understanding of the essence of business problems and handling challenges that have not been addressed well by existing learning theories and tools. This argument is verified by several case studies on coupling learning, including handling coupling in recommender systems, incorporating couplings into coupled clustering, coupling document clustering, coupled recommender algorithms and coupled behavior analysis for groups.
ER  - 

TY  - JOUR
T1  - Incremental learning with partial-supervision based on hierarchical Dirichlet process and the application for document classification
JO  - Applied Soft Computing
VL  - 33
IS  - 
SP  - 250
EP  - 262
PY  - 2015/8//
T2  - 
AU  - Wang, Di
AU  - Al-Rubaie, Ahmad
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2015.04.044
UR  - http://www.sciencedirect.com/science/article/pii/S1568494615002719
KW  - Hierachical Dirichlet process
KW  - Semi-supervised learning
KW  - Partial-supervision incremental learning
KW  - Text classification
KW  - Natural language processing
AB  - Abstract
Hierarchical Dirichlet process (HDP) is an unsupervised method which has been widely used for topic extraction and document clustering problems. One advantage of HDP is that it has an inherent mechanism to determine the total number of clusters/topics. However, HDP has three weaknesses: (1) there is no mechanism to use known labels or incorporate expert knowledge into the learning procedure, thus precluding users from directing the learning and making the final results incomprehensible; (2) it cannot detect the categories expected by applications without expert guidance; (3) it does not automatically adjust the model parameters and structure in a changing environment. To address these weaknesses, this paper proposes an incremental learning method, with partial supervision for HDP, which enables the topic model (initially guided by partial knowledge) to incrementally adapt to the latest available information. An important contribution of this work is the application of granular computing to HDP for partial-supervision and incremental learning which results in a more controllable and interpretable model structure. These enhancements provide a more flexible approach with expert guidance for the model learning and hence results in better prediction accuracy and interpretability.
ER  - 

TY  - JOUR
T1  - Knowledge discovery in inspection reports of marine structures
JO  - Expert Systems with Applications
VL  - 41
IS  - 4, Part 1
SP  - 1153
EP  - 1167
PY  - 2014/3//
T2  - 
AU  - Lee, Seung-kyung
AU  - Kim, Bongseok
AU  - Huh, Minhoe
AU  - Park, Jooseoung
AU  - Kang, Seokho
AU  - Cho, Sungzoon
AU  - Lee, Dongha
AU  - Lee, Daehyung
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2013.07.109
UR  - http://www.sciencedirect.com/science/article/pii/S0957417413006118
KW  - Knowledge Discovery in Textual Databases
KW  - Text mining
KW  - Shipbuilding and marine engineering industry
KW  - Inspection process
AB  - Abstract
Inspection reports, commonly called “punches” in the marine structuring domain, are written documents about defects or supplementations on marine structures. Analyzing the inspection reports improves the construction process for the structure and prevents additional “punches.” This consequently reduces construction delays and supplementary costs. The free-form texts of the reports, however, hinder management from understanding the nature of defects. Therefore, we applied Knowledge Discovery in the Textual Databases (KDT) process to answer the questions, “what kinds of defects are reported while inspecting a marine structure, and which of them are closely related?” In particular, we propose a concept extraction and linkage approach as an “add-on” module for the Self-Organizing Map (SOM), a clustering algorithm for document organization. A purely data-driven graph is derived for defect-types, which gives it in an easy-to-understand form for domain experts and reduces the gap between data analysis and its practical use. Interpretation with domain experts showed that our KDT process is useful in understanding the nature of defects in the domain and systematically responding to some other related defects.
ER  - 

TY  - JOUR
T1  - Topic identification techniques applied to dynamic language model adaptation for automatic speech recognition
JO  - Expert Systems with Applications
VL  - 42
IS  - 1
SP  - 101
EP  - 112
PY  - 2015/1//
T2  - 
AU  - Echeverry-Correa, J.D.
AU  - Ferreiros-López, J.
AU  - Coucheiro-Limeres, A.
AU  - Córdoba, R.
AU  - Montero, J.M.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2014.07.035
UR  - http://www.sciencedirect.com/science/article/pii/S0957417414004424
KW  - Language model adaptation
KW  - Topic identification
KW  - Automatic speech recognition
AB  - Abstract
In this paper we present an efficient speech recognition approach for multitopic speech by combining information retrieval techniques and topic-based language modeling. Information retrieval based techniques, such as topic identification by means of Latent Semantic Analysis, are used to identify the topic in a recognized transcription of an audio segment. According to the confidence on the topics that have been identified, we propose a dynamic language model adaptation in order to improve the recognition performance in ‘a two stages’ automatic speech recognition system. The scheme used for the adaptation of the language model is a linear interpolation between a background general LM and a topic dependent LM. We have studied different approaches to generate the topic dependent LM and also for determining the interpolation weight of this model with the background model. In one of these approaches we use the given topic labels in the training dataset to obtain the topic models. In the other approach we separate the documents in the training dataset into topic clusters by using the k-means algorithm. For strengthening the adaptation models we also use topic identification techniques to group non topic-labeled documents from the EUROPARL text database in order to increase the amount of data for training specific topic based language models. For the evaluation of the proposed system we are using the Spanish partition of the European Parliament Plenary Sessions (EPPS) Database; we selected a subset of the database with 67 labeled topics for the evaluation. For the task of topic identification our experiments show a relative reduction in topic identification error of 44.94% when compared to the baseline method, the Generalized Vector Model with a classic TF–IDF weighting scheme. For the task of dynamic adaptation of LMs applied to ASR we have achieved a relative reduction in WER of 13.52% over a single background language model.
ER  - 

TY  - JOUR
T1  - Learning a taxonomy from a set of text documents
JO  - Applied Soft Computing
VL  - 12
IS  - 3
SP  - 1138
EP  - 1148
PY  - 2012/3//
T2  - 
AU  - Paukkeri, Mari-Sanna
AU  - García-Plaza, Alberto Pérez
AU  - Fresno, Víctor
AU  - Unanue, Raquel Martínez
AU  - Honkela, Timo
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2011.11.009
UR  - http://www.sciencedirect.com/science/article/pii/S1568494611004340
KW  - Taxonomy learning
KW  - Knowledge representation
KW  - Document clustering
KW  - Keyphrase extraction
KW  - Fuzzy logic
KW  - Multilinguality
KW  - Self-Organizing Map
AB  - We present a methodology for learning a taxonomy from a set of text documents that each describes one concept. The taxonomy is obtained by clustering the concept definition documents with a hierarchical approach to the Self-Organizing Map. In this study, we compare three different feature extraction approaches with varying degree of language independence. The feature extraction schemes include fuzzy logic-based feature weighting and selection, statistical keyphrase extraction, and the traditional tf-idf weighting scheme. The experiments are conducted for English, Finnish, and Spanish. The results show that while the rule-based fuzzy logic systems have an advantage in automatic taxonomy learning, taxonomies can also be constructed with tolerable results using statistical methods without domain- or style-specific knowledge.
ER  - 

TY  - JOUR
T1  - Nonparametric Bayesian topic modelling with the hierarchical Pitman–Yor processes
JO  - International Journal of Approximate Reasoning
VL  - 78
IS  - 
SP  - 172
EP  - 191
PY  - 2016/11//
T2  - 
AU  - Lim, Kar Wai
AU  - Buntine, Wray
AU  - Chen, Changyou
AU  - Du, Lan
SN  - 0888-613X
DO  - http://dx.doi.org/10.1016/j.ijar.2016.07.007
UR  - http://www.sciencedirect.com/science/article/pii/S0888613X16301128
KW  - Bayesian nonparametric methods
KW  - Markov chain Monte Carlo
KW  - Topic models
KW  - Hierarchical Pitman–Yor processes
AB  - Abstract
The Dirichlet process and its extension, the Pitman–Yor process, are stochastic processes that take probability distributions as a parameter. These processes can be stacked up to form a hierarchical nonparametric Bayesian model. In this article, we present efficient methods for the use of these processes in this hierarchical context, and apply them to latent variable models for text analytics. In particular, we propose a general framework for designing these Bayesian models, which are called topic models in the computer science community. We then propose a specific nonparametric Bayesian topic model for modelling text from social media. We focus on tweets (posts on Twitter) in this article due to their ease of access. We find that our nonparametric model performs better than existing parametric models in both goodness of fit and real world applications.
ER  - 

TY  - JOUR
T1  - Efficient Nonnegative Matrix Factorization via projected Newton method
JO  - Pattern Recognition
VL  - 45
IS  - 9
SP  - 3557
EP  - 3565
PY  - 2012/9//
T2  - Best Papers of Iberian Conference on Pattern Recognition and Image Analysis (IbPRIA'2011)
AU  - Gong, Pinghua
AU  - Zhang, Changshui
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2012.02.037
UR  - http://www.sciencedirect.com/science/article/pii/S003132031200115X
KW  - Nonnegative Matrix Factorization
KW  - Projected Newton method
KW  - Quadratic convergence rate
KW  - Nonnegative least squares
KW  - Low rank
AB  - Nonnegative Matrix Factorization (NMF) is a popular decomposition technique in pattern analysis, document clustering, image processing and related fields. In this paper, we propose a fast NMF algorithm via Projected Newton Method (PNM). First, we propose PNM to efficiently solve a nonnegative least squares problem, which achieves a quadratic convergence rate under appropriate assumptions. Second, in the framework of an alternating optimization method, we adopt PNM as an essential subroutine to efficiently solve the NMF problem. Moreover, by exploiting the low rank assumption of NMF, we make PNM very suitable for solving NMF efficiently. Empirical studies on both synthetic and real-world (text and image) data demonstrate that PNM is quite efficient to solve NMF compared with several state of the art algorithms.
ER  - 

TY  - JOUR
T1  - Mapping product knowledge to life cycle inventory bounds: a case study of steel manufacturing
JO  - Journal of Cleaner Production
VL  - 113
IS  - 
SP  - 557
EP  - 564
PY  - 2016/2/1/
T2  - 
AU  - Bawden, Kim R.
AU  - Williams, Eric D.
AU  - Babbitt, Callie W.
SN  - 0959-6526
DO  - http://dx.doi.org/10.1016/j.jclepro.2015.10.014
UR  - http://www.sciencedirect.com/science/article/pii/S0959652615013955
KW  - Life cycle assessment
KW  - Uncertainty
KW  - Product knowledge mapping
KW  - Steel manufacturing
KW  - Bill of attributes
AB  - Abstract
This study develops and demonstrates a bounding methodology to quantify uncertainty in life cycle inventory (LCI) results arising from lack of detailed information on constituent materials. The method starts with the observation that the LCI of a material can change significantly with different attributes such as country of origin and recycled content, information often not specified in available bill-of-materials data. This lack of detailed information can be mapped to numerical bounds for LCI results. We demonstrate this idea via a case study of the contribution of steel manufacturing to the cumulative energy demand (CED) and life cycle global warming potential (GWP) of residential buildings. If steel type, recycled content and country of origin are all unknown, life cycle CO2-equivalent emissions of steel can vary from .7 to 5.9 kg CO2eq/kg. When used in compiling an LCI of a building, this wide range leads to overlapping results in a comparison of life cycle GWP impact between steel- and concrete-framed buildings. That is, without knowledge of the particulars of steel used, life cycle assessment (LCA) cannot distinguish between the two building types. In contrast, with knowledge that the steel is low or un-alloyed, produced in the U.S., and has greater than 60% recycled content, uncertainty bounds are reduced to .8–1.4 kg CO2eq/kg steel. With this range, the net impact of concrete-framed buildings is unambiguously larger than steel-framed residences. While demonstrated here for steel manufacturing, this bounding approach is broadly applicable in LCA.
ER  - 

TY  - JOUR
T1  - Analyzing the research in Integrative &amp; Complementary Medicine by means of science mapping
JO  - Complementary Therapies in Medicine
VL  - 22
IS  - 2
SP  - 409
EP  - 418
PY  - 2014/4//
T2  - 
AU  - Moral-Muñoz, J.A.
AU  - Cobo, M.J.
AU  - Peis, E.
AU  - Arroyo-Morales, M.
AU  - Herrera-Viedma, E.
SN  - 0965-2299
DO  - http://dx.doi.org/10.1016/j.ctim.2014.02.003
UR  - http://www.sciencedirect.com/science/article/pii/S0965229914000272
KW  - Complementary therapy
KW  - Integrative therapy
KW  - Science Mapping Analysis
AB  - AbstractObjectives
The research in the Complementary and Alternative Medicine (CAM) field is analyzed according to the journals indexed in ISI Web of Science. Science Mapping Analysis (SMA) is used to provide and overview of the conceptual evolution of the CAM field.
Methods
The software SciMAT is used to detect and visualize the hidden themes and their evolution over a consecutive span of years. It combines SMA and performance analysis. Twenty one journals related to CAM were analyzed, in four consecutive periods from 1974 to 2011.
Results
Strategic diagrams and the thematic evolution of CAM, together with performance indicators (h-index), were obtained. The results show that CAM research has focused on seven main thematic areas: MEDICINAL-PLANTS, CHIROPRACTIC-AND-LOW-BACK-PAIN, ACUPUNCTURE-AND-PAIN, CELL-PROCESSES-AND-DISEASES, LIPID-PEROXIDATION and DIABETES-AND-INSULIN.
Conclusion
The research output could be used by the scientific community to identify thematic areas on which interest is focused.
ER  - 

TY  - JOUR
T1  - An integrated K-means – Laplacian cluster ensemble approach for document datasets
JO  - Neurocomputing
VL  - 214
IS  - 
SP  - 495
EP  - 507
PY  - 2016/11/19/
T2  - 
AU  - Xu, Sen
AU  - Chan, Kung-Sik
AU  - Gao, Jun
AU  - Xu, Xiufang
AU  - Li, Xianfeng
AU  - Hua, Xiaopeng
AU  - An, Jing
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2016.06.034
UR  - http://www.sciencedirect.com/science/article/pii/S0925231216306725
KW  - Cluster analysis
KW  - Cluster ensemble
KW  - K-means
KW  - Laplacian
AB  - Abstract
Cluster ensemble has become an important extension to traditional clustering algorithms, yet the cluster ensemble problem is very challenging due to the inherent difficulty in resolving the label correspondence problem. We adapted the integrated K-means – Laplacian clustering approach to solve the cluster ensemble problem by exploiting both the attribute information embedded in the cluster labels and the pairwise relations among the objects. The optimal solution of the proposed approach requires computing the pseudo inverse of the normalized Laplacian matrix and the eigenvalue decomposition of a large matrix, which can be computationally burdensome for large scale document datasets. We devised an effective algebraic transformation method for efficiently carrying out the aforementioned computations and proposed an integrated K-means – Laplacian cluster ensemble approach (IKLCEA). Experimental results with benchmark document datasets demonstrate that IKLCEA outperforms other cluster ensemble techniques on most cases. In addition, IKLCEA is computationally efficient and can be readily employed in large scale document applications.
ER  - 

TY  - JOUR
T1  - Clustering analysis using manifold kernel concept factorization
JO  - Neurocomputing
VL  - 87
IS  - 
SP  - 120
EP  - 131
PY  - 2012/6/15/
T2  - 
AU  - Li, Ping
AU  - Chen, Chun
AU  - Bu, Jiajun
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2012.02.013
UR  - http://www.sciencedirect.com/science/article/pii/S092523121200118X
KW  - Manifold kernel learning
KW  - Concept factorization
KW  - Graph Laplacian
KW  - Document clustering
KW  - Image clustering
AB  - Various exponential-growing documents and images have become omnipresent in past decades, and it is of vital importance to group them into clusters upon desired. Matrix factorization is exhibited to help yield encouraging clustering results in previous works, whereas the data manifold structure, which holds plentiful spatial model information, is not fully respected by most existing techniques. And kernel learning is advantageous for unfolding nonlinear structure. Therefore, in this paper we propose a novel clustering approach called Manifold Kernel Concept Factorization (MKCF) that incorporates the manifold kernel learning in concept factorization, which encodes the local geometrical structure in the kernel space. This method efficiently preserves the data semantic structure using graph Laplacian, and the nonlinear manifold learning in the warped RKHS potentially reflects the underlying local geometry of the data. Thus, the concepts consistent with the intrinsic manifold structure are well extracted, and this greatly benefits aggregating documents and images within the same concept into the same cluster. Extensive empirical studies demonstrate that MKCF owns the superiority of achieving the more satisfactory clustering performance as well as deriving the better-represented lower data space.
ER  - 

TY  - JOUR
T1  - Discriminative Orthogonal Nonnegative matrix factorization with flexibility for data representation
JO  - Expert Systems with Applications
VL  - 41
IS  - 4, Part 1
SP  - 1283
EP  - 1293
PY  - 2014/3//
T2  - 
AU  - Li, Ping
AU  - Bu, Jiajun
AU  - Yang, Yi
AU  - Ji, Rongrong
AU  - Chen, Chun
AU  - Cai, Deng
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2013.08.026
UR  - http://www.sciencedirect.com/science/article/pii/S0957417413006386
KW  - Nonnegative matrix factorization
KW  - Flexible orthogonality
KW  - Manifold discriminant learning
KW  - Data representation
AB  - Abstract
Learning an informative data representation is of vital importance in multidisciplinary applications, e.g., face analysis, document clustering and collaborative filtering. As a very useful tool, Nonnegative matrix factorization (NMF) is often employed to learn a well-structured data representation. While the geometrical structure of the data has been studied in some previous NMF variants, the existing works typically neglect the discriminant information revealed by the between-class scatter and the total scatter of the data. To address this issue, we present a novel approach named Discriminative Orthogonal Nonnegative matrix factorization (DON), which preserves both the local manifold structure and the global discriminant information simultaneously through manifold discriminant learning. In particular, to learn the discriminant structure for the data representation, we introduce the scaled indicator matrix, which naturally satisfies the orthogonality condition. Thus, we impose the orthogonality constraints on the objective function. However, too heavy constraints will lead to a very sparse data representation that is unexpected in reality. So we further make this orthogonality flexible. In addition, we provide the optimization framework with the convergence proof of the updating rules. Extensive comparisons over several state-of-the-art approaches demonstrate the efficacy of the proposed method.
ER  - 

TY  - JOUR
T1  - A quality driven Hierarchical Data Divisive Soft Clustering for information retrieval
JO  - Knowledge-Based Systems
VL  - 26
IS  - 
SP  - 9
EP  - 19
PY  - 2012/2//
T2  - 
AU  - Bordogna, Gloria
AU  - Pasi, Gabriella
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2011.06.012
UR  - http://www.sciencedirect.com/science/article/pii/S0950705111001274
KW  - Soft Hierarchical Clustering
KW  - Fuzzy C-Means
KW  - Cluster’s quality
KW  - Document clustering
KW  - Quality measures
AB  - In this paper an adaptive hierarchical fuzzy clustering algorithm is presented, named Hierarchical Data Divisive Soft Clustering (H2D-SC). The main novelty of the proposed algorithm is that it is a quality driven algorithm, since it dynamically evaluates a multi-dimensional quality measure of the clusters to drive the generation of the soft hierarchy. Specifically, it generates a hierarchy in which each node is split into a variable number of sub-nodes, determined by an innovative quality assessment of soft clusters, based on the evaluation of multiple dimensions such as the cluster’s cohesion, its cardinality, its mass, and its fuzziness, as well as the partition’s entropy. Clusters at the same hierarchical level share a minimum quality value: clusters in the lower levels of the hierarchy have a higher quality; this way more specific clusters (lower level clusters) have a higher quality than more general clusters (upper level clusters). Further, since the algorithm generates a soft partition, a document can belong to several sub-clusters with distinct membership degrees. The proposed algorithm is divisive, and it is based on a combination of a modified bisecting K-Means algorithm with a flat soft clustering algorithm used to partition each node. The paper describes the algorithm and its evaluation on two standard collections.
ER  - 

TY  - JOUR
T1  - Scalable semi-supervised clustering by spectral kernel learning
JO  - Pattern Recognition Letters
VL  - 45
IS  - 
SP  - 161
EP  - 171
PY  - 2014/8/1/
T2  - 
AU  - Soleymani Baghshah, M.
AU  - Afsari, F.
AU  - Bagheri Shouraki, S.
AU  - Eslami, E.
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2014.02.014
UR  - http://www.sciencedirect.com/science/article/pii/S0167865514000555
KW  - Kernel learning
KW  - Spectral
KW  - Scalable
KW  - Semi-supervised clustering
KW  - Laplacian
KW  - Constraint
AB  - Abstract
Kernel learning is one of the most important and recent approaches to constrained clustering. Until now many kernel learning methods have been introduced for clustering when side information in the form of pairwise constraints is available. However, almost all of the existing methods either learn a whole kernel matrix or learn a limited number of parameters. Although the non-parametric methods that learn whole kernel matrix can provide capability of finding clusters of arbitrary structures, they are very computationally expensive and these methods are feasible only on small data sets. In this paper, we propose a kernel learning method that shows flexibility in the number of variables between the two extremes of freedom degree. The proposed method uses a spectral embedding to learn a square matrix whose number of rows is the number of dimensions in the embedded space. Therefore, the proposed method shows much higher scalability compared to other methods that learn a kernel matrix. Experimental results on synthetic and real-world data sets show that the performance of the proposed method is generally near to the learning a whole kernel matrix while its time cost is very low compared to these methods.
ER  - 

TY  - JOUR
T1  - The semantic mapping of words and co-words in contexts
JO  - Journal of Informetrics
VL  - 5
IS  - 3
SP  - 469
EP  - 475
PY  - 2011/7//
T2  - 
AU  - Leydesdorff, Loet
AU  - Welbers, Kasper
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2011.01.008
UR  - http://www.sciencedirect.com/science/article/pii/S1751157711000095
KW  - Semantic
KW  - Map
KW  - Document
KW  - Text
KW  - Word
KW  - Latent
KW  - Meaning
AB  - Meaning can be generated when information is related at a systemic level. Such a system can be an observer, but also a discourse, for example, operationalized as a set of documents. The measurement of semantics as similarity in patterns (correlations) and latent variables (factor analysis) has been enhanced by computer techniques and the use of statistics; for example, in “latent semantic analysis”. This communication provides an introduction, an example, pointers to relevant software, and summarizes the choices that can be made by the analyst. Visualization (“semantic mapping”) is thus made more accessible.
ER  - 

TY  - JOUR
T1  - A concept-driven biomedical knowledge extraction and visualization framework for conceptualization of text corpora
JO  - Journal of Biomedical Informatics
VL  - 43
IS  - 6
SP  - 1020
EP  - 1035
PY  - 2010/12//
T2  - 
AU  - Jahiruddin
AU  - Abulaish, Muhammad
AU  - Dey, Lipika
SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2010.09.008
UR  - http://www.sciencedirect.com/science/article/pii/S1532046410001401
KW  - Biological text mining
KW  - Biological relation extraction
KW  - Biomedical knowledge extraction and visualization
KW  - Semantic network
KW  - Biomedical query answering
AB  - A number of techniques such as information extraction, document classification, document clustering and information visualization have been developed to ease extraction and understanding of information embedded within text documents. However, knowledge that is embedded in natural language texts is difficult to extract using simple pattern matching techniques and most of these methods do not help users directly understand key concepts and their semantic relationships in document corpora, which are critical for capturing their conceptual structures. The problem arises due to the fact that most of the information is embedded within unstructured or semi-structured texts that computers can not interpret very easily. In this paper, we have presented a novel Biomedical Knowledge Extraction and Visualization framework, BioKEVis to identify key information components from biomedical text documents. The information components are centered on key concepts. BioKEVis applies linguistic analysis and Latent Semantic Analysis (LSA) to identify key concepts. The information component extraction principle is based on natural language processing techniques and semantic-based analysis. The system is also integrated with a biomedical named entity recognizer, ABNER, to tag genes, proteins and other entity names in the text. We have also presented a method for collating information extracted from multiple sources to generate semantic network. The network provides distinct user perspectives and allows navigation over documents with similar information components and is also used to provide a comprehensive view of the collection. The system stores the extracted information components in a structured repository which is integrated with a query-processing module to handle biomedical queries over text documents. We have also proposed a document ranking mechanism to present retrieved documents in order of their relevance to the user query.
ER  - 

TY  - JOUR
T1  - Evolving soft subspace clustering
JO  - Applied Soft Computing
VL  - 14, Part B
IS  - 
SP  - 210
EP  - 228
PY  - 2014/1//
T2  - Evolving Soft Computing Techniques and Applications
AU  - Zhu, Lin
AU  - Cao, Longbing
AU  - Yang, Jie
AU  - Lei, Jingsheng
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2013.03.002
UR  - http://www.sciencedirect.com/science/article/pii/S1568494613000756
KW  - Subspace clustering
KW  - Data stream clustering
KW  - Online clustering
KW  - Scalable clustering
AB  - Abstract
A key challenge to most conventional clustering algorithms in handling many real world problems is that, data points in different clusters are often correlated with different subsets of features. To address this problem, subspace clustering has attracted increasing attention in recent years. In practical data mining applications, data points may arrive in continuous streams with chunks of samples being collected at different time points. In addition, huge amounts of data often cannot be kept in the main memory due to memory restriction. Accordingly, a range of evolving clustering algorithms has been proposed, however, traditional evolving clustering methods cannot be effectively applied to large-scale high dimensional data and data streams. In this study, we extend the online learning strategy and scalable clustering technique to soft subspace clustering to form evolving soft subspace clustering. We propose two online soft subspace clustering algorithms, OFWSC and OEWSC, and two streaming soft subspace clustering algorithms, SSSC_F and SSSC_E. The proposed evolving soft subspace clustering leverages on the effectiveness of online learning scheme and scalable clustering methods for streaming data by revealing the important local subspace characteristics of high dimensional data. Substantial experimental results on both artificial and real-world datasets demonstrate that our proposed methods are generally effective in evolving clustering and achieve superior performance over existing soft subspace clustering techniques.
ER  - 

TY  - JOUR
T1  - An advanced multiobjective genetic algorithm design for the time and space assembly line balancing problem
JO  - Computers & Industrial Engineering
VL  - 61
IS  - 1
SP  - 103
EP  - 117
PY  - 2011/8//
T2  - 
AU  - Chica, Manuel
AU  - Cordón, Óscar
AU  - Damas, Sergio
SN  - 0360-8352
DO  - http://dx.doi.org/10.1016/j.cie.2011.03.001
UR  - http://www.sciencedirect.com/science/article/pii/S0360835211000775
KW  - Assembly lines
KW  - Time and space assembly line balancing
KW  - Evolutionary multiobjective optimization
KW  - NSGA-II
AB  - Time and space assembly line balancing considers realistic multiobjective versions of the classical assembly line balancing industrial problems involving the joint optimization of conflicting criteria such as the cycle time, the number of stations, and/or the area of these stations. In addition to their multi-criteria nature, the different problems included in this field inherit the precedence constraints and the cycle time limitations from assembly line balancing problems, which altogether make them very hard to solve. Therefore, time and space assembly line balancing problems have been mainly tackled using multiobjective constructive metaheuristics. Global search algorithms in general – and multiobjective genetic algorithms in particular – have shown to be ineffective to solve them up to now because the existing approaches lack of a proper design taking into account the specific characteristics of this family of problems. The aim of this contribution is to demonstrate the latter assumption by proposing an advanced multiobjective genetic algorithm design for the 1/3 variant of the time and space assembly line balancing problem which involves the joint minimization of the number and the area of the stations given a fixed cycle time limit. This novel design takes the well known NSGA-II algorithm as a base and considers the use of a new coding scheme and sophisticated problem specific operators to properly deal with the said problematic questions. A detailed experimental study considering 10 different problem instances (including a real-world instance from the Nissan plant in Barcelona, Spain) will show the good yield of the new proposal in comparison with the state-of-the-art methods.
ER  - 

TY  - JOUR
T1  - Constrained neighborhood preserving concept factorization for data representation
JO  - Knowledge-Based Systems
VL  - 102
IS  - 
SP  - 127
EP  - 139
PY  - 2016/6/15/
T2  - 
AU  - Lu, Mei
AU  - Zhang, Li
AU  - Zhao, Xiang-Jun
AU  - Li, Fan-Zhang
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2016.04.003
UR  - http://www.sciencedirect.com/science/article/pii/S0950705116300375
KW  - Concept factorization
KW  - Locally consistent concept factorization
KW  - Semi-supervised document clustering
KW  - Neighborhood preserving
KW  - Data representation
AB  - Abstract
Matrix factorization based techniques, such as nonnegative matrix factorization (NMF) and concept factorization (CF), have attracted a great deal of attentions in recent years, mainly due to their ability of dimension reduction and sparse data representation. Both techniques are of unsupervised nature and thus do not make use of a priori knowledge to guide the clustering process. This could lead to inferior performance in some scenarios. As a remedy to this, a semi-supervised learning method called Pairwise Constrained Concept Factorization (PCCF) was introduced to incorporate some pairwise constraints into the CF framework. Despite its improved performance, PCCF uses only a priori knowledge and neglects the proximity information of the whole data distribution; this could lead to rather poor performance (although slightly improved comparing to CF) when only limited a priori information is available. To address this issue, we propose in this paper a novel method called Constrained Neighborhood Preserving Concept Factorization (CNPCF). CNPCF utilizes both a priori knowledge and local geometric structure of the dataset to guide its clustering. Experimental studies on three real-world clustering tasks demonstrate that our method yields a better data representation and achieves much improved clustering performance in terms of accuracy and mutual information comparing to the state-of-the-arts techniques.
ER  - 

TY  - JOUR
T1  - Mapping the dementia research area at the micro level using co-terms analysis and positioning for herbal medicine
JO  - Alzheimer's & Dementia
VL  - 8
IS  - 4, Supplement
SP  - P404
EP  - 
PY  - 2012/7//
T2  - Alzheimer's Association International Conference 2012Alzheimer's Association International Conference 2012
AU  - Kim, Bu-Yeo
AU  - Kang, Jong Seok
AU  - Jeon, Won Kyung
SN  - 1552-5260
DO  - http://dx.doi.org/10.1016/j.jalz.2012.05.1112
UR  - http://www.sciencedirect.com/science/article/pii/S1552526012012447
ER  - 

TY  - JOUR
T1  - Combined biological and health effects of electromagnetic fields and other agents in the published literature
JO  - Technological Forecasting and Social Change
VL  - 80
IS  - 7
SP  - 1331
EP  - 1349
PY  - 2013/9//
T2  - 
AU  - Kostoff, Ronald N.
AU  - Lau, Clifford G.Y.
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2012.12.006
UR  - http://www.sciencedirect.com/science/article/pii/S0040162512003216
KW  - EMF
KW  - Electromagnetic fields
KW  - Magnetic fields
KW  - Radio frequency radiation
KW  - Microwave radiation
KW  - Interactive effects
KW  - Combined effects
KW  - Synergistic effects
KW  - Additive effects
KW  - Antagonist effects
KW  - Potentiative effects
KW  - Co-promotion
KW  - Co-mutagenic
KW  - Co-carcinogenic
KW  - Combined exposure
KW  - Combined treatment
KW  - DMBA
KW  - TPA
KW  - Text mining
KW  - Document clustering
AB  - Abstract
Electromagnetic field (EMF) radiation exerts both stand-alone and combined effects on biological systems. The present study examines the scope of the combined effects; i.e., identify effects on biological systems from combined exposure to electromagnetic fields/radiation and at least one other agent. Only articles in which the presence of EMF had some effect (beneficial or adverse) on the biological system were selected. A comprehensive and novel query was developed using an iterative hybrid approach, whereby articles related by common text and by citation linkages were retrieved. This retrieved literature was: 1) clustered algorithmically into 32 biomedical sub-themes (assigned by the authors); 2) grouped through factor analysis into 32 factors; and 3) subsequently grouped manually (by the authors) into an effects-based taxonomy. The common principles within each thematic cluster/group that accounted for the combined effects were identified.

There is a wide range of potential effects in which EMF plays a supportive role. Beneficial effects include improved treatment of chronic diseases like cancer by enhancing ionizing radiation or chemotherapy, and accelerated healing of wounds and injuries in concert with other agents. Adverse effects, on the other hand, include enhanced carcinogenesis, cellular or genetic mutations, and teratogenicity. It should be noted that community consensus does not exist on these potential effects, either beneficial or adverse, although there is substantial credible scientific evidence supporting the above effects (as the body of this paper shows). In real life, the body is exposed to multiple environmental agents simultaneously, e.g., a variety of EMF, pesticides, food additives, and air pollution. The number of potential environmental agent combinations is large, and each combination could potentially have beneficial or adverse effects; much work remains to be done before definitive statements about EMF safety can be made.
ER  - 

TY  - JOUR
T1  - Conscious worst case definition for risk assessment, part I: A knowledge mapping approach for defining most critical risk factors in integrative risk management of chemicals and nanomaterials
JO  - Science of The Total Environment
VL  - 408
IS  - 18
SP  - 3852
EP  - 3859
PY  - 2010/8/15/
T2  - Cumulative Stressors - Risk assessment of mixtures of chemicals and combinations of chemicals and natural stressors
AU  - Sørensen, Peter B.
AU  - Thomsen, Marianne
AU  - Assmuth, Timo
AU  - Grieger, Khara D.
AU  - Baun, Anders
SN  - 0048-9697
DO  - http://dx.doi.org/10.1016/j.scitotenv.2009.11.010
UR  - http://www.sciencedirect.com/science/article/pii/S0048969709010997
KW  - Risk management
KW  - Uncertainty
KW  - Worst case
KW  - Modelling
KW  - Protection
KW  - Chemicals
KW  - Nanomaterials
AB  - This paper helps bridge the gap between scientists and other stakeholders in the areas of human and environmental risk management of chemicals and engineered nanomaterials. This connection is needed due to the evolution of stakeholder awareness and scientific progress related to human and environmental health which involves complex methodological demands on risk management. At the same time, the available scientific knowledge is also becoming more scattered across multiple scientific disciplines. Hence, the understanding of potentially risky situations is increasingly multifaceted, which again challenges risk assessors in terms of giving the ‘right’ relative priority to the multitude of contributing risk factors. A critical issue is therefore to develop procedures that can identify and evaluate worst case risk conditions which may be input to risk level predictions. Therefore, this paper suggests a conceptual modelling procedure that is able to define appropriate worst case conditions in complex risk management. The result of the analysis is an assembly of system models, denoted the Worst Case Definition (WCD) model, to set up and evaluate the conditions of multi-dimensional risk identification and risk quantification. The model can help optimize risk assessment planning by initial screening level analyses and guiding quantitative assessment in relation to knowledge needs for better decision support concerning environmental and human health protection or risk reduction. The WCD model facilitates the evaluation of fundamental uncertainty using knowledge mapping principles and techniques in a way that can improve a complete uncertainty analysis. Ultimately, the WCD is applicable for describing risk contributing factors in relation to many different types of risk management problems since it transparently and effectively handles assumptions and definitions and allows the integration of different forms of knowledge, thereby supporting the inclusion of multifaceted risk components in cumulative risk management.
ER  - 

TY  - JOUR
T1  - Virtual and remote labs in education: A bibliometric analysis
JO  - Computers & Education
VL  - 98
IS  - 
SP  - 14
EP  - 38
PY  - 2016/7//
T2  - 
AU  - Heradio, Ruben
AU  - de la Torre, Luis
AU  - Galan, Daniel
AU  - Cabrerizo, Francisco Javier
AU  - Herrera-Viedma, Enrique
AU  - Dormido, Sebastian
SN  - 0360-1315
DO  - http://dx.doi.org/10.1016/j.compedu.2016.03.010
UR  - http://www.sciencedirect.com/science/article/pii/S0360131516300677
KW  - Virtual laboratory
KW  - Remote laboratory
KW  - Web-based experimentation
KW  - Bibliometrics
KW  - Science mapping
AB  - Abstract
Laboratory experimentation plays an essential role in engineering and scientific education. Virtual and remote labs reduce the costs associated with conventional hands-on labs due to their required equipment, space, and maintenance staff. Furthermore, they provide additional benefits such as supporting distance learning, improving lab accessibility to handicapped people, and increasing safety for dangerous experimentation. This paper analyzes the literature on virtual and remote labs from its beginnings to 2015, identifying the most influential publications, the most researched topics, and how the interest in those topics has evolved along the way. To do so, bibliographical data gathered from ISI Web of Science, Scopus and GRC2014 have been examined using two prominent bibliometric approaches: science mapping and performance analysis.
ER  - 

TY  - JOUR
T1  - A general knowledge mediation infrastructure for multi-agent systems
JO  - Expert Systems with Applications
VL  - 38
IS  - 1
SP  - 495
EP  - 503
PY  - 2011/1//
T2  - 
AU  - Chen, Kun
AU  - Wang, Huaiqing
AU  - Lai, Hokyin
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2010.06.091
UR  - http://www.sciencedirect.com/science/article/pii/S0957417410005956
KW  - General knowledge
KW  - Knowledge acquisition
KW  - Multi-agent systems
KW  - Semantic integration
AB  - Intelligent decision making needs to be equipped with broader knowledge in order to enhance the decision quality. Knowledge for decision making can be categorized as domain specific and general. Applying domain knowledge in intelligent systems is not new, but applying general knowledge to support business decision making is a possible way to obtain an edge over competitors. For this reason, the paper focuses primarily on designing a general knowledge mediation infrastructure (GKMI) which supports the use of general knowledge from multiple heterogeneous sources, and provides an unified access point for typical multi-agent systems (MAS) to access that knowledge. The finite state automaton (FSA) is used to model and analyze the commonsense inference ability of GKMI. By carrying out two use cases of GKMI for MAS development and operation the effectiveness of this infrastructure is examined.
ER  - 

TY  - JOUR
T1  - General subspace constrained non-negative matrix factorization for data representation
JO  - Neurocomputing
VL  - 173, Part 2
IS  - 
SP  - 224
EP  - 232
PY  - 2016/1/15/
T2  - 
AU  - Liu, Yong
AU  - Liao, Yiyi
AU  - Tang, Liang
AU  - Tang, Feng
AU  - Liu, Weicong
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2014.11.099
UR  - http://www.sciencedirect.com/science/article/pii/S092523121501262X
KW  - Non-negative matrix factorization
KW  - Subspace
KW  - Generalize framework
AB  - Abstract
Nonnegative matrix factorization (NMF) has been proved to be a powerful data representation method, and has shown success in applications such as data representation and document clustering. However, the non-negative constraint alone is not able to capture the underlying properties of the data. In this paper, we present a framework to enforce general subspace constraints into NMF by augmenting the original objective function with two additional terms. One on constraints of the basis, the other on preserving the structural properties of the original data. This framework is general as it can be used to regularize NMF with a wide variety of subspace constraints that can be formulated into a certain form such as PCA, Fisher LDA and LPP. In addition, we present an iterative optimization algorithm to solve the general subspace constrained non-negative matrix factorization (GSC NMF). We show that the resulting subspace has enriched representation power as shown in our experiments.
ER  - 

TY  - JOUR
T1  - De-identification of clinical narratives through writing complexity measures
JO  - International Journal of Medical Informatics
VL  - 83
IS  - 10
SP  - 750
EP  - 767
PY  - 2014/10//
T2  - 
AU  - Li, Muqun
AU  - Carrell, David
AU  - Aberdeen, John
AU  - Hirschman, Lynette
AU  - Malin, Bradley A.
SN  - 1386-5056
DO  - http://dx.doi.org/10.1016/j.ijmedinf.2014.07.002
UR  - http://www.sciencedirect.com/science/article/pii/S1386505614001373
KW  - Electronic medical records
KW  - Privacy
KW  - Natural language processing
AB  - AbstractPurpose
Electronic health records contain a substantial quantity of clinical narrative, which is increasingly reused for research purposes. To share data on a large scale and respect privacy, it is critical to remove patient identifiers. De-identification tools based on machine learning have been proposed; however, model training is usually based on either a random group of documents or a pre-existing document type designation (e.g., discharge summary). This work investigates if inherent features, such as the writing complexity, can identify document subsets to enhance de-identification performance.
Methods
We applied an unsupervised clustering method to group two corpora based on writing complexity measures: a collection of over 4500 documents of varying document types (e.g., discharge summaries, history and physical reports, and radiology reports) from Vanderbilt University Medical Center (VUMC) and the publicly available i2b2 corpus of 889 discharge summaries. We compare the performance (via recall, precision, and F-measure) of de-identification models trained on such clusters with models trained on documents grouped randomly or VUMC document type.
Results
For the Vanderbilt dataset, it was observed that training and testing de-identification models on the same stylometric cluster (with the average F-measure of 0.917) tended to outperform models based on clusters of random documents (with an average F-measure of 0.881). It was further observed that increasing the size of a training subset sampled from a specific cluster could yield improved results (e.g., for subsets from a certain stylometric cluster, the F-measure raised from 0.743 to 0.841 when training size increased from 10 to 50 documents, and the F-measure reached 0.901 when the size of the training subset reached 200 documents). For the i2b2 dataset, training and testing on the same clusters based on complexity measures (average F-score 0.966) did not significantly surpass randomly selected clusters (average F-score 0.965).
Conclusions
Our findings illustrate that, in environments consisting of a variety of clinical documentation, de-identification models trained on writing complexity measures are better than models trained on random groups and, in many instances, document types.
ER  - 

TY  - JOUR
T1  - Topic model validation
JO  - Neurocomputing
VL  - 76
IS  - 1
SP  - 125
EP  - 133
PY  - 2012/1/15/
T2  - Seventh International Symposium on Neural Networks (ISNN 2010)Advances in Web Intelligence
AU  - Ramirez, Eduardo H.
AU  - Brena, Ramon
AU  - Magatti, Davide
AU  - Stella, Fabio
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2011.04.032
UR  - http://www.sciencedirect.com/science/article/pii/S0925231211003912
KW  - Topic models
KW  - Soft clustering
KW  - Fowlkes–Mallows index
KW  - Monte Carlo
AB  - In this paper the problem of performing external validation of the semantic coherence of topic models is considered. The Fowlkes–Mallows index, a known clustering validation metric, is generalized for the case of overlapping partitions and multi-labeled collections, thus making it suitable for validating topic modeling algorithms. In addition, we propose new probabilistic metrics inspired by the concepts of recall and precision. The proposed metrics also have clear probabilistic interpretations and can be applied to validate and compare other soft and overlapping clustering algorithms. The approach is exemplified by using the Reuters-21578 multi-labeled collection to validate LDA models, then using Monte Carlo simulations to show the convergence to the correct results. Additional statistical evidence is provided to better understand the relation of the metrics presented.
ER  - 

TY  - JOUR
T1  - Locally discriminative topic modeling
JO  - Pattern Recognition
VL  - 45
IS  - 1
SP  - 617
EP  - 625
PY  - 2012/1//
T2  - 
AU  - Wu, Hao
AU  - Bu, Jiajun
AU  - Chen, Chun
AU  - Zhu, Jianke
AU  - Zhang, Lijun
AU  - Liu, Haifeng
AU  - Wang, Can
AU  - Cai, Deng
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2011.04.029
UR  - http://www.sciencedirect.com/science/article/pii/S0031320311001889
KW  - Topic modeling
KW  - Generative
KW  - Discriminative
KW  - Local learning
AB  - Topic modeling is a powerful tool for discovering the underlying or hidden structure in text corpora. Typical algorithms for topic modeling include probabilistic latent semantic analysis (PLSA) and latent Dirichlet allocation (LDA). Despite their different inspirations, both approaches are instances of generative model, whereas the discriminative structure of the documents is ignored. In this paper, we propose locally discriminative topic model (LDTM), a novel topic modeling approach which considers both generative and discriminative structures of the data space. Different from PLSA and LDA in which the topic distribution of a document is dependent on all the other documents, LDTM takes a local perspective that the topic distribution of each document is strongly dependent on its neighbors. By modeling the local relationships of documents within each neighborhood via a local linear model, we learn topic distributions that vary smoothly along the geodesics of the data manifold, and can better capture the discriminative structure in the data. The experimental results on text clustering and web page categorization demonstrate the effectiveness of our proposed approach.
ER  - 

TY  - JOUR
T1  - Dual-graph regularized concept factorization for clustering
JO  - Neurocomputing
VL  - 138
IS  - 
SP  - 120
EP  - 130
PY  - 2014/8/22/
T2  - 
AU  - Ye, Jun
AU  - Jin, Zhong
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2014.02.029
UR  - http://www.sciencedirect.com/science/article/pii/S0925231214004287
KW  - NMF
KW  - Concept factorization
KW  - Dual-graph regularized
KW  - Document clustering
KW  - Image clustering
AB  - Abstract
In past decades, tremendous growths in the amount of text documents and images have become omnipresent, and it is very important to group them into clusters upon desired. Recently, matrix factorization based techniques, such as Non-negative Matrix Factorization (NMF) and Concept Factorization (CF), have yielded impressive results for clustering. However, both of them effectively see only the global Euclidean geometry, whereas the local manifold geometry is not fully considered. Recent research has shown that not only the observed data are found to lie on a nonlinear low dimensional manifold, namely data manifold, but also the features lie on a manifold, namely feature manifold. In this paper, we propose a novel algorithm, called dual-graph regularized concept factorization for clustering (GCF), which simultaneously considers the geometric structures of both the data manifold and the feature manifold. As an extension of GCF, we extend that our proposed method can also be apply to the negative dataset. Moreover, we develop the iterative updating optimization schemes for GCF, and provide the convergence proof of our optimization scheme. Experimental results on TDT2 and Reuters document datasets, COIL20 and PIE image datasets demonstrate the effectiveness of our proposed method.
ER  - 

TY  - JOUR
T1  - A clustering study of a 7000 EU document inventory using MDS and SOM
JO  - Expert Systems with Applications
VL  - 38
IS  - 7
SP  - 8835
EP  - 8849
PY  - 2011/7//
T2  - 
AU  - De Mazière, Patrick A.
AU  - Van Hulle, Marc M.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2011.01.094
UR  - http://www.sciencedirect.com/science/article/pii/S095741741100114X
KW  - Text mining
KW  - Data warehousing
KW  - High dimensional data
KW  - Visualisation methods
KW  - High performance computing (HPC)
KW  - Parallel algorithms
AB  - In this article, we discuss a number of methods and tools to cluster a 7000 document inventory in order to evaluate the impact of EU funded research in social sciences and humanities on EU policies. The inventory, which is not publicly available, but provided to us by the European Union (EU) in the framework of an EU project, could be divided into three main categories: research documents, influential policy documents, and policy documents. To represent the results in a way that non-experts could make use of it, we explored and compared two visualisation techniques, multi-dimensional scaling (MDS) and the self-organising map (SOM), and one of the latter’s derivatives, the U-matrix. Contrary to most other approaches, which perform text analyses only on document titles and abstracts, we performed a full text analysis on more than 300,000 pages in total. Due to the inability of many software suites to handle text mining problems of this size, we developed our own analysis platform. We show that the combination of a U-matrix and an MDS map, which is rarely performed in the domain of text mining, reveals information that would go unnoticed otherwise. Furthermore, we show that the combination of a database, to store the data and the (intermediate) results, and a webserver, to visualise the results, offers a powerful platform to analyse the data and share the results with all participants/collaborators involved in a data- and computation intensive EU-project, thereby guaranteeing both data- and result consistency.
ER  - 

TY  - JOUR
T1  - Multiview self-learning
JO  - Neurocomputing
VL  - 155
IS  - 
SP  - 117
EP  - 127
PY  - 2015/5/1/
T2  - 
AU  - Fakeri-Tabrizi, Ali
AU  - Amini, Massih-Reza
AU  - Goutte, Cyril
AU  - Usunier, Nicolas
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2014.12.041
UR  - http://www.sciencedirect.com/science/article/pii/S0925231214017056
KW  - Multiview learning
KW  - Self-learning
KW  - Image annotation
KW  - Multilingual document categorization
AB  - Abstract
In many applications, observations are available with different views. This is, for example, the case with image-text classification, multilingual document classification or document classification on the web. In addition, unlabeled multiview examples can be easily acquired, but assigning labels to these examples is usually a time consuming task. We describe a multiview self-learning strategy which trains different voting classifiers on different views. The margin distributions over the unlabeled training data, obtained with each view-specific classifier are then used to estimate an upper-bound on their transductive Bayes error. Minimizing this upper-bound provides an automatic margin-threshold which is used to assign pseudo-labels to unlabeled examples. Final class labels are then assigned to these examples, by taking a vote on the pool of the previous pseudo-labels. New view-specific classifiers are then trained using the labeled and pseudo-labeled training data. We consider applications to image-text classification and to multilingual document classification. We present experimental results on the NUS-WIDE collection and on Reuters RCV1-RCV2 which show that despite its simplicity, our approach is competitive with other state-of-the-art techniques.
ER  - 

TY  - JOUR
T1  - Improving constrained clustering via swarm intelligence
JO  - Neurocomputing
VL  - 116
IS  - 
SP  - 317
EP  - 325
PY  - 2013/9/20/
T2  - Advanced Theory and Methodology in Intelligent ComputingSelected Papers from the Seventh International Conference on Intelligent Computing (ICIC 2011).
AU  - Xu, Xiaohua
AU  - Lu, Lin
AU  - He, Ping
AU  - Pan, Zhoujin
AU  - Chen, Ling
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2012.03.031
UR  - http://www.sciencedirect.com/science/article/pii/S0925231212007278
KW  - Ant-based clustering
KW  - Constrained clustering
KW  - Random walk
AB  - By simulating the clustering behavior of the real-world ant colonies, we propose in this paper a constrained ant clustering algorithm. This algorithm is embedded with the heuristic walk mechanism based on random walk to deal with the constrained clustering problems given pairwise must-link and cannot-link constraints. Experimental results show that our approach is more effective on both the synthetic datasets and the real datasets compared with the Cop-Kmeans and ant-based clustering algorithm.
ER  - 

TY  - JOUR
T1  - Learning low-rank kernel matrices for constrained clustering
JO  - Neurocomputing
VL  - 74
IS  - 12–13
SP  - 2201
EP  - 2211
PY  - 2011/6//
T2  - 
AU  - Baghshah, Mahdieh Soleymani
AU  - Shouraki, Saeed Bagheri
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2011.02.009
UR  - http://www.sciencedirect.com/science/article/pii/S0925231211001251
KW  - Low-rank kernel
KW  - Kernel learning
KW  - Distance metric
KW  - Constrained clustering
KW  - Semi-supervised
KW  - Spectral
AB  - Constrained clustering methods (that usually use must-link and/or cannot-link constraints) have been received much attention in the last decade. Recently, kernel adaptation or kernel learning has been considered as a powerful approach for constrained clustering. However, these methods usually either allow only special forms of kernels or learn non-parametric kernel matrices and scale very poorly. Therefore, they either learn a metric that has low flexibility or are applicable only on small data sets due to their high computational complexity. In this paper, we propose a more efficient non-linear metric learning method that learns a low-rank kernel matrix from must-link and cannot-link constraints and the topological structure of data. We formulate the proposed method as a trace ratio optimization problem and learn appropriate distance metrics through finding optimal low-rank kernel matrices. We solve the proposed optimization problem much more efficiently than SDP solvers. Additionally, we show that the spectral clustering methods can be considered as a special form of low-rank kernel learning methods. Extensive experiments have demonstrated the superiority of the proposed method compared to recently introduced kernel learning methods.
ER  - 

TY  - JOUR
T1  - Keyword selection and processing strategy for applying text mining to patent analysis
JO  - Expert Systems with Applications
VL  - 42
IS  - 9
SP  - 4348
EP  - 4360
PY  - 2015/6/1/
T2  - 
AU  - Noh, Heeyong
AU  - Jo, Yeongran
AU  - Lee, Sungjoo
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2015.01.050
UR  - http://www.sciencedirect.com/science/article/pii/S0957417415000652
KW  - Patent analysis
KW  - Text-mining
KW  - Keyword selection
KW  - Keyword processing
KW  - Document clustering
AB  - Abstract
Previous studies have applied various methodologies to analyze patent data for technology management, given the advances in data analysis techniques available. In particular, efforts have recently been made to use text-mining (i.e. extracting keywords from patent documents) for patent analysis purposes. The results of these studies may be affected by the keywords selected from the relevant documents – but, despite its importance, the existing literature has seldom explored strategies for selecting and processing keywords from patent documents.

The purpose of this research is to fill this research gap by focusing on keyword strategies for applying text-mining to patent data. Specifically, four factors are addressed; (1) which element of the patent documents to adopt for keyword selection, (2) what keyword selection methods to use, (3) how many keywords to select, and (4) how to transform the keyword selection results into an analyzable data format. An experiment based on an orthogonal array of the four factors was designed in order to identify the best strategy, in which the four factors were evaluated and compared through k-means clustering and entropy values. The research findings are expected to offer useful guidelines for how to select and process keywords for patent analysis, and so further increase the reliability and validity of research using text-mining for patent analysis.
ER  - 

TY  - JOUR
T1  - Kernel methods for point symmetry-based clustering
JO  - Pattern Recognition
VL  - 48
IS  - 9
SP  - 2812
EP  - 2830
PY  - 2015/9//
T2  - 
AU  - Cleuziou, Guillaume
AU  - Moreno, Jose G.
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2015.03.013
UR  - http://www.sciencedirect.com/science/article/pii/S0031320315001144
KW  - Pattern recognition
KW  - Clustering
KW  - Point symmetry-based distance measure
KW  - Kernel function
KW  - K-means
AB  - Abstract
This paper deals with the point symmetry-based clustering task that consists in retrieving – from a data set – clusters having a point symmetric shape. Prototype-based algorithms are considered and a non-trivial generalization to kernel methods is proposed, thanks to the geometric properties satisfied by the point symmetry distances proposed until now. The proposed kernelized framework offers new opportunities to deal with non-Euclidean symmetries and to reconsider any intractable examples by means of implicit feature spaces.

A deep experimental study is proposed that brings out, on artificial data sets, the capabilities and the limits of the current point symmetry-based clustering methods. It reveals that kernel methods are quite capable of stretching the current limits for the considered task and encourages new research on the kernel selection issue in order to design a fully unsupervised symmetric pattern recognition process.
ER  - 

TY  - JOUR
T1  - Augmented Reality: An Enhancer for Higher Education Students in Math's Learning?
JO  - Procedia Computer Science
VL  - 67
IS  - 
SP  - 332
EP  - 339
PY  - 2015///
T2  - Proceedings of the 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion
AU  - Coimbra, MMath. Teresa
AU  - Cardoso, Teresa
AU  - Mateus, Artur
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.09.277
UR  - http://www.sciencedirect.com/science/article/pii/S1877050915031233
KW  - Augmented Reality
KW  - Three-Dimensional Contents
KW  - Information and Communication Technologies (ICT)
KW  - Higher Education students
KW  - Maths learning
KW  - Knowledge mapping.
AB  - Abstract
In this text, we intend to answer to the following question: is Augmented Reality an enhancer for Higher Education students in math's learning? For this purpose, we define augmented reality and present a state of the art mapped mainly by studies that focus AR in educational contexts. We also describe our research, including methodological aspects in data collection and the creation of 3D contents in AR. Then, we synthesize the analysis of some preliminary data, briefly presenting perceptions and practices of students in math's learning with AR contents. Finally, we conclude that the challenges that are nowadays put to teaching methods, acquisition and subsequent knowledge consolidation may be met, to some extent, by the application of available technologies. These, in turn, should enhance a more complete understanding of contents, leading to knowledge endogenization and also to the internalization of more sustained competencies. Among those technologies, we highlight augmented reality since it can encourage motivation, comprehension and a higher involvement with the contents to be learned. Thus, it may increase the use of information and the access to knowledge, improving digital and info-inclusion.
ER  - 

TY  - JOUR
T1  - An approach for detecting, quantifying, and visualizing the evolution of a research field: A practical application to the Fuzzy Sets Theory field
JO  - Journal of Informetrics
VL  - 5
IS  - 1
SP  - 146
EP  - 166
PY  - 2011/1//
T2  - 
AU  - Cobo, M.J.
AU  - López-Herrera, A.G.
AU  - Herrera-Viedma, E.
AU  - Herrera, F.
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2010.10.002
UR  - http://www.sciencedirect.com/science/article/pii/S1751157710000891
KW  - Science mapping
KW  - Co-word analysis
KW  - Bibliometric studies
KW  - Fuzzy Sets Theory
KW  - Thematic evolution
KW  - h-Index
AB  - This paper presents an approach to analyze the thematic evolution of a given research field. This approach combines performance analysis and science mapping for detecting and visualizing conceptual subdomains (particular themes or general thematic areas). It allows us to quantify and visualize the thematic evolution of a given research field. To do this, co-word analysis is used in a longitudinal framework in order to detect the different themes treated by the research field across the given time period. The performance analysis uses different bibliometric measures, including the h-index, with the purpose of measuring the impact of both the detected themes and thematic areas. The presented approach includes a visualization method for showing the thematic evolution of the studied field.

Then, as an example, the thematic evolution of the Fuzzy Sets Theory field is analyzed using the two most important journals in the topic: Fuzzy Sets and Systems and IEEE Transactions on Fuzzy Systems.
ER  - 

TY  - JOUR
T1  - Toward a taxonomy of career studies through bibliometric visualization
JO  - Journal of Vocational Behavior
VL  - 85
IS  - 3
SP  - 339
EP  - 351
PY  - 2014/12//
T2  - 
AU  - Lee, Colin I.S.G.
AU  - Felps, Will
AU  - Baruch, Yehuda
SN  - 0001-8791
DO  - http://dx.doi.org/10.1016/j.jvb.2014.08.008
UR  - http://www.sciencedirect.com/science/article/pii/S0001879114001092
KW  - Careers
KW  - Career studies
KW  - Career theory
KW  - Science maps
KW  - Bibliometrics
AB  - Abstract
One of the greatest strengths and liabilities of the career field is its diversity. This diversity allows for wide coverage of relevant career dynamics across the lifespan and across levels of analysis. However, this diversity also reflects fragmentation, with career scholars failing to appreciate how the insights from other thought worlds can advance their own work. Using advanced bibliometric mapping techniques, we provide a systematic review of the 3141 articles on careers published in the management literature between 1990 and 2012. In doing so, we (1) map key terms to create a systematic taxonomy of career studies within the field of management studies, (2) provide a synthetic overview of each topic cluster which extends prior reviews of more limited scope, and (3) identify the most highly influential studies on careers within each cluster. Specifically, six local clusters emerged — i.e., international careers, career management, career choice, career adaptation, individual and relational career success, and life opportunities. To classify a broad range of research opportunities for career scholars, we also create a “global” map of 16,146 career articles from across the social sciences. Specifically, six global clusters emerged — i.e., organizational, individual, education, doctorate careers, high-profile careers, and social policy. We describe and compare the clusters in the map with an emphasis on those avenues career scholars in management have yet to explore.
ER  - 

TY  - JOUR
T1  - Large scale opinion mining for social, news and blog data
JO  - Journal of Systems and Software
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Tsirakis, Nikos
AU  - Poulopoulos, Vasilis
AU  - Tsantilas, Panagiotis
AU  - Varlamis, Iraklis
SN  - 0164-1212
DO  - http://dx.doi.org/10.1016/j.jss.2016.06.012
UR  - http://www.sciencedirect.com/science/article/pii/S0164121216300814
KW  - Opinion mining
KW  - News streams
KW  - Social media
AB  - Abstract
Companies that collect and analyze data from social media, news and other data streams are faced with several challenges that concern storage and processing of huge amounts of data. When they want to serve the processed information to their customers and moreover, when they want to cover different information needs for each customer, they need solutions that process data in near real time in order to gain insights on the data in motion. The volume and volatility of opinionated data that is published in social media, in combination with the variety of data sources has created a demanding ecosystem for stream processing. Although, there are several solutions that can handle information of static nature and small volume quite efficiently, they usually do not scale up properly because of their high complexity. Moreover, such solutions have been designed to run once or to run in a fixed dataset and they are not sufficient for processing huge volumes of streamed data. To address this problem, a platform for real-time opinion mining is proposed. Based on prior research and real application services that have been developed, a new platform called “PaloPro” is presented to cover the needs for brand monitoring.
ER  - 

TY  - JOUR
T1  - Geodesic distance based fuzzy c-medoid clustering – searching for central points in graphs and high dimensional data
JO  - Fuzzy Sets and Systems
VL  - 286
IS  - 
SP  - 157
EP  - 172
PY  - 2016/3/1/
T2  - Theme: Images and Clustering
AU  - Király, András
AU  - Vathy-Fogarassy, Ágnes
AU  - Abonyi, János
SN  - 0165-0114
DO  - http://dx.doi.org/10.1016/j.fss.2015.06.022
UR  - http://www.sciencedirect.com/science/article/pii/S0165011415003115
KW  - Clustering
KW  - Fuzzy c-medoid
KW  - Centrality
KW  - Geodesic distance
AB  - Abstract
Clustering high dimensional data and identifying central nodes in a graph are complex and computationally expensive tasks. We utilize k-nn graph of high dimensional data as efficient representation of the hidden structure of the clustering problem. Initial cluster centers are determined by graph centrality measures. Cluster centers are fine-tuned by minimizing fuzzy-weighted geodesic distances. The shortest-path based representation is parallel to the concept of transitive closure. Therefore, our algorithm is capable to cluster networks or even more complex and abstract objects based on their partially known pairwise similarities.

The algorithm is proven to be effective to identify senior researchers in a co-author network, central cities in topographical data, and clusters of documents represented by high dimensional feature vectors.
ER  - 

TY  - JOUR
T1  - On the application of Bayesian Networks in Digital Soil Mapping
JO  - Geoderma
VL  - 259–260
IS  - 
SP  - 134
EP  - 148
PY  - 2015/12//
T2  - 
AU  - Taalab, K.
AU  - Corstanje, R.
AU  - Zawadzka, J.
AU  - Mayr, T.
AU  - Whelan, M.J.
AU  - Hannam, J.A.
AU  - Creamer, R.
SN  - 0016-7061
DO  - http://dx.doi.org/10.1016/j.geoderma.2015.05.014
UR  - http://www.sciencedirect.com/science/article/pii/S0016706115001688
KW  - Bayesian Networks
KW  - Soil
KW  - Bulk density
KW  - Expert knowledge
KW  - Mapping
KW  - Modelling
AB  - Abstract
Two corresponding issues concerning Digital Soil Mapping are the demand for up-to-date, fine resolution soil data and the need to determine soil–landscape relationships. In this study, we propose a Bayesian Network framework as a suitable modelling approach to fulfil these requirements. Bayesian Networks are graphical probabilistic models in which predictions are obtained using prior probabilities derived from either measured data or expert opinion. They represent cause and effect relationships through connections in a network system. The advantage of the Bayesian Networks approach is that the models are easy to interpret and the uncertainty inherent in the relationships between variables can be expressed in terms of probability. In this study we will define the fundamentals of a Bayesian Network and the probability theory that underpins predictions. Then, using case studies, we demonstrate how they can be applied to predict soil properties (bulk density) and soil taxonomic class (associations).
ER  - 

TY  - JOUR
T1  - Clustering web people search results using fuzzy ants
JO  - Information Sciences
VL  - 180
IS  - 17
SP  - 3192
EP  - 3209
PY  - 2010/9/1/
T2  - Including Special Section on Virtual Agent and Organization Modeling: Theory and Applications
AU  - Lefever, E.
AU  - Fayruzov, T.
AU  - Hoste, V.
AU  - De Cock, M.
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2010.05.018
UR  - http://www.sciencedirect.com/science/article/pii/S0020025510002215
KW  - Web People Search
KW  - Web Person Disambiguation
KW  - Document clustering
KW  - Fuzzy ant based clustering
AB  - Person name queries often bring up web pages that correspond to individuals sharing the same name. The Web People Search (WePS) task consists of organizing search results for ambiguous person name queries into meaningful clusters, with each cluster referring to one individual. This paper presents a fuzzy ant based clustering approach for this multi-document person name disambiguation problem. The main advantage of fuzzy ant based clustering, a technique inspired by the behavior of ants clustering dead nestmates into piles, is that no specification of the number of output clusters is required. This makes the algorithm very well suited for the Web Person Disambiguation task, where we do not know in advance how many individuals each person name refers to. We compare our results with state-of-the-art partitional and hierarchical clustering approaches (k-means and Agnes) and demonstrate favorable results. This is particularly interesting as the latter involve manual setting of a similarity threshold, or estimating the number of clusters in advance, while the fuzzy ant based clustering algorithm does not.
ER  - 

TY  - JOUR
T1  - A cross-paradigm macro-structure analysis of research articles in Information Systems
JO  - English for Specific Purposes
VL  - 45
IS  - 
SP  - 14
EP  - 30
PY  - 2017/1//
T2  - 
AU  - Kwan, Becky S.C.
SN  - 0889-4906
DO  - http://dx.doi.org/10.1016/j.esp.2016.08.002
UR  - http://www.sciencedirect.com/science/article/pii/S0889490616300710
KW  - Research articles
KW  - Cross-paradigm comparison
KW  - Macro-structures
KW  - Paradigm-specific macro-structures
AB  - Abstract
The study presented in this paper examined the macro-structures (MSs) of research articles (RAs) in Information Systems (IS). Unlike most previous MS studies, which have tended to look for a single unified MS model to represent the discipline under investigation and have provided post hoc explanations of intra-disciplinary variability, this study set out to examine how MSs of RAs in IS may vary with the epistemological paradigms they follow. Thirty articles of behavioural science research and thirty design science research articles were collected from eight IS journals. Their main sections were subjected to a series of analyses. Results show distinct macro-structural variations across the two corpora. Implications for teaching and future research of MS will be discussed.
ER  - 

TY  - JOUR
T1  - Object cosegmentation by nonrigid mapping
JO  - Neurocomputing
VL  - 135
IS  - 
SP  - 107
EP  - 116
PY  - 2014/7/5/
T2  - 
AU  - Liu, Zhao
AU  - Zhu, Jianke
AU  - Bu, Jiajun
AU  - Chen, Chun
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2013.12.050
UR  - http://www.sciencedirect.com/science/article/pii/S0925231214001763
KW  - Image segmentation
KW  - Cosegmentation
KW  - Nonrigid mapping
KW  - Deformable model
AB  - Abstract
Image segmentation is an important research topic in image processing and computer vision. Recently, cosegmentation has received more and more attention. Although lots of research efforts have already studied this problem in the case of single object, there still lacks the deep investigation on multiple objects cosegmentation. In this paper, we try to attack this challenge by transferring the foreground segmentations using nonrigid mapping. We present a framework, in which we first take advantage of deformable part models to detect the foreground regions across the images, and the segmentation is formulated as an energy minimization problem on pixel labeling. We have conducted a set of experiments on the FlickrMFC dataset and iCoseg dataset. The experimental results demonstrate that our proposed approach outperforms the state-of-the-art methods.
ER  - 

TY  - JOUR
T1  - Towards a canonical classical natural deduction system
JO  - Annals of Pure and Applied Logic
VL  - 164
IS  - 6
SP  - 618
EP  - 650
PY  - 2013/6//
T2  - Classical Logic and Computation 2010(CLAC 2010)
AU  - Espírito Santo, José
SN  - 0168-0072
DO  - http://dx.doi.org/10.1016/j.apal.2012.05.008
UR  - http://www.sciencedirect.com/science/article/pii/S016800721200084X
KW  - Classical logic
KW  - Sequent calculus
KW  - Natural deduction
KW  - Control operators
KW  - Let-expressions
KW  - Eta-reduction
AB  - This paper studies a new classical natural deduction system, presented as a typed calculus named λ ̲ μ let . It is designed to be isomorphic to Curien and Herbelinʼs λ ¯ μ μ ˜ -calculus, both at the level of proofs and reduction, and the isomorphism is based on the correct correspondence between cut (resp. left-introduction) in sequent calculus, and substitution (resp. elimination) in natural deduction. It is a combination of Parigotʼs λμ-calculus with the idea of “coercion calculus” due to Cervesato and Pfenning, accommodating let-expressions in a surprising way: they expand Parigotʼs syntactic class of named terms.

This calculus and the mentioned isomorphism Θ offer three missing components of the proof theory of classical logic: a canonical natural deduction system; a robust process of “read-back” of calculi in the sequent calculus format into natural deduction syntax; a formalization of the usual semantics of the λ ¯ μ μ ˜ -calculus, that explains co-terms and cuts as, respectively, contexts and hole-filling instructions. λ ̲ μ let is not yet another classical calculus, but rather a canonical reflection in natural deduction of the impeccable treatment of classical logic by sequent calculus; and Θ provides the “read-back” map and the formalized semantics, based on the precise notions of context and “hole-expression” provided by λ ̲ μ let .

We use “read-back” to achieve a precise connection with Parigotʼs λμ, and to derive λ-calculi for call-by-value combining control and let-expressions in a logically founded way. Finally, the semantics Θ, when fully developed, can be inverted at each syntactic category. This development gives us license to see sequent calculus as the semantics of natural deduction; and uncovers a new syntactic concept in λ ¯ μ μ ˜ (“co-context”), with which one can give a new definition of η-reduction.
ER  - 

TY  - JOUR
T1  - A novel XML document structure comparison framework based-on sub-tree commonalities and label semantics
JO  - Web Semantics: Science, Services and Agents on the World Wide Web
VL  - 11
IS  - 
SP  - 14
EP  - 40
PY  - 2012/3//
T2  - 
AU  - Tekli, Joe
AU  - Chbeir, Richard
SN  - 1570-8268
DO  - http://dx.doi.org/10.1016/j.websem.2011.10.002
UR  - http://www.sciencedirect.com/science/article/pii/S1570826811000825
KW  - XML (semi-structured) data
KW  - Structural similarity
KW  - Tree edit distance
KW  - Semantic similarity
KW  - Information retrieval
KW  - Vector space model
AB  - XML similarity evaluation has become a central issue in the database and information communities, its applications ranging over document clustering, version control, data integration and ranked retrieval. Various algorithms for comparing hierarchically structured data, XML documents in particular, have been proposed in the literature. Most of them make use of techniques for finding the edit distance between tree structures, XML documents being commonly modeled as Ordered Labeled Trees. Yet, a thorough investigation of current approaches led us to identify several similarity aspects, i.e., sub-tree related structural and semantic similarities, which are not sufficiently addressed while comparing XML documents. In this paper, we provide an integrated and fine-grained comparison framework to deal with both structural and semantic similarities in XML documents (detecting the occurrences and repetitions of structurally and semantically similar sub-trees), and to allow the end-user to adjust the comparison process according to her requirements. Our framework consists of four main modules for (i) discovering the structural commonalities between sub-trees, (ii) identifying sub-tree semantic resemblances, (iii) computing tree-based edit operations costs, and (iv) computing tree edit distance. Experimental results demonstrate higher comparison accuracy with respect to alternative methods, while timing experiments reflect the impact of semantic similarity on overall system performance.
ER  - 

TY  - JOUR
T1  - Co-production of knowledge–action systems in urban sustainable governance: The KASA approach
JO  - Environmental Science & Policy
VL  - 37
IS  - 
SP  - 182
EP  - 191
PY  - 2014/3//
T2  - 
AU  - Muñoz-Erickson, Tischa A.
SN  - 1462-9011
DO  - http://dx.doi.org/10.1016/j.envsci.2013.09.014
UR  - http://www.sciencedirect.com/science/article/pii/S1462901113002086
KW  - Co-production
KW  - Knowledge–action systems
KW  - Science–policy interface
KW  - Sustainability
KW  - Urban governance
KW  - Social networks
KW  - Boundary work
KW  - Epistemic cultures
KW  - Future visions
KW  - Tropical city
AB  - Abstract
This paper examines how knowledge–action systems – the networks of actors involved in the production, sharing and use of policy-relevant knowledge – work in the process of developing sustainable strategies for cities. I developed an interdisciplinary framework – the knowledge–action system analysis (KASA) framework – that integrates concepts of the co-production of knowledge and social order with social network analysis tools to analyze existing configurations of knowledge–action systems in the city of San Juan, Puerto Rico, and how these are shaping both what we know and how we envision the future of cities. I applied KASA in the context of land use and green area governance and found that a diverse network of actors are contributing diverse knowledge types, thus showing potential for innovation in governance. This potential is conditioned, however, by various political and cultural factors, such as: (1) actors dominating knowledge about land use are the same ones that control urban land resources, (2) conventional planning expertise and procedures dominate over other alternative ways of knowing; (3) multiple visions and boundary arrangements co-exist in the city, and (4) boundary spanning opportunities limited by assumptions that knowledge and action should be done in distinct spheres of city planning. This study shows that developing adaptive and innovative capacities for sustainability is not solely a matter of harnessing more science, but about managing the politics of knowledge and visions that emerge from complex governance systems.
ER  - 

TY  - JOUR
T1  - Mapping altruism
JO  - Journal of Informetrics
VL  - 8
IS  - 2
SP  - 431
EP  - 447
PY  - 2014/4//
T2  - 
AU  - Klavans, Richard
AU  - Boyack, Kevin W.
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2014.02.002
UR  - http://www.sciencedirect.com/science/article/pii/S1751157714000285
KW  - Altruism
KW  - Non-profit organizations
KW  - Topic modeling
KW  - Science mapping
AB  - Abstract
A great deal of work has been done to understand how science contributes to technological innovation and medicine. This is no surprise given the amount of money invested annually in R&amp;D. However, what is not well known is that US science (R&amp;D) investment is only one-sixth that of the annual revenue received by non-profit organizations (NPOs) in the US. The large majority of NPO revenues are devoted to the remaining landscape of altruistic causes – those not relying as heavily on scientific inquiry. Given this broader context, one might reasonably expect the non-profit world to have been as well characterized as that of scientific research. The unfortunate truth is that no map of altruistic missions and causes exists; the landscape of altruistic activity is virtually unknown. In this paper, we present the first maps of altruistic mission space. These maps were created using the text from websites of 125,000 non-profit organizations (NPOs) in the US. The maps consist of 357 topics covering areas such as religion, education, sports, culture, human services, public policy and medical care. The role of science in this altruistic landscape is examined. Possible applications are discussed.
ER  - 

TY  - JOUR
T1  - THE GROWTH AND IMPACT OF ADNI GENETICS PUBLICATIONS AS MEASURED BY SCIENCE MAPPING
JO  - Alzheimer's & Dementia
VL  - 12
IS  - 7, Supplement
SP  - P60
EP  - P61
PY  - 2016/7//
T2  - 2016 Abstract Supplement
AU  - Yao, Xiaohui
AU  - Yan, Jingwen
AU  - Ginda, Michael
AU  - Börner, Katy
AU  - Kim, Sungeun
AU  - Nho, Kwangsik
AU  - Risacher, Shannon L.
AU  - Foroud, Tatiana M.
AU  - Potkin, Steven G.
AU  - Thompson, Paul M.
AU  - Moore, Jason H.
AU  - Weiner, Michael W.
AU  - Saykin, Andy J.
AU  - Shen, Li
SN  - 1552-5260
DO  - http://dx.doi.org/10.1016/j.jalz.2016.06.105
UR  - http://www.sciencedirect.com/science/article/pii/S1552526016304071
ER  - 

TY  - JOUR
T1  - THE GROWTH AND IMPACT OF ADNI GENETICS PUBLICATIONS AS MEASURED BY SCIENCE MAPPING
JO  - Alzheimer's & Dementia
VL  - 12
IS  - 7, Supplement
SP  - P725
EP  - P726
PY  - 2016/7//
T2  - 2016 Abstract Supplement
AU  - Yao, Xiaohui
AU  - Yan, Jingwen
AU  - Ginda, Michael
AU  - Börner, Katy
AU  - Kim, Sungeun
AU  - Nho, Kwangsik
AU  - Risacher, Shannon L.
AU  - Foroud, Tatiana M.
AU  - Potkin, Steven G.
AU  - Thompson, Paul M.
AU  - Moore, Jason H.
AU  - Weiner, Michael W.
AU  - Saykin, Andy J.
AU  - Shen, Li
SN  - 1552-5260
DO  - http://dx.doi.org/10.1016/j.jalz.2016.06.1427
UR  - http://www.sciencedirect.com/science/article/pii/S1552526016317290
ER  - 

TY  - JOUR
T1  - Mapping Human Resource Management: Reviewing the field and charting future directions
JO  - Human Resource Management Review
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Markoulli, Maria
AU  - Lee, Colin I.S.G.
AU  - Byington, Eliza
AU  - Felps, Will A.
SN  - 1053-4822
DO  - http://dx.doi.org/10.1016/j.hrmr.2016.10.001
UR  - http://www.sciencedirect.com/science/article/pii/S1053482216300699
KW  - Human Resource Management
KW  - Science mapping
KW  - Bibliometric
KW  - Research-practice gap
AB  - Abstract
Using recent advances in science mapping, this article systematically reviews the Human Resource Management (HRM) field. We analyze 12,157 HRM research articles published over 23 years to reveal the topic content and intellectual structure of HRM scholarship. A downloadable, searchable HRM topic map is provided (http://bit.ly/HRM-Map) that reveals: a) 1702 HRM article topics, b) the number of articles on each topic, c) topic relations, trends, and impact, and d) five major HRM topic clusters. We discuss the overall intellectual structure of HRM scholarship and review the five topic clusters. Next, the topic content of HRM scholarship is compared to that of 6114 articles from the practitioner-oriented outlet HR Magazine. We identify 100 topics emphasized to a much greater degree in the practitioner-oriented literature. Seven key themes for future research that could help align HRM scholarship with the interests of HR practitioners are identified and discussed.
ER  - 

TY  - JOUR
T1  - Robust and efficient analysis of signals and images
JO  - Pattern Recognition Letters
VL  - 31
IS  - 6
SP  - 445
EP  - 446
PY  - 2010/4/15/
T2  - CIARP 2008: Robust and Efficient Analysis of Signals and Images
AU  - Kropatsch, Walter G.
AU  - Ruiz-Shulcloper, José
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2010.01.023
UR  - http://www.sciencedirect.com/science/article/pii/S0167865510000322
ER  - 

TY  - JOUR
T1  - Building semantic trees from XML documents
JO  - Web Semantics: Science, Services and Agents on the World Wide Web
VL  - 37–38
IS  - 
SP  - 1
EP  - 24
PY  - 2016/3//
T2  - 
AU  - Tekli, Joe
AU  - Charbel, Nathalie
AU  - Chbeir, Richard
SN  - 1570-8268
DO  - http://dx.doi.org/10.1016/j.websem.2016.03.002
UR  - http://www.sciencedirect.com/science/article/pii/S1570826816000202
KW  - XML and Semi-structured data
KW  - Word sense disambiguation
KW  - Semantic-aware processing
KW  - Semantic ambiguity
KW  - Context representation
KW  - Knowledge bases
AB  - Abstract
The distributed nature of the Web, as a decentralized system exchanging information between heterogeneous sources, has underlined the need to manage interoperability, i.e., the ability to automatically interpret information in Web documents exchanged between different sources, necessary for efficient information management and search applications. In this context, XML was introduced as a data representation standard that simplifies the tasks of interoperation and integration among heterogeneous data sources, allowing to represent data in (semi-) structured documents consisting of hierarchically nested elements and atomic attributes. However, while XML was shown most effective in exchanging data, i.e., in syntactic interoperability, it has been proven limited when it comes to handling semantics, i.e.,  semantic interoperability, since it only specifies the syntactic and structural properties of the data without any further semantic meaning. As a result, XML semantic-aware processing has become a motivating challenge in Web data management, requiring dedicated semantic analysis and disambiguation methods to assign well-defined meaning to XML elements and attributes. In this context, most existing approaches: (i) ignore the problem of identifying ambiguous XML elements/nodes, (ii) only partially consider their structural relationships/context, (iii) use syntactic information in processing XML data regardless of the semantics involved, and (iv) are static in adopting fixed disambiguation constraints thus limiting user involvement. In this paper, we provide a new XML Semantic Disambiguation Framework titled XSDFdesigned to address each of the above limitations, taking as input: an XML document, and then producing as output a semantically augmented XML tree made of unambiguous semantic concepts extracted from a reference machine-readable semantic network. XSDF consists of four main modules for: (i) linguistic pre-processing of simple/compound XML node labels and values, (ii) selecting ambiguous XML nodes as targets for disambiguation, (iii) representing target nodes as special sphere neighborhood vectors including all XML structural relationships within a (user-chosen) range, and (iv) running context vectors through a hybrid disambiguation process, combining two approaches: concept-basedand context-based disambiguation, allowing the user to tune disambiguation parameters following her needs. Conducted experiments demonstrate the effectiveness and efficiency of our approach in comparison with alternative methods. We also discuss some practical applications of our method, ranging over semantic-aware query rewriting, semantic document clustering and classification, Mobile and Web services search and discovery, as well as blog analysis and event detection in social networks and tweets.
ER  - 

TY  - JOUR
T1  - Including cited non-source items in a large-scale map of science: What difference does it make?
JO  - Journal of Informetrics
VL  - 8
IS  - 3
SP  - 569
EP  - 580
PY  - 2014/7//
T2  - 
AU  - Boyack, Kevin W.
AU  - Klavans, Richard
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2014.04.001
UR  - http://www.sciencedirect.com/science/article/pii/S1751157714000406
KW  - Science mapping
KW  - Direct citation
KW  - Non-source documents
KW  - Books
AB  - Abstract
Cited non-source documents such as articles from regional journals, conference papers, books and book chapters, working papers and reports have begun to attract more attention in the literature. Most of this attention has been directed at understanding the effects of including non-source items in research evaluation. In contrast, little work has been done to examine the effects of including non-source items on science maps and on the structure of science as reflected by those maps. In this study we compare two direct citation maps of a 16-year set of Scopus documents – one that includes only source documents, and one that includes non-source documents along with the source documents. In addition to more than doubling the contents of the map, from 19 M to 43 M documents, the inclusion of non-source items strongly augments the social sciences relative to the natural sciences and medicine and makes their position in the map more central. Books are also found to play a significant role in the map, and are much more highly cited on average than articles.
ER  - 

TY  - JOUR
T1  - SMOTE–IPF: Addressing the noisy and borderline examples problem in imbalanced classification by a re-sampling method with filtering
JO  - Information Sciences
VL  - 291
IS  - 
SP  - 184
EP  - 203
PY  - 2015/1/10/
T2  - 
AU  - Sáez, José A.
AU  - Luengo, Julián
AU  - Stefanowski, Jerzy
AU  - Herrera, Francisco
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2014.08.051
UR  - http://www.sciencedirect.com/science/article/pii/S0020025514008561
KW  - Imbalanced classification
KW  - Borderline examples
KW  - Noisy data
KW  - Noise filters
KW  - SMOTE
AB  - Abstract
Classification datasets often have an unequal class distribution among their examples. This problem is known as imbalanced classification. The Synthetic Minority Over-sampling Technique (SMOTE) is one of the most well-know data pre-processing methods to cope with it and to balance the different number of examples of each class. However, as recent works claim, class imbalance is not a problem in itself and performance degradation is also associated with other factors related to the distribution of the data. One of these is the presence of noisy and borderline examples, the latter lying in the areas surrounding class boundaries. Certain intrinsic limitations of SMOTE can aggravate the problem produced by these types of examples and current generalizations of SMOTE are not correctly adapted to their treatment.

This paper proposes the extension of SMOTE through a new element, an iterative ensemble-based noise filter called Iterative-Partitioning Filter (IPF), which can overcome the problems produced by noisy and borderline examples in imbalanced datasets. This extension results in SMOTE–IPF. The properties of this proposal are discussed in a comprehensive experimental study. It is compared against a basic SMOTE and its most well-known generalizations. The experiments are carried out both on a set of synthetic datasets with different levels of noise and shapes of borderline examples as well as real-world datasets. Furthermore, the impact of introducing additional different types and levels of noise into these real-world data is studied. The results show that the new proposal performs better than existing SMOTE generalizations for all these different scenarios. The analysis of these results also helps to identify the characteristics of IPF which differentiate it from other filtering approaches.
ER  - 

TY  - JOUR
T1  - Would you like to know who knows? Connecting employees based on process-oriented knowledge mapping
JO  - Decision Support Systems
VL  - 87
IS  - 
SP  - 94
EP  - 104
PY  - 2016/7//
T2  - 
AU  - Leyer, Michael
AU  - Schneider, Christian
AU  - Claus, Nina
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2016.05.003
UR  - http://www.sciencedirect.com/science/article/pii/S0167923616300768
KW  - Knowledge management
KW  - Business processes
KW  - Information system
KW  - System evaluation
AB  - Abstract
Employees' knowledge as the guarantor of companies' success is an important asset of the enterprises' value. However, this knowledge is often not optimally used or even visible and available for employees and management within companies. This intangible knowledge leads to continuously reinvented wheels within organisations and employees misspend time learning processes in a cumbersome way on their own. To overcome this problem, we present a new approach aimed at connecting employees socially. The main novelty is the use of the organisation's business processes as basis for connecting employees by indicating their process-related areas of expertise. The goal is to enable enduring sharing and distribution of knowledge within an organisation to support decision making in process execution. Our evaluation results from two financial services companies show that employees perceive such a network as very helpful. Our approach leads to easier access, better search results and more opportunities to connect knowledge with other employees.
ER  - 

TY  - JOUR
T1  - Characteristics and trends of research on waste-to-energy incineration: A bibliometric analysis, 1999–2015
JO  - Renewable and Sustainable Energy Reviews
VL  - 66
IS  - 
SP  - 95
EP  - 104
PY  - 2016/12//
T2  - 
AU  - Wang, Yuan
AU  - Lai, Nan
AU  - Zuo, Jian
AU  - Chen, Guanyi
AU  - Du, Huibin
SN  - 1364-0321
DO  - http://dx.doi.org/10.1016/j.rser.2016.07.006
UR  - http://www.sciencedirect.com/science/article/pii/S1364032116303343
KW  - Bibliometrics
KW  - Incineration
KW  - Statistical analysis
KW  - Co-words analysis
KW  - Waste-to-energy
AB  - Abstract
This study aims to provide an up-to-date contemporary bibliometric view of the waste-to-energy incineration literature and a correlative analysis of this field. Based on the bibliometric method, a statistical analysis was undertaken on papers published from 1999 to 2015 in Science Citation Index (SCI) and the Social Science Citation Index (SSCI). There were 4348 publications in the field of waste-to-energy incineration. The number of publications per year has increased steadily since 2009. China produced 15.71% of all pertinent articles followed by Japan with 11.37% and USA with 7.97%. China has played a key role in the collaboration network of 30 most productive countries and regions. In addition, the cooperation within the European countries was notable. However, China ranked first in all aspects except h-index. This means China's impact (number of citations) in this field could be further strengthened though its quantity (number of publications) was the highest. Five clusters were identified from keywords networks, i.e. Central Cluster node (“combustion”), Cluster(I) (central nodes were “fly ash”,” heavy metal(s)” and “bottom ash”), Cluster(II) (central nodes were dioxin-related substances), Clusters(III) (central nodes focused on waste management), and Cluster(IV) “chemistry methods”. These findings are useful for the future endeavor of waste-to-energy incineration academic research.
ER  - 

TY  - JOUR
T1  - Evolución de la literatura sobre empresa familiar como disciplina científica
JO  - Cuadernos de Economía y Dirección de la Empresa
VL  - 14
IS  - 2
SP  - 78
EP  - 90
PY  - 2011/4//
Y2  - 2011/6//
T2  - 
AU  - Benavides Velasco, Carlos A.
AU  - Guzmán Parra, Vanesa F.
AU  - Quintana García, Cristina
SN  - 1138-5758
DO  - http://dx.doi.org/10.1016/j.cede.2011.02.004
UR  - http://www.sciencedirect.com/science/article/pii/S1138575811000107
KW  - Bibliometría
KW  - Empresa familiar
KW  - Indicadores de actividad
KW  - Co-palabras
KW  - Metodología
KW  - Bibliometrics
KW  - Family firm
KW  - Activity indicators
KW  - Co-words
KW  - Methodology
AB  - Resumen
El presente trabajo describe la evolución de la investigación en empresa familiar en el período 1961-2008 a través del análisis de los contenidos de los artículos sobre dicha temática publicados en revistas indexadas en el Social Science Citation Index; este proceso ha llevado a la creación de una base de datos de 684 documentos. La aplicación de métodos y técnicas bibliométricas ha permitido reflejar la evolución del nivel de publicaciones, instituciones activas, metodologías empleadas y principales temas de investigación tratados. Teniendo en cuenta los resultados obtenidos, se proponen líneas futuras de investigación que permitan avanzar en la consolidación del estudio de la empresa familiar como disciplina científica.

This paper describes the evolution of the family firm research over the 1961-2008 time period. We have compiled a database of the 684 articles focused on the field published in journals included in the Social Science Citation Index. Bibliometric methods and techniques are used to describe the evolution of publication activity, the most active institutions, the methodologies applied, and the main subjects researched. Based on these analyses, potential avenues for future research are proposed to advance in the consolidation of the field as a scientific discipline.
ER  - 

TY  - JOUR
T1  - Transactive directories of organizational memory: Towards a working data model
JO  - Information & Management
VL  - 49
IS  - 2
SP  - 118
EP  - 125
PY  - 2012/3//
T2  - 
AU  - Jackson, Paul
SN  - 0378-7206
DO  - http://dx.doi.org/10.1016/j.im.2012.01.002
UR  - http://www.sciencedirect.com/science/article/pii/S0378720612000110
KW  - Transactive memory systems
KW  - Organizational memory
KW  - Organizational learning
KW  - Knowledge mapping
KW  - Knowledge sharing
AB  - Transactive memory system is a term from group psychology that describes a system that helps small groups maintain and use personal directories to allocate and retrieve knowledge. Such systems have been observed at the level of whole organizations, suggesting that they provide a means for conceptualizing the exploitation of organizational memory. In this paper, I describe a longitudinal investigation of a global engineering consulting firm in which I used inductive analysis of interview data to map and then develop a conceptual entity-relationship model of organizational memory. This model formed the basis for a transactive directory to facilitate knowledge retrieval and allocation in the firm.
ER  - 

TY  - JOUR
T1  - Expert knowledge sourcing for public health surveillance: National tsetse mapping in Uganda
JO  - Social Science & Medicine
VL  - 91
IS  - 
SP  - 246
EP  - 255
PY  - 2013/8//
T2  - 
AU  - Berrang-Ford, Lea
AU  - Garton, Kelly
SN  - 0277-9536
DO  - http://dx.doi.org/10.1016/j.socscimed.2013.03.011
UR  - http://www.sciencedirect.com/science/article/pii/S0277953613001640
KW  - Expert knowledge
KW  - Mapping
KW  - GIS
KW  - Tsetse
KW  - Trypanosomiasis
KW  - Uganda
KW  - Africa
KW  - Glossina
AB  - Abstract
In much of sub-Saharan Africa, availability of standardized and reliable public health data is poor or negligible. Despite continued calls for the prioritization of improved health datasets in poor regions, public health surveillance remains a significant global health challenge.

Alternate approaches to surveillance and collection of public health data have thus garnered increasing interest, though there remains relatively limited research evaluating these approaches for public health. Herein, we present a case study applying and evaluating the use of expert knowledge sources for public health dataset development, using the case of vector distributions of Human African Trypanosomiasis (HAT) in Uganda. Specific objectives include: 1) Review the use of expert knowledge sourcing methods for public health surveillance, 2) Review current knowledge on tsetse vector distributions of public health importance in Uganda and the methods used for tsetse mapping in Africa; 3) Quantify confidence of the presence or absence of tsetse flies in Uganda based on expert informant reports, and 4) Assess the reliability and potential utility of expert knowledge sourcing as an alternative or complimentary method for public health surveillance in general and tsetse mapping in particular. Information on tsetse presence or absence, and associated confidence, was collected through interviews with District Entomologist and Veterinary Officers to develop a database of tsetse distributions for 952 sub-counties in Uganda. Results show high consistency with existing maps, indicating potential reliability of modeling approaches, though failing to provide evidence for successful tsetse control in past decades. Expert-sourcing methods provide a novel, low-cost and rapid complimentary approach for triangulating data from prediction modeling where field-based validation is not feasible. Data quality is dependent, however, on the level of expertise and documentation to support confidence levels for data reporting. Results highlight the need for increased evaluation of alternate approaches and methods to data collection.
ER  - 

TY  - JOUR
T1  - Mapping local spatial knowledge in the assessment of agricultural systems: A case study on the provision of agricultural services
JO  - Applied Geography
VL  - 42
IS  - 
SP  - 23
EP  - 33
PY  - 2013/8//
T2  - 
AU  - Debolini, M.
AU  - Marraccini, E.
AU  - Rizzo, D.
AU  - Galli, M.
AU  - Bonari, E.
SN  - 0143-6228
DO  - http://dx.doi.org/10.1016/j.apgeog.2013.04.006
UR  - http://www.sciencedirect.com/science/article/pii/S0143622813000921
KW  - Map-based interview
KW  - Integrative research
KW  - Qualitative data
KW  - Spatial analysis
KW  - Tuscany
KW  - Agricultural planning
AB  - Abstract
Interest in spatial evaluation to develop comprehensive strategies to plan and manage agricultural systems and to assess the impact of agricultural policies has been growing among policy-makers and scientists. Innovative methods of acquiring and processing spatial data and information related to agricultural topics have therefore been gaining attention. In this context, place-based and experiential knowledge of local actors has been recognized as an important source of data, especially for decision-making and planning. Several methods have been proposed in the literature for retrieving and analyzing this knowledge. Our aim was to analyze the capability of one of these methods (the mapping of local spatial knowledge) to identify the organizational gaps in the provision of agricultural services in rural areas. The method consisted of an interview supported with a fixed-scale map; the goal of the interview was to retrieve both spatial data and descriptive information (local spatial knowledge mapping) for GIS processing. Map-based interviews were conducted with 26 representative collective structures of the Grosseto (central Italy) agro-food system. Five agricultural systems (field crops, livestock, viticulture, olive-growing, and fruit-growing/horticulture) and five services (stocking/selling of farm products, technical advising, sale of farm inputs, promotion and contract services) were identified by local spatial knowledge. The main organizational and spatial gaps were assessed in each agricultural system for the following: (a) the number, typology and combinations of supplied services and (b) the overlap of operational areas of the agro-food system structures with the areas reported as being suitable for the five agricultural systems. This analysis allowed us to identify the benefits and drawbacks related to the spatial configurations that determine the provision of agricultural services for local farming activities.
ER  - 

TY  - JOUR
T1  - A bibliometric investigation of research performance in emerging nanobiopharmaceuticals
JO  - Journal of Informetrics
VL  - 5
IS  - 2
SP  - 233
EP  - 247
PY  - 2011/4//
T2  - 
AU  - Chen, Kaihua
AU  - Guan, Jiancheng
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2010.10.007
UR  - http://www.sciencedirect.com/science/article/pii/S1751157710000945
KW  - Nanobiopharmaceutics
KW  - Growth pattern
KW  - Cross-country comparisons
KW  - Intellectual structure and evolutions
KW  - Bibliometric study
KW  - Co-occurrence analysis
KW  - Visual mapping
AB  - The three important research domains, nanotechnology, biotechnology and pharmaceuticals, integratedly breed a promising multidisciplinary domain in the post-genomic age, which was recently defined by the term “nanobiopharmaceuticals”. In this paper, we firstly investigate its general development profiles, and then implement cross-country comparisons in its research performances, with the focus on the world share, relative research effort, impact and quality of five productive countries. Furthermore, from the science mapping perspective, we build the co-word and co-citation networks respectively for detecting its intellectual structure as well as evolution footprints of intellectual turning points. The growth examinations based on the datasets from WoS, MEDLINE and BIOSIS Review confirm the exponential growth of publications and citations in nanobiopharm-research. The cross-country comparisons show that USA is the leading country, and China is an up-and-coming contributor. The visual mapping structures by co-occurrence analyses show that nanobiopharm-research is currently focused on the drug development for improving biodistribution, bioavailability and pharmacokinetics, and the drug delivery for improving delivery of existing drugs. Some pivot publications is identified by CiteSpace, which work as structural holes, research fronts and intellectual bases for the nanobiopharm-research development in the given time window.
ER  - 

TY  - JOUR
T1  - Characterizing the emergence of two nanotechnology topics using a contemporaneous global micro-model of science
JO  - Journal of Engineering and Technology Management
VL  - 32
IS  - 
SP  - 147
EP  - 159
PY  - 2014/4//
Y2  - 2014/6//
T2  - Special Issue on Emergence of Technologies: Methods and Tools for Management
AU  - Boyack, Kevin W.
AU  - Klavans, Richard
AU  - Small, Henry
AU  - Ungar, Lyle
SN  - 0923-4748
DO  - http://dx.doi.org/10.1016/j.jengtecman.2013.07.001
UR  - http://www.sciencedirect.com/science/article/pii/S0923474813000386
KW  - Emergence
KW  - Emerging technologies
KW  - Hot topics
KW  - Graphene
KW  - Science mapping
AB  - Abstract
This study presents a methodology that can be used to characterize emergent topics within the context of a contemporaneous, global micro-model of the scientific literature. To illustrate its effectiveness, two known emergent nanotechnology topics (graphene and dye-sensitized solar cells) are characterized. We show that the model and methodology are suitable for characterizing the emergence of topics as they are emerging. In addition, we show that the two topics follow two different patterns of emergence – one where topic is not focused but then grows explosively, and one in which the topic quickly becomes an area of focus and grows steadily.
ER  - 

TY  - JOUR
T1  - CitNetExplorer: A new software tool for analyzing and visualizing citation networks
JO  - Journal of Informetrics
VL  - 8
IS  - 4
SP  - 802
EP  - 823
PY  - 2014/10//
T2  - 
AU  - van Eck, Nees Jan
AU  - Waltman, Ludo
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2014.07.006
UR  - http://www.sciencedirect.com/science/article/pii/S1751157714000662
KW  - Citation network
KW  - CitNetExplorer
KW  - Computer software
KW  - Network analysis
KW  - Visualization
AB  - Abstract
We present CitNetExplorer, a new software tool for analyzing and visualizing citation networks of scientific publications. CitNetExplorer can for instance be used to study the development of a research field, to delineate the literature on a research topic, and to support literature reviewing. We first introduce the main concepts that need to be understood when working with CitNetExplorer. We then demonstrate CitNetExplorer by using the tool to analyze the scientometric literature and the literature on community detection in networks. Finally, we discuss some technical details on the construction, visualization, and analysis of citation networks in CitNetExplorer.
ER  - 

TY  - JOUR
T1  - Investigating biofuels through network analysis
JO  - Energy Policy
VL  - 97
IS  - 
SP  - 60
EP  - 72
PY  - 2016/10//
T2  - 
AU  - Curci, Ylenia
AU  - Mongeau Ospina, Christian A.
SN  - 0301-4215
DO  - http://dx.doi.org/10.1016/j.enpol.2016.07.001
UR  - http://www.sciencedirect.com/science/article/pii/S0301421516303536
KW  - Biofuel
KW  - Innovation
KW  - Patent data
KW  - Topic model
KW  - Text mining
KW  - Network analysis
AB  - Abstract
Biofuel policies are motivated by a plethora of political concerns related to energy security, environmental damages, and support of the agricultural sector. In response to this, much scientific work has chiefly focussed on analysing the biofuel domain and on giving policy advice and recommendations. Although innovation has been acknowledged as one of the key factors in sustainable and cost-effective biofuel development, there is an urgent need to investigate technological trajectories in the biofuel sector by starting from consistent data and appropriate methodological tools. To do so, this work proposes a procedure to select patent data unequivocally related to the investigated sector, it uses co-occurrence of technological terms to compute patent similarity and highlights content and interdependencies of biofuels technological trajectories by revealing hidden topics from unstructured patent text fields. The analysis suggests that there is a breaking trend towards modern generation biofuels and that innovators seem to focus increasingly on the ability of alternative energy sources to adapt to the transport/industrial sector.
ER  - 

TY  - JOUR
T1  - Supervised input space scaling for non-negative matrix factorization
JO  - Signal Processing
VL  - 92
IS  - 8
SP  - 1864
EP  - 1874
PY  - 2012/8//
T2  - Latent Variable Analysis and Signal Separation
AU  - Driesen, J.
AU  - Van hamme, H.
SN  - 0165-1684
DO  - http://dx.doi.org/10.1016/j.sigpro.2011.07.016
UR  - http://www.sciencedirect.com/science/article/pii/S0165168411002507
KW  - Machine learning
KW  - Pattern detection
KW  - Feature selection
KW  - Automatic relevance determination
KW  - Vocabulary acquisition
KW  - Document clustering
AB  - Discovering structure within a collection of high-dimensional input vectors is a problem that often recurs in the area of machine learning. A very suitable and widely used algorithm for solving such tasks is Non-negative Matrix Factorization (NMF). The high-dimensional vectors are arranged as columns in a data matrix, which is decomposed into two non-negative matrix factors of much lower rank. Here, we adopt the NMF learning scheme proposed by Van hamme (2008) [1]. It involves combining the training data with supervisory data, which imposes the low-dimensional structure known to be present. The reconstruction of such supervisory data on previously unseen inputs then reveals their underlying structure in an explicit way. It has been noted that for many problems, not all features of the training data correlate equally well with the underlying structure. In other words, some features are relevant for detecting patterns in the data, while others are not. In this paper, we propose an algorithm that builds upon the learning scheme of Van hamme (2008) [1], and automatically weights each input feature according to its relevance. Applications include both data improvement and feature selection. We experimentally show that our algorithm outperforms similar techniques on both counts.
ER  - 

TY  - JOUR
T1  - Antecedents and determinants of information technology habit
JO  - Information & Management
VL  - 47
IS  - 5–6
SP  - 300
EP  - 307
PY  - 2010/8//
T2  - 
AU  - Lankton, Nancy K.
AU  - Wilson, E. Vance
AU  - Mao, En
SN  - 0378-7206
DO  - http://dx.doi.org/10.1016/j.im.2010.06.004
UR  - http://www.sciencedirect.com/science/article/pii/S0378720610000534
KW  - Habit
KW  - Continued IT use
KW  - Satisfaction
KW  - Group analysis
KW  - PLS
AB  - IT researchers have recently distinguished habits from prior behavior frequency. We expanded this research by examining habit's antecedents and investigating the simultaneous effect of habit and prior IT use on continued IT use. We found that the research model was relatively robust over four specific use activities of one software application. Indeed, prior IT use, satisfaction, and importance significantly influenced IT habits. Also, while prior IT use predicted continued IT use in the combined data set, habit only predicted continued IT use for activities with higher habit levels. Practical implications are discussed.
ER  - 

TY  - JOUR
T1  - Labeling of Web Search Result Clusters Using Heuristic Search and Frequent Itemset
JO  - Procedia Computer Science
VL  - 46
IS  - 
SP  - 216
EP  - 222
PY  - 2015///
T2  - Proceedings of the International Conference on Information and Communication Technologies, ICICT 2014, 3-5 December 2014 at Bolgatty Palace &amp; Island Resort, Kochi, India
AU  - Alam, Mansaf
AU  - Sadaf, Kishwar
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.02.014
UR  - http://www.sciencedirect.com/science/article/pii/S1877050915000782
KW  - Web search result clustering
KW  - cluster labeling
KW  - heuristic search.
AB  - Abstract
Clustering of search result is undoubtedly a tool that can provide the summarization of the millions of documents in a way where a user can easily locate his/her information. To guide user to the right cluster of documents, cluster labels should be meaningful and correctly representing the clusters. However significant a cluster is, if the label is not proper, user will never select it. In this paper, we present a method to label clusters based on their linking information. Our cluster labeling method is independent of any clustering method but restricted to only search result documents. We use heuristic search method to find all the linked documents of a cluster. If all or some documents of a cluster share hyperlinks, then we deduce label from these linked documents’ titles using famous Apriori algorithm for frequent itemset mining. This removes the requirement of reviewing other members of a cluster in labeling process.
ER  - 

TY  - JOUR
T1  - A VNS-based quartet algorithm for biomedical literature clustering
JO  - Electronic Notes in Discrete Mathematics
VL  - 47
IS  - 
SP  - 13
EP  - 20
PY  - 2015/2//
T2  - The 3rd International Conference on Variable Neighborhood 
Search (VNS'14)
AU  - Consoli, Sergio
AU  - Stilianakis, Nikolaos I.
SN  - 1571-0653
DO  - http://dx.doi.org/10.1016/j.endm.2014.11.003
UR  - http://www.sciencedirect.com/science/article/pii/S1571065314000456
KW  - Hierarchical clustering
KW  - quartets
KW  - variable neighbourhood search
KW  - biomedical information extraction
KW  - data representation
KW  - graphs
AB  - Abstract
This paper proposes a methodology that is able to search for relevant references for systematic reviews and meta-analysis from Medline/PubMed, and then to represent the retrieved bibliography through the quartet method of hierarchical clustering. As this novel approach is based on a NP-hard combinatorial problem, a Reduced Variable Neighbourhood Search is used to produce the graph of document clusters as output from the input distance matrix whereby the number of clusters is not known in advance. The distance matrix is derived from the link-ranking XML data returned by PubMed with the search results.
ER  - 

TY  - JOUR
T1  - Nonnegative Matrix Factorization on Orthogonal Subspace
JO  - Pattern Recognition Letters
VL  - 31
IS  - 9
SP  - 905
EP  - 911
PY  - 2010/7/1/
T2  - 
AU  - Li, Zhao
AU  - Wu, Xindong
AU  - Peng, Hong
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2009.12.023
UR  - http://www.sciencedirect.com/science/article/pii/S0167865509003651
KW  - Nonnegative Matrix Factorization
KW  - Orthogonality
KW  - Clustering
AB  - Nonnegative Matrix Factorization (NMF), a parts-based representation using two small factor matrices to approximate an input data matrix, has been widely used in data mining, pattern recognition and signal processing. Orthogonal NMF which imposes orthogonality constraints on the factor matrices can improve clustering performance. However, the existing orthogonal NMF algorithms are either computationally expensive or have to incorporate prior information to achieve orthogonality. In our research, we propose an algorithm called Nonnegative Matrix Factorization on Orthogonal Subspace (NMFOS), in which the generation of orthogonal factor matrices is part of objective function minimization. Thus, orthogonality is achieved without resorting to additional constraints, and the computational complexity is decreased. We develop two algorithms based on the Euclidean distance metric and the generalized Kullback–Leibler divergence, respectively. Experiments on 10 document datasets show that NMFOS improves clustering accuracy. On a facial image database, NMFOS achieves a better parts-based representation with a significant reduction in computational complexity.
ER  - 

TY  - JOUR
T1  - Text Mining Using Metadata for Generation of Side Information
JO  - Procedia Computer Science
VL  - 78
IS  - 
SP  - 807
EP  - 814
PY  - 2016///
T2  - 1st International Conference on Information Security &amp; Privacy 2015
AU  - Bhanuse, Shraddha S.
AU  - Kamble, Shailesh D.
AU  - Kakde, Sandeep M.
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2016.02.061
UR  - http://www.sciencedirect.com/science/article/pii/S1877050916000636
KW  - Text Mining,metadata
KW  - side information
KW  - classification
KW  - clustering
KW  - filtering
KW  - security
AB  - Abstract
Text Mining is knowledge discovery process from large database to find out unknown patterns. In many metadata based text mining applications, side information also known as metadata which is associated with the text document. There are different types side information containing large amount of data i.e. metadata, weblogs and non-textual data (image, video, etc.). The side information is difficult to estimate when it contains noisy data. To achieve this, there is scope of improvement in generating side information i.e. selecting efficient classification and clustering algorithms, providing security for clustered side information, document organization, exploring filtering approaches. In future, there is a scope to design an extended approach for clustering using classical partitioning and probabilistic model.
ER  - 

TY  - JOUR
T1  - Exploring the impact of the IPCC Assessment Reports on science
JO  - Environmental Science & Policy
VL  - 14
IS  - 8
SP  - 1052
EP  - 1061
PY  - 2011/12//
T2  - 
AU  - Vasileiadou, Eleftheria
AU  - Heimeriks, Gaston
AU  - Petersen, Arthur C.
SN  - 1462-9011
DO  - http://dx.doi.org/10.1016/j.envsci.2011.07.002
UR  - http://www.sciencedirect.com/science/article/pii/S1462901111001080
KW  - IPCC
KW  - Scientometrics
KW  - Impact
KW  - Disciplinary differences
KW  - Geographical differences
AB  - Even though critique to IPCC is certainly not new, the climate controversies of 2009 and 2010 brought this critique again to the fore in public media. The paper contributes to this ongoing debate, and investigates empirically the impact of the four Assessment Reports of the IPCC on scientific publications and science, through scientometric analyses of cited references to IPCC reports. The results indicate, among other things, that the aggregate impact of IPCC reports on scientific publications has increased through each consecutive assessment report, independently from the increase of the climate change field, showing a pattern which suggests that the references are quite generic. Both disciplinary distribution and geographical distribution of the impact of the reports are skewed, the former towards geophysical sciences, the latter towards western/developed countries. However, this skewness is decreasing over time. Given the increasing impact further away from the climate change field, it is important that the IPCC becomes more transparent about its internal processes and main conclusions.
ER  - 

TY  - JOUR
T1  - Publisher's Note
JO  - International Journal of Human-Computer Studies
VL  - 70
IS  - 5
SP  - v
EP  - vi
PY  - 2012/5//
T2  - 

SN  - 1071-5819
DO  - http://dx.doi.org/10.1016/S1071-5819(12)00047-X
UR  - http://www.sciencedirect.com/science/article/pii/S107158191200047X
ER  - 

TY  - JOUR
T1  - Proximity-based k-partitions clustering with ranking for document categorization and analysis
JO  - Expert Systems with Applications
VL  - 41
IS  - 16
SP  - 7095
EP  - 7105
PY  - 2014/11/15/
T2  - 
AU  - Mei, Jian-Ping
AU  - Chen, Lihui
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2014.06.016
UR  - http://www.sciencedirect.com/science/article/pii/S0957417414003571
KW  - Clustering
KW  - Similarity-based
KW  - k-Medoids
KW  - Partitioning
KW  - Document categorization
AB  - Abstract
As one of the most fundamental yet important methods of data clustering, center-based partitioning approach clusters the dataset into k subsets, each of which is represented by a centroid or medoid. In this paper, we propose a new medoid-based k-partitions approach called Clustering Around Weighted Prototypes (CAWP), which works with a similarity matrix. In CAWP, each cluster is characterized by multiple objects with different representative weights. With this new cluster representation scheme, CAWP aims to simultaneously produce clusters of improved quality and a set of ranked representative objects for each cluster. An efficient algorithm is derived to alternatingly update the clusters and the representative weights of objects with respect to each cluster. An annealing-like optimization procedure is incorporated to alleviate the local optimum problem for better clustering results and at the same time to make the algorithm less sensitive to parameter setting. Experimental results on benchmark document datasets show that, CAWP achieves favorable effectiveness and efficiency in clustering, and also provides useful information for cluster-specified analysis.
ER  - 

TY  - JOUR
T1  - Science mapping analysis characterizes 235 biases in biomedical research
JO  - Journal of Clinical Epidemiology
VL  - 63
IS  - 11
SP  - 1205
EP  - 1215
PY  - 2010/11//
T2  - 
AU  - Chavalarias, David
AU  - Ioannidis, John P.A.
SN  - 0895-4356
DO  - http://dx.doi.org/10.1016/j.jclinepi.2009.12.011
UR  - http://www.sciencedirect.com/science/article/pii/S0895435610000223
KW  - Bias
KW  - Mapping
KW  - Clustering
KW  - Directed clique
KW  - Text-mining
KW  - Biomedical literature
AB  - Objective
Many different types of bias have been described. Some biases may tend to coexist or be associated with specific research settings, fields, and types of studies. We aimed to map systematically the terminology of bias across biomedical research.
Study Design and Setting
We used advanced text-mining and clustering techniques to evaluate 17,265,924 items from PubMed (1958–2008). We considered 235 bias terms and 103 other terms that appear commonly in articles dealing with bias.
Results
Forty bias terms were used in the title or abstract of more than 100 articles each. Pseudo-inclusion clustering identified 252 clusters of terms. The clusters were organized into macroscopic maps that cover a continuum of research fields. The resulting maps highlight which types of biases tend to co-occur and may need to be considered together and what biases are commonly encountered and discussed in specific fields. Most of the common bias terms have had continuous use over time since their introduction, and some (in particular confounding, selection bias, response bias, and publication bias) show increased usage through time.
Conclusion
This systematic mapping offers a dynamic classification of biases in biomedical investigation and related fields and can offer insights for the multifaceted aspects of bias.
ER  - 

TY  - JOUR
T1  - Clustering and Classification of Software Component for Efficient Component Retrieval and Building Component Reuse Libraries
JO  - Procedia Computer Science
VL  - 31
IS  - 
SP  - 1044
EP  - 1050
PY  - 2014///
T2  - 2nd International Conference on Information Technology and Quantitative Management, ITQM 2014
AU  - Srinivas, Chintakindi
AU  - Radhakrishna, Vangipuram
AU  - Rao, C.V. Guru
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2014.05.358
UR  - http://www.sciencedirect.com/science/article/pii/S1877050914005353
KW  - component
KW  - reuse
KW  - similarity
KW  - cluster
KW  - mining
KW  - repository
AB  - Abstract
A Software Repository is a collection of library files and function codes. Programmers and Engineers design develop and build software libraries in a continuous process. Selecting suitable function code from one among many in the repository is quite challenging and cumbersome as we need to analyze semantic issues in function codes or components. Clustering and Mining Software Components for efficient reuse is the current topic of interest among researchers in Software Reuse Engineering and Information Retrieval. A relatively less research work is contributed in this field and has a good scope in the future. In this paper, the main idea is to cluster the software components and form a subset of libraries from the available repository. These clusters thus help in choosing the required component with high cohesion and low coupling quickly and efficiently. We define a similarity function and use the same for the process of clustering the software components and for estimating the cost of new project. The approach carried out is a feature vector based approach.
ER  - 

TY  - JOUR
T1  - Recent developments in the organization goals conformance using ontology
JO  - Expert Systems with Applications
VL  - 40
IS  - 10
SP  - 4252
EP  - 4267
PY  - 2013/8//
T2  - 
AU  - Izhar, Tengku Adil Tengku
AU  - Torabi, Torab
AU  - Bhatti, M. Ishaq
AU  - Liu, Fei
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2013.01.025
UR  - http://www.sciencedirect.com/science/article/pii/S0957417413000389
KW  - Ontology
KW  - Ontology comparison
KW  - Organization goals
KW  - Organization modeling
KW  - Organization ontology
KW  - Literature review
AB  - Organizational goals serve as the most important achievement target in every organization. Even though some researchers have developed the concept of the organization goals, but structuring the organization goals model is always questionable by the way it is being used. In this paper, we propose ontology to develop a unified model for the organization goals structure. We review the recent literature on the organization modelling and ontology development as an effort to evaluate the organization goals using a metrics for the achievement of the organization goals. We suggest that the metrics is important to identify the relevant organization data in relation to the organization goals conformance. In order to achieve this purpose, we investigate various associated concepts and organize the literature based on the organization goals, organization ontology and metrics model. We observe our proposed models are important for domain experts and entrepreneurs to evaluate the relevant organization data and to assist them in decision making. In summary, the contribution of this survey may serve as a first step in understanding the evaluation of the organization data for the achievement of the organization goals.
ER  - 

TY  - JOUR
T1  - Socially augmented argumentation tools: Rationale, design and evaluation of a debate dashboard
JO  - International Journal of Human-Computer Studies
VL  - 72
IS  - 3
SP  - 298
EP  - 319
PY  - 2014/3//
T2  - 
AU  - Iandoli, Luca
AU  - Quinto, Ivana
AU  - De Liddo, Anna
AU  - Buckingham Shum, Simon
SN  - 1071-5819
DO  - http://dx.doi.org/10.1016/j.ijhcs.2013.08.006
UR  - http://www.sciencedirect.com/science/article/pii/S1071581913001043
KW  - Computer-supported argument visualization
KW  - Grounding process
KW  - Common ground
KW  - Debate dashboard
KW  - Collective deliberation
KW  - Visual feedback
AB  - Abstract
Collaborative Computer-Supported Argument Visualization (CCSAV) is a technical methodology that offers support for online collective deliberation over complex dilemmas. As compared with more traditional conversational technologies, like wikis and forums, CCSAV is designed to promote more critical thinking and evidence-based reasoning, by using representations that highlight conceptual relationships between contributions, and through computational analytics that assess the structural integrity of the network. However, to date, CCSAV tools have achieved adoption primarily in small-scale educational contexts, and only to a limited degree in real world applications. We hypothesise that by reifying conversations as logical maps to address the shortcomings of chronological streams, CCSAV tools underestimate the importance of participation and interaction in enhancing collaborative knowledge-building. We argue, therefore, that CCSAV platforms should be socially augmented in order to improve their mediation capability. Drawing on Clark and Brennan influential Common Ground theory, we designed a Debate Dashboard, which augmented a CCSAV tool with a set of widgets that deliver meta-information about participants and the interaction process. An empirical study simulating a moderately sized collective deliberation scenario provides evidence that this experimental version outperformed the control version on a range of indicators, including usability, mutual understanding, quality of perceived collaboration, and accuracy of individual decisions. No evidence was found that the addition of the Debate Dashboard impeded the quality of the argumentation or the richness of content.
ER  - 

TY  - JOUR
T1  - Transition-aware DVS algorithm for real-time systems using tree structure analysis
JO  - Journal of Systems Architecture
VL  - 56
IS  - 8
SP  - 352
EP  - 367
PY  - 2010/8//
T2  - Special Issue on HW/SW Co-Design: Tools and Applications
AU  - Chen, Da-Ren
AU  - Hsu, Chiun-Chieh
AU  - Chen, You-Shyang
AU  - Kuo, Chi-Jung
AU  - Chen, Lin-Chih
SN  - 1383-7621
DO  - http://dx.doi.org/10.1016/j.sysarc.2010.05.003
UR  - http://www.sciencedirect.com/science/article/pii/S1383762110000391
KW  - Dynamic voltage scaling
KW  - Real-time scheduling
KW  - Distance-constraint tasks scheduling
AB  - Dynamic voltage scaling (DVS) is a key technique for embedded real-time systems to reduce energy consumption by lowering the supply voltage and operating frequency. Many existing DVS algorithms have to generate the canonical schedules or estimate the lengths of slack time in advance for generating the voltage scaling decisions. Therefore, these methods have to compute the schedules with exponential time complexities in general. In this paper, we consider a set of jitter-controlled, independent, periodic, hard real-time tasks scheduled according to preemptive pinwheel model. Our approach constructs a tree structure corresponding to a schedule and maintains the data structure at each early-completion point. Our approach consists of off-line and on-line algorithms which consider the effects of transition time and energy. The off-line and on-line algorithm takes O(k + n log n) and O(k + (pmax/pmin)) time complexity, respectively, where n, k, pmax and pmin denotes the number of tasks, jobs, longest and shortest task period, respectively. Experimental results show that the proposed approach is effective in reducing computational complexity, transition time and energy overhead.
ER  - 

TY  - JOUR
T1  - Clustering and polarization in the distribution of output: A multivariate perspective
JO  - Journal of Macroeconomics
VL  - 35
IS  - 
SP  - 144
EP  - 162
PY  - 2013/3//
T2  - 
AU  - Battisti, Michele
AU  - Parmeter, Christopher F.
SN  - 0164-0704
DO  - http://dx.doi.org/10.1016/j.jmacro.2012.10.003
UR  - http://www.sciencedirect.com/science/article/pii/S0164070412001024
KW  - Convergence
KW  - Orientation
KW  - Mixture densities
AB  - Modeling the cross-country distribution of per capita income using mixture analysis provides a natural platform for the detection of clubs of countries. Unfortunately, these mixture methods, when based on a strictly univariate approach are limiting towards one’s ability to learn about the underlying process of the emergence of what constitutes a club. This paper takes a fresh look at the constitution of the emerging clubs in the distribution of cross-country output using bivariate and multivariate mixture analysis. Our results suggest that clubs are also forming in the main Solowian determinants of economic growth.
ER  - 

TY  - JOUR
T1  - Selected papers from the 2011 International Conference on Neural Information Processing (ICONIP 2011)
JO  - Neurocomputing
VL  - 129
IS  - 
SP  - 1
EP  - 2
PY  - 2014/4/10/
T2  - 
AU  - Kwok, James T.
AU  - Zhang, Liqing
AU  - Lu, Hongtao
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2013.10.014
UR  - http://www.sciencedirect.com/science/article/pii/S0925231213010199
ER  - 

TY  - JOUR
T1  - Editorial: Special issue on natural language processing and text analytics in industry
JO  - Computers in Industry
VL  - 78
IS  - 
SP  - 1
EP  - 2
PY  - 2016/5//
T2  - Natural Language Processing and Text Analytics in Industry
AU  - Ittoo, Ashwin
AU  - Nguyen, Le Minh
AU  - van den Bosch, Antal
SN  - 0166-3615
DO  - http://dx.doi.org/10.1016/j.compind.2016.01.001
UR  - http://www.sciencedirect.com/science/article/pii/S0166361516000129
ER  - 

TY  - JOUR
T1  - Finding Similar Documents Using Different Clustering Techniques
JO  - Procedia Computer Science
VL  - 82
IS  - 
SP  - 28
EP  - 34
PY  - 2016///
T2  - 4th Symposium on Data Mining Applications, SDMA2016, 30 March 2016, Riyadh, Saudi Arabia
AU  - Al-Anazi, Sumayia
AU  - AlMahmoud, Hind
AU  - Al-Turaiki, Isra
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2016.04.005
UR  - http://www.sciencedirect.com/science/article/pii/S1877050916300199
KW  - clustering
KW  - k-means
KW  - k-medoids
KW  - text mining
KW  - data mining
KW  - cosine similarity
AB  - Abstract
Text clustering is an important application of data mining. It is concerned with grouping similar text documents together. In this paper, several models are built to cluster capstone project documents using three clustering techniques: k-means, k-means fast, and k-medoids. Our datatset is obtained from the library of the College of Computer and Information Sciences, King Saud University, Riyadh. Three similarity measure are tested: cosine similarity, Jaccard similarity, and Correlation Coefficient. The quality of the obtained models is evaluated and compared. The results indicate that the best performance is achieved using k-means and k-medoids combined with cosine similarity. We observe variation in the quality of clustering based on the evaluation measure used. In addition, as the value of k increases, the quality of the resulting cluster improves. Finally, we reveal the categories of graduation projects offered in the Information Technology department for female students.
ER  - 

TY  - JOUR
T1  - Synonyms Based Term Weighting Scheme: An Extension to TF.IDF
JO  - Procedia Computer Science
VL  - 89
IS  - 
SP  - 555
EP  - 561
PY  - 2016///
T2  - Twelfth International Conference on Communication Networks, ICCN 2016, August 19– 21, 2016, Bangalore, India Twelfth International Conference on Data Mining and Warehousing, ICDMW 2016, August 19-21, 2016, Bangalore, India Twelfth International Conference on Image and Signal Processing, ICISP 2016, August 19-21, 2016, Bangalore, India
		
AU  - Kumari, Madhu
AU  - Jain, Akshat
AU  - Bhatia, Ankit
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2016.06.093
UR  - http://www.sciencedirect.com/science/article/pii/S1877050916311589
KW  - Information Retrieval
KW  - Keyword Extraction
KW  - Modifiedtf.idf
KW  - Synonyms based Term Weighting
KW  - Term Weighting.
AB  - Abstract
Information retrieval is pivotal task in any web search and navigation on World Wide Web. Therefore effective document retrieval techniques can affect not only the efficiency of search engines but also the users experience in terms of relevant information. TF.IDF (Term Frequency Inverse Document Frequency) is the most widely used weighting scheme for key words to facilitate the relevant documents each. But whereas the existing TF.IDF approach does not take into account the semantic correlations between the terms which may lead to less relevant document retrieval. In order to overcome this challenge, we propose a novel Synonyms-Based Term weighting scheme (SBT) which changes Inverse Document Frequency (IDF) according to the synonyms based cluster of any term. We have employed MeSH to compute the dynamic cluster of synonyms of the terms in biomedical text documents. The efficacy of the proposed scheme is corroborated through experiments.
ER  - 

TY  - JOUR
T1  - Combining the scenario technique with bibliometrics for technology foresight: The case of personalized medicine
JO  - Technological Forecasting and Social Change
VL  - 98
IS  - 
SP  - 137
EP  - 156
PY  - 2015/9//
T2  - 
AU  - Stelzer, Birgit
AU  - Meyer-Brötz, Fabian
AU  - Schiebel, Edgar
AU  - Brecht, Leo
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2015.06.008
UR  - http://www.sciencedirect.com/science/article/pii/S0040162515001754
KW  - Scenario technique
KW  - Bibliometrics
KW  - Method combination
KW  - Emerging technologies
KW  - Technology foresight
KW  - Personalized medicine
AB  - Abstract
The purpose of this article is to present a novel method for combining bibliometrics and scenario technique for the sake of conducting technology foresight. First, we derive an eight-step scenario approach and add the identification of emerging technologies as well as their respective effects on each scenario. Second, we illustrate this combined method in the field of personalized medicine (PM). Existing literature on method combination often focuses singular challenges and benefits associated with the scenario technique. In this paper, however, we integrate the results of a bibliometric analysis at each step of the scenario technique. Herein, we refer mainly to the co-citation analysis and bibliographic coupling network. Third, we describe the findings of our case study for every step of the application of the scenario technique. In doing so, we offer practical guidelines for applying this novel combined method in other contexts. The overall benefit of the method combination is the integration of scientifically based information that exceeds the knowledge bases of the scenario team and other experts. Most notably, the examination of vast amounts of technology-specific information facilitates the identification of emerging technologies. Moreover, the combined method allows for a more precise projection of future states when narrowing the scenario funnel. Using this eight-step scenario approach, we build three scenarios for the field of PM, discuss disruptive events, and identify and integrate emerging technologies into each scenario. Finally, we explore strategic decisions for various stakeholders in the PM field.
ER  - 

TY  - JOUR
T1  - Approaches to understanding and measuring interdisciplinary scientific research (IDR): A review of the literature
JO  - Journal of Informetrics
VL  - 5
IS  - 1
SP  - 14
EP  - 26
PY  - 2011/1//
T2  - 
AU  - Wagner, Caroline S.
AU  - Roessner, J. David
AU  - Bobb, Kamau
AU  - Klein, Julie Thompson
AU  - Boyack, Kevin W.
AU  - Keyton, Joann
AU  - Rafols, Ismael
AU  - Börner, Katy
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2010.06.004
UR  - http://www.sciencedirect.com/science/article/pii/S1751157710000581
KW  - Interdisciplinary
KW  - Science
KW  - Research
KW  - Indicators
KW  - Bibliometrics
KW  - Evaluation
AB  - Interdisciplinary scientific research (IDR) extends and challenges the study of science on a number of fronts, including creating output science and engineering (S&amp;E) indicators. This literature review began with a narrow search for quantitative measures of the output of IDR that could contribute to indicators, but the authors expanded the scope of the review as it became clear that differing definitions, assessment tools, evaluation processes, and measures all shed light on different aspects of IDR. Key among these broader aspects is (a) the importance of incorporating the concept of knowledge integration, and (b) recognizing that integration can occur within a single mind as well as among a team. Existing output measures alone cannot adequately capture this process. Among the quantitative measures considered, bibliometrics (co-authorships, co-inventors, collaborations, references, citations and co-citations) are the most developed, but leave considerable gaps in understanding of the social dynamics that lead to knowledge integration. Emerging measures in network dynamics (particularly betweenness centrality and diversity), and entropy are promising as indicators, but their use requires sophisticated interpretations. Combinations of quantitative measures and qualitative assessments being applied within evaluation studies appear to reveal IDR processes but carry burdens of expense, intrusion, and lack of reproducibility year-upon-year. This review is a first step toward providing a more holistic view of measuring IDR, although research and development is needed before metrics can adequately reflect the actual phenomenon of IDR.
ER  - 

TY  - JOUR
T1  - Comprehension priming as rational expectation for repetition: Evidence from syntactic processing
JO  - Cognition
VL  - 147
IS  - 
SP  - 29
EP  - 56
PY  - 2016/2//
T2  - 
AU  - Myslín, Mark
AU  - Levy, Roger
SN  - 0010-0277
DO  - http://dx.doi.org/10.1016/j.cognition.2015.10.021
UR  - http://www.sciencedirect.com/science/article/pii/S0010027715300998
KW  - Psycholinguistics
KW  - Priming
KW  - Expectation
KW  - Rational analysis
KW  - Syntax
KW  - Probabilistic models of cognition
AB  - Abstract
Why do comprehenders process repeated stimuli more rapidly than novel stimuli? We consider an adaptive explanation for why such facilitation may be beneficial: priming is a consequence of expectation for repetition due to rational adaptation to the environment. If occurrences of a stimulus cluster in time, given one occurrence it is rational to expect a second occurrence closely following. Leveraging such knowledge may be particularly useful in online processing of language, where pervasive clustering may help comprehenders negotiate the considerable challenge of continual expectation update at multiple levels of linguistic structure and environmental variability. We test this account in the domain of structural priming in syntax, making use of the sentential complement–direct object (SC–DO) ambiguity. We first show that sentences containing SC continuations cluster in natural language, motivating an expectation for repetition of this structure. Second, we show that comprehenders are indeed sensitive to the syntactic clustering properties of their current environment. In a series of between-groups self-paced reading studies, we find that participants who are exposed to clusters of SC sentences subsequently process repetitions of SC structure more rapidly than participants who are exposed to the same number of SCs spaced in time, and attribute the difference to the learned degree of expectation for repetition. We model this behavior through Bayesian belief update, showing that (the optimal degree of) sensitivity to clustering properties of syntactic structures is indeed learnable through experience. Comprehension priming effects are thus consistent with rational expectation for repetition based on adaptation to the linguistic environment.
ER  - 

TY  - JOUR
T1  - Component-based design of cyber-physical applications with safety-critical requirements
JO  - Microprocessors and Microsystems
VL  - 42
IS  - 
SP  - 70
EP  - 86
PY  - 2016/5//
T2  - 
AU  - Masrur, Alejandro
AU  - Kit, Michał
AU  - Matěna, Vladimír
AU  - Bureš, Tomáš
AU  - Hardt, Wolfram
SN  - 0141-9331
DO  - http://dx.doi.org/10.1016/j.micpro.2016.01.007
UR  - http://www.sciencedirect.com/science/article/pii/S0141933116000107
KW  - Cyber-physical systems
KW  - Component-based design
KW  - Safety-critical applications
KW  - Real-time and timing analysis
KW  - Unreliable communication
KW  - Reliability-aware design
AB  - Abstract
Cyber-physical systems typically involve large numbers of mobile autonomous devices that closely interact with each other and their environment. Standard design and development techniques often fail to effectively manage the complexity and dynamics of such systems. As a result, there is a strong need for new programing models and abstractions. Towards this, component-based design methods are a promising solution. However, existing such approaches either do not accurately model transitory interactions between components – which are typical of cyber-physical systems – or do not provide guarantees for real-time behavior which is essential in safety-critical applications. To overcome this problem, we present a component-based design technique based on DEECo (Dependable Emergent Ensembles of Components). The DEECo framework allows modeling large-scale dynamic systems by a set of interacting components and, in contrast to approaches from the literature, it provides mechanisms to describe transitory interactions between them. To allow reasoning about timing behavior at the component-description level, we characterize DEECo’s closed-loop delay in the worst case, i.e., the maximum time needed to react to a change in the environment. Based on this, we incorporate real-time analysis into DEECo’s design flow. This further allows us to analyze the system’s robustness under unreliable communication and to design decentralized safety-preserving mechanisms. To illustrate the simplicity and usefulness of our approach, we present a case study consisting of an intelligent crossroad system.
ER  - 

TY  - JOUR
T1  - Research on the Selection of Feature Transfer Relations in Latent Semantic Indexing
JO  - AASRI Procedia
VL  - 3
IS  - 
SP  - 680
EP  - 685
PY  - 2012///
T2  - Conference on Modelling, Identification and Control
AU  - Jiang, Dongyang
AU  - Zheng, Wei
SN  - 2212-6716
DO  - http://dx.doi.org/10.1016/j.aasri.2012.11.108
UR  - http://www.sciencedirect.com/science/article/pii/S2212671612002673
KW  - Latent semantic index
KW  - Feature transfer
KW  - Feature similar matrix
AB  - The latent semantic index (LSI) has been widely used in many fields of natural language processing in which co- occurrence features can be captured by the transfer relations between the documents and in the documents. Document features with a higher frequency in the collection of the document are more likely to introduce some unreasonable feature transfer relations to the latent semantic space which affects the similarity between features and between documents in document sets in our recent study. In the paper a feature optimize technology in latent semantic indexing that uses feature transfer relation in documents and between documents is proposed. By the complete-link algorithm, the experimental results show that the method effectively improves the performance of latent semantic indexing.
ER  - 

TY  - JOUR
T1  - Introduction to the special issue on Arabic NLP: Current state and future challenges
JO  - Journal of King Saud University - Computer and Information Sciences
VL  - 26
IS  - 4
SP  - 355
EP  - 356
PY  - 2014/12//
T2  - Special Issue on Arabic NLP
AU  - Al-Khalifa, Hend S.
SN  - 1319-1578
DO  - http://dx.doi.org/10.1016/j.jksuci.2014.10.001
UR  - http://www.sciencedirect.com/science/article/pii/S1319157814000457
ER  - 

TY  - JOUR
T1  - China/USA nanotechnology research output comparison—2011 update
JO  - Technological Forecasting and Social Change
VL  - 79
IS  - 5
SP  - 986
EP  - 990
PY  - 2012/6//
T2  - 
AU  - Kostoff, Ronald N.
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2012.01.007
UR  - http://www.sciencedirect.com/science/article/pii/S0040162512000315
KW  - Nanotechnology
KW  - Nanoscience
KW  - Nanocomposites
KW  - China
KW  - Bibliometrics
KW  - Scientometrics
KW  - Citation analysis
AB  - This Research Note updates our 2006 and 2009 China/USA nanotechnology and nanoscience (NN) research output comparisons.

A 2009 comparison of China/USA research publication outputs showed that China is about to overtake the USA in NN research output. As predicted by the extrapolated 2009 curve, China has passed USA in NN research publication output. This transition occurred in the 2008/2009 time frame, and if the 2011 results (taken at mid-2011) hold for the full year, will become quite pronounced (~ 20%).

When specific sub-disciplines are examined, the differences between China and USA become more pronounced. For example, the 2009 paper presented the time trend for China/USA publications in nanocomposites, an important sub-discipline of NN. The updated nanocomposites curve has increased about twice the rate of the overall NN curve, and shows no sign of abating.

The USA papers lead in the numbers of citations by all metrics considered, but the Chinese papers are showing significant improvement with time. Overall, the Chinese papers are cited very modestly, but there is a core of 'heavy hitters' that appears to be increasing substantially with time, and is increasingly making its presence known in the higher Impact Factor journals.
ER  - 

TY  - JOUR
T1  - Special issue on Data Intensive Computing
JO  - Journal of Parallel and Distributed Computing
VL  - 71
IS  - 2
SP  - 143
EP  - 144
PY  - 2011/2//
T2  - Data Intensive Computing
AU  - Byna, Surendra
AU  - Sun, Xian-He
SN  - 0743-7315
DO  - http://dx.doi.org/10.1016/j.jpdc.2010.10.009
UR  - http://www.sciencedirect.com/science/article/pii/S0743731510002078
ER  - 

TY  - JOUR
T1  - Agricultural Ontology Based Feature Optimization for Agricultural Text Clustering
JO  - Journal of Integrative Agriculture
VL  - 11
IS  - 5
SP  - 752
EP  - 759
PY  - 2012/5//
T2  - 
AU  - SU, Ya-ru
AU  - WANG, Ru-jing
AU  - CHEN, Peng
AU  - WEI, Yuan-yuan
AU  - LI, Chuan-xi
AU  - HU, Yi-min
SN  - 2095-3119
DO  - http://dx.doi.org/10.1016/S2095-3119(12)60064-1
UR  - http://www.sciencedirect.com/science/article/pii/S2095311912600641
KW  - agricultural ontology
KW  - feature optimization
KW  - agricultural text clustering
AB  - Feature optimization is important to agricultural text mining. Usually, the vector space model is used to represent text documents. However, this basic approach still suffers from two drawbacks: the curse of dimension and the lack of semantic information. In this paper, a novel ontology-based feature optimization method for agricultural text was proposed. First, terms of vector space model were mapped into concepts of agricultural ontology, which concept frequency weights are computed statistically by term frequency weights; second, weights of concept similarity were assigned to the concept features according to the structure of the agricultural ontology. By combining feature frequency weights and feature similarity weights based on the agricultural ontology, the dimensionality of feature space can be reduced drastically. Moreover, the semantic information can be incorporated into this method. The results showed that this method yields a significant improvement on agricultural text clustering by the feature optimization.
ER  - 

TY  - JOUR
T1  - Introduction to the special issue on “interactive data analysis”
JO  - Information Processing & Management
VL  - 51
IS  - 2
SP  - 141
EP  - 143
PY  - 2015/3//
T2  - 
AU  - Holzinger, Andreas
AU  - Pasi, Gabriella
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2014.11.002
UR  - http://www.sciencedirect.com/science/article/pii/S0306457314001101
ER  - 

TY  - JOUR
T1  - Special Issue on Mining Big Data in Biomedicine and Health Care
JO  - Journal of Biomedical Informatics
VL  - 51
IS  - 
SP  - 1
EP  - 2
PY  - 2014/10//
T2  - 

SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2014.08.009
UR  - http://www.sciencedirect.com/science/article/pii/S1532046414001907
ER  - 

TY  - JOUR
T1  - Enhancing service discovery using cat swarm optimisation based web service clustering
JO  - Perspectives in Science
VL  - 8
IS  - 
SP  - 715
EP  - 717
PY  - 2016/9//
T2  - Recent Trends in Engineering and Material Sciences
AU  - Kotekar, Sunaina
AU  - Kamath, Sowmya S.
SN  - 2213-0209
DO  - http://dx.doi.org/10.1016/j.pisc.2016.06.068
UR  - http://www.sciencedirect.com/science/article/pii/S2213020916302075
KW  - Web service discovery
KW  - WSDL
KW  - CSO
KW  - Clustering
KW  - Swarm intelligence
AB  - Summary
Web service discovery is a critical task in service oriented application development. Due to extensive proliferation in the number of available services, it is challenging to obtain all the relevant services available for a given task. For the retrieval of most relevant Web services, a user would have to use those service-specific terms that best describe and match the natural language documentation contained within a service description. This process can be time intensive, due to functional diversity of available services in a repository. Domain specific clustering of Web Services based on the similarities of their functionalities would greatly boost the ability of a Web service search engine to retrieve the most relevant service. In this paper, we propose a novel technique to cluster service documents into functionally similar service groups using the Cat Swarm Optimisation Algorithm. We present experimental results that show that the proposed technique was effective and enhanced the process of service discovery.
ER  - 

TY  - JOUR
T1  - Selecting publication keywords for domain analysis in bibliometrics: A comparison of three methods
JO  - Journal of Informetrics
VL  - 10
IS  - 1
SP  - 212
EP  - 223
PY  - 2016/2//
T2  - 
AU  - Chen, Guo
AU  - Xiao, Lu
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2016.01.006
UR  - http://www.sciencedirect.com/science/article/pii/S175115771600002X
KW  - Domain analysis
KW  - Keyword analysis
KW  - Keyword Activity Index
KW  - Digital Library in China
AB  - Abstract
Publication keywords have been widely utilized to reveal the knowledge structure of research domains. An important but under-addressed problem is the decision of which keywords should be retained as analysis objects after a great number of keywords are gathered from domain publications. In this paper, we discuss the problems with the traditional term frequency (TF) method and introduce two alternative methods: TF-inverse document frequency (TF-IDF) and TF-Keyword Activity Index (TF-KAI). These two methods take into account keyword discrimination by considering their frequency both in and out of the domain. To test their performance, the keywords they select in China's Digital Library domain are evaluated both qualitatively and quantitatively. The evaluation results show that the TF-KAI method performs the best: it can retain keywords that match expert selection much better and reveal the research specialization of the domain with more details.
ER  - 

TY  - JOUR
T1  - Visualizing the intellectual structure of information science (2006–2015): Introducing author keyword coupling analysis
JO  - Journal of Informetrics
VL  - 10
IS  - 1
SP  - 132
EP  - 150
PY  - 2016/2//
T2  - 
AU  - Yang, Siluo
AU  - Han, Ruizhen
AU  - Wolfram, Dietmar
AU  - Zhao, Yuehua
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2015.12.003
UR  - http://www.sciencedirect.com/science/article/pii/S1751157715301103
KW  - Author keyword coupling analysis
KW  - Information science
KW  - Author bibliographic coupling analysis
KW  - Bibliometric mapping
AB  - Abstract
We introduce the author keyword coupling analysis (AKCA) method to visualize the field of information science (2006–2015). We then compare the AKCA method with the author bibliographic coupling analysis (ABCA) method in terms of first- and all-author citation counts. We obtain the following findings: (1) The AKCA method is a new and feasible method for visualizing a discipline's structure, and the ABCA and AKCA methods have their respective strengths and emphases. The relation within the ABCA method is based on the same references (knowledge base), whereas that within the AKCA method is based on the same keywords (lexical linguistic). The AKCA method appears to provide a less detailed picture, and more uneven sub-areas of a discipline structure. The relationships between authors are narrow and direct and feature multiple levels in AKCA. (2) All-author coupling provides a comprehensive picture; thus, a complete view of a discipline structure may require both first- and all-author coupling analyses. (3) Information science evolved continuously during the second decade of the World Wide Web. The KDA (knowledge domain analysis) camp became remarkably prominent, while the IR camp (information retrieval) experienced a further decline in hard IR research, and became significantly smaller; Patent analysis and Open Access emerged during this period. Mapping of Science and Bibliometric evaluation also experienced substantial growth.
ER  - 

TY  - JOUR
T1  - A novel soft clustering algorithm
JO  - Procedia Engineering
VL  - 15
IS  - 
SP  - 5536
EP  - 5540
PY  - 2011///
T2  - CEIS 2011
AU  - Ma, Ruixin
AU  - Wang, Xiao
AU  - Meng, Fancheng
SN  - 1877-7058
DO  - http://dx.doi.org/10.1016/j.proeng.2011.08.1027
UR  - http://www.sciencedirect.com/science/article/pii/S1877705811025288
KW  - citation network
KW  - complex priority
KW  - soft clustering
KW  - thegrouth theorem
AB  - Paper clustering problems in citation network is one of the hottest spots in data mining. However, traditional paper clustering algorithm stresses on the keywords analysis while ignores the “refer-to” relationship, which results in the problem of high time complexity and low accuracy. In this paper, we come up with a novel soft clustering algorithm in accordance with the complex priority and thegrouth theorem, and classify our algorithm into two steps: refer-to relationship analysis and keywords comparison. Experimental results show that our algorithm is able to greatly improve the search accuracy and efficiency.
ER  - 

TY  - JOUR
T1  - Specialized Corpora Processing with Automatic Extraction Tools
JO  - Procedia - Social and Behavioral Sciences
VL  - 95
IS  - 
SP  - 293
EP  - 297
PY  - 2013/10/25/
T2  - Corpus Resources for Descriptive and Applied Studies. Current Challenges and Future Directions: Selected Papers from the 5th International Conference on Corpus Linguistics (CILC2013)
AU  - Goncharova, Yuliya
AU  - Cárdenas, Beatriz Sánchez
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2013.10.650
UR  - http://www.sciencedirect.com/science/article/pii/S1877042813041700
KW  - frame-based terminology
KW  - verb macro structures
KW  - semantic frames
KW  - automatic terminology extraction
AB  - Abstract
This research describes a protocol for specialized corpus analysis using natural language processing (NLP) tools to define semantic hierarchies of verbs in the specialized domain of Volcanology. The experimental analysis was carried out with a domain-specific corpus in English of approximately 500,000 tokens composed of dissertations and scientific articles in the domain of Volcanology. The combination of semantic and syntactic analysis results in the verb macro structure that illustrates the evolution of the meaning from more general to more specific verbs.
ER  - 

TY  - JOUR
T1  - Parallel approaches to machine learning—A comprehensive survey
JO  - Journal of Parallel and Distributed Computing
VL  - 73
IS  - 3
SP  - 284
EP  - 292
PY  - 2013/3//
T2  - Models and Algorithms for High-Performance Distributed Data Mining
AU  - Upadhyaya, Sujatha R.
SN  - 0743-7315
DO  - http://dx.doi.org/10.1016/j.jpdc.2012.11.001
UR  - http://www.sciencedirect.com/science/article/pii/S0743731512002705
KW  - Distributed and parallel machine learning
KW  - GPU
KW  - Map reduce
AB  - Literature has always witnessed efforts that make use of parallel algorithms / parallel architecture to improve performance; machine learning space is no exception. In fact, a considerable effort has gone into this area in the past fifteen years. Our report attempts to bring together and consolidate such attempts. It tracks the development in this area since the inception of the idea in 1995, identifies different phases during the time period 1995–2011 and marks important achievements. When it comes to performance enhancement, GPU platforms have carved a special niche for themselves. The strength of these platforms comes from the capability to speed up computations exponentially by way of parallel architecture / programming methods. While it is evident that computationally complex processes like image processing, gaming etc. stand to gain much from parallel architectures; studies suggest that general purpose tasks such as machine learning, graph traversal, and finite state machines are also identified as the parallel applications of the future. Map reduce is another important technique that has evolved during this period and as the literature has it, it has been proved to be an important aid in delivering performance of machine learning algorithms on GPUs. The report summarily presents the path of developments.
ER  - 

TY  - JOUR
T1  - Extraction of Interlingual Documents Clusters Based on Closed Concepts Mining
JO  - Procedia Computer Science
VL  - 60
IS  - 
SP  - 537
EP  - 546
PY  - 2015///
T2  - Knowledge-Based and Intelligent Information &amp; Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings
AU  - Chebel, Mohamed
AU  - Latiri, Chiraz
AU  - Gaussier, Eric
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.08.176
UR  - http://www.sciencedirect.com/science/article/pii/S1877050915023030
KW  - multilingual documents
KW  - interlingual cluster
KW  - clustering
KW  - textmining
KW  - Closed Concepts
KW  - degree of comparability.
AB  - Abstract
To address multilingual document classification in an effcient and effective manner, we claim that a synergy between classical IR techniques such as vector model and some advanced data mining methods, especially Formal Concept Analysis, is particularly appropriate. We propose in this paper, a new statistical approach for extracting inter-language clusters from multilingual documents based on Closed Concepts Mining and vector model. Formal Concept Analysis techniques are applied to extract Closed Concepts from comparable corpora; and, then, exploit these Closed Concepts and vector models in the clustering and alignment of multilin- gual documents. An experimental evaluation is conducted on the collection of bilingual documents French-English of CLEF’2003. The results confirmed that the synergy between Formal Concept Analysis and vector model is fruitful to extract bilingual classes of documents, with an interesting comparability score.
ER  - 

TY  - JOUR
T1  - Global Environmental Impact Assessment Research Trends (1973-2009)
JO  - Procedia Environmental Sciences
VL  - 11, Part C
IS  - 
SP  - 1499
EP  - 1507
PY  - 2011///
T2  - 2011 2nd International Conference on Challenges in Environmental Science and Computer Engineering (CESCE 2011)
AU  - Yanhua, Zhuang
AU  - Song, Hong
AU  - Hongyan, Lin
AU  - Beibei, Niu
SN  - 1878-0296
DO  - http://dx.doi.org/10.1016/j.proenv.2011.12.226
UR  - http://www.sciencedirect.com/science/article/pii/S1878029611010498
KW  - Environmental impact assessment (EIA)
KW  - strategic environmental assessment (SEA)
KW  - bibliometric analysis
KW  - keywords analysis
KW  - Research Trends
AB  - According to the samples of 1781 literatures about environmental impact assessment (EIA) of SCI and SSCI databases from 1973 to 2009, this paper analyzes the literatures in their trend of growth, subject categories and journals, International collaborations, geographic distribution of publications and scientific research issues by using bibliometrics analysis. The result shows that EIA research steadily increases over the past 40 years and the annual number of papers published in 2009 is 50 times than that in 1973. EIA was involved into 130 kinds of subjects and appeared in 587 journals. The main study area with strong scientific research capabilities distributed in USA and European Union, while the USA was the largest contributor in EIA research and had a central position in collaboration networks. A keyword analysis found that the priority in assessment would gradually change from project environmental impact assessment to Strategic Environmental Assessment (SEA) and Plan Environmental Impact Assessment (PEIA); EIA research would focus on using and improving new techniques and methods, such as “life cycle assessment (LCA)”, “geographic information system (GIS)” and “modeling” etc.; “biodiversity” and “climate change” would attract more attention and will be the emphasis of EIA; the improvement of developing countries’ EIA system became popular research. This study reveals patterns in scientific outputs and academic collaborations and serves as an alternative and innovative way of identifying global research trends in EIA.
ER  - 

TY  - JOUR
T1  - Mapping biofuel field: A bibliometric evaluation of research output
JO  - Renewable and Sustainable Energy Reviews
VL  - 28
IS  - 
SP  - 82
EP  - 91
PY  - 2013/12//
T2  - 
AU  - Yaoyang, Xu
AU  - Boeing, Wiebke J.
SN  - 1364-0321
DO  - http://dx.doi.org/10.1016/j.rser.2013.07.027
UR  - http://www.sciencedirect.com/science/article/pii/S1364032113004723
KW  - Scientific outputs
KW  - Research trends
KW  - Microalgal biodiesel
KW  - Biorefinery
KW  - Life cycle assessment
AB  - Abstract
Among sustainable and renewable energies, biofuels appear to be the most promising and attractive, and related research has been expanding along with an exceptional growth of scientific knowledge. Based on the Science Citation Index Expanded from the Web of Science, a bibliometric evaluation of research output was carried out to map research activities and tendencies of the global biofuel field. The results indicate that annual output of scientific articles rocketed during the past decade (2003–2012). The United States of America (USA) is leading biofuels research and collaborated mainly with other productive countries (China, United Kingdom, Germany, Canada and South Korea). In general, international collaborative publications resulted in more citations than single country publications. Institutional collaborations became increasingly prevalent over time and the 15 most productive institutions of USA tended to collaborate more with each other. Most research publications on biofuels appeared in the journals Biomass and Bioenergy and Bioresource Technology. Furthermore, biofuels research was based on combinations of multi-subject categories including “Energy and fuels”, “Biotechnology and applied microbiology”, “Chemical engineering”, “Environmental sciences” and “Agricultural engineering”. The keyword analysis confirmed the production of biodiesel from microalgae as the mainstream of recent biofuels research. Biorefinery was the most common technology for conversions of biological feedstock and life cycle assessment was the most popular tool of decision support to evaluate the sustainability of biofuel development.
ER  - 

TY  - JOUR
T1  - Mapping the evolution of scientific fields based on cross-field authors
JO  - Journal of Informetrics
VL  - 10
IS  - 3
SP  - 750
EP  - 761
PY  - 2016/8//
T2  - 
AU  - Sun, Xiaoling
AU  - Ding, Kun
AU  - Lin, Yuan
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2016.04.016
UR  - http://www.sciencedirect.com/science/article/pii/S1751157715302352
KW  - Scientific evolution
KW  - Network analysis
KW  - Interdisciplinary research
AB  - Abstract
Mapping the evolution of scientific fields has drawn much attention in recent years. Researchers have proposed various methods to describe, explain and predict different aspects of science. Network-based analysis has been widely used for knowledge networks, in order to track the changes of research topics and the spread of scientific ideas. Here we propose a novel approach for mapping the science from the perspective of cross-field authors. Computer science is selected based on its interdisciplinary applications. We build a scientific network consisting of computer science conferences as nodes, and two conferences are linked if there exist authors that published papers on both conferences. The scientific fields are identified by community detection algorithm. The results suggest the proposed method based on author overlaps across fields are effective in mapping the science.
ER  - 

TY  - JOUR
T1  - Fuzzy semi-supervised co-clustering for text documents
JO  - Fuzzy Sets and Systems
VL  - 215
IS  - 
SP  - 74
EP  - 89
PY  - 2013/3/16/
T2  - Theme : Clustering
AU  - Yan, Yang
AU  - Chen, Lihui
AU  - Tjhi, William-Chandra
SN  - 0165-0114
DO  - http://dx.doi.org/10.1016/j.fss.2012.10.016
UR  - http://www.sciencedirect.com/science/article/pii/S0165011412004708
KW  - Semi-supervised learning
KW  - Heuristic
KW  - Must-link/cannot-link constraint
KW  - Fuzzy co-clustering
AB  - In this paper we propose a new heuristic semi-supervised fuzzy co-clustering algorithm (SS-HFCR) for categorization of large web documents. In this approach, the clustering process is carried out by incorporating some prior knowledge in the form of pair-wise constraints provided by users into the fuzzy co-clustering framework. Each constraint specifies whether a pair of documents “must” or “cannot” be clustered together. Moreover, we formulate the competitive agglomeration cost function which is also able to make use of prior knowledge in the clustering process. The experimental studies on a number of large benchmark datasets demonstrate the strength and potentials of SS-HFCR in terms of accuracy, stability and efficiency, compared with some of the recent popular semi-supervised clustering approaches.
ER  - 

TY  - JOUR
T1  - Collective taxonomizing: A collaborative approach to organizing document repositories
JO  - Decision Support Systems
VL  - 50
IS  - 1
SP  - 292
EP  - 303
PY  - 2010/12//
T2  - 
AU  - Wu, Harris
AU  - Gordon, Michael D.
AU  - Fan, Weiguo
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2010.08.031
UR  - http://www.sciencedirect.com/science/article/pii/S0167923610001557
KW  - Collective taxonomizing
KW  - Web 2.0
KW  - Design science
KW  - Structural knowledge
KW  - Knowledge management
AB  - Keeping large, growing document repositories organized is a critical challenge. For example, the security failure prior to the 9/11 tragedy was partly due to the ineffectiveness of organizing documents shared among various intelligence organizations. Drawing on the success of Web 2.0 and theories from knowledge management, we argue that a shared document repository with no central organizer may benefit from collective taxonomizing: allowing community members to categorize documents with local document hierarchies and systematically coalesce those local hierarchies into a global taxonomy. Using a design science approach, we develop and evaluate a hierarchy coalescing algorithm. Empirical and analytical evaluation shows promise.
ER  - 

TY  - JOUR
T1  - Clustering digital forensic string search output
JO  - Digital Investigation
VL  - 11
IS  - 4
SP  - 314
EP  - 322
PY  - 2014/12//
T2  - 
AU  - Beebe, Nicole L.
AU  - Liu, Lishu
SN  - 1742-2876
DO  - http://dx.doi.org/10.1016/j.diin.2014.10.002
UR  - http://www.sciencedirect.com/science/article/pii/S1742287614001108
KW  - Digital forensics
KW  - Text string search
KW  - Clustering
KW  - k-means
KW  - SOM
KW  - LDA
AB  - Abstract
This research comparatively evaluates four competing clustering algorithms for thematically clustering digital forensic text string search output. It does so in a more realistic context, respecting data size and heterogeneity, than has been researched in the past. In this study, we used physical-level text string search output, consisting of over two million search hits found in nearly 50,000 allocated files and unallocated blocks. Holding the data set constant, we comparatively evaluated k-Means, Kohonen SOM, Latent Dirichlet Allocation (LDA) followed by k-Means, and LDA followed by SOM. This enables true cross-algorithm evaluation, whereas past studies evaluated singular algorithms using unique, non-reproducible datasets. Our research shows an LDA + k-Means using a linear, centroid-based user navigation procedure produces optimal results. The winning approach increased information retrieval effectiveness, from the baseline random walk absolute precision rate of 0.04, to an average precision rate of 0.67. We also explored a variety of algorithms for user navigation of search hit results, finding that the performance of k-means clustering can be greatly improved with a non-linear, non-centroid-based cluster and document navigation procedure, which has potential implications for digital forensic tools and use thereof, particularly given the popularity and speed of k-means clustering.
ER  - 

TY  - JOUR
T1  - Feature Extension for Short Text Categorization Using Frequent Term Sets
JO  - Procedia Computer Science
VL  - 31
IS  - 
SP  - 663
EP  - 670
PY  - 2014///
T2  - 2nd International Conference on Information Technology and Quantitative Management, ITQM 2014
AU  - Man, Yuan
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2014.05.314
UR  - http://www.sciencedirect.com/science/article/pii/S1877050914004918
KW  - frequent term sets
KW  - short text classification
KW  - feature extension
AB  - Abstract
A short text feature extension method based on frequent term sets is proposed to overcome the drawbacks of the vector space model (VSM) on representing short text content. After defining the co-occurring and class orientation relations between terms, frequent term sets with identical class orientation are generated by calculating the support and confidence of word sets, and then taken as the background knowledge for short text feature extension. For each single term of the short text, the term sets containing this term are retrieved in the background knowledge and added into the original term vector as the feature extension. The experimental results on Sougou corpus show that the support and confidence have great impact on the scale of the background knowledge, but excessive extension also has redundancy and cannot obtain further improvement. The background knowledge based on frequent term sets is an effective way for feature extension. When the number of the training documents is limited, these extended features can greatly improve the classification results of SVM.
ER  - 

TY  - JOUR
T1  - Semantic Retrieval of Relevant Sources for Large Scale Virtual Documents
JO  - Procedia Computer Science
VL  - 54
IS  - 
SP  - 371
EP  - 379
PY  - 2015///
T2  - Eleventh International Conference on Communication Networks, ICCN 2015, August 21-23, 2015, Bangalore, India Eleventh International Conference on Data Mining and Warehousing, ICDMW 2015, August 21-23, 2015, Bangalore, India Eleventh International Conference on Image and Signal Processing, ICISP 2015, August 21-23, 2015, Bangalore, India
AU  - Priyadarshini, R.
AU  - Tamilselvan, Latha
AU  - Khuthbudin, T.
AU  - Saravanan, S.
AU  - Satish, S.
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.06.043
UR  - http://www.sciencedirect.com/science/article/pii/S1877050915013678
KW  - Virtual documents (VD)
KW  - Source document
KW  - Hadoop file System (HDFS)
KW  - DW Ranking algorithm
KW  - Top K algorithm.
AB  - Abstract
The term big data has come into use in recent years. It is used to refer to the ever-increasing amount of data that organizations are storing, processing and analyzing. An Interesting fact with bigdata is that it differ in Volume, Variety, Velocity characteristics which makes it difficult to process using the conventional Database Management System. Hence there is a need of schema less Management Systems even this will never be complete solution to bigdata analysis since the processing has no focus on the semantic information as they consider only the structural information. Content Management System like Wikipedia stores and links huge amount of documents and files. There is lack of semantic linking and analysis in such systems even though this kind of CMS uses clusters and distributed framework for storing big data. The retrieved references for a particular article are random and enormous. In order to reduce the number of references for a selected content there is a need for semantic matching. In this paper we propose framework which make use of the distributed parallel processing capability of Hadoop Distributed File System (HDFS) to perform semantic analysis over the volume of documents (bigdata) to find the best matched source document from the collection source documents for the same virtual document.
ER  - 

TY  - JOUR
T1  - Unsupervised Concept Hierarchy Learning: A Topic Modeling Guided Approach
JO  - Procedia Computer Science
VL  - 89
IS  - 
SP  - 386
EP  - 394
PY  - 2016///
T2  - Twelfth International Conference on Communication Networks, ICCN 2016, August 19– 21, 2016, Bangalore, India Twelfth International Conference on Data Mining and Warehousing, ICDMW 2016, August 19-21, 2016, Bangalore, India Twelfth International Conference on Image and Signal Processing, ICISP 2016, August 19-21, 2016, Bangalore, India
		
AU  - Anoop, V.S.
AU  - Asharaf, S.
AU  - Deepak, P.
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2016.06.086
UR  - http://www.sciencedirect.com/science/article/pii/S1877050916311516
KW  - Concept Learning
KW  - Latent Dirichlet Allocation
KW  - Subsumption Hierarchy
KW  - Text Mining
KW  - Topic Modeling
AB  - Abstract
This paper proposes an efficient and scalable method for concept extraction and concept hierarchy learning from large unstructured text corpus which is guided by a topic modeling process. The method leverages “concepts” from statistically discovered “topics” and then learns a hierarchy of those concepts by exploiting a subsumption relation between them. Advantage of the proposed method is that the entire process falls under the unsupervised learning paradigm thus the use of a domain specific training corpus can be eliminated. Given a massive collection of text documents, the method maps topics to concepts by some lightweight statistical and linguistic processes and then probabilistically learns the subsumption hierarchy. Extensive experiments with large text corpora such as BBC News dataset and Reuters News corpus shows that our proposed method outperforms some of the existing methods for concept extraction and efficient concept hierarchy learning is possible if the overall task is guided by a topic modeling process.
ER  - 

TY  - JOUR
T1  - Citation analysis: A social and dynamic approach to knowledge organization
JO  - Information Processing & Management
VL  - 49
IS  - 6
SP  - 1313
EP  - 1325
PY  - 2013/11//
T2  - 
AU  - Hjørland, Birger
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2013.07.001
UR  - http://www.sciencedirect.com/science/article/pii/S0306457313000733
KW  - Approaches to knowledge organization
KW  - Information organization
KW  - Bibliometrics
KW  - Citation analysis
KW  - Epistemology
AB  - Abstract
Knowledge organization (KO) and bibliometrics have traditionally been seen as separate subfields of library and information science, but bibliometric techniques make it possible to identify candidate terms for thesauri and to organize knowledge by relating scientific papers and authors to each other and thereby indicating kinds of relatedness and semantic distance. It is therefore important to view bibliometric techniques as a family of approaches to KO in order to illustrate their relative strengths and weaknesses. The subfield of bibliometrics concerned with citation analysis forms a distinct approach to KO which is characterized by its social, historical and dynamic nature, its close dependence on scholarly literature and its explicit kind of literary warrant. The two main methods, co-citation analysis and bibliographic coupling represent different things and thus neither can be considered superior for all purposes. The main difference between traditional knowledge organization systems (KOSs) and maps based on citation analysis is that the first group represents intellectual KOSs, whereas the second represents social KOSs. For this reason bibliometric maps cannot be expected ever to be fully equivalent to scholarly taxonomies, but they are – along with other forms of KOSs – valuable tools for assisting users’ to orient themselves to the information ecology. Like other KOSs, citation-based maps cannot be neutral but will always be based on researchers’ decisions, which tend to favor certain interests and views at the expense of others.
ER  - 

TY  - JOUR
T1  - Special issue on contribution of ontologies in designing advanced information systems
JO  - Data & Knowledge Engineering
VL  - 69
IS  - 11
SP  - 1081
EP  - 1083
PY  - 2010/11//
T2  - Special issue on contribution of ontologies in designing advanced information systems
AU  - Bellatreche, Ladjel
AU  - Ameur, Yamine Aït
AU  - Pierra, Guy
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2010.08.002
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X10000960
ER  - 

TY  - JOUR
T1  - MCMR: Maximum coverage and minimum redundant text summarization model
JO  - Expert Systems with Applications
VL  - 38
IS  - 12
SP  - 14514
EP  - 14522
PY  - 2011/11//
Y2  - 2011/12//
T2  - 
AU  - Alguliev, Rasim M.
AU  - Aliguliyev, Ramiz M.
AU  - Hajirahimova, Makrufa S.
AU  - Mehdiyev, Chingiz A.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2011.05.033
UR  - http://www.sciencedirect.com/science/article/pii/S0957417411008177
KW  - Text summarization
KW  - Maximum coverage
KW  - Less redundancy
KW  - Integer linear programming
KW  - Particle swarm optimization
KW  - Branch-and-bound
AB  - In paper, we propose an unsupervised text summarization model which generates a summary by extracting salient sentences in given document(s). In particular, we model text summarization as an integer linear programming problem. One of the advantages of this model is that it can directly discover key sentences in the given document(s) and cover the main content of the original document(s). This model also guarantees that in the summary can not be multiple sentences that convey the same information. The proposed model is quite general and can also be used for single- and multi-document summarization. We implemented our model on multi-document summarization task. Experimental results on DUC2005 and DUC2007 datasets showed that our proposed approach outperforms the baseline systems.
ER  - 

TY  - JOUR
T1  - Subtopic mining using simple patterns and hierarchical structure of subtopic candidates from web documents
JO  - Information Processing & Management
VL  - 51
IS  - 6
SP  - 773
EP  - 785
PY  - 2015/11//
T2  - 
AU  - Kim, Se-Jong
AU  - Lee, Jong-Hyeok
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2015.07.001
UR  - http://www.sciencedirect.com/science/article/pii/S0306457315000850
KW  - Search intention
KW  - Subtopic mining
KW  - Hierarchical structure
AB  - Abstract
The intention gap between users and queries results in ambiguous and broad queries. To solve these problems, subtopic mining has been studied, which returns a ranked list of possible subtopics according to their relevance, popularity, and diversity. This paper proposes a novel method to mine subtopics using simple patterns and a hierarchical structure of subtopic candidates. First, relevant and various phrases are extracted as subtopic candidates using simple patterns based on noun phrases and alternative partial-queries. Second, a hierarchical structure of the subtopic candidates is constructed using sets of relevant documents from a web document collection. Finally, the subtopic candidates are ranked considering a balance between popularity and diversity using this structure. In experiments, our proposed methods outperformed the baselines and even an external resource based method at high-ranked subtopics, which shows that our methods can be effective and useful in various search scenarios like result diversification.
ER  - 

TY  - JOUR
T1  - Prediction of Online Lectures Popularity: A Text Mining Approach
JO  - Procedia Computer Science
VL  - 92
IS  - 
SP  - 468
EP  - 474
PY  - 2016///
T2  - 2nd International Conference on Intelligent Computing, Communication &amp; Convergence, ICCC 2016, 24-25 January 2016, Bhubaneswar, Odisha, India
AU  - Oza, Kavita S.
AU  - Naik, Poornima G.
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2016.07.369
UR  - http://www.sciencedirect.com/science/article/pii/S1877050916316258
KW  - Text Mining
KW  - Clustering
KW  - R studio
KW  - Video lectures
KW  - online learning
AB  - Abstract
Text mining is an emerging area of research with flavors of opinion mining, sentiment mining, document classification, content mining etc. Another flavor of text mining is text clustering. Proposed work is based on clustering the comments posted by users to online learning. The dataset is prepared using comments posted by users for text mining video lectures using R and Weka. In the proposed work learners comments for online text mining lectures have been clustered to observe the popularity of the lectures by analyzing the terms in each cluster.
ER  - 

TY  - JOUR
T1  - Data clustering with size constraints
JO  - Knowledge-Based Systems
VL  - 23
IS  - 8
SP  - 883
EP  - 889
PY  - 2010/12//
T2  - 
AU  - Zhu, Shunzhi
AU  - Wang, Dingding
AU  - Li, Tao
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2010.06.003
UR  - http://www.sciencedirect.com/science/article/pii/S095070511000095X
KW  - Constrained clustering
KW  - Size constraints
KW  - Linear programming
KW  - Data mining
KW  - Background knowledge
AB  - Data clustering is an important and frequently used unsupervised learning method. Recent research has demonstrated that incorporating instance-level background information to traditional clustering algorithms can increase the clustering performance. In this paper, we extend traditional clustering by introducing additional prior knowledge such as the size of each cluster. We propose a heuristic algorithm to transform size constrained clustering problems into integer linear programming problems. Experiments on both synthetic and UCI datasets demonstrate that our proposed approach can utilize cluster size constraints and lead to the improvement of clustering accuracy.
ER  - 

TY  - JOUR
T1  - Clustering Text Data Streams – A Tree based Approach with Ternary Function and Ternary Feature Vector
JO  - Procedia Computer Science
VL  - 31
IS  - 
SP  - 976
EP  - 984
PY  - 2014///
T2  - 2nd International Conference on Information Technology and Quantitative Management, ITQM 2014
AU  - PhridviRaj
AU  - Srinivas, Chintakindi
AU  - GuruRao, C.V.
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2014.05.350
UR  - http://www.sciencedirect.com/science/article/pii/S1877050914005274
KW  - similarity
KW  - ternary vector
KW  - cluster
KW  - data stream
KW  - frequent item
AB  - Abstract
Data is the primary concern in data mining. Data Stream Mining is gaining a lot of practical significance with the huge online data generated from Sensors, Internet Relay Chats, Twitter, Facebook, Online Bank or ATM Transactions. The primary constraint in finding the frequent patterns in data streams is to perform only one time scan of the data with limited memory and requires less processing time. The concept of dynamically changing data is becoming a key challenge, what we call as data streams. In our present work, the algorithm is based on finding frequent patterns in the data streams using a tree based approach and to continuously cluster the text data streams being generated using a new ternary similarity measure defined.
ER  - 

TY  - JOUR
T1  - An Improved Memetic Algorithm for Web Search
JO  - Procedia Computer Science
VL  - 45
IS  - 
SP  - 52
EP  - 59
PY  - 2015///
T2  - International Conference on Advanced Computing Technologies and Applications (ICACTA)
AU  - Deulkar, Khushali
AU  - Narvekar, Meera
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.03.083
UR  - http://www.sciencedirect.com/science/article/pii/S1877050915003191
KW  - Local Search
KW  - Genetic Algorithm
KW  - Memetic Algorithm
KW  - Snippets.
AB  - Abstract
In order to search a relevant data from World Wide Web, user use to submit query to search engine. Search engine returns combination of relevant and irrelevant results. This paper proposes a novel method based on Memetic Algorithm (MA) for searching the most relevant snippets in case of complex queries. The improved memetic algorithm (IMA) uses a hybrid-selection strategy to enhance the search result. Classical local search operators are combined for improvement in final output. Besides, the same chromosomes are modified to be different so that the population diversity is preserved and the algorithm kept from premature convergence. The performance of IMA is tested by comparing the result of search engine, basic Memetic and Improved Memetic Algorithm. Experimental results show that IMA could obtain superior solutions to the counterparts.
ER  - 

TY  - JOUR
T1  - CONQUIRO: A cluster-based meta-search engine
JO  - Computers in Human Behavior
VL  - 27
IS  - 4
SP  - 1303
EP  - 1309
PY  - 2011/7//
T2  - Social and Humanistic Computing for the Knowledge Society
AU  - Vargas-Vera, Maria
AU  - Castellanos, Yesica
AU  - Lytras, Miltiadis D.
SN  - 0747-5632
DO  - http://dx.doi.org/10.1016/j.chb.2010.07.025
UR  - http://www.sciencedirect.com/science/article/pii/S0747563210002219
AB  - This paper presents CONQUIRO a cluster based information retrieval engine. The main task of CONQUIRO is to organize documents in groups/clusters relevant to the request or query. The main purpose of CONQUIRO is to help to manage information in an efficient manner. CONQUIRO uses Machine learning algorithms (Clustering methods) as underlying technology. It has been equipped with hierarchical and non-hierarchical clustering algorithms both using Euclidean and cosine similarity as distance measures. Authors believe that CONQUIRO represents a solution to the problem of information management since CONQUIRO goes beyond just a ranked list of documents (Google like).
ER  - 

TY  - JOUR
T1  - Comparison of ITSS Definition and A Questionnaire to Software engineer′s Skill Improvement
JO  - Procedia Computer Science
VL  - 22
IS  - 
SP  - 689
EP  - 698
PY  - 2013///
T2  - 17th International Conference in Knowledge Based and Intelligent Information and Engineering Systems - KES2013
AU  - El-Agamy, Rasha
AU  - Morimoto, Chikako
AU  - Tsuda, Kazuhiko
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2013.09.150
UR  - http://www.sciencedirect.com/science/article/pii/S1877050913009435
KW  - Information Technology
KW  - Learn
KW  - Human Resources Development
KW  - Skills
AB  - Abstract
Information Technology Skill Standards (ITSS) are the indices which identify and systemize practical abilities for IT services. ITSS was published by the Japanese Ministry of Economy, Trade and Industry(METI) in December 2002. Since then, it has come into widespread use as indices of skills of human resources among companies in the IT service industry. Our previous work analyzed the documents of ITSS using data mining techniques, but a proof or evaluation of the results is required. This paper compares between the results of the previous work and the results of a questionnaire that was applied in a Japanese company that uses ITSS to develop its human resources. The questionnaire was applied to 1080 employees in 15 departments in a Japanese company. The purpose of this questionnaire is to grasp the skills of the employees. The correlation coefficient between the questionnaire and the previous work is 0.67 and this is good value. This proves that the results of previous work is very near to the real life.
ER  - 

TY  - JOUR
T1  - Introducing Product Lifecycle Management to Small Medium Enterprises: discussion and analysis
JO  - IFAC Proceedings Volumes
VL  - 45
IS  - 6
SP  - 1059
EP  - 1064
PY  - 23///
Y2  - 2012/5/25/
T2  - 14th IFAC Symposium on Information Control Problems in Manufacturing
AU  - Antonelli, D.
AU  - Chiabert, P.
AU  - Villa, A.
SN  - 1474-6670
DO  - http://dx.doi.org/10.3182/20120523-3-RO-2023.00261
UR  - http://www.sciencedirect.com/science/article/pii/S1474667016332918
KW  - Product Lifecycle Management
KW  - Business Process Reengineering
AB  - Abstract
Industrial interest in Product Lifecycle Management (PLM) is twofaced. Large companies exhibit successful stories of PLM implementation because it has often shown to be an effective tool in increasing the quality and reliability of the development process of their products. On the opposite, small enterprises face relevant problems in the adoption of a PLM system, essentially because it requests for a relevant reorganization of their internal processes. Large PLM systems already operate in several enterprises but new light software suites, based on the “out of the shelf” commercial policy and open source software, makes PLM systems affordable also for a Small and Medium Enterprise (SME). The introduction of PLM in the work environment of a SME is not a problem of costs but of organization. In order to define and highlight the issues in the implementation of a PLM system in a SME, the analysis method presented by the authors in former studies was further developed and applied to a case study.
ER  - 

TY  - JOUR
T1  - European research and the Hungarian school of food irradiation
JO  - Radiation Physics and Chemistry
VL  - 129
IS  - 
SP  - 13
EP  - 23
PY  - 2016/12//
T2  - Special issue on Food Irradiation commemorating József Farkas
AU  - Lakner, Zoltán
AU  - Soós, Sándor
AU  - Vida, Zsófia
AU  - Farkas, Csilla
SN  - 0969-806X
DO  - http://dx.doi.org/10.1016/j.radphyschem.2016.08.010
UR  - http://www.sciencedirect.com/science/article/pii/S0969806X16302675
KW  - Citation analysis
KW  - Co-author analysis
KW  - Multidimensional scaling
KW  - Science mapping
KW  - Scientometrics
AB  - Abstract
In second half of the 20th century the research of application of irradiation to food preservation become a new and prospective field of food science and technology. This activity has been supported and developed in a parallel way in both halves of the that-time world, divided by the iron-curtain. Under these conditions, fulfilling a specific "bridge-role", some highly innovative scientists, first of all Professor József Farkas has been able to achieve considerable results in this new field of science. Based on citation analysis and science mapping it can be proven, that his path-breaking research has been exercise a fertilising effect on development of a wide range of fields of science, and considerably contributed to proliferation of this science and technology in numerous countries of the world.
ER  - 

TY  - JOUR
T1  - Research literature clustering using diffusion maps
JO  - Journal of Informetrics
VL  - 7
IS  - 4
SP  - 874
EP  - 886
PY  - 2013/10//
T2  - 
AU  - Nieminen, Paavo
AU  - Pölönen, Ilkka
AU  - Sipola, Tuomo
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2013.08.004
UR  - http://www.sciencedirect.com/science/article/pii/S1751157713000680
KW  - Knowledge discovery process
KW  - Literature mapping
KW  - Data mining
KW  - Clustering
KW  - Diffusion map
AB  - Abstract
We apply the knowledge discovery process to the mapping of current topics in a particular field of science. We are interested in how articles form clusters and what are the contents of the found clusters. A framework involving web scraping, keyword extraction, dimensionality reduction and clustering using the diffusion map algorithm is presented. We use publicly available information about articles in high-impact journals. The method should be of use to practitioners or scientists who want to overview recent research in a field of science. As a case study, we map the topics in data mining literature in the year 2011.
ER  - 

TY  - JOUR
T1  - Knowledge acquisition method from domain text based on theme logic model and artificial neural network
JO  - Expert Systems with Applications
VL  - 37
IS  - 1
SP  - 267
EP  - 275
PY  - 2010/1//
T2  - 
AU  - Wang, Jun
AU  - Wu, Yunpeng
AU  - Liu, Xuening
AU  - Gao, Xiaoying
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2009.05.009
UR  - http://www.sciencedirect.com/science/article/pii/S0957417409004217
KW  - Knowledge acquisition
KW  - Domain text
KW  - Theme logic model
KW  - Artificial neural network
KW  - Failure analysis report
AB  - In order to acquire knowledge from domain text such as failure analysis text of aviation product, a framework is proposed to enhance the efficiency and accuracy of knowledge acquisition. In this framework, sentence templates are defined to extract the meta-knowledge and RDF is used to describe the extracted knowledge. After the preprocessing steps, the authors propose a new model: theme logic model (TLM) to present all the themes of a piece of text and the logical relations among different themes. In this model, the text of each theme can be represented as an attribute–value vector based on domain ontology. Meanwhile, the logical relations are the domain knowledge to be acquired. The theme logic model then will be transformed to the training set of the artificial neural network to acquire the failure analysis knowledge. After training process, acquired knowledge will be extracted by SD method from the artificial neural network and represented by rules. Therefore, a prototype is developed to acquire knowledge from failure analysis reports of aviation product. Empirical results show that the framework can acquire knowledge from domain text efficiently.
ER  - 

TY  - JOUR
T1  - Collaborative clustering of XML documents
JO  - Journal of Computer and System Sciences
VL  - 77
IS  - 6
SP  - 988
EP  - 1008
PY  - 2011/11//
T2  - 
AU  - Greco, Sergio
AU  - Gullo, Francesco
AU  - Ponti, Giovanni
AU  - Tagarelli, Andrea
SN  - 0022-0000
DO  - http://dx.doi.org/10.1016/j.jcss.2011.02.005
UR  - http://www.sciencedirect.com/science/article/pii/S0022000011000341
KW  - Collaborative distributed clustering
KW  - XML
KW  - P2P networks
KW  - XML structure and content information
KW  - Transactional data
AB  - Clustering XML documents is extensively used to organize large collections of XML documents in groups that are coherent according to structure and/or content features. The growing availability of distributed XML sources and the variety of high-demand environments raise the need for clustering approaches that can exploit distributed processing techniques. Nevertheless, existing methods for clustering XML documents are designed to work in a centralized way. In this paper, we address the problem of clustering XML documents in a collaborative distributed framework. XML documents are first decomposed based on semantically cohesive subtrees, then modeled as transactional data that embed both XML structure and content information. The proposed clustering framework employs a centroid-based partitional clustering method that has been developed for a peer-to-peer network. Each peer in the network is allowed to compute a local clustering solution over its own data, and to exchange its cluster representatives with other peers. The exchanged representatives are used to compute representatives for the global clustering solution in a collaborative way. We evaluated effectiveness and efficiency of our approach on real XML document collections varying the number of peers. Results have shown that major advantages with respect to the corresponding centralized clustering setting are obtained in terms of runtime behavior, although clustering solutions can still be accurate with a moderately low number of nodes in the network. Moreover, the collaborativeness characteristic of our approach has revealed to be a convenient feature in distributed clustering as found in a comparative evaluation with a distributed non-collaborative clustering method.
ER  - 

TY  - JOUR
T1  - A semantic approach for text clustering using WordNet and lexical chains
JO  - Expert Systems with Applications
VL  - 42
IS  - 4
SP  - 2264
EP  - 2275
PY  - 2015/3//
T2  - 
AU  - Wei, Tingting
AU  - Lu, Yonghe
AU  - Chang, Huiyou
AU  - Zhou, Qiang
AU  - Bao, Xianyu
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2014.10.023
UR  - http://www.sciencedirect.com/science/article/pii/S0957417414006472
KW  - Text clustering
KW  - WordNet
KW  - Lexical chains
KW  - Core semantic features
AB  - Abstract
Traditional clustering algorithms do not consider the semantic relationships among words so that cannot accurately represent the meaning of documents. To overcome this problem, introducing semantic information from ontology such as WordNet has been widely used to improve the quality of text clustering. However, there still exist several challenges, such as synonym and polysemy, high dimensionality, extracting core semantics from texts, and assigning appropriate description for the generated clusters. In this paper, we report our attempt towards integrating WordNet with lexical chains to alleviate these problems. The proposed approach exploits ontology hierarchical structure and relations to provide a more accurate assessment of the similarity between terms for word sense disambiguation. Furthermore, we introduce lexical chains to extract a set of semantically related words from texts, which can represent the semantic content of the texts. Although lexical chains have been extensively used in text summarization, their potential impact on text clustering problem has not been fully investigated. Our integrated way can identify the theme of documents based on the disambiguated core features extracted, and in parallel downsize the dimensions of feature space. The experimental results using the proposed framework on reuters-21578 show that clustering performance improves significantly compared to several classical methods.
ER  - 

TY  - JOUR
T1  - Non-negative Matrix Tri-Factorization for co-clustering: An analysis of the block matrix
JO  - Information Sciences
VL  - 301
IS  - 
SP  - 13
EP  - 26
PY  - 2015/4/20/
T2  - 
AU  - Del Buono, N.
AU  - Pio, G.
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2014.12.058
UR  - http://www.sciencedirect.com/science/article/pii/S0020025515000109
KW  - Co-clustering
KW  - Non-negative Matrix Factorization
KW  - Subspace approximation
KW  - Text mining
AB  - Abstract
Non-negative dyadic data, that is data representing observations which relate two finite sets of objects, appear in several domain applications, such as text-mining-based information retrieval, collaborative filtering and recommender systems, micro-array analysis and computer vision. Discovering latent subgroups among data is a fundamental task to be performed on dyadic data. In this context, clustering and co-clustering techniques are relevant tools for extracting and representing latent information in high dimensional data. Recently, Non-negative Matrix Factorizations attracted a great interest as clustering methods, due to their capability of performing a parts-based decomposition of data. In this paper, we focus our attention on how NMF with additional constraints can be properly applied for co-clustering non-negative dyadic data. In particular, we present a process which aims at enhancing the performance of 3-factors NMF as a co-clustering method, by identifying a clearer correlation structure represented by the block matrix.

Experimental evaluation performed on some common datasets, by applying the proposed approach on two different NMF algorithms, shows that, in most cases, the quality of the obtained clustering increases, especially in terms of average inter-cluster similarity.
ER  - 

TY  - JOUR
T1  - Using local density information to improve IB algorithms
JO  - Pattern Recognition Letters
VL  - 32
IS  - 2
SP  - 310
EP  - 320
PY  - 2011/1/15/
T2  - 
AU  - Ye, Yangdong
AU  - Ren, Yongli
AU  - Li, Gang
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2010.09.009
UR  - http://www.sciencedirect.com/science/article/pii/S0167865510003132
KW  - Information Bottleneck
KW  - Density
KW  - Neighborhood information
KW  - Hierarchical tree-structure
AB  - The Information Bottleneck principle provides a systematic method to extract relevant features from complex data sets, and it models features extraction as data compression and quantifies the relevance of extracted feature by how much information it preserved about a specified feature. How to construct an optimal solution to IB remains a problem. The current Information Bottleneck (IB) algorithms only utilize the information between element pairs, and ignore the information among the neighborhood of elements. This is one of the major reasons for most IB algorithms’ failure to preserve as much relative information as possible, which further limits IB applicability in many areas. In this paper, we present the concept of density connectivity component, by which the information loss among the neighbors of an element, rather than the information loss between paired elements, can be considered. Then, we introduce this concept into the current agglomerative IB algorithm (aIB) and sequential IB algorithm (sIB), and propose two density-based IB algorithms, DaIB and DsIB. The experiment results on the benchmark data sets indicate that the DaIB and DsIB algorithm can preserve more relevant information and achieve higher precision than the aIB and sIB algorithm, respectively.
ER  - 

TY  - JOUR
T1  - Validation of overlapping clustering: A random clustering perspective
JO  - Information Sciences
VL  - 180
IS  - 22
SP  - 4353
EP  - 4369
PY  - 2010/11/15/
T2  - 
AU  - Wu, Junjie
AU  - Yuan, Hua
AU  - Xiong, Hui
AU  - Chen, Guoqing
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2010.07.028
UR  - http://www.sciencedirect.com/science/article/pii/S0020025510003464
KW  - Information retrieval
KW  - Cluster validation
KW  - F-measure
KW  - Implication intensity (IMI)
KW  - Incomplete beta function
AB  - As a widely used clustering validation measure, the F-measure has received increased attention in the field of information retrieval. In this paper, we reveal that the F-measure can lead to biased views as to results of overlapped clusters when it is used for validating the data with different cluster numbers (incremental effect) or different prior probabilities of relevant documents (prior-probability effect). We propose a new “IMplication Intensity” (IMI) measure which is based on the F-measure and is developed from a random clustering perspective. In addition, we carefully investigate the properties of IMI. Finally, experimental results on real-world data sets show that IMI significantly alleviates biased incremental and prior-probability effects which are inherent to the F-measure.
ER  - 

TY  - JOUR
T1  - Beyond cluster labeling: Semantic interpretation of clusters’ contents using a graph representation
JO  - Knowledge-Based Systems
VL  - 56
IS  - 
SP  - 141
EP  - 155
PY  - 2014/1//
T2  - 
AU  - Role, François
AU  - Nadif, Mohamed
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2013.11.005
UR  - http://www.sciencedirect.com/science/article/pii/S0950705113003559
KW  - Cluster labeling
KW  - Clustering
KW  - Exploratory data analysis
KW  - Visualization
KW  - Network analysis
AB  - Abstract
Efficient clustering algorithms have been developed to automatically group documents into subgroups (clusters). Once clustering has been performed, an important additional step is to help users make sense of the obtained clusters. Existing methods address this issue by assigning to each cluster a flat list of descriptive terms (labels) that are extracted from the documents, most often using statistical techniques borrowed from the field of feature selection or reduction.

A limitation of these unstructured descriptions of clusters’ contents is that they do not account for the meaningful relationships between the terms. In contrast, we propose a graph representation, which makes the clusters easier to interpret by putting the descriptive terms in context, and by performing some simple network analysis. Our experiments reveal that the proposed method allows for a deeper level of interpretation, both when the clusters under study are homogeneous and when they are heterogeneous. In addition, evaluation procedures presented in the paper show that the graph-based representation of each cluster, while being very synthetic, still quite faithfully reflects the original content of the cluster.
ER  - 

TY  - JOUR
T1  - NEST: A quantitative model for detecting emerging trends using a global monitoring expert network and Bayesian network
JO  - Futures
VL  - 52
IS  - 
SP  - 59
EP  - 73
PY  - 2013/8//
T2  - 
AU  - Kim, Seonho
AU  - Kim, You-Eil
AU  - Bae, Kuk-Jin
AU  - Choi, Sung-Bae
AU  - Park, Jong-Kyu
AU  - Koo, Young-Duk
AU  - Park, Young-Wook
AU  - Choi, Hyun-Kyoo
AU  - Kang, Hyun-Moo
AU  - Hong, Sung-Wha
SN  - 0016-3287
DO  - http://dx.doi.org/10.1016/j.futures.2013.08.004
UR  - http://www.sciencedirect.com/science/article/pii/S001632871300102X
KW  - Weak signal
KW  - Emerging trend
KW  - Qualitative analysis
KW  - Quantitative analysis
KW  - Bayesian network
KW  - Delphi study
AB  - Abstract
The analysis of changes in the research and development (R&amp;D) environment and developing foresight of future technologies are increasingly recognized as important to support policy decision making and efficient resource distribution. Many futurists are developing foresight of future technologies based on Delphi studies, unfolding history, brainstorming, expert surveys, trend analysis, data mining, and so on. However, formalizing these processes is still a necessary task. In this paper, we introduce the NEST (New and Emerging Signals of Trends) model developed by the Korea Institute of Science and Technology Information (KISTI). The NEST collects information from worldwide expert networks and detects the weak signals of emerging future trends systematically, based on massive data analysis, inference techniques, and Delphi studies, to support the development of foresight of future research and technology. The NEST model combines quantitative and qualitative approaches. In the quantitative approach stages, NEST uses clustering, pattern recognition, and cross-impact analysis using a Bayesian network. In the stages of qualitative approaches, NEST conducts environmental scanning, brainstorming, and a Delphi study.
ER  - 

TY  - JOUR
T1  - A deterministic resampling method using overlapping document clusters for pseudo-relevance feedback
JO  - Information Processing & Management
VL  - 49
IS  - 4
SP  - 792
EP  - 806
PY  - 2013/7//
T2  - 
AU  - Lee, Kyung Soon
AU  - Croft, W. Bruce
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2013.01.001
UR  - http://www.sciencedirect.com/science/article/pii/S030645731300006X
KW  - Information retrieval
KW  - Pseudo-relevance feedback
KW  - Relevance model
KW  - Deterministic resampling
KW  - Dominant documents
KW  - Query expansion
AB  - Typical pseudo-relevance feedback methods assume the top-retrieved documents are relevant and use these pseudo-relevant documents to expand terms. The initial retrieval set can, however, contain a great deal of noise. In this paper, we present a cluster-based resampling method to select novel pseudo-relevant documents based on Lavrenko’s relevance model approach. The main idea is to use overlapping clusters to find dominant documents for the initial retrieval set, and to repeatedly use these documents to emphasize the core topics of a query.

The proposed resampling method can skip some documents in the initial high-ranked documents and deterministically construct overlapping clusters as sampling units. The hypothesis behind using overlapping clusters is that a good representative document for a query may have several nearest neighbors with high similarities, participating in several different clusters. Experimental results on large-scale web TREC collections show significant improvements over the baseline relevance model.

To justify the proposed approach, we examine the relevance density and redundancy ratio of feedback documents. A higher relevance density will result in greater retrieval accuracy, ultimately approaching true relevance feedback. The resampling approach shows higher relevance density than the baseline relevance model on all collections, resulting in better retrieval accuracy in pseudo-relevance feedback.
ER  - 

TY  - JOUR
T1  - Clustering rule bases using ontology-based similarity measures
JO  - Web Semantics: Science, Services and Agents on the World Wide Web
VL  - 25
IS  - 
SP  - 1
EP  - 8
PY  - 2014/3//
T2  - 
AU  - Hassanpour, Saeed
AU  - O’Connor, Martin J.
AU  - Das, Amar K.
SN  - 1570-8268
DO  - http://dx.doi.org/10.1016/j.websem.2014.03.001
UR  - http://www.sciencedirect.com/science/article/pii/S1570826814000092
KW  - Rule management
KW  - Rule categorization
KW  - Semantic similarity
KW  - SWRL
KW  - OWL
AB  - Abstract
Rules are increasingly becoming an important form of knowledge representation on the Semantic Web. There are currently few methods that can ensure that the acquisition and management of rules can scale to the size of the Web. We previously developed methods to help manage large rule bases using syntactical analyses of rules. This approach did not incorporate semantics. As a result, rule categorization based on syntactic features may not be effective. In this paper, we present a novel approach for grouping rules based on whether the rule elements share relationships within a domain ontology. We have developed our method for rules specified in the Semantic Web Rule Language (SWRL), which is based on the Web Ontology Language (OWL) and shares its formal underpinnings. Our method uses vector space modeling of rule atoms and an ontology-based semantic similarity measure. We apply a clustering method to detect rule relatedness, and we use a statistical model selection method to find the optimal number of clusters within a rule base. Using three different SWRL rule bases, we evaluated the results of our semantic clustering method against those of our syntactic approach. We have found that our new approach creates clusters that better match the rule bases’ logical structures. Semantic clustering of rule bases may help users to more rapidly comprehend, acquire, and manage the growing numbers of rules on the Semantic Web.
ER  - 

TY  - JOUR
T1  - Finding a representative subset from large-scale documents
JO  - Journal of Informetrics
VL  - 10
IS  - 3
SP  - 762
EP  - 775
PY  - 2016/8//
T2  - 
AU  - Zhang, Jin
AU  - Liu, Guannan
AU  - Ren, Ming
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2016.05.003
UR  - http://www.sciencedirect.com/science/article/pii/S1751157716300566
KW  - Information extraction method
KW  - Coverage
KW  - Redundancy
KW  - Distribution consistency
AB  - Abstract
Large-scale information, especially in the form of documents, is potentially useful for decision-making but intensifies the information overload problem. To cope with this problem, this paper proposes a method named RepExtract to extract a representative subset from large-scale documents. The extracted representative subset possesses three desirable features: high coverage of the content of the original document set, low redundancy within the extracted subset, and consistent distribution with the original set. Extensive experiments were conducted on benchmark datasets, demonstrating the superiority of RepExtract over the benchmark methods in terms of the three features above. A user study was also conducted by collecting human evaluations of different methods, and the results indicate that users can gain an understanding of large-scale documents precisely and efficiently through a representative subset extracted by the proposed method.
ER  - 

TY  - JOUR
T1  - Stable locality sensitive discriminant analysis for image recognition
JO  - Neural Networks
VL  - 54
IS  - 
SP  - 49
EP  - 56
PY  - 2014/6//
T2  - 
AU  - Gao, Quanxue
AU  - Liu, Jingjing
AU  - Cui, Kai
AU  - Zhang, Hailin
AU  - Wang, Xiaogang
SN  - 0893-6080
DO  - http://dx.doi.org/10.1016/j.neunet.2014.02.009
UR  - http://www.sciencedirect.com/science/article/pii/S0893608014000501
KW  - Dimensionality reduction
KW  - Diversity
KW  - Similarity
KW  - Manifold learning
AB  - Abstract
Locality Sensitive Discriminant Analysis (LSDA) is one of the prevalent discriminant approaches based on manifold learning for dimensionality reduction. However, LSDA ignores the intra-class variation that characterizes the diversity of data, resulting in unstableness of the intra-class geometrical structure representation and not good enough performance of the algorithm. In this paper, a novel approach is proposed, namely stable locality sensitive discriminant analysis (SLSDA), for dimensionality reduction. SLSDA constructs an adjacency graph to model the diversity of data and then integrates it in the objective function of LSDA. Experimental results in five databases show the effectiveness of the proposed approach.
ER  - 

TY  - JOUR
T1  - Exploratory analytics on patent data sets using the SIMPLE platform
JO  - World Patent Information
VL  - 33
IS  - 4
SP  - 328
EP  - 339
PY  - 2011/12//
T2  - 
AU  - Spangler, Scott
AU  - Ying, Chen
AU  - Kreulen, Jeffrey
AU  - Boyer, Stephen
AU  - Griffin, Thomas
AU  - Alba, Alfredo
AU  - Kato, Linda
AU  - Lelescu, Ana
AU  - Yan, Su
SN  - 0172-2190
DO  - http://dx.doi.org/10.1016/j.wpi.2011.07.001
UR  - http://www.sciencedirect.com/science/article/pii/S0172219011001074
KW  - Patent mining
KW  - Exploratory analytics
KW  - Bioinformatics
KW  - Text analytics
KW  - SIMPLE
KW  - Mining platform
AB  - Exploratory Analytics is the process of analyzing data for the purpose of forming hypotheses. Patent data sets, because they are relatively large and diverse and because they consist of a mixture of structured and unstructured information present a formidable challenge and a great opportunity in applying exploratory analytics techniques. In this paper we describe methods we have implemented for effective exploratory analytics on patent data sets using an interactive approach and a web based software tool called SIMPLE. We use real-world case studies to demonstrate the effectiveness of our exploratory analytics approach in the discovery of useful information from the patent corpus.
ER  - 

TY  - JOUR
T1  - MeSHy: Mining unanticipated PubMed information using frequencies of occurrences and concurrences of MeSH terms
JO  - Journal of Biomedical Informatics
VL  - 44
IS  - 6
SP  - 919
EP  - 926
PY  - 2011/12//
T2  - 
AU  - Theodosiou, T.
AU  - Vizirianakis, I.S.
AU  - Angelis, L.
AU  - Tsaftaris, A.
AU  - Darzentas, N.
SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2011.05.009
UR  - http://www.sciencedirect.com/science/article/pii/S1532046411001006
KW  - PubMed
KW  - MeSH terms
KW  - Ontology
KW  - Imatinib
AB  - Motivation
PubMed is the most widely used database of biomedical literature. To the detriment of the user though, the ranking of the documents retrieved for a query is not content-based, and important semantic information in the form of assigned Medical Subject Headings (MeSH) terms is not readily presented or productively utilized. The motivation behind this work was the discovery of unanticipated information through the appropriate ranking of MeSH term pairs and, indirectly, documents. Such information can be useful in guiding novel research and following promising trends.
Methods
A web-based tool, called MeSHy, was developed implementing a mainly statistical algorithm. The algorithm takes into account the frequencies of occurrences, concurrences, and the semantic similarities of MeSH terms in retrieved PubMed documents to create MeSH term pairs. These are then scored and ranked, focusing on their unexpectedly frequent or infrequent occurrences.
Results
MeSHy presents results through an online interactive interface facilitating further manipulation through filtering and sorting. The results themselves include the MeSH term pairs, along with MeSH categories, the score, and document IDs, all of which are hyperlinked for convenience. To highlight the applicability of the tool, we report the findings of an expert in the pharmacology field on querying the molecularly-targeted drug imatinib and nutrition-related flavonoids. To the best of our knowledge, MeSHy is the first publicly available tool able to directly provide such a different perspective on the complex nature of published work.
Implementation and availability
Implemented in Perl and served by Apache2 at http://bat.ina.certh.gr/tools/meshy/ with all major browsers supported.
ER  - 

TY  - JOUR
T1  - An application of the text mining approach to select technology centers of excellence
JO  - Technological Forecasting and Social Change
VL  - 80
IS  - 5
SP  - 918
EP  - 931
PY  - 2013/6//
T2  - 
AU  - Ghazinoory, S.
AU  - Ameri, F.
AU  - Farnoodi, S.
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2012.09.001
UR  - http://www.sciencedirect.com/science/article/pii/S0040162512002132
KW  - Centers of excellence
KW  - Nanotechnology
KW  - Text mining
KW  - Iran
AB  - During the past century, achieving a high level of research capacity in all branches of science and technology simultaneously in all active scientific centers has not been possible due to resource constraints. Therefore, countries try to create specialized centers and professional associations to form hubs in specific fields of science in order to achieve a clear comparative advantage. This article attempts to propose an algorithm for selecting which centers of excellence to support. Using text mining techniques, this study presents a process for selecting technology centers of excellence and then implements this process using the nanotechnology field in Iran as a case study. The results of this case study show that, Iranian centers of excellence in the field of nanotechnology have been prioritized according to several approaches to provide policymakers with a proper tool for allocating governmental supports.
ER  - 

TY  - JOUR
T1  - Unsupervised Mining of Activities for Smart Home Prediction
JO  - Procedia Computer Science
VL  - 19
IS  - 
SP  - 503
EP  - 510
PY  - 2013///
T2  - The 4th International Conference on Ambient Systems, Networks and Technologies (ANT 2013), the 3rd International Conference on Sustainable Energy Information Technology (SEIT-2013)
AU  - Lapalu, Jérémy
AU  - Bouchard, Kevin
AU  - Bouzouane, Abdenour
AU  - Bouchard, Bruno
AU  - Giroux, Sylvain
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2013.06.067
UR  - http://www.sciencedirect.com/science/article/pii/S1877050913006753
KW  - Flocking
KW  - Data mining
KW  - Clustering
KW  - Smart home
AB  - Abstract
This paper addresses the problem of learning the Activities of Daily Living (ADLs) in smart home for cognitive assistance to an occupant suffering from some type of dementia, such as Alzheimer's disease. We present an extension of the Flocking algorithm for ADL clustering analysis. The Flocking based algorithm does not require an initial number of clusters, unlike other partition algorithms such as K-means. This approach allows us to learn ADL models automatically (without human supervision) to carry out activity recognition. By simulating a set of real case scenarios, an implementation of this model was tested in our smart home laboratory, the LIARA.
ER  - 

TY  - JOUR
T1  - Clients’ Freely Written Assessment as the Source of Automatically Mined Opinions
JO  - Procedia Economics and Finance
VL  - 12
IS  - 
SP  - 103
EP  - 110
PY  - 2014///
T2  - 17th International Conference Enterprise and Competitive Environment 2014
AU  - Dařena, František
AU  - Žižka, Jan
AU  - Přichystal, Jan
SN  - 2212-5671
DO  - http://dx.doi.org/10.1016/S2212-5671(14)00325-6
UR  - http://www.sciencedirect.com/science/article/pii/S2212567114003256
KW  - Medical service evaluation
KW  - opinion discovery
KW  - text mining
KW  - machine learning
KW  - clustering
AB  - Abstract
Measuring the quality of products or services, a challenging task is to reveal clients’ satisfaction or sentiment. As people have many opportunities to express their opinions using various on-line channels (e.g., discussions, microblogs, social networks), the question is whether such data might be used for this purpose. Information hidden in the data includes the reasons why people perceive products or services as good or bad, what are the reasons of clients’ satisfaction or dissatisfaction, or what affects their sentiment. However, having the needed large amounts of data, it is hardly possible to process it manually. This paper presents a method that aims at automatic discovery of sources of human feelings hidden in textual messages that clients produce. For a demonstration, messages having a form of freely written reviews containing subjective evaluation of medical services were used. During analysis of the data, clusters representing groups of the whole reviews (or individual sentences) with a certain requested degree of similarity were created in an unsupervised manner. Then, a decision tree classifier was trained in order to find attributes (words) of the reviews that were significant for assigning the reviews to the clusters. Because individual words were sometimes not informative enough they were subsequently used as a starting point for searching for frequent multi-word expressions. As a result, the list of multi-word phrases representing frequent and important sources of clients’ opinions was presented.
ER  - 

TY  - JOUR
T1  - Mining Unstructured Turkish Economy News Articles
JO  - Procedia Economics and Finance
VL  - 16
IS  - 
SP  - 320
EP  - 328
PY  - 2014///
T2  - 21st International Economic Conference of Sibiu 2014, IECS 2014 Prospects of Economic Recovery in a Volatile International Context: Major Obstacles, Initiatives and Projects
AU  - Özyirmidokuz, Esra Kahya
SN  - 2212-5671
DO  - http://dx.doi.org/10.1016/S2212-5671(14)00809-0
UR  - http://www.sciencedirect.com/science/article/pii/S2212567114008090
KW  - Knowledge discovery in databases
KW  - Text mining
KW  - Natural language processing
AB  - Abstract
Text mining is the analysis of unstructured data by combining techniques from knowledge discovery in databases, natural language processing, information retrieval, and machine learning. Text mining allows us to analyze web content dynamically to find meaningful patterns within large collections of textual data.

There are too many economic news articles to read. Therefore, it is a necessary to summarize them. In this study, TM is used to analyze the vast amount of text produced in newspaper articles in Turkey. We mine unstructured economy news with natural language processing techniques including tokenization, transform cases, filtering stopwords and stemming. Similarity analysis is also used to determine similar documents. The word vector is extracted. Therefore, economy news is structured into numeric representations that summarize them. In addition, k-means clustering is used. Consequently, the clusters and similarities of the articles are obtained.
ER  - 

TY  - JOUR
T1  - Cognitive Parameter Adaption for Model Based Control Systems
JO  - Procedia CIRP
VL  - 33
IS  - 
SP  - 133
EP  - 138
PY  - 2015///
T2  - 9th CIRP Conference on Intelligent Computation in Manufacturing Engineering - CIRP ICME '14
AU  - Schmid, Martin
AU  - Berger, Simon
AU  - Reinhart, Gunther
SN  - 2212-8271
DO  - http://dx.doi.org/10.1016/j.procir.2015.06.025
UR  - http://www.sciencedirect.com/science/article/pii/S221282711500668X
KW  - Machine Learning
KW  - Adaptive Control
AB  - Abstract
Modern printing machines are designed to produce big quantities with high product quality in a short time. Due to large dead times in the control system, the first sheets have an insufficient quality and need to be wasted. In the context of decreasing lot sizes the total production costs increase. To improve the resource and cost efficiency, a model based control system was developed. The model parameter will be adapted by a neural network according to all relevant influence parameters, which enables high simulation accuracy. A data base contains all relevant production parameters and influences, which are used to train the neural network. It is designed to learn the correlation between 26 different influence parameters and the resulting system behaviour without any manual assistance.

This paper describes a method to handle irregular distributed data sets to improve the training performance by using cluster algorithms. The initialization of the net weights is done according to the Nguyen-Widrow algorithm and different training algorithms are compared. Additionally, different network topologies are tested automatically to identify the best suited network. To combine the real time simulation model with the non-deterministic training process, the system is divided into two platforms. With the described control system it is possible to reduce the waste up to 80% at the start of the production.
ER  - 

TY  - JOUR
T1  - Content-based File Sharing in Peer-to-peer Networks Using Threshold
JO  - Procedia Computer Science
VL  - 79
IS  - 
SP  - 53
EP  - 60
PY  - 2016///
T2  - Proceedings of International Conference on Communication, Computing and Virtualization (ICCCV) 2016
AU  - Bhagat, Amol
AU  - Chaudhari, Radhika
AU  - Dongre, Kiran
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2016.03.008
UR  - http://www.sciencedirect.com/science/article/pii/S1877050916001393
KW  - Content-based file sharing
KW  - interest extracton
KW  - interest oriented file sharing
KW  - peer-to-peer network
KW  - threshold based sharing
AB  - Abstract
In content based file sharing peer-to-peer (P2P) [1] network model nodes share files directly with each other without a centralized server. In such a file sharing system, nodes meet and exchange requests and files in the format of text, short videos, and voice clips in different interest categories. Content is various and large file sharing such as the multimedia content is required with the rapid development of the wireless communication technology. File sharing can also mean having an allocated amount of personal file storage in a common file system. A P2P content based file sharing system, for efficient file searching, threshold takes advantage of node mobility by designating stable nodes, which have the most frequent contact with community members, as community coordinators for intra community searching, and highly mobile nodes that visit other communities frequently as community ambassadors for intercommunity searching. The large file sharing needs more stable end to end path and long transmission time. Last but not least, more relationship between nodes will be used to promote the file sharing process. Content based file sharing is helpful for taking certain decisions during file transmission. These decisions will benefit in proper utilization of network resources. In this paper content-based file sharing scheme using threshold is proposed. The user's interest is determined by the proposed scheme before searching and sharing the files in the peer-to-peer network. The resources in the network are utilized as per the contents of the files to be shared. The performance evaluation show that proposed system significantly lowers transmission cost and improves file sharing success rate compared to current methods.
ER  - 

TY  - JOUR
T1  - Locality sensitive C-means clustering algorithms
JO  - Neurocomputing
VL  - 73
IS  - 16–18
SP  - 2935
EP  - 2943
PY  - 2010/10//
T2  - 10th Brazilian Symposium on Neural Networks (SBRN2008)
AU  - Huang, Pengfei
AU  - Zhang, Daoqiang
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2010.07.015
UR  - http://www.sciencedirect.com/science/article/pii/S0925231210003450
KW  - Locality sensitive weight
KW  - Fuzzy C-means (FCM)
KW  - Semi-supervised clustering
AB  - The concept of preserving locality information in dimensionality reduction and semi-supervised classification have been very popular recently. In this paper, we attempt to use locality sensitive weight for clustering, where the neighborhood structure information between objects are transformed into weights of objects. We develop two novel locality sensitive C-means algorithms, i.e. Locality-weighted Hard C-Means (LHCM) and Locality-weighted Fuzzy C-Means (LFCM), following the standard C-Means and fuzzy C-means, respectively. In addition, two semi-supervised extensions of LFCM are proposed to better use some given partial supervision information in data objects. Experimental results on both artificial and real datasets validate the effectiveness of the proposed algorithms.
ER  - 

TY  - JOUR
T1  - Information bottleneck based incremental fuzzy clustering for large biomedical data
JO  - Journal of Biomedical Informatics
VL  - 62
IS  - 
SP  - 48
EP  - 58
PY  - 2016/8//
T2  - 
AU  - Liu, Yongli
AU  - Wan, Xing
SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2016.05.009
UR  - http://www.sciencedirect.com/science/article/pii/S1532046416300430
KW  - Fuzzy clustering
KW  - Information bottleneck
KW  - Incremental clustering
AB  - Abstract
Incremental fuzzy clustering combines advantages of fuzzy clustering and incremental clustering, and therefore is important in classifying large biomedical literature. Conventional algorithms, suffering from data sparsity and high-dimensionality, often fail to produce reasonable results and may even assign all the objects to a single cluster. In this paper, we propose two incremental algorithms based on information bottleneck, Single-Pass fuzzy c-means (spFCM-IB) and Online fuzzy c-means (oFCM-IB). These two algorithms modify conventional algorithms by considering different weights for each centroid and object and scoring mutual information loss to measure the distance between centroids and objects. spFCM-IB and oFCM-IB are used to group a collection of biomedical text abstracts from Medline database. Experimental results show that clustering performances of our approaches are better than such prominent counterparts as spFCM, spHFCM, oFCM and oHFCM, in terms of accuracy.
ER  - 

TY  - JOUR
T1  - The Development and Research of Bioinformatics in Neuroscience
JO  - AASRI Procedia
VL  - 1
IS  - 
SP  - 359
EP  - 364
PY  - 2012///
T2  - AASRI Conference on Computational Intelligence and Bioinformatics
AU  - Xu, Qing
AU  - Zhang, Wuke
AU  - Hu, Linfeng
AU  - Wang, Jiajiong
AU  - Jin, Jia
SN  - 2212-6716
DO  - http://dx.doi.org/10.1016/j.aasri.2012.06.055
UR  - http://www.sciencedirect.com/science/article/pii/S221267161200056X
KW  - bioinformatics
KW  - neuroscience
KW  - CiteSpace II
AB  - Recent years, the inter-discipline of bioinformatics and neuroscience has been developed with more and more researchers studying in molecular and cellular level, which resulting huge number of publications and findings. A tool of scientometrics, Citespace II was used to identify the hot topic and evolution map of this inter-discipline with the data download from Web of Science. Five research clusters were found with the method of co-citation analysis. The evolution map of knowledge base with 1991-2012 was described.
ER  - 

TY  - JOUR
T1  - Introduction to special section on enterprise integration, networking and collaboration
JO  - Annual Reviews in Control
VL  - 39
IS  - 
SP  - 81
EP  - 82
PY  - 2015///
T2  - 
AU  - Molina, Arturo
SN  - 1367-5788
DO  - http://dx.doi.org/10.1016/j.arcontrol.2015.03.007
UR  - http://www.sciencedirect.com/science/article/pii/S1367578815000085
ER  - 

TY  - JOUR
T1  - Special Issue on Advances in Computer Supported Collaboration: Systems and Technologies
JO  - Future Generation Computer Systems
VL  - 31
IS  - 
SP  - 105
EP  - 110
PY  - 2014/2//
T2  - Special Section: Advances in Computer Supported Collaboration: Systems and Technologies
AU  - Divoli, Anna
AU  - Potena, Domenico
AU  - Diamantini, Claudia
AU  - Smari, Waleed W.
SN  - 0167-739X
DO  - http://dx.doi.org/10.1016/j.future.2013.11.001
UR  - http://www.sciencedirect.com/science/article/pii/S0167739X13002549
ER  - 

TY  - JOUR
T1  - Information mining — Reflections on recent advancements and the road ahead in data, text, and media mining
JO  - Decision Support Systems
VL  - 51
IS  - 4
SP  - 727
EP  - 731
PY  - 2011/11//
T2  - Recent Advances in Data, Text, and Media Mining &amp; Information Issues in Supply Chain and in Service System Design
AU  - Gopal, Ram
AU  - Marsden, James R.
AU  - Vanthienen, Jan
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2011.01.008
UR  - http://www.sciencedirect.com/science/article/pii/S0167923611000376
KW  - Data mining
KW  - Text mining
KW  - Media mining
KW  - Information mining
KW  - Opinion and sentiment analysis
AB  - In this introduction, we briefly summarize the state of data and text mining today. Taking a very broad view, we use the term information mining to refer to the organization and analysis of structured or unstructured data that can be quantitative, textual, and/or pictorial in nature. The key question, in our view, is, “How can we transform data (in the very broad sense of this term) into ‘actionable knowledge’, knowledge that we can use in pursuit of a specified objective(s).” After detailing a set of key components of information mining, we introduce each of the papers in this volume and detail the focus of their contributions.
ER  - 

TY  - JOUR
T1  - An Advanced Multi Class Instance Selection based Support Vector Machine for Text Classification
JO  - Procedia Computer Science
VL  - 57
IS  - 
SP  - 1124
EP  - 1130
PY  - 2015///
T2  - 3rd International Conference on Recent Trends in Computing 2015 (ICRTC-2015)
AU  - Ramesh, B.
AU  - Sathiaseelan, J.G.R.
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.07.400
UR  - http://www.sciencedirect.com/science/article/pii/S1877050915019298
KW  - Text Mining
KW  - Classification
KW  - Support Vector Machine
KW  - Instance Selection ;
AB  - Abstract
Machine learning techniques is most commonly used technique in text mining. Support Vector Machine (SVM) is a most useful supervised learning technique for text classification. In this paper we proposed advanced Multi Class Instance Selection based support vector machine (AMCISSVM) to increasing efficiency of support vector machine. The proposed algorithm is compared with Multi Class Instance Selection (MCIS) and Neighborhood Property based Pattern Selection (NPPS) algorithm. The advanced MCIS has shown high accuracy to multi datasets. These experimental datasets are retrieved from UCI machine learning repositories.
ER  - 

TY  - JOUR
T1  - Projected Clustering Using Particle Swarm Optimization
JO  - Procedia Technology
VL  - 4
IS  - 
SP  - 360
EP  - 364
PY  - 2012///
T2  - 2nd International Conference on Computer, Communication, Control and Information Technology( C3IT-2012) on February 25 - 26, 2012
AU  - Gajawada, Satish
AU  - Toshniwal, Durga
SN  - 2212-0173
DO  - http://dx.doi.org/10.1016/j.protcy.2012.05.055
UR  - http://www.sciencedirect.com/science/article/pii/S2212017312003349
KW  - Particle swarm optimization
KW  - projected clustering ;k-means clustering ;high dimensional data
AB  - Clustering methods divide the dataset into groups of similar objects, where objects in the same group are similar and objects in different groups are dissimilar. Traditional clustering techniques that find clusters in full dimensional space may fail to find clusters in high dimensional data due to various problems associated with clustering on high dimensional data. Subspace and projected clustering methods find clusters that exist in subspaces of dataset. These methods provide solutions to challenges associated with clustering on high dimensional data. Projected clustering methods output subspace clusters where one point in the dataset belongs to only one subspace cluster. Points may be assigned to multiple subspace clusters by subspace clustering methods. Projected clustering is preferable to subspace clustering when partition of points is required. Particle swarm optimization (PSO) has been proven to be effective for solving complex optimization problems. In this paper, we propose a Projected Clustering Particle Swarm Optimization (PCPSO) method to find subspace clusters that are present in the dataset. In PCPSO, Particle swarm optimization has been used to find optimal cluster centers by optimizing a subspace cluster validation index. In this paper, kmeans has been used to find neighbourhood of subspace cluster centers. The proposed method has been used to find subspace clusters that are present in some synthetic datasets.
ER  - 

TY  - JOUR
T1  - Distance metrics for high dimensional nearest neighborhood recovery: Compression and normalization
JO  - Information Sciences
VL  - 184
IS  - 1
SP  - 92
EP  - 110
PY  - 2012/2/1/
T2  - 
AU  - France, Stephen L.
AU  - Douglas Carroll, J.
AU  - Xiong, Hui
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2011.07.048
UR  - http://www.sciencedirect.com/science/article/pii/S0020025511003872
KW  - Dimensionality
KW  - Latent classes
KW  - Minkowski metrics
KW  - Nearest neighbors
KW  - GINI
KW  - Normalization
AB  - Previous work has shown that the Minkowski-p distance metrics are unsuitable for clustering very high dimensional document data. We extend this work. We frame statistical theory on the relationships between the Euclidean, cosine, and correlation distance metrics in terms of item neighborhoods. We discuss the differences between the cosine and correlation distance metrics and illustrate our discussion with an example from collaborative filtering. We introduce a family of normalized Minkowski metrics and test their use on both document data and synthetic data generated from the uniform distribution. We describe a range of criteria for testing neighborhood homogeneity relative to underlying latent classes. We discuss how these criteria are explicitly and implicitly linked to classification performance. By testing both normalized and non-normalized Minkowski-p metrics for multiple values of p, we separate out distance compression effects from normalization effects. For multi-class classification problems, we believe that distance compression on high dimensional data aids classification and data analysis. For document data, we find that the cosine (and normalized Euclidean), correlation, and proportioned city block metrics give strong neighborhood recovery. The proportioned city block metric gives particularly good results for nearest neighbors recovery and should be used when utilizing document data analysis techniques for which nearest neighborhood recovery is important. For data generated from the uniform distribution, neighborhood recovery improves as the value of p increases.
ER  - 

TY  - JOUR
T1  - In search of optimal centroids on data clustering using a binary search algorithm
JO  - Pattern Recognition Letters
VL  - 33
IS  - 13
SP  - 1756
EP  - 1760
PY  - 2012/10/1/
T2  - 
AU  - Hatamlou, Abdolreza
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2012.06.008
UR  - http://www.sciencedirect.com/science/article/pii/S0167865512001961
KW  - A binary search algorithm
KW  - Optimal centroids
KW  - Data clustering
AB  - Data clustering is an important technique in data mining. It is a method of partitioning data into clusters, in which each cluster must have data of great similarity and different clusters must have data of high dissimilarity. A lot of clustering algorithms are found in the literature. In general, there is no single algorithm that is suitable for all types of data, conditions and applications. Each algorithm has its own advantages, limitations and shortcomings. Therefore, introducing novel and effective approaches for data clustering is an open and active research area. This paper presents a novel binary search algorithm for data clustering that not only finds high quality clusters but also converges to the same solution in different runs. In the proposed algorithm a set of initial centroids are chosen from different parts of the test dataset and then optimal locations for the centroids are found by thoroughly exploring around of the initial centroids. The simulation results using six benchmark datasets from the UCI Machine Learning Repository indicate that proposed algorithm can efficiently be used for data clustering.
ER  - 

TY  - JOUR
T1  - An efficient Particle Swarm Optimization approach to cluster short texts
JO  - Information Sciences
VL  - 265
IS  - 
SP  - 36
EP  - 49
PY  - 2014/5/1/
T2  - 
AU  - Cagnina, Leticia
AU  - Errecalde, Marcelo
AU  - Ingaramo, Diego
AU  - Rosso, Paolo
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2013.12.010
UR  - http://www.sciencedirect.com/science/article/pii/S0020025513008542
KW  - Clustering
KW  - Short-text corpora
KW  - Particle Swarm Optimization
AB  - Abstract
Short texts such as evaluations of commercial products, news, FAQ’s and scientific abstracts are important resources on the Web due to the constant requirements of people to use this on line information in real life. In this context, the clustering of short texts is a significant analysis task and a discrete Particle Swarm Optimization (PSO) algorithm named CLUDIPSO has recently shown a promising performance in this type of problems. CLUDIPSO obtained high quality results with small corpora although, with larger corpora, a significant deterioration of performance was observed. This article presents CLUDIPSO★, an improved version of CLUDIPSO, which includes a different representation of particles, a more efficient evaluation of the function to be optimized and some modifications in the mutation operator. Experimental results with corpora containing scientific abstracts, news and short legal documents obtained from the Web, show that CLUDIPSO★ is an effective clustering method for short-text corpora of small and medium size.
ER  - 

TY  - JOUR
T1  - The Clustering Algorithm of Query Result based on Maximal Frequent
JO  - Procedia Engineering
VL  - 15
IS  - 
SP  - 1642
EP  - 1646
PY  - 2011///
T2  - CEIS 2011
AU  - Yu-wei, WEI
SN  - 1877-7058
DO  - http://dx.doi.org/10.1016/j.proeng.2011.08.306
UR  - http://www.sciencedirect.com/science/article/pii/S1877705811018078
KW  - Search Engine ;Frequent Itemsets ;Page Clustering
AB  - Most of existing web page clustering algorithms is based on short and uneven snippets of web page, which often cause bad clustering performance. On the other hand, the classical clustering algorithm for full text web pages is too complex to provide good cluster label in addition to the incapability on-line clustering. To address above problems, this article presents an on-line web page clustering algorithm based on maximal frequent item sets (MFIC). At first, the maximal frequent item sets are mined, and then the web pages are clustered based on shared frequent item sets. Secondly, clusters are labelled based on the frequent items. Experimental results show that MFIC can effectively reduce clustering time, improve clustering accuracy by 15%, and generate understandable labels.
ER  - 

TY  - JOUR
T1  - Association rules analysis of human factor events based on statistics method in digital nuclear power plant
JO  - Safety Science
VL  - 49
IS  - 6
SP  - 946
EP  - 950
PY  - 2011/7//
T2  - 
AU  - Jiang, Jian-jun
AU  - Zhang, Li
AU  - Wang, Yi-qun
AU  - Zhang, Kun
AU  - Yang, Da-Xin
AU  - He, Wen
SN  - 0925-7535
DO  - http://dx.doi.org/10.1016/j.ssci.2011.02.010
UR  - http://www.sciencedirect.com/science/article/pii/S0925753511000634
KW  - Human factor events
KW  - A weight association rules
KW  - Dynamic function
KW  - SGTR
AB  - With human factor events rising in recent years, many researches begin to pay much attention to them. Especially, human factor events in nuclear power plant show more important than other human factor events. To effectively decrease human factor events, the authors propose the method of association rule analysis of human factor events in this paper. Association rule is one of the most popular data mining techniques applied to many scientific and industrial problems. Based on traditional methods, the authors propose a weight association rule based on statistics. Weight factors consist of inner and exterior human factors. In this paper, the authors propose a dynamic function and some methods with weight in order to assess support, confidence and correlation degree among human factor events. The proposed methods are tested by experiments. From results of experiments, we can easily find higher error rate events caused by human, higher confidence and correlation degree events among human factor events of steam generator tube rupture (SGTR) of nuclear power plant (NPP).
ER  - 

TY  - JOUR
T1  - A survey on nature inspired metaheuristic algorithms for partitional clustering
JO  - Swarm and Evolutionary Computation
VL  - 16
IS  - 
SP  - 1
EP  - 18
PY  - 2014/6//
T2  - 
AU  - Nanda, Satyasai Jagannath
AU  - Panda, Ganapati
SN  - 2210-6502
DO  - http://dx.doi.org/10.1016/j.swevo.2013.11.003
UR  - http://www.sciencedirect.com/science/article/pii/S221065021300076X
KW  - Partitional clustering
KW  - Nature inspired metaheuristics
KW  - Evolutionary algorithms
KW  - Swarm intelligence
KW  - Multi-objective Clustering
AB  - Abstract
The partitional clustering concept started with K-means algorithm which was published in 1957. Since then many classical partitional clustering algorithms have been reported based on gradient descent approach. The 1990 kick started a new era in cluster analysis with the application of nature inspired metaheuristics. After initial formulation nearly two decades have passed and researchers have developed numerous new algorithms in this field. This paper embodies an up-to-date review of all major nature inspired metaheuristic algorithms employed till date for partitional clustering. Further, key issues involved during formulation of various metaheuristics as a clustering problem and major application areas are discussed.
ER  - 

TY  - JOUR
T1  - SOMSE: A semantic map based meta-search engine for the purpose of web information customization
JO  - Applied Soft Computing
VL  - 11
IS  - 1
SP  - 1310
EP  - 1321
PY  - 2011/1//
T2  - 
AU  - Hamdi, Mohamed Salah
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2010.04.004
UR  - http://www.sciencedirect.com/science/article/pii/S1568494610000803
KW  - Information Customization
KW  - Semantic Map
KW  - Kohonen Feature Map
KW  - Self-organizing map
KW  - Information overload
KW  - Meta-search engine
KW  - Machine learning
KW  - Neural network
KW  - Parameter tuning
AB  - To combat information overload, systems that are often referred to as information customization systems are needed. Such systems act on the user's behalf and can rely on existing information services like search engines that do the resource-intensive part of the work. These systems will be sufficiently lightweight to run on an average PC and serve as personal assistants. Since such an assistant has relatively modest resource requirements it can reside on an individual user's machine. If the assistant resides on the user's machine, there is no need to turn down intelligence. The system can have substantial local intelligence. In this paper, we propose an information customization system that combines meta-search and unsupervised learning. A meta-search engine simultaneously searches multiple search engines and returns a single list of results. The results retrieved by this engine can be highly relevant, since it is usually grabbing the first items from the relevancy-ranked list of hits returned by the individual search engines. The Kohonen Feature Map is then used to construct a self-organizing semantic map such that documents of similar contents are placed close to one another.
ER  - 

TY  - JOUR
T1  - Cross-lingual text categorization: Conquering language boundaries in globalized environments
JO  - Information Processing & Management
VL  - 47
IS  - 5
SP  - 786
EP  - 804
PY  - 2011/9//
T2  - Managing and Mining Multilingual Documents
AU  - Wei, Chih-Ping
AU  - Lin, Yen-Ting
AU  - Yang, Christopher C.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2011.01.011
UR  - http://www.sciencedirect.com/science/article/pii/S0306457311000203
KW  - Document management
KW  - Text mining
KW  - Text categorization
KW  - Cross-lingual text categorization
AB  - Text categorization pertains to the automatic learning of a text categorization model from a training set of preclassified documents on the basis of their contents and the subsequent assignment of unclassified documents to appropriate categories. Most existing text categorization techniques deal with monolingual documents (i.e., written in the same language) during the learning of the text categorization model and category assignment (or prediction) for unclassified documents. However, with the globalization of business environments and advances in Internet technology, an organization or individual may generate and organize into categories documents in one language and subsequently archive documents in different languages into existing categories, which necessitate cross-lingual text categorization (CLTC). Specifically, cross-lingual text categorization deals with learning a text categorization model from a set of training documents written in one language (e.g., L1) and then classifying new documents in a different language (e.g., L2). Motivated by the significance of this demand, this study aims to design a CLTC technique with two different category assignment methods, namely, individual- and cluster-based. Using monolingual text categorization as a performance reference, our empirical evaluation results demonstrate the cross-lingual capability of the proposed CLTC technique. Moreover, the classification accuracy achieved by the cluster-based category assignment method is statistically significantly higher than that attained by the individual-based method.
ER  - 

TY  - JOUR
T1  - Orthogonal nonnegative matrix factorization based local hidden Markov model for multimode process monitoring
JO  - Chinese Journal of Chemical Engineering
VL  - 24
IS  - 7
SP  - 856
EP  - 860
PY  - 2016/7//
T2  - 
AU  - Wang, Fan
AU  - Zhu, Honglin
AU  - Tan, Shuai
AU  - Shi, Hongbo
SN  - 1004-9541
DO  - http://dx.doi.org/10.1016/j.cjche.2016.01.016
UR  - http://www.sciencedirect.com/science/article/pii/S1004954116000173
KW  - Multimode process
KW  - Fault detection
KW  - Hidden Markov model
KW  - Orthogonal nonnegative matrix factorization
AB  - Abstract
Traditional data driven fault detection methods assume that the process operates in a single mode so that they cannot perform well in processes with multiple operating modes. To monitor multimode processes effectively, this paper proposes a novel process monitoring scheme based on orthogonal nonnegative matrix factorization (ONMF) and hidden Markov model (HMM). The new clustering technique ONMF is employed to separate data from different process modes. The multiple HMMs for various operating modes lead to higher modeling accuracy. The proposed approach does not presume the distribution of data in each mode because the process uncertainty and dynamics can be well interpreted through the hidden Markov estimation. The HMM-based monitoring indication named negative log likelihood probability is utilized for fault detection. In order to assess the proposed monitoring strategy, a numerical example and the Tennessee Eastman process are used. The results demonstrate that this method provides efficient fault detection performance.
ER  - 

TY  - JOUR
T1  - A polynomial-time algorithm for computing low CP-rank decompositions
JO  - Information Processing Letters
VL  - 118
IS  - 
SP  - 10
EP  - 14
PY  - 2017/2//
T2  - 
AU  - Elbassioni, Khaled
AU  - Nguyen, Trung Thanh
SN  - 0020-0190
DO  - http://dx.doi.org/10.1016/j.ipl.2016.09.004
UR  - http://www.sciencedirect.com/science/article/pii/S0020019016301314
KW  - Completely positive matrix
KW  - CP-rank
KW  - CP-decomposition
KW  - Polynomial-time algorithm
KW  - Computational complexity
AB  - Abstract
This paper investigates computing completely positive (cp) decompositions of positive semi-definite (PSD) matrices, a problem which arises in many applications. We propose the first polynomial-time algorithm for checking if a given PSD matrix has cp-rank of at most r, when r is a given constant. In addition, we present a polynomial-time algorithm for computing a (rational) cp-decomposition of such a matrix if it exists, within any desired accuracy.
ER  - 

TY  - JOUR
T1  - Research Trends in Non Point Source during 1975-2010
JO  - Physics Procedia
VL  - 33
IS  - 
SP  - 138
EP  - 143
PY  - 2012///
T2  - 2012 International Conference on Medical Physics and Biomedical Engineering (ICMPBE2012)
AU  - Yanhua, Zhuang
AU  - Thuminh, Nguyen
AU  - Beibei, Niu
AU  - ei, Shao
AU  - Song, Hong
SN  - 1875-3892
DO  - http://dx.doi.org/10.1016/j.phpro.2012.05.041
UR  - http://www.sciencedirect.com/science/article/pii/S1875389212013545
KW  - non point source
KW  - bibliometric analysis
KW  - analysis
KW  - research trends
AB  - According to the samples of 2924 articles about non point source of SCI and SSCI databases from 1975 to 2010, this study analysed the articles in the growth trend of article outputs, subject categories and journals, international collaborations, geographic distribution and scientific research issues by using bibliometric analysis. The results showed that non point source research steadily increased over the past 35 years and the annual number of articles published in 2010 was 79 times of that in 1975. Non point source was involved into 67 kinds of subjects and appeared in 451 journals. The main study area was concentrated in North America and Europe, following by East Asia. There were 79 countries/territories participated in non point source research, and USA was the largest contributor in non point source research and had a central position in collaboration networks. A keyword analysis indicated that water quality, non point pollutions, and watershed were the hottest issues of non point source research; “GIS, “watershed management”, “modeling”, “simulation”, “monitoring”, and “remote sensing” were the most popular research methods; and “agriculture”, “land use”, “runoff”, and “pollution” were the leading causes of non point pollution.
ER  - 

TY  - JOUR
T1  - Bibliometric and visualized analysis of emergy research
JO  - Ecological Engineering
VL  - 90
IS  - 
SP  - 285
EP  - 293
PY  - 2016/5//
T2  - 
AU  - Chen, Dan
AU  - Liu, Zhi
AU  - Luo, Zhaohui
AU  - Webber, Michael
AU  - Chen, Jing
SN  - 0925-8574
DO  - http://dx.doi.org/10.1016/j.ecoleng.2016.01.026
UR  - http://www.sciencedirect.com/science/article/pii/S092585741630026X
KW  - Bibliometric analysis
KW  - Emergy
KW  - Web of Science
KW  - Citespace
AB  - Abstract
A bibliometric approach, along with Citespace software, was used to quantitatively and visually evaluate global scientific research on emergy from 1996 to 2014. 637 publications – in accordance with the search criteria from the Science Citation Index Expanded (SCI-Expanded) and Social Science Citation Index (SSCI) of the Web of Science database – were statistically analyzed. The assessments on document type and language, publication year, authorship, subject categories and journals, countries/territories and institutions, most-frequently cited publications and author keywords were conducted with respect to seven categories. The amount of emergy publications per year has sharply increased in recent years. The most productive author was S. Ulgiati with 50 articles, who was also one of the most frequently cited publication authors. China produced 35.95% of all pertinent publications followed by the USA with 25.59% and Italy with 21.66%. Ecological Modeling, Ecological Engineering and Ecological Indicators were the three most common journals in this field. By synthetically analyzing the keywords, the dominant hot spots of emergy research could be concluded as “energy”, “sustainability”, “transformity”, and “indicators”.
ER  - 

TY  - JOUR
T1  - Output distributions and topic maps of safety related journals
JO  - Safety Science
VL  - 82
IS  - 
SP  - 236
EP  - 244
PY  - 2016/2//
T2  - 
AU  - Li, Jie
AU  - Hale, Andrew
SN  - 0925-7535
DO  - http://dx.doi.org/10.1016/j.ssci.2015.09.004
UR  - http://www.sciencedirect.com/science/article/pii/S0925753515002337
KW  - Safety science
KW  - Safety journals
KW  - Topic visualization
KW  - Text analysis
KW  - VOSviewer
AB  - Abstract
This paper presents topic maps of six core safety journals, based on analysis of 13,028 articles published in those journals as downloaded from the Web of Science. Bibliometric mapping methods were used to visualize the map of the topics covered in each journal. Analysis was also made of the changes in topics over time. The results show that safety science research in those journals has grown very rapidly over the last half century, with USA as the most productive in total and also in each year in the period. The topic clusters of these journals reveal the focus of each journal, which may be determined by the dominant methodologies used, the activity whose safety is studied or the object of study (e.g. workplace, safety management, regulation, etc.). The different journals also show regional differences in the papers they attract. The field in total is highly multidisciplinary. The topics of Safety Science have been focused on major hazard, transportation and work safety; Journal of Safety Research divides its attention between work and traffic safety, with a smaller cluster on statistics; Accident Analysis and Prevention is concerned almost exclusively with road safety; Injury Prevention is concerned mainly with injury mechanisms, but includes topics not treated by the other 5 journals, such as violence, suicide and other intentional injury and child safety at school and in the home. Reliability Engineering and System Safety and the Journal of Loss Prevention in the Process Industries focus mainly on major hazard, with the latter most concerned with the technology of failure mechanisms and the former on quantitative risk assessment.
ER  - 

TY  - JOUR
T1  - Unsupervised method for sentiment analysis in online texts
JO  - Expert Systems with Applications
VL  - 58
IS  - 
SP  - 57
EP  - 75
PY  - 2016/10/1/
T2  - 
AU  - Fernández-Gavilanes, Milagros
AU  - Álvarez-López, Tamara
AU  - Juncal-Martínez, Jonathan
AU  - Costa-Montenegro, Enrique
AU  - Javier González-Castaño, Francisco
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2016.03.031
UR  - http://www.sciencedirect.com/science/article/pii/S0957417416301300
KW  - Sentiment analysis
KW  - Opinion mining
KW  - nlp
KW  - Artificial intelligence
AB  - Abstract
In recent years, the explosive growth of online media, such as blogs and social networking sites, has enabled individuals and organizations to write about their personal experiences and express opinions. Classifying these documents using a polarity metric is an arduous task. We propose a novel approach to predicting sentiment in online textual messages such as tweets and reviews, based on an unsupervised dependency parsing-based text classification method that leverages a variety of natural language processing techniques and sentiment features primarily derived from sentiment lexicons. These lexicons were created by means of a semiautomatic polarity expansion algorithm in order to improve accuracy in specific application domains. The results obtained for the Cornell Movie Review, Obama-McCain Debate and SemEval-2015 datasets confirm the competitive performance and the robustness of the system.
ER  - 

TY  - JOUR
T1  - Visualizing information science: Author direct citation analysis in China and around the world
JO  - Journal of Informetrics
VL  - 9
IS  - 1
SP  - 208
EP  - 225
PY  - 2015/1//
T2  - 
AU  - Yang, Siluo
AU  - Wang, Feifei
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2015.01.001
UR  - http://www.sciencedirect.com/science/article/pii/S1751157715000024
KW  - Author direct citation
KW  - Information science
KW  - Citation network
KW  - Visualization
AB  - Abstract
Author direct citation analysis (ADCA, also called inter-citation or cross citation) is a new feasible and applicable technique for exploring knowledge communication and discovering scientific structure. This study explored ADCA among prolific, highly cited, and core authors in information science in China and around the world. The results revealed the following. (1) The datasets in China and around the world cover overlapping, but also unique topics. Research subjects on information science around the world can be divided into three categories and 10 clusters; meanwhile, that in China can be divided into three categories and 9 clusters. Chinese scholars who are mostly involved in cross subjects and multi-fields are not as specialized and profound as foreign scholars. An obvious imbalance exists in the evolution of discipline structure around the world, indicating the necessity of a synchronous promotion of research specialty and cross comprehensiveness. Chinese scholars concentrate more on topics such as competitive intelligence, information resource management, and information retrieval, and they focus less on information security and user analysis. (2) Knowledge communication between active authors is stronger than the knowledge flow from highly influential authors to active authors around the world; meanwhile, Chinese researchers tend to adopt the knowledge of authoritative literature. The knowledge flow through bidirectional direct citation is related to mutual knowledge communication. Authoritative scholars are produced when prolific authors cite highly cited authors. The level of mutual recognition among Chinese scholars has not reached that among foreign scholars; in the former, less bidirectional flow of knowledge is involved, and unidirectional flow is limited to geographical proximity, cooperation, or teacher–student relationship. (3) In contrast to traditional author co-citation analysis (ACA), ADCA pays more attention to the mutual interaction among currently active scholars and to mainly showing the current research focus.
ER  - 

TY  - JOUR
T1  - Mapping the managerial areas of Building Information Modeling (BIM) using scientometric analysis
JO  - International Journal of Project Management
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - He, Qinghua
AU  - Wang, Ge
AU  - Luo, Lan
AU  - Shi, Qian
AU  - Xie, Jianxun
AU  - Meng, Xianhai
SN  - 0263-7863
DO  - http://dx.doi.org/10.1016/j.ijproman.2016.08.001
UR  - http://www.sciencedirect.com/science/article/pii/S026378631630062X
KW  - Construction project management
KW  - Building Information Modeling (BIM)
KW  - Scientometrics
KW  - Literature analysis
AB  - Abstract
The successful adoption of Building Information Modeling (BIM) leads to the subsequent need for improving management practices and stakeholders' relationships. Previous studies have attempted to explore solutions for non-technical issues; however, a systematic and quantitative review of the details of non-technical field, namely, the managerial areas of BIM (MA–BIM), seems to be missing. Hence, a scientometric approach is used to construct knowledge maps in MA–BIM, thereby allowing bibliometric data to provide an objective and accurate perspective in the field as a whole. Through keyword and abstract term analysis of 126 related papers published from 2007 to 2015, an integrated conceptual framework is proposed to summarize current status and structure future directions of MA–BIM based on five principal research areas. This study shows the transformation of MA–BIM from an individual approach to a wide-ranging organizational strategy. It provides new insights into managing BIM projects by referring to the accurate representation and analysis of previous research efforts.
ER  - 

TY  - JOUR
T1  - Identification of collective viewpoints on microblogs
JO  - Data & Knowledge Engineering
VL  - 87
IS  - 
SP  - 374
EP  - 393
PY  - 2013/9//
T2  - 
AU  - Zhao, Bin
AU  - Zhang, Zhao
AU  - Qian, Weining
AU  - Zhou, Aoying
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2013.05.003
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X13000487
KW  - Graph clustering
KW  - Random walk
KW  - Microblog
AB  - Abstract
Towards hot events, microblogs usually collect diverse and abundant thoughts, comments and opinions from various viewpoints in a short period. In this paper, we aim to identify collective viewpoints from massive messages. Since individuals may have multiple viewpoints on a given event, and individual viewpoints may also change as time goes by, these present a challenge of extracting collective viewpoints. To address this, we propose a Term–Tweet–User (TWU) graph, which simultaneously incorporates text content, temporal information and community structure, to model postings over time. Based on such model, we propose Time-Sensitive Random Walk (TSRW) to effectively measure the relevance between pairs of terms through considering temporal aspects, and then group terms into collective viewpoints. Additionally, we propose Incremental RandomWalk method to recompute relevance between nodes incrementally and efficiently. Finally, we evaluate our approaches on a real dataset collected from Sina microblog, which is the biggest microblog in China. Extensive experiments show the effectiveness and efficiency of our algorithms.
ER  - 

TY  - JOUR
T1  - Clustering in extreme learning machine feature space
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 88
EP  - 95
PY  - 2014/3/27/
T2  - 
AU  - He, Qing
AU  - Jin, Xin
AU  - Du, Changying
AU  - Zhuang, Fuzhen
AU  - Shi, Zhongzhi
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2012.12.063
UR  - http://www.sciencedirect.com/science/article/pii/S092523121301000X
KW  - Extreme learning machine (ELM)
KW  - ELM feature space
KW  - Data clustering
KW  - Nonnegative matrix factorization (NMF)
KW  - ELM kMeans
KW  - ELM NMF clustering
AB  - Abstract
Extreme learning machine (ELM), used for the “generalized” single-hidden-layer feedforward networks (SLFNs), is a unified learning platform that can use a widespread type of feature mappings. In theory, ELM can approximate any target continuous function and classify any disjoint regions; in application, many experiment results have already demonstrated the good performance of ELM. In view of the good properties of the ELM feature mapping, the clustering problem using ELM feature mapping techniques is studied in this paper. Experiments show that the proposed ELM kMeans algorithm and ELM NMF (nonnegative matrix factorization) clustering can get better clustering results than the corresponding Mercer kernel based methods and the traditional algorithms using the original data. Moreover, the proposed methods have the advantage of being more convenient to implementation and computation, as the ELM feature mapping is much simpler than the Mercer kernel function based feature mapping methods.
ER  - 

TY  - JOUR
T1  - A web page usage prediction scheme using sequence indexing and clustering techniques
JO  - Data & Knowledge Engineering
VL  - 69
IS  - 4
SP  - 371
EP  - 382
PY  - 2010/4//
T2  - Including Special Section: 12th International Conference on Applications of Natural Language to Information Systems (NLDB’07) – Three selected and extended papers
AU  - Dimopoulos, Costantinos
AU  - Makris, Christos
AU  - Panagis, Yannis
AU  - Theodoridis, Evangelos
AU  - Tsakalidis, Athanasios
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2009.04.010
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X0900072X
KW  - World Wide Web
KW  - Web mining
KW  - On-line web page recommendation
KW  - Weighted sequences
AB  - In this paper we consider the problem of web page usage prediction in a web site by modeling users’ navigation history and web page content with weighted suffix trees. This user’s navigation prediction can be exploited either in an on-line recommendation system in a web site or in a web page cache system. The method proposed has the advantage that it demands a constant amount of computational effort per one user’s action and consumes a relatively small amount of extra memory space. These features make the method ideal for an on-line working environment. Finally, we have performed an evaluation of the proposed scheme with experiments on various web site log files and web pages and we have found that its quality performance is fairly well and in many cases an outperforming one.
ER  - 

TY  - JOUR
T1  - WisColl: Collective wisdom based blog clustering
JO  - Information Sciences
VL  - 180
IS  - 1
SP  - 39
EP  - 61
PY  - 2010/1/2/
T2  - Special Issue on Collective Intelligence
AU  - Agarwal, Nitin
AU  - Galan, Magdiel
AU  - Liu, Huan
AU  - Subramanya, Shankar
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2009.07.010
UR  - http://www.sciencedirect.com/science/article/pii/S0020025509003211
KW  - Blog
KW  - Cluster
KW  - Collective wisdom
KW  - Blogosphere
KW  - Social networks
KW  - Web 2.0
KW  - Wisdom of crowds
AB  - The Blogosphere is expanding in an unprecedented speed. A better understanding of the blogosphere can greatly facilitate the development of the Social Web to serve the needs of users, service providers, and advertisers. One important task in this process is clustering blog sites. Although a good number of traditional clustering methods exists, they are not designed to take into account the blogosphere unique characteristics. Clustering blog sites presents new challenges. A prominent feature of the Social Web is that many enthusiastic bloggers voluntarily write, tag, and catalog their posts in order to reach the widest possible audience who will share their thoughts and appreciate their ideas. In the process a new kind of collective wisdom is generated. We propose WisColl by tapping into this collective wisdom when clustering blog sites. In this paper, we study how clustering with collective wisdom can be achieved and compare it with a representative traditional clustering method. We present statistical and visual results, report findings and suggest future work extending to many real-world applications.
ER  - 

TY  - JOUR
T1  - Research of fast SOM clustering for text information
JO  - Expert Systems with Applications
VL  - 38
IS  - 8
SP  - 9325
EP  - 9333
PY  - 2011/8//
T2  - 
AU  - Liu, Yuan-chao
AU  - Wu, Chong
AU  - Liu, Ming
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2011.01.126
UR  - http://www.sciencedirect.com/science/article/pii/S0957417411001461
KW  - Self organizing maps
KW  - Text mining
KW  - Clustering efficiency
KW  - Feature coding
KW  - Similarity computation
AB  - The state-of-the-art text clustering methods suffer from the huge size of documents with high-dimensional features. In this paper, we studied fast SOM clustering technology for Text Information. Our focus is on how to enhance the efficiency of text clustering system whereas high clustering qualities are also kept. To achieve this goal, we separate the system into two stages: offline and online. In order to make text clustering system more efficient, feature extraction and semantic quantization are done offline. Although neurons are represented as numerical vectors in high-dimension space, documents are represented as collections of some important keywords, which is different from many related works, thus the requirement for both time and space in the offline stage can be alleviated. Based on this scenario, fast clustering techniques for online stage are proposed including how to project documents onto output layers in SOM, fast similarity computation method and the scheme of Incremental clustering technology for real-time processing, We tested the system using different datasets, the practical performance demonstrate that our approach has been shown to be much superior in clustering efficiency whereas the clustering quality are comparable to traditional methods.
ER  - 

TY  - JOUR
T1  - GOClonto: An ontological clustering approach for conceptualizing PubMed abstracts
JO  - Journal of Biomedical Informatics
VL  - 43
IS  - 1
SP  - 31
EP  - 40
PY  - 2010/2//
T2  - 
AU  - Zheng, Hai-Tao
AU  - Borchert, Charles
AU  - Kim, Hong-Gee
SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2009.07.006
UR  - http://www.sciencedirect.com/science/article/pii/S1532046409000999
KW  - GOClonto
KW  - PubMed abstract
KW  - Ontological clustering
KW  - Gene ontology
KW  - Conceptualization
KW  - Ontology generation
KW  - Suffix tree clustering
KW  - Lingo
KW  - Fuzzy Ants clustering
KW  - Tolerance rough set
AB  - Concurrent with progress in biomedical sciences, an overwhelming of textual knowledge is accumulating in the biomedical literature. PubMed is the most comprehensive database collecting and managing biomedical literature. To help researchers easily understand collections of PubMed abstracts, numerous clustering methods have been proposed to group similar abstracts based on their shared features. However, most of these methods do not explore the semantic relationships among groupings of documents, which could help better illuminate the groupings of PubMed abstracts. To address this issue, we proposed an ontological clustering method called GOClonto for conceptualizing PubMed abstracts. GOClonto uses latent semantic analysis (LSA) and gene ontology (GO) to identify key gene-related concepts and their relationships as well as allocate PubMed abstracts based on these key gene-related concepts. Based on two PubMed abstract collections, the experimental results show that GOClonto is able to identify key gene-related concepts and outperforms the STC (suffix tree clustering) algorithm, the Lingo algorithm, the Fuzzy Ants algorithm, and the clustering based TRS (tolerance rough set) algorithm. Moreover, the two ontologies generated by GOClonto show significant informative conceptual structures.
ER  - 

TY  - JOUR
T1  - DF-Miner: Domain-specific facet mining by leveraging the hyperlink structure of Wikipedia
JO  - Knowledge-Based Systems
VL  - 77
IS  - 
SP  - 80
EP  - 91
PY  - 2015/3//
T2  - 
AU  - Wei, Bifan
AU  - Liu, Jun
AU  - Zheng, Qinghua
AU  - Zhang, Wei
AU  - Wang, Chenchen
AU  - Wu, Bei
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2015.01.001
UR  - http://www.sciencedirect.com/science/article/pii/S0950705115000088
KW  - Domain-specific facet mining
KW  - Community structure
KW  - Hyperlink structure
KW  - Scale-free property
KW  - Wikipedia
AB  - Abstract
Organizing a set of domain-specific terms into a meaningful hierarchical structure is an essential task for faceted search and knowledge organization. In this paper, we present an automatic approach, called domain-specific facet (DF)-Miner, to discover DFs based on the hyperlink structure within the Wikipedia article pages. Each article page corresponds to a domain-specific term. The hyperlink structures among article pages represent the connections among these terms. The community structure of the connections among a domain-specific term set reveals the facets of the domain. The terms with more connections provide important clues for facet labeling. Accordingly, DF-Miner first constructs a domain-specific hyperlink graph from the Wikipedia article pages. Then it extracts a tree structure from the Wikipedia category pages. DF-Miner groups the terms of a domain into multiple facets based on the result of community detection. Finally, DF-Miner selects a meaningful label for each facet based on the connection number of terms and the extracted tree structure from the category pages. Two experiments were conducted with six real-world datasets to evaluate DF-Miner. The experimental results show that DF-Miner performs better than the textual content-based approaches.
ER  - 

TY  - JOUR
T1  - Data Pre-processing Evaluation for Text Mining: Transaction/Sequence Model
JO  - Procedia Computer Science
VL  - 18
IS  - 
SP  - 1198
EP  - 1207
PY  - 2013///
T2  - 2013 International Conference on Computational Science
AU  - Munková, Daša
AU  - Munk, Michal
AU  - Vozár, Martin
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2013.05.286
UR  - http://www.sciencedirect.com/science/article/pii/S1877050913004298
KW  - Data pre-processing
KW  - stop words
KW  - sequence identification
KW  - transaction/sequence model
KW  - text mining
KW  - evaluation
AB  - Abstract
Data pre-processing presents the most time consuming phase in the whole process of knowledge discovery. The complexity of data pre-processing depends on the data sources used. The aim of this work is to determine to what extent it is necessary to carry out the time consuming data pre-processing in the process of discovering sequential patterns in e-documents. We used the transaction/sequence model for text representation and sequence rule analysis as a method of modelling. We compare four datasets of different quality obtained from texts and pre-processed in different ways: data with identified the paragraph sequences, data with identified the sentence sequences, data with identified the paragraph sequences without stop words and data with identified the sentence sequences without stop words. We try to assess the impact of these advanced techniques of data pre-processing on the quantity and quality of the extracted rules. The results confirm some initial assumptions, but they also show that the stop words removal has a substantial impact on the quantity and quality of extracted rules in case of paragraph sequence identification. Contrary, in case of sentence sequence identification, removing the stop words has not any significant impact on the quantity and quality of extracted rules.
ER  - 

TY  - JOUR
T1  - Literature-related discovery: Potential treatments and preventatives for SARS
JO  - Technological Forecasting and Social Change
VL  - 78
IS  - 7
SP  - 1164
EP  - 1173
PY  - 2011/9//
T2  - Contains Special Section: Emerging Technologies in Emerging Markets
AU  - Kostoff, Ronald N.
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2011.03.022
UR  - http://www.sciencedirect.com/science/article/pii/S0040162511000746
KW  - Severe acute respiratory syndrome (SARS)
KW  - Literature-related-discovery
KW  - Literature-based discovery
KW  - Text mining
KW  - Radical discovery
KW  - Radical innovation
KW  - Infectious disease
AB  - Literature-related discovery (LRD) is the linking of two or more previously disjoint concepts in order to produce novel, interesting, plausible, and intelligible connections (i.e., potential discovery). LRD has been used to identify potential treatments or preventative actions for challenging medical problems, among myriad other applications.

Severe acute respiratory syndrome (SARS) was the first pandemic of the 21st century. SARS was eventually controlled through increased hygienic measures (e.g., face mask protection, frequent hand washing, living quarter disinfection), travel restrictions, and quarantine. According to recent reviews of SARS, none of the drugs that were used during the pandemic worked.

For the present paper, SARS was selected as the first application of LRD to an infectious disease. The main goal of this research was to identify non-drug non-surgical treatments that would 1) prevent the occurrence, or 2) reduce the progression rate, or 3) stop/reverse the progression of SARS. The MeSH taxonomy of Medline was used to restrict potential discoveries to selected semantic classes, and to identify potential discoveries efficiently. To enhance the volume of potential discovery, databases were used in addition to Medline. These included the Science Citation Index (SCI) and, in contrast to previous work, a full text database. Because of the richness of the full text, ‘surgical’ queries were developed that targeted the exact types of potential discovery of interest while eliminating clutter more efficiently.
ER  - 

TY  - JOUR
T1  - Ensemble methods for biclustering tasks
JO  - Pattern Recognition
VL  - 45
IS  - 11
SP  - 3938
EP  - 3949
PY  - 2012/11//
T2  - 
AU  - Hanczar, Blaise
AU  - Nadif, Mohamed
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2012.04.010
UR  - http://www.sciencedirect.com/science/article/pii/S0031320312001677
KW  - Co-clustering
KW  - Ensemble methods
KW  - Microarray data
AB  - Several biclustering algorithms have been proposed in different fields of microarray data analysis. We present a new approach that improves their performance in using the ensemble methods. An ensemble biclustering is considered and formalized by a problem of binary triclustering. We propose a simple and efficient algorithm to solve it. To illustrate the interest of our ensemble approach, numerical experiments are performed on both artificial and real datasets with two biclustering algorithms commonly used in bioinformatics.
ER  - 

TY  - JOUR
T1  - Accelerating text mining workloads in a MapReduce-based distributed GPU environment
JO  - Journal of Parallel and Distributed Computing
VL  - 73
IS  - 2
SP  - 198
EP  - 206
PY  - 2013/2//
T2  - 
AU  - Wittek, Peter
AU  - Darányi, Sándor
SN  - 0743-7315
DO  - http://dx.doi.org/10.1016/j.jpdc.2012.10.001
UR  - http://www.sciencedirect.com/science/article/pii/S0743731512002353
KW  - GPU computing
KW  - MapReduce
KW  - Text mining
KW  - Self-organizing maps
KW  - Random projection
AB  - Scientific computations have been using GPU-enabled computers successfully, often relying on distributed nodes to overcome the limitations of device memory. Only a handful of text mining applications benefit from such infrastructure. Since the initial steps of text mining are typically data intensive, and the ease of deployment of algorithms is an important factor in developing advanced applications, we introduce a flexible, distributed, MapReduce-based text mining workflow that performs I/O-bound operations on CPUs with industry-standard tools and then runs compute-bound operations on GPUs which are optimized to ensure coalesced memory access and effective use of shared memory. We have performed extensive tests of our algorithms on a cluster of eight nodes with two NVidia Tesla M2050s attached to each, and we achieve considerable speedups for random projection and self-organizing maps.
ER  - 

TY  - JOUR
T1  - Automatically building templates for entity summary construction
JO  - Information Processing & Management
VL  - 49
IS  - 1
SP  - 330
EP  - 340
PY  - 2013/1//
T2  - 
AU  - Li, Peng
AU  - Wang, Yinglin
AU  - Jiang, Jing
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2012.03.006
UR  - http://www.sciencedirect.com/science/article/pii/S0306457312000568
KW  - Summary template
KW  - LDA
KW  - Pattern mining
AB  - In this paper, we propose a novel approach to automatic generation of summary templates from given collections of summary articles. We first develop an entity-aspect LDA model to simultaneously cluster both sentences and words into aspects. We then apply frequent subtree pattern mining on the dependency parse trees of the clustered and labeled sentences to discover sentence patterns that well represent the aspects. Finally, we use the generated templates to construct summaries for new entities. Key features of our method include automatic grouping of semantically related sentence patterns and automatic identification of template slots that need to be filled in. Also, we implement a new sentence compression algorithm which use dependency tree instead of parser tree. We apply our method on five Wikipedia entity categories and compare our method with three baseline methods. Both quantitative evaluation based on human judgment and qualitative comparison demonstrate the effectiveness and advantages of our method.
ER  - 

TY  - JOUR
T1  - Collective intelligence applied to legal e-discovery: A ten-year case study of Australia franchise and trademark litigation
JO  - Advanced Engineering Informatics
VL  - 29
IS  - 4
SP  - 787
EP  - 798
PY  - 2015/10//
T2  - Collective Intelligence Modeling, Analysis, and Synthesis for Innovative Engineering Decision MakingSpecial Issue of the 1st International Conference on Civil and Building Engineering Informatics
AU  - Trappey, Charles V.
AU  - Trappey, Amy J.C.
SN  - 1474-0346
DO  - http://dx.doi.org/10.1016/j.aei.2015.04.006
UR  - http://www.sciencedirect.com/science/article/pii/S147403461500052X
KW  - Collective litigation intelligence
KW  - Legal e-discovery
KW  - Retail franchise
KW  - Trademark infringement
AB  - Abstract
The purpose of this research is to develop a formal knowledge e-discovery methodology, using advanced information technology and decision support analysis, to define legal case evolution based on Collective Litigation Intelligence (CLI). In this research, a decade of Australia’s retail franchise and trademark litigation cases are used as the corpus to analyze and synthesize the evolution of modern retail franchise law in Australia. The formal processes used in the legal e-discovery research include a LexisNexis search strategy to collect legal documents, text mining to find key concepts and their representing key phrases in the documents, clustering algorithms to associate the legal cases into groups, and concept lattice analysis to trace the evolutionary trends of the main groups. The case analysis discovers the fundamental issues for retail modernization, advantages and disadvantages of retail franchising systems, and the potential litigation hazards to be avoided in the Australian market. Given the growing number of legal documents in global court systems, this research provides a systematic and generalized CLI methodology to improve the efficiency and efficacy of research across international legal systems. In the context of the case study, the results demonstrate the critical importance of quickly processing and interpreting existing legal knowledge using the CLI approach. For example, a brand management company, which purchases a successful franchise in one market is under limited time constraints to evaluate the legal environment across global markets of interest. The proposed CLI methodology can be applied to derive market entry strategies to secure growth and brand expansion of a global franchise.
ER  - 

TY  - JOUR
T1  - Online graph regularized non-negative matrix factorization for large-scale datasets
JO  - Neurocomputing
VL  - 204
IS  - 
SP  - 162
EP  - 171
PY  - 2016/9/5/
T2  - Big Learning in Social Media AnalyticsContaining a selection of papers from the 2014 International Conference on Security, Pattern Analysis, and Cybernetics (ICSPAC2014)
AU  - Liu, Fudong
AU  - Yang, Xuejun
AU  - Guan, Naiyang
AU  - Yi, Xiaodong
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2015.07.150
UR  - http://www.sciencedirect.com/science/article/pii/S0925231216301011
KW  - Non-negative matrix factorization (NMF)
KW  - Graph regularized non-negative matrix factorization (GNMF)
KW  - Online algorithm
KW  - Large-scale datasets
AB  - Abstract
Non-negative matrix factorization (NMF) has been widely used to reduce dimensionality of data in image processing and various applications. Incorporating the geometric structure into NMF, graph regularized non-negative matrix factorization (GNMF) has shown significant performance improvement in comparison to conventional NMF. However, both NMF and GNMF require the data matrix to reside in the memory, which gives rise to tremendous pressure for computation and storage. Moreover, this problem becomes more serious if the scale of datasets increases dramatically. In this paper, we propose an online GNMF (OGNMF) method to process the incoming data in an incremental manner, i.e., OGNMF processes one data point or one chunk of data points one by one. By utilizing buffering and random projection tree strategy, OGNMF scales gracefully to large-scale datasets. Experimental results on popular text corpora and image databases demonstrate that OGNMF achieves better performance than the existing online NMF algorithms in terms of both accuracy and normalized mutual information, and outperforms the existing batch GNMF algorithms in terms of scalability.
ER  - 

TY  - JOUR
T1  - Hybrid linear matrix factorization for topic-coherent terms clustering
JO  - Expert Systems with Applications
VL  - 62
IS  - 
SP  - 358
EP  - 372
PY  - 2016/11/15/
T2  - 
AU  - Liang, Ping
AU  - Wongthanavasu, Sartra
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2016.06.022
UR  - http://www.sciencedirect.com/science/article/pii/S0957417416303049
KW  - Matrix factorization
KW  - Dimensional reduction
KW  - Term clustering
KW  - Karhunen–Loève transformation
AB  - Abstract
Topic-coherent term clustering is the foundation of document organization, corpus summarization and document classification. It is especially useful in solving the emerging problem of big data. However, a term clustering method that can cope with high-dimension data with variable length and topics and meanwhile achieve high topic coherence is an ongoing request. It is a challenging problem in research. This paper proposes a hybrid linear matrix factorization method to identify the topic-coherent terms from documents to form a thesaurus for clustering. Starting from an analog Karhunen–Loève transformation from PCA scores fully into FA's factor coefficients space (loadings), the high-dimension of the full set of PCA scores is reduced and topic-coherent terms are classified by the main factors of FA which could be topics. Karhunen–Loève transformation reduces the total mean square error to increase topic coherence. The optimization of the initial transformation is carried out further in a manner of Karhunen–Loève expansion based on stochastic Wiener process. The optimal topic coherent bags of terms are found to build a more topic-coherent model. This approach is experimented on the CISI, MedSH and Tweets dataset in different sizes and number of topics. It achieves outstanding results better than the methods in comparison.
ER  - 

TY  - JOUR
T1  - Graph regularized and sparse nonnegative matrix factorization with hard constraints for data representation
JO  - Neurocomputing
VL  - 173, Part 2
IS  - 
SP  - 233
EP  - 244
PY  - 2016/1/15/
T2  - 
AU  - Sun, Fuming
AU  - Xu, Meixiang
AU  - Hu, Xuekao
AU  - Jiang, Xiaojun
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2015.01.103
UR  - http://www.sciencedirect.com/science/article/pii/S092523121501276X
KW  - Nonnegative matrix factorization
KW  - Graph-based regularizer
KW  - Sparseness constraints
KW  - Label information
AB  - Abstract
Nonnegative Matrix Factorization (NMF) as a popular technique for finding parts-based, linear representations of nonnegative data has been successfully applied in a wide range of applications. This is because it can provide components with physical meaning and interpretations, which is consistent with the psychological intuition of combining parts to form whole. For practical classification tasks, NMF ignores both the local geometry of data and the discriminative information of different classes. In addition, existing research results demonstrate that leveraging sparseness can greatly enhance the ability of the learning parts. Motivated by these advances aforementioned, we propose a novel matrix decomposition algorithm, called Graph regularized and Sparse Non-negative Matrix Factorization with hard Constraints (GSNMFC). It attempts to find a compact representation of the data so that further learning tasks can be facilitated. The proposed GSNMFC jointly incorporates a graph regularizer and hard prior label information as well as sparseness constraint as additional conditions to uncover the intrinsic geometrical and discriminative structures of the data space. The corresponding update solutions and the convergence proofs for the optimization problem are also given in detail. Experimental results demonstrate the effectiveness of our algorithm in comparison to the state-of-the-art approaches through a set of evaluations.
ER  - 

TY  - JOUR
T1  - Clustering time-stamped data using multiple nonnegative matrices factorization
JO  - Knowledge-Based Systems
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Huang, Xiaohui
AU  - Ye, Yunming
AU  - Xiong, Liyan
AU  - Wang, Shaokai
AU  - Yang, Xiaofei
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2016.10.007
UR  - http://www.sciencedirect.com/science/article/pii/S0950705116303914
KW  - Clustering
KW  - Time-stamped data set
KW  - Matrix factorization
KW  - Social media
AB  - Abstract
Time-stamped data are ubiquitous in our daily life, such as twitter data, academic papers and sensor data. Finding clusters and their evolutionary trends in time-stamped data sets are receiving increasing attention from researchers. Most existing methods, however, can only tackle the clustering problem of a data set without time-stamped information which is inherent in almost all the data objects. Actually, not only the performance can be improved by effectively incorporating the time-stamped information in the clustering process on most data sets, but also we can find the evolutionary trends of the clusters with time information. In this paper, we introduce an approach for clustering time-stamped data and discovering the evolutionary trends of the clusters by using Multiple Nonnegative Matrices Factorization (MNMF) with smooth constraint over time. To utilize time-stamped information in the clustering process, an extra object-time matrix is constructed in our proposed method. Then, we jointly factorize multiple feature matrices using smooth constraint to perform the object-time matrix to obtain the clusters and their evolutionary trends. Experimental results on real data sets demonstrate that our proposed approach outperforms the comparative algorithms with respect to Fscore, NMI or Entropy.
ER  - 

TY  - JOUR
T1  - A tree based representation for effective pattern discovery from multimedia documents
JO  - Pattern Recognition Letters
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - K, Pushpalatha
AU  - V S, Ananthanarayana
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2016.10.005
UR  - http://www.sciencedirect.com/science/article/pii/S0167865516302707
KW  - Multimedia document
KW  - Multimedia document representation
KW  - Suffix tree
KW  - Multimedia mining
AB  - Abstract
The growing amount of multimedia documents demanded the efficient knowledge discovery systems. The efficacy of the knowledge discovery systems is influenced by the representation of multimedia documents. The suitable multimedia document representation acts as a platform for multimedia mining tasks. In this paper, a Multimedia Suffix Tree Document model (MSTD) is presented to represent the multimedia documents in a tree based structure. The MSTD model discovers the useful patterns embedded in the multimedia documents and reduces the search time thereby aiding the multimedia mining methods. It provides the complete information of the multimedia documents in one structure. In order to evaluate the proficiency of the proposed MSTD model, the MSTD model based mining methods are proposed. The experiments are conducted with three multimodal multimedia document datasets. The experimental analysis of the proposed methods reveal the significance of MSTD representation for multimedia documents in achieving the significant performance of multimedia mining tasks.
ER  - 

TY  - JOUR
T1  - Using climate classification to evaluate building energy performance
JO  - Energy
VL  - 36
IS  - 3
SP  - 1797
EP  - 1801
PY  - 2011/3//
T2  - 
AU  - Lee, Wen-Shing
AU  - Kung, Chung-Kuan
SN  - 0360-5442
DO  - http://dx.doi.org/10.1016/j.energy.2010.12.034
UR  - http://www.sciencedirect.com/science/article/pii/S0360544210007243
KW  - Energy management
KW  - Data envelopment analysis
KW  - Climate classification
KW  - Cluster analysis
AB  - Traditional benchmarking of building energy performance usually starts by considering a wide range of different factors and giving these factors different weights to help reach one general indicator measuring a building’s overall energy performance. For obtaining more specific information in building energy management performance, this paper proposes an adjustment to the traditional approach by using climate classification and data envelopment analysis (DEA). The study first adopts cluster analysis to classify the evaluated buildings into different climate clusters. Secondly, scale factors are identified by regression analysis. DEA is then employed to assess the energy management efficiency of the evaluated buildings. The samples of 122 office buildings in Taiwan in summer are classified into three climate clusters (warm and long rain hour, hot and middle rain hour, and hot and short rain hour). Research results indicate that the average indicators of energy management performance in each of the three climate clusters are 0.5, 0.56, and 0.56 respectively. The lower value indicator of energy management performance, resulted from the comparison between the energy consumption of the evaluated building and the minimum energy consumption among buildings in the same scale and similar climate conditions, indicates a more potential in energy saving.
ER  - 

TY  - JOUR
T1  - QuestionHolic: Hot topic discovery and trend analysis in community question answering systems
JO  - Expert Systems with Applications
VL  - 38
IS  - 6
SP  - 6848
EP  - 6855
PY  - 2011/6//
T2  - 
AU  - Zhang, Zhongfeng
AU  - Li, Qiudan
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2010.12.052
UR  - http://www.sciencedirect.com/science/article/pii/S0957417410014156
KW  - Community question answering (CQA)
KW  - Hot topic
KW  - Trend analysis
AB  - Community question answering (CQA) has recently become a popular social media where users can post questions on any topic of interest and get answers from enthusiasts. The variation of topics in questions and answers indicate the change of users’ interests over time. It can help users focus on the most popular products or events and track their changes by exploiting hot topics and analyzing the trend of a specific topic. In this paper, we present a hot topic detection and trend analysis system to capture hot topics in a CQA system and track their evolutions over time. Our system consists of hot term extraction, question clustering and trend analysis. Experimental results using datasets from Yahoo! Answers show that our system can discover meaningful hot topics. We also show that the evolution of topics over time can be accurately exploited by trend graphing.
ER  - 

TY  - JOUR
T1  - Aggregator: A machine learning approach to identifying MEDLINE articles that derive from the same underlying clinical trial
JO  - Methods
VL  - 74
IS  - 
SP  - 65
EP  - 70
PY  - 2015/3/1/
T2  - Text mining of biomedical literature
AU  - Shao, Weixiang
AU  - Adams, Clive E.
AU  - Cohen, Aaron M.
AU  - Davis, John M.
AU  - McDonagh, Marian S.
AU  - Thakurta, Sujata
AU  - Yu, Philip S.
AU  - Smalheiser, Neil R.
SN  - 1046-2023
DO  - http://dx.doi.org/10.1016/j.ymeth.2014.11.006
UR  - http://www.sciencedirect.com/science/article/pii/S1046202314003661
KW  - Evidence-based medicine
KW  - Clinical trials
KW  - Systematic reviews
KW  - Bias
KW  - Information retrieval
KW  - Informatics
AB  - AbstractObjective
It is important to identify separate publications that report outcomes from the same underlying clinical trial, in order to avoid over-counting these as independent pieces of evidence.
Methods
We created positive and negative training sets (comprised of pairs of articles reporting on the same condition and intervention) that were, or were not, linked to the same clinicaltrials.gov trial registry number. Features were extracted from MEDLINE and PubMed metadata; pairwise similarity scores were modeled using logistic regression.
Results
Article pairs from the same trial were identified with high accuracy (F1 score = 0.843). We also created a clustering tool, Aggregator, that takes as input a PubMed user query for RCTs on a given topic, and returns article clusters predicted to arise from the same clinical trial.
Discussion
Although painstaking examination of full-text may be needed to be conclusive, metadata are surprisingly accurate in predicting when two articles derive from the same underlying clinical trial.
ER  - 

TY  - JOUR
T1  - Semi-supervised locally discriminant projection for classification and recognition
JO  - Knowledge-Based Systems
VL  - 24
IS  - 2
SP  - 341
EP  - 346
PY  - 2011/3//
T2  - 
AU  - Zhang, Shanwen
AU  - Lei, Ying-Ke
AU  - Wu, Yan-Hua
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2010.11.002
UR  - http://www.sciencedirect.com/science/article/pii/S0950705110001681
KW  - Manifold learning
KW  - Plant leaf classification
KW  - Palmprint recognition
KW  - Semi-supervised dimensional reduction
KW  - Semi-supervised locally discriminant projection
AB  - Semi-supervised dimensional reduction methods play an important role in pattern recognition, which are likely to be more suitable for plant leaf and palmprint classification, since labeling plant leaf and palmprint often requires expensive human labor, whereas unlabeled plant leaf and palmprint is far easier to obtain at very low cost. In this paper, we attempt to utilize the unlabeled data to aid plant leaf and palmprint classification task with the limited number of the labeled plant leaf or palmprint data, and propose a semi-supervised locally discriminant projection (SSLDP) algorithm for plant leaf and palmprint classification. By making use of both labeled and unlabeled data in learning a transformation for dimensionality reduction, the proposed method can overcome the small-sample-size (SSS) problem under the situation where labeled data are scant. In SSLDP, the labeled data points, combined with the unlabeled data ones, are used to construct the within-class and between-class weight matrices incorporating the neighborhood information of the data set. The experiments on plant leaf and palmprint databases demonstrate that SSLDP is effective and feasible for plant leaf and palmprint classification.
ER  - 

TY  - JOUR
T1  - Dragon exploratory system on Hepatitis C Virus (DESHCV)
JO  - Infection, Genetics and Evolution
VL  - 11
IS  - 4
SP  - 734
EP  - 739
PY  - 2011/6//
T2  - Bamako 2009 Conference on the Bioinformatics of Infectious Diseases
AU  - Kwofie, Samuel K.
AU  - Radovanovic, Aleksandar
AU  - Sundararajan, Vijayaraghava S.
AU  - Maqungo, Monique
AU  - Christoffels, Alan
AU  - Bajic, Vladimir B.
SN  - 1567-1348
DO  - http://dx.doi.org/10.1016/j.meegid.2010.12.006
UR  - http://www.sciencedirect.com/science/article/pii/S1567134810003448
KW  - Hepatitis C Virus
KW  - Text-mining
KW  - Dictionaries
KW  - Biomedical concepts
KW  - Database
KW  - Hypotheses generation
AB  - Even though Hepatitis C Virus (HCV) cDNA was characterized about 20 years ago, there is insufficient understanding of the molecular etiology underlying HCV infections. Current global rates of infection and its increasingly chronic character are causes of concern for health policy experts. Vast amount of data accumulated from biochemical, genomic, proteomic, and other biological analyses allows for novel insights into the HCV viral structure, life cycle and functions of its proteins. Biomedical text-mining is a useful approach for analyzing the increasing corpus of published scientific literature on HCV. We report here the first comprehensive HCV customized biomedical text-mining based online web resource, dragon exploratory system on Hepatitis C Virus (DESHCV), a biomedical text-mining and relationship exploring knowledgebase was developed by exploring literature on HCV. The pre-compiled dictionaries existing in the dragon exploratory system (DES) were enriched with biomedical concepts pertaining to HCV proteins, their name variants and symbols to make it suitable for targeted information exploration and knowledge extraction as focused on HCV. A list of 32,895 abstracts retrieved via PubMed database using specific keywords searches related to HCV were processed based on concept recognition of terms from several dictionaries. The web query interface enables retrieval of information using specified concepts, keywords and phrases, generating text-derived association networks and hypotheses, which could be tested to identify potentially novel relationship between different concepts. Such an approach could also augment efforts in the search for diagnostic or even therapeutic targets. DESHCV thus represents online literature-based discovery resource freely accessible for academic and non-profit users via http://apps.sanbi.ac.za/DESHCV/ and its mirror site http://cbrc.kaust.edu.sa/deshcv/.
ER  - 

TY  - JOUR
T1  - Searching in peer-to-peer networks
JO  - Computer Science Review
VL  - 6
IS  - 4
SP  - 161
EP  - 183
PY  - 2012/7//
T2  - 
AU  - Klampanos, Iraklis A.
AU  - Jose, Joemon M.
SN  - 1574-0137
DO  - http://dx.doi.org/10.1016/j.cosrev.2012.07.001
UR  - http://www.sciencedirect.com/science/article/pii/S1574013712000238
KW  - Information retrieval
KW  - Content-based retrieval
KW  - Ontologies
KW  - Semantic overlay networks
KW  - P2P networking
KW  - Applications
KW  - Distributed hash tables
AB  - As peer-to-peer networks are proving capable of handling huge volumes of data, the need for effective search tools is lasting and imperative. During the last years, a number of research studies have been published, which attempt to address the problem of search in large, decentralized networks. In this article, we mainly focus on content and concept-based retrieval. After providing a useful discussion on terminology, we introduce a representative sample of such studies and categorize them according to basic functional and non-functional characteristics. Following our analysis and discussion we conclude that future work should focus on information filtering, re-ranking and merging of results, relevance feedback and content replication as well as on related user-centric aspects of the problem.
ER  - 

TY  - JOUR
T1  - Text Clustering Based on a Divide and Merge Strategy
JO  - Procedia Computer Science
VL  - 55
IS  - 
SP  - 825
EP  - 832
PY  - 2015///
T2  - 3rd International Conference on Information Technology and Quantitative Management, ITQM 2015
AU  - Yuan, Man
AU  - Shi, Yong
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.07.153
UR  - http://www.sciencedirect.com/science/article/pii/S1877050915016282
KW  - Text clustering
KW  - feature extension
KW  - k-means
AB  - Abstract
A text clustering algorithm is proposed to overcome the drawback of division based clustering method on sensitivity of estimated class number. Complex features including synonym and co-occurring words are extracted to make a feature space containing more semantic information. Then the divide and merge strategy helps the iteration converge to a reasonable cluster number. Experimental results showed that the dynamically updated center number prevent the deterioration of clustering result when k deviates from the real class numbers. When k is too small or large, the difference of clustering results between FC-DM and k-means is more obvious and FC-DM also outperformed other benchmark algorithms.
ER  - 

TY  - JOUR
T1  - An Investigation of Parallel Road Map Inference from Big GPS Traces Data
JO  - Procedia Computer Science
VL  - 53
IS  - 
SP  - 131
EP  - 140
PY  - 2015///
T2  - INNS Conference on Big Data 2015 Program San Francisco, CA, USA 8-10 August 2015
AU  - Elleuch, Wiam
AU  - Wali, Ali
AU  - Alimi, Adel M.
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.07.287
UR  - http://www.sciencedirect.com/science/article/pii/S1877050915017901
KW  - road generation,road map
KW  - GPS big data
KW  - Mapreduce
KW  - K-means
KW  - clustering
KW  - map matching
AB  - Abstract
With the increased use of GPS sensors in several everyday devices, persons trip data are be- coming very abundant. Many opportunities for exploration of the wealth GPS data and in this paper, we inferred, the geometry of road maps in Tunisia and the connectivity between them. This phenomenon is known as map generation and also map inference procedure. For that, we gathered big GPS data from about ten thousands of vehicles equipped with GPS receivers and circulating in Tunisia, which does not have a road map like other developing countries. We collected a big database with approximately 100 gigabytes. After preprocessing it, we were obliged to partition data in order to facilitate handling an unstructured database with a such size. In fact, we used for that K-means with its sequential mode and the parallel mode based on Mapreduce, which is one of the most famous proposed solution to analyse the rapidly growing data. The proposed parallel k-means algorithm was tested with our GPS data and the results are efficient in processing large datasets. It is a parallel data processing tool which is gathering significant importance from industry and academia especially with appearance of a new term to describe massive datasets having large-volume, high-complexity and growing data from different sources, “big data”.
ER  - 

TY  - JOUR
T1  - Efficiency investigation of manifold matching for text document classification
JO  - Pattern Recognition Letters
VL  - 34
IS  - 11
SP  - 1263
EP  - 1269
PY  - 2013/8/1/
T2  - 
AU  - Sun, Ming
AU  - Priebe, Carey E.
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2013.03.025
UR  - http://www.sciencedirect.com/science/article/pii/S0167865513001293
KW  - Manifold matching
KW  - MDS    ∘    Procrustes
KW  - CCA
KW  - JOFC
KW  - Efficiency
KW  - Classification
AB  - Abstract
Manifold matching works to identify embeddings of multiple disparate data spaces into the same low-dimensional space, where joint inference can be pursued. It is an enabling methodology for fusion and inference from multiple and massive disparate data sources. In this paper three methods of manifold matching are considered: PoM, which stands for Multidimensional Scaling (MDS) composed with Procrustes; CCA (Canonical Correlation Analysis) and JOFC (Joint Optimization of Fidelity and Commensurability). We present a comparative efficiency investigation of the three methods for a particular text document classification application.
ER  - 

TY  - JOUR
T1  - GIS analysis of depression among Twitter users
JO  - Applied Geography
VL  - 60
IS  - 
SP  - 217
EP  - 223
PY  - 2015/6//
T2  - 
AU  - Yang, Wei
AU  - Mu, Lan
SN  - 0143-6228
DO  - http://dx.doi.org/10.1016/j.apgeog.2014.10.016
UR  - http://www.sciencedirect.com/science/article/pii/S0143622814002537
KW  - Depression
KW  - Tweets
KW  - Clustering
KW  - GIS
KW  - Social media
AB  - Abstract
Depression is a common chronic disorder. It often goes undetected due to limited diagnosis methods and brings serious results to public and personal health. Former research detected geographic pattern for depression using questionnaires or self-reported measures of mental health, this may induce same-source bias. Recent studies use social media for depression detection but none of them examines the geographic patterns. In this paper, we apply GIS methods to social media data to provide new perspectives for public health research. We design a procedure to automatically detect depressed users in Twitter and analyze their spatial patterns using GIS technology. This method can improve diagnosis techniques for depression. It is faster at collecting data and more promptly at analyzing and providing results. Also, this method can be expanded to detect other major events in real-time, such as disease outbreaks and earthquakes.
ER  - 

TY  - JOUR
T1  - Sample-weighted clustering methods
JO  - Computers & Mathematics with Applications
VL  - 62
IS  - 5
SP  - 2200
EP  - 2208
PY  - 2011/9//
T2  - 
AU  - Yu, Jian
AU  - Yang, Miin-Shen
AU  - Lee, E. Stanley
SN  - 0898-1221
DO  - http://dx.doi.org/10.1016/j.camwa.2011.07.005
UR  - http://www.sciencedirect.com/science/article/pii/S0898122111005591
KW  - Cluster analysis
KW  - Maximum entropy principle
KW  - k  -means
KW  - Fuzzy   c  -means
KW  - Sample weights
KW  - Robustness
AB  - Although there have been many researches on cluster analysis considering feature (or variable) weights, little effort has been made regarding sample weights in clustering. In practice, not every sample in a data set has the same importance in cluster analysis. Therefore, it is interesting to obtain the proper sample weights for clustering a data set. In this paper, we consider a probability distribution over a data set to represent its sample weights. We then apply the maximum entropy principle to automatically compute these sample weights for clustering. Such method can generate the sample-weighted versions of most clustering algorithms, such as k -means, fuzzy c -means (FCM) and expectation &amp; maximization (EM), etc. The proposed sample-weighted clustering algorithms will be robust for data sets with noise and outliers. Furthermore, we also analyze the convergence properties of the proposed algorithms. This study also uses some numerical data and real data sets for demonstration and comparison. Experimental results and comparisons actually demonstrate that the proposed sample-weighted clustering algorithms are effective and robust clustering methods.
ER  - 

TY  - JOUR
T1  - Recommending the Meanings of Newly Coined Words
JO  - Procedia - Social and Behavioral Sciences
VL  - 27
IS  - 
SP  - 267
EP  - 273
PY  - 2011///
T2  - Computational Linguistics and Related Fields
AU  - Lee, Jong Gun
AU  - Kim, Young-Min
AU  - Park, Jungyeul
AU  - Cha, Jeong-Won
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2011.10.607
UR  - http://www.sciencedirect.com/science/article/pii/S1877042811024347
KW  - Newly Coined Word
KW  - Topic Model
KW  - Probabilistic Latent Semantic Analysis
AB  - Abstract
In this paper, we investigate how to recommend the meanings of newly coined words, such as newly coined named entities and Internet jargon. Our approach automatically chooses a document explaining a given newly coined word among candidate documents from multiple web references using Probabilistic Latent Semantic Analysis [1]. Briefly, it involves finding the topic of a document containing the newly coined word and computing the conditional probability of the topic given each candidate document. We validate our methodology with two real datasets from MySpace forums and Twitter by referencing three web services, Google, Urbandictionary, and Wikipedia, and we show that we properly recommend the meanings of a set of given newly coined words with 69.5% and 80.5% accuracies based on our three recommendations, respectively. Moreover, we compare our approach against three baselines where one references the result from each web service and our approach outperforms them.
ER  - 

TY  - JOUR
T1  - Reducing network congestion by separating nets of single-row networks into layers
JO  - Procedia - Social and Behavioral Sciences
VL  - 28
IS  - 
SP  - 39
EP  - 44
PY  - 2011///
T2  - World Conference on Educational Technology Researches - 2011
AU  - Noraziah, A.
AU  - Herawan, Tutut
AU  - Zin, Noriyani Mohd
AU  - Jamil, Norazaliza Mohd
AU  - Deris, Mustafa Mat
AU  - Abdullah, Zailani
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2011.11.008
UR  - http://www.sciencedirect.com/science/article/pii/S1877042811024475
KW  - ESSR
KW  - graph clustering
KW  - k-means algorithm
KW  - single-row routing
AB  - Single-row routing is a method for routing pair of nodes set in a single-row axis. The nets construct the wire without traverse each other in the printed circuit board design that has been drawn from left to right. The main purpose in single-row routing is to achieve the optimal results of minimum congestion arise from the number of horizontal tracks in the network. Optimal results for a single layer network have been achieved through a model called Enhanced Simulated Annealing Single-row Routing (ESSR). However, a single layer model suffers from non-tolerable lower bound values with high congestion depending on the network size. These results may further be improved by partitioning the network into two or more layers. In this paper, a technique for partitioning the nodes from a single-row network into several layers of planar graphs by using k-means algorithm has been proposed. The experiment result shows that the proposed technique is able to minimize the network congestions.
ER  - 

TY  - JOUR
T1  - Accessing Relevant and Accurate Information using Entropy
JO  - Procedia Computer Science
VL  - 54
IS  - 
SP  - 449
EP  - 455
PY  - 2015///
T2  - Eleventh International Conference on Communication Networks, ICCN 2015, August 21-23, 2015, Bangalore, India Eleventh International Conference on Data Mining and Warehousing, ICDMW 2015, August 21-23, 2015, Bangalore, India Eleventh International Conference on Image and Signal Processing, ICISP 2015, August 21-23, 2015, Bangalore, India
AU  - Kumar, Sarowar
AU  - Abhishek, Kumar
AU  - Singh, M.P.
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.06.052
UR  - http://www.sciencedirect.com/science/article/pii/S1877050915013769
KW  - Clustering
KW  - Entropy
KW  - Information content
KW  - Meta tag
KW  - Semantic web
KW  - Synaptic web.
AB  - Abstract
Keyword based search engine generally provides result set with a large number of web pages, mostly irrelevant. The world wide web is a large collection of web/hypertext document, so effort is required to provide relevant data for a given set of query with less response time. This paper implements the semantic-synaptic web mining algorithm, and compares the result with other existing algorithm. The algorithm focuses on use of entropy for finding accurate results for any given query.
ER  - 

TY  - JOUR
T1  - Improving DBSCAN’s execution time by using a pruning technique on bit vectors
JO  - Pattern Recognition Letters
VL  - 32
IS  - 13
SP  - 1572
EP  - 1580
PY  - 2011/10/1/
T2  - 
AU  - Mimaroglu, Selim
AU  - Aksehirli, Emin
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2011.06.003
UR  - http://www.sciencedirect.com/science/article/pii/S0167865511001796
KW  - Clustering
KW  - DBSCAN
KW  - Binary methods
KW  - Pruning
AB  - Clustering is the process of assigning a set of physical or abstract objects into previously unknown groups. The goal of clustering is to group similar objects into the same clusters and dissimilar objects into different clusters. Similarities between objects are evaluated by using the attribute values of objects. There are many clustering algorithms in the literature; among them, DBSCAN is a well known density-based clustering algorithm. We improve DBSCAN’s execution time performance for binary data sets and Hamming distances. We achieve considerable speed gains by using a novel pruning technique, as well as bit vectors, and binary operations. Our novel method effectively discards distant neighbors of an object and computes only the distances between an object and its possible neighbors. By discarding distant neighbors, we avoid unnecessary distance computations and use less CPU time when compared with the conventional DBSCAN algorithm. However, the accuracy of our method is identical to that of the original DBSCAN. Experimental test results on real and synthetic data sets demonstrate that, by using our pruning technique, we obtain considerably faster execution time results compared to DBSCAN.
ER  - 

TY  - JOUR
T1  - Combining multiple classifications of chemical structures using consensus clustering
JO  - Bioorganic & Medicinal Chemistry
VL  - 20
IS  - 18
SP  - 5366
EP  - 5371
PY  - 2012/9/15/
T2  - Chemoinformatics in Drug Discovery
AU  - Chu, Chia-Wei
AU  - Holliday, John D.
AU  - Willett, Peter
SN  - 0968-0896
DO  - http://dx.doi.org/10.1016/j.bmc.2012.03.010
UR  - http://www.sciencedirect.com/science/article/pii/S0968089612001897
KW  - Cluster analysis
KW  - Consensus clustering
KW  - Fingerprint
KW  - Group-average clustering method
KW  - k-Means clustering method
AB  - Consensus clustering involves combining multiple clusterings of the same set of objects to achieve a single clustering that will, hopefully, provide a better picture of the groupings that are present in a dataset. This Letter reports the use of consensus clustering methods on sets of chemical compounds represented by 2D fingerprints. Experiments with DUD, IDAlert, MDDR and MUV data suggests that consensus methods are unlikely to result in significant improvements in clustering effectiveness as compared to the use of a single clustering method.
ER  - 

TY  - JOUR
T1  - The use of a genetic algorithm for clustering the weighing station performance in transportation – A case study
JO  - Expert Systems with Applications
VL  - 38
IS  - 9
SP  - 11744
EP  - 11750
PY  - 2011/9//
T2  - 
AU  - Mahmoudabadi, Abbas
AU  - Tavakkoli-Moghaddam, Reza
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2011.03.061
UR  - http://www.sciencedirect.com/science/article/pii/S0957417411004696
KW  - Genetic algorithm
KW  - Clustering
KW  - Weighing station
KW  - Transportation
KW  - Performance analysis
AB  - In this paper, a genetic algorithm (GA) is developed to solve a clustering problem for evaluating and ranking the weighing stations according to their performances. In hierarchical steps of clustering, observations with the least similarities should be merged and some of them will be lost. To improve this defect, the main concept behind the proposed algorithm is to avoid losing data in the hierarchical process of clustering, so all of the observations are randomly assigned into a predefined number of clusters by GA procedures. In this model, we consider the performance factors related to the weighing operation, such as the traffic volume of trucks, detected overloading, type of portable or fixed scales, and rate of acceding detections compared to the same duration in the previous year. The required data of 126 weighing stations are collected during two 6-month periods. Different dimensions of the collected data are standardized to uniform dimensions. The main performance of a clustering method considered as the fitness value in a genetic algorithm (GA) is to maximize the sum of deviation squares from the mean of within groups. It guaranties that the clusters have most similarities within groups and least similarities in among groups. Four different techniques of the mathematical clustering are compared with the result of the proposed GA by using the MATLAB software. The related results show that the clustering of weighing stations is more likely to other methods.
ER  - 

TY  - JOUR
T1  - An expansion and reranking approach for annotation-based image retrieval from Web
JO  - Expert Systems with Applications
VL  - 38
IS  - 10
SP  - 13121
EP  - 13127
PY  - 2011/9/15/
T2  - 
AU  - Kılınç, Deniz
AU  - Alpkocak, Adil
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2011.04.118
UR  - http://www.sciencedirect.com/science/article/pii/S0957417411006452
KW  - Information retrieval
KW  - Image retrieval
KW  - Query expansion
KW  - Document expansion
KW  - Reranking
KW  - WordNet
AB  - In this paper, we introduce an expansion and reranking approach for annotation based image retrieval from Web pages. Our suggestion considers an image retrieval system using the surrounding texts nearby the image in a Web page as annotations. However, annotations may include too much and uninformative text such as copyright notice, date, author. In order to choose indexing terms effectively, we propose a term selection approach, which first expands the document using WordNet, and then selects descriptive terms among them. Notably, we applied this term selection methodology to both document and query. This is because applying either of documents or query does not help to increase retrieval performance. On the other hand, term selection process increases the number of terms per documents, and both documents and queries become more exhaustive than original. Consequently, this results high recall with low precision in retrieval. Thus, we also proposed a two-level reranking approach. In order to evaluate our approaches we have participated ImageCLEF2009 WikipediaMM subtask. The results we obtained are superior to any participating approaches and our approach has obtained the best four ranks, in text-only image retrieval. The results also showed that document expansion and effective term selection to annotations plays an important role in text-based image retrieval.
ER  - 

TY  - JOUR
T1  - A combined approach for clustering based on K-means and gravitational search algorithms
JO  - Swarm and Evolutionary Computation
VL  - 6
IS  - 
SP  - 47
EP  - 52
PY  - 2012/10//
T2  - 
AU  - Hatamlou, Abdolreza
AU  - Abdullah, Salwani
AU  - Nezamabadi-pour, Hossein
SN  - 2210-6502
DO  - http://dx.doi.org/10.1016/j.swevo.2012.02.003
UR  - http://www.sciencedirect.com/science/article/pii/S2210650212000235
KW  - Clustering
KW  - K-means
KW  - Gravitational search algorithm
AB  - Clustering is an attractive and important task in data mining that is used in many applications. Clustering refers to grouping together data objects so that objects within a cluster are similar to one another, while objects in different clusters are dissimilar. K-means is a simple and efficient algorithm that is widely used for data clustering. However, its performance depends on the initial state of centroids and may trap in local optima. The gravitational search algorithm (GSA) is one effective method for searching problem space to find a near optimal solution. In this paper, we present a hybrid data clustering algorithm based on GSA and k-means (GSA-KM), which uses the advantages of both algorithms. The GSA-KM algorithm helps the k-means algorithm to escape from local optima and also increases the convergence speed of the GSA algorithm. We compared the performance of GSA-KM with other well-known algorithms, including k-means, genetic algorithm (GA), simulated annealing (SA), ant colony optimization (ACO), honey bee mating optimization (HBMO), particle swarm optimization (PSO) and gravitational search algorithm (GSA). Five real and standard datasets from the UCI repository have been used to demonstrate the results of the algorithms. The experimental results are encouraging in terms of the quality of the solutions and the convergence speed of the proposed algorithm.
ER  - 

TY  - JOUR
T1  - Analyzing documents with Quantum Clustering: A novel pattern recognition algorithm based on quantum mechanics
JO  - Pattern Recognition Letters
VL  - 77
IS  - 
SP  - 8
EP  - 13
PY  - 2016/7/1/
T2  - 
AU  - Liu, Ding
AU  - Jiang, Minghu
AU  - Yang, Xiaofang
AU  - Li, Hui
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2016.03.008
UR  - http://www.sciencedirect.com/science/article/pii/S0167865516000775
KW  - Quantum clustering
KW  - Text analysis
KW  - Text clustering
AB  - Abstract
The article introduces Quantum Clustering, a novel pattern recognition algorithm inspired by quantum mechanics and extend it to text analysis. This novel method improves upon nonparametric density estimation (i.e. Parzen-window), and differentiates itself from it in a significant way, Quantum Clustering constructs the potential function to determine the cluster center instead of the Gaussian kernel function. Specifically, detailed comparative analysis shows that the potential function could clearly reveal the underlying structure of the data that the Gaussian kernel could not handle. Moreover, the problem of parameter estimation is solved successfully by the numerical optimization approach (i.e. Pattern Search). Afterwards, the results of detailed comparative experiments on three benchmark datasets confirms the advantage of Quantum Clustering over the Parzen-window, and the additional trial on authorship identification illustrates the wide application scope of this novel method.
ER  - 

TY  - JOUR
T1  - Efficient protocol for data clustering by fuzzy Cuckoo Optimization Algorithm
JO  - Applied Soft Computing
VL  - 41
IS  - 
SP  - 15
EP  - 21
PY  - 2016/4//
T2  - 
AU  - Amiri, Ehsan
AU  - Mahmoudi, Shadi
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2015.12.008
UR  - http://www.sciencedirect.com/science/article/pii/S1568494615007875
KW  - Data clustering
KW  - Cuckoo Optimization Algorithm (COA)
KW  - Dataset
KW  - Fuzzy logic
KW  - Artificial intelligence
AB  - Abstract
Data clustering is a technique for grouping similar and dissimilar data. Many clustering algorithms fail when dealing with multi-dimensional data. This paper introduces efficient methods for data clustering by Cuckoo Optimization Algorithm; called COAC and Fuzzy Cuckoo Optimization Algorithm, called FCOAC. The COA by inspire of cuckoo bird nature life tries to solve continuous problems. This algorithm clusters a large dataset to prior determined clusters numbers by this meta-heuristic algorithm and optimal the results by fuzzy logic. Firstly, the algorithm generates a random solutions equal to cuckoo population and with length dataset objects and with a cost function calculates the cost of each solution. Finally, fuzzy logic tries for the optimal solution. The performance of our algorithm is evaluated and compared with COAC, Black hole, CS, K-mean, PSO and GSA. The results show that our algorithm has better performance in comparison with them.
ER  - 

TY  - JOUR
T1  - PLM Ontology Exploitation through Inference and Statistical Analysis A Case Study for LCC
JO  - IFAC Proceedings Volumes
VL  - 46
IS  - 9
SP  - 1004
EP  - 1008
PY  - 2013///
T2  - 7th IFAC Conference on Manufacturing Modelling, Management, and Control
AU  - Milicic, A
AU  - Perdikakis, A.
AU  - Kadiri, S.El.
AU  - Kiritsis, D
SN  - 1474-6670
DO  - http://dx.doi.org/10.3182/20130619-3-RU-3018.00043
UR  - http://www.sciencedirect.com/science/article/pii/S1474667016344202
KW  - ontology
KW  - product life-cycle management
KW  - inference
KW  - statistical analysis
KW  - industrial use-case
KW  - LCC
AB  - Abstract
In a time of growing complexity and amount of a product related data, ontology has show to be an efficient and convenient method for structuring and modeling the domain of interest. It provides a clear picture of all relevant concepts, their relationships and the rules they follow. It is a structured, centralized data base, that allows fast updates and prevents redundancy. Still, fast, real-time functions of today's companies impose additional requirements on a operational domain model and in this paper, we argue that product life-cycle management (PLM) ontology can meet those requirements. In that sense, tools that we propose for ontology exploitation are mainly inference on ontology rules on one side, and ontology instances extraction for the purpose of visualization and data mining on the other side. We implement these tools for the case of manufacturing company on a real life data provided and analyze benefits from the aspect of non-expert end-user. This research is done as a part of FP7 project LinkedDesign.
ER  - 

TY  - JOUR
T1  - Visual representation of safety narratives
JO  - Safety Science
VL  - 88
IS  - 
SP  - 123
EP  - 128
PY  - 2016/10//
T2  - 
AU  - Robinson, S.D.
SN  - 0925-7535
DO  - http://dx.doi.org/10.1016/j.ssci.2016.05.005
UR  - http://www.sciencedirect.com/science/article/pii/S0925753516300790
KW  - LSA
KW  - Adaptive taxonomy
KW  - Safety
KW  - Isometric mapping
KW  - Machine learning
AB  - Abstract
A computational method for the visualization of text-based safety narratives on a two dimensional plane is shown. This multi-step approach utilizes latent semantic analysis to first infer higher-order structures and then isometric mapping to reduce the projection to two dimensions. Metadata may then be overlaid on the projection. Demonstrated is the application of this process to the human coded primary-problems identified and the phase of flight for a sample of the Aviation Safety Reporting System database. It is evident that this approach provides additional insight for the analysis of large inter-related corpora commonly found in safety programs.
ER  - 

TY  - JOUR
T1  - An Efficient Text Classification Scheme Using Clustering
JO  - Procedia Technology
VL  - 24
IS  - 
SP  - 1220
EP  - 1225
PY  - 2016///
T2  - International Conference on Emerging Trends in Engineering, Science and Technology (ICETEST - 2015)
AU  - Thomas, Anisha Mariam
AU  - Resmipriya, M.G.
SN  - 2212-0173
DO  - http://dx.doi.org/10.1016/j.protcy.2016.05.095
UR  - http://www.sciencedirect.com/science/article/pii/S2212017316301840
KW  - Data Mining
KW  - Classification
KW  - Semi-supervised Clustering
KW  - Similarity Measures
AB  - Abstract
Text classification method that uses efficient similarity measures to achieve better performance is being proposed in this paper. Semi-supervised clustering is used as a complementary step to text classification and is used to identify the components in text collection. Clustering makes use of labeled texts to capture silhouettes of text clusters and unlabeled texts to adapt its centroids. The category of each text cluster is labeled by the label of texts in it. Thus here the text clustering is used to generate the classification model for the next text classification step. When a new unlabeled text is incoming, measure its similarity with the centroids of the text clusters and give its label with that of the nearest text cluster. The similarity is calculated using different similarity measures. Results and evaluations are summarized and it is found that the system provides better accuracy when a Similarity Measure for Text Processing (SMTP) used for the distance calculation.
ER  - 

TY  - JOUR
T1  - User Search Goals Evaluation with Feedback Sessions
JO  - Procedia Technology
VL  - 24
IS  - 
SP  - 1256
EP  - 1262
PY  - 2016///
T2  - International Conference on Emerging Trends in Engineering, Science and Technology (ICETEST - 2015)
AU  - Febna, V.
AU  - Abraham, Anish
SN  - 2212-0173
DO  - http://dx.doi.org/10.1016/j.protcy.2016.05.107
UR  - http://www.sciencedirect.com/science/article/pii/S2212017316301967
KW  - Feedback Sessions
KW  - Pseudo-documents
KW  - CAP
KW  - K-Medoid
AB  - Abstract
In today's e-world, search engines play a vital role in retrieving and organizing relevant data for various purposes. Different methods are used to find user search goals. Personalization is the process of finding exact needs of a user using different representations and machine learning techniques. These methods exploit feedback sessions and bipartite graphs, along with machine learning techniques such as clustering, classification and Apriori algorithms. This paper proposes a variant of feedback session method for inferring user search goals, where bag of words approach is employed for representation. K-Medoid clustering algorithm is used to derive the cluster for the keywords entered by the user. The performance improvement can be evaluated by using evaluation measures like Average Precision (AP), Voted Average Precision (VAP) and Classified Average Precision (CAP).
ER  - 

TY  - JOUR
T1  - A novel travel-time based similarity measure for hierarchical clustering
JO  - Neurocomputing
VL  - 173, Part 1
IS  - 
SP  - 3
EP  - 8
PY  - 2016/1/15/
T2  - 
AU  - Lu, Yonggang
AU  - Hou, Xiaoli
AU  - Chen, Xurong
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2015.01.090
UR  - http://www.sciencedirect.com/science/article/pii/S0925231215010383
KW  - Clustering
KW  - Similarity measure
KW  - Travel time
AB  - Abstract
The similarity measure plays an important role in agglomerative hierarchical clustering. Following the idea of gravitational clustering which treats all the data points as mass points under a hypothetical gravitational force field, we propose a novel similarity measure for hierarchical clustering. The similarity measure is based on the estimated travel time between data points under the gravitational force field: the shorter the travel time from one point to another, the larger the similarity between the two data points. To simplify the computation, the travel time between a pair of data points is estimated using the potential field produced by all the data points. Based on the new similarity measure, we also propose a new hierarchical clustering method called Travel-Time based Hierarchical Clustering (TTHC). In the TTHC method, an edge-weighted tree of all the data points is first built using the travel-time based similarity measure, and then the clustering results are derived from the edge-weighted tree directly. To evaluate the proposed TTHC method, it is compared with four other hierarchical clustering methods on six real datasets and two synthetic dataset families composed of 200 datasets. The experiments show that using the travel-time based similarity measure can improve both the robustness and the quality of hierarchical clustering.
ER  - 

TY  - JOUR
T1  - An architecture for component-based design of representative-based clustering algorithms
JO  - Data & Knowledge Engineering
VL  - 75
IS  - 
SP  - 78
EP  - 98
PY  - 2012/5//
T2  - 
AU  - Delibašić, Boris
AU  - Vukićević, Milan
AU  - Jovanović, Miloš
AU  - Kirchner, Kathrin
AU  - Ruhland, Johannes
AU  - Suknović, Milija
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2012.03.005
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X12000286
KW  - Representative-based clustering algorithms
KW  - Architecture
KW  - Reusable component
KW  - Generic algorithm
KW  - K-means
AB  - We propose an architecture for the design of representative-based clustering algorithms based on reusable components. These components were derived from K-means-like algorithms and their extensions. With the suggested clustering design architecture, it is possible to reconstruct popular algorithms, but also to build new algorithms by exchanging components from original algorithms and their improvements. In this way, the design of a myriad of representative-based clustering algorithms and their fair comparison and evaluation are possible. In addition to the architecture, we show the usefulness of the proposed approach by providing experimental evaluation.
ER  - 

TY  - JOUR
T1  - Extractive single-document summarization based on genetic operators and guided local search
JO  - Expert Systems with Applications
VL  - 41
IS  - 9
SP  - 4158
EP  - 4169
PY  - 2014/7//
T2  - 
AU  - Mendoza, Martha
AU  - Bonilla, Susana
AU  - Noguera, Clara
AU  - Cobos, Carlos
AU  - León, Elizabeth
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2013.12.042
UR  - http://www.sciencedirect.com/science/article/pii/S0957417413010312
KW  - Extractive summarization
KW  - Single document
KW  - Memetic algorithm
KW  - Guided local search
AB  - Abstract
Due to the exponential growth of textual information available on the Web, end users need to be able to access information in summary form – and without losing the most important information in the document when generating the summaries. Automatic generation of extractive summaries from a single document has traditionally been given the task of extracting the most relevant sentences from the original document. The methods employed generally allocate a score to each sentence in the document, taking into account certain features. The most relevant sentences are then selected, according to the score obtained for each sentence. These features include the position of the sentence in the document, its similarity to the title, the sentence length, and the frequency of the terms in the sentence. However, it has still not been possible to achieve a quality of summary that matches that performed by humans and therefore methods continue to be brought forward that aim to improve on the results. This paper addresses the generation of extractive summaries from a single document as a binary optimization problem where the quality (fitness) of the solutions is based on the weighting of individual statistical features of each sentence – such as position, sentence length and the relationship of the summary to the title, combined with group features of similarity between candidate sentences in the summary and the original document, and among the candidate sentences of the summary. This paper proposes a method of extractive single-document summarization based on genetic operators and guided local search, called MA-SingleDocSum. A memetic algorithm is used to integrate the own-population-based search of evolutionary algorithms with a guided local search strategy. The proposed method was compared with the state of the art methods UnifiedRank, DE, FEOM, NetSum, CRF, QCS, SVM, and Manifold Ranking, using ROUGE measures on the datasets DUC2001 and DUC2002. The results showed that MA-SingleDocSum outperforms the state of the art methods.
ER  - 

TY  - JOUR
T1  - GenDocSum + MCLR: Generic document summarization based on maximum coverage and less redundancy
JO  - Expert Systems with Applications
VL  - 39
IS  - 16
SP  - 12460
EP  - 12473
PY  - 2012/11/15/
T2  - 
AU  - Alguliev, Rasim M.
AU  - Aliguliyev, Ramiz M.
AU  - Hajirahimova, Makrufa S.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2012.04.067
UR  - http://www.sciencedirect.com/science/article/pii/S0957417412006641
KW  - Generic document summarization
KW  - Maximum coverage
KW  - Less redundancy
KW  - Optimization model
KW  - Differential evolution algorithm
AB  - With the rapid growth of information on the Internet and electronic government recently, automatic multi-document summarization has become an important task. Multi-document summarization is an optimization problem requiring simultaneous optimization of more than one objective function. In this study, when building summaries from multiple documents, we attempt to balance two objectives, content coverage and redundancy. Our goal is to investigate three fundamental aspects of the problem, i.e. designing an optimization model, solving the optimization problem and finding the solution to the best summary. We model multi-document summarization as a Quadratic Boolean Programing (QBP) problem where the objective function is a weighted combination of the content coverage and redundancy objectives. The objective function measures the possible summaries based on the identified salient sentences and overlap information between selected sentences. An innovative aspect of our model lies in its ability to remove redundancy while selecting representative sentences. The QBP problem has been solved by using a binary differential evolution algorithm. Evaluation of the model has been performed on the DUC2002, DUC2004 and DUC2006 data sets. We have evaluated our model automatically using ROUGE toolkit and reported the significance of our results through 95% confidence intervals. The experimental results show that the optimization-based approach for document summarization is truly a promising research direction.
ER  - 

TY  - JOUR
T1  - Revealing research themes and trends in knowledge management: From 1995 to 2010
JO  - Knowledge-Based Systems
VL  - 28
IS  - 
SP  - 47
EP  - 58
PY  - 2012/4//
T2  - 
AU  - Lee, Maria R.
AU  - Chen, Tsung Teng
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2011.11.016
UR  - http://www.sciencedirect.com/science/article/pii/S0950705111002528
KW  - Knowledge management
KW  - Research trends
KW  - Visualization
KW  - Intellectual structure
KW  - Literature review
AB  - Visualizing the entire domain of knowledge and tracking the latest developments of an important discipline are challenging tasks for researchers. This study builds an intellectual structure by examining a total of 10,974 publications in the knowledge management (KM) field from 1995 to 2010. Document co-citation analysis, pathfinder network and strategic diagram techniques are applied to provide a dynamic view of the evolution of knowledge management research trends. This study provides a systematic and objective means in exploring the development of the KM discipline. This paper not only drew its finding from a large data set but also presented a longitudinal analysis of the development of the KM related studies. The results of this study reflect that the coverage of key KM papers has expanded into a broad spectrum of disciplines. A discussion of the future of KM research is also provided.
ER  - 

TY  - JOUR
T1  - Review of the application of social network analysis (SNA) in construction project management research
JO  - International Journal of Project Management
VL  - 34
IS  - 7
SP  - 1214
EP  - 1225
PY  - 2016/10//
T2  - 
AU  - Zheng, Xian
AU  - Le, Yun
AU  - Chan, Albert P.C.
AU  - Hu, Yi
AU  - Li, Yongkui
SN  - 0263-7863
DO  - http://dx.doi.org/10.1016/j.ijproman.2016.06.005
UR  - http://www.sciencedirect.com/science/article/pii/S0263786316300448
KW  - Social network analysis
KW  - Stakeholder theory
KW  - Construction project management
KW  - Review
AB  - Abstract
Over the past two decades, social network analysis (SNA) has elicited increasing attention in construction project management (CPM) research as a response to the emerging perspective of viewing projects as network-based organizational organizations. However, a thorough review of SNA application in CPM research is unavailable. This study aims to address this gap by reviewing 63 SNA papers published in eight peer-reviewed journals from 1997 to 2015 to ascertain the status of this research area and identify future research directions. The papers are analyzed in terms of institutional and individual contribution, citations, topic coverage and research design and methodologies. Three research directions, namely, internal stakeholder networks for outcome-related values, external stakeholder networks for process-related values, and external stakeholder networks for outcome-related values, are identified. The findings of this study are believed to provide useful references for the future application of SNA in CPM research.
ER  - 

TY  - JOUR
T1  - A study of learning performance of e-learning materials design with knowledge maps
JO  - Computers & Education
VL  - 54
IS  - 1
SP  - 253
EP  - 264
PY  - 2010/1//
T2  - 
AU  - Shaw, Ruey-Shiang
SN  - 0360-1315
DO  - http://dx.doi.org/10.1016/j.compedu.2009.08.007
UR  - http://www.sciencedirect.com/science/article/pii/S0360131509002036
KW  - Authoring tools and methods
KW  - Media in education
KW  - Teaching/learning strategies
AB  - This research investigated the application of knowledge maps in e-learning materials design and hypothesized that knowledge maps would be more effective than e-learning in general at improving the performance and satisfaction of e-learning. In order to test the hypotheses, we conducted an experiment with 175 participants and randomly assigned them into knowledge map-based and browse-based groups. Both groups of participants needed to acquire specific skills and knowledge to write the target ADO.NET program. In the end of each training session subjects received an assessment to understand their learning score, satisfaction level, and computer self-efficacy. Our statistical analysis result showed that knowledge map-based learning group outperformed browse-based group in these three measurements. Thus, the proposed hypotheses were supported. We concluded that if knowledge map-based materials design approach were employed novice users would acquire the ADO.NET programming in a more effective manner. In addition, the satisfaction and computer self-efficacy of users could be improved substantially as a result of knowledge map-based materials design approach.

Thus, we propose that if knowledge maps are employed to adequately present the relationships of learning contents that knowledge could be better understood and learning performance could be improved.
ER  - 

TY  - JOUR
T1  - Conceptual map – didactic method of constructivist type during the physics lessons
JO  - Procedia - Social and Behavioral Sciences
VL  - 2
IS  - 2
SP  - 3622
EP  - 3631
PY  - 2010///
T2  - Innovation and Creativity in Education
AU  - Garabet, Mihaela
AU  - Miron, Cristina
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2010.03.564
UR  - http://www.sciencedirect.com/science/article/pii/S187704281000604X
KW  - Conceptual map
KW  - constructivist learning
KW  - Physics
KW  - teaching
KW  - evaluation
KW  - interdisciplinary
AB  - The purpose of this article is to show / to present that the method of conceptual map in studying, systematization and evaluation of Physics knowledge is a method which is based on constructivist learning / studying. We begin with a short introduction, necessary to the presentation of the studying theory of Ausubel and Novak, then we will make some references to the notion of conceptual map, which shows how we have used this method in teaching, studying and evaluation of Physics and we will end with the presentation of some examples that show both the usage modality and the importance of the conceptual maps. This method improves the quality of teaching and learning Physics in the pre-university education.
ER  - 

TY  - JOUR
T1  - Expert systems and artificial intelligence in the 21st century logistics and supply chain management
JO  - Expert Systems with Applications
VL  - 41
IS  - 1
SP  - 1
EP  - 4
PY  - 2014/1//
T2  - 21st Century Logistics and Supply Chain Management
AU  - Gunasekaran, Angappa
AU  - Ngai, Eric W.T.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2013.09.006
UR  - http://www.sciencedirect.com/science/article/pii/S0957417413007252
ER  - 

TY  - JOUR
T1  - Effective risk governance for environmental policy making: A knowledge management perspective
JO  - Environmental Science & Policy
VL  - 41
IS  - 
SP  - 23
EP  - 32
PY  - 2014/8//
T2  - 
AU  - Mauelshagen, Craig
AU  - Smith, Mark
AU  - Schiller, Frank
AU  - Denyer, David
AU  - Rocks, Sophie
AU  - Pollard, Simon
SN  - 1462-9011
DO  - http://dx.doi.org/10.1016/j.envsci.2014.04.014
UR  - http://www.sciencedirect.com/science/article/pii/S1462901114000860
KW  - Environmental policy
KW  - Risk
KW  - Enterprise risk management
KW  - Knowledge management
AB  - Abstract
Effective risk management within environmental policy making requires knowledge on natural, economic and social systems to be integrated; knowledge characterised by complexity, uncertainty and ambiguity. We describe a case study in a (UK) central government department exploring how risk governance supports and hinders this challenging integration of knowledge. Forty-five semi-structured interviews were completed over a two year period. We found that lateral knowledge transfer between teams working on different policy areas was widely viewed as a key source of knowledge. However, the process of lateral knowledge transfer was predominantly informal and unsupported by risk governance structures. We argue this made decision quality vulnerable to a loss of knowledge through staff turnover, and time and resource pressures. Our conclusion is that the predominant form of risk governance framework, with its focus on centralised decision-making and vertical knowledge transfer is insufficient to support risk-based, environmental policy making. We discuss how risk governance can better support environmental policy makers through systematic knowledge management practices.
ER  - 

TY  - JOUR
T1  - Technological Knowledge Framework Towards Organizational Knowledge Transfer in Mexico
JO  - Procedia - Social and Behavioral Sciences
VL  - 73
IS  - 
SP  - 556
EP  - 563
PY  - 2013/2/27/
T2  - Proceedings of the 2nd International Conference on Integrated Information (IC-ININFO 2012), Budapest, Hungary, August 30 – September 3, 2012
AU  - López, Valentino Morales
AU  - Carrillo, Miguel Ortega
AU  - Bustamente, Tania Poom
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2013.02.091
UR  - http://www.sciencedirect.com/science/article/pii/S1877042813003844
KW  - Organizational Knowledge
KW  - Enterprise Network
KW  - Knowledge Transfer
KW  - Knowledge Management
KW  - Knowledge System.
AB  - This paper presents the technological framework in order to advance research model of organizational knowledge transfer to Mexico. There are diverse studies and programs available in both the literature and in the market of software of knowledge management. However, few software programs integrate knowledge storage with user interaction to transfer knowledge, and besides are quite expensive for mid-size organizations in emerging countries, such as Mexico. The aim of this study was to develop a research program in order to model an organizational knowledge transfer to Mexico. The program developed for this research was based on Web 2.0 and on the Semantic Web to offer users the benefit of greater interaction with the feasibility of locating in a quick way the required knowledge that comprises the system. The platform that runs the software is Semantic Web Builder, a tool developed in the Fondo de Información y Documentación para la Industria INFOTEC for the developing of semantic portals. The software is comprised by four elements: a) Corporate network based on the vision of inter-operability of the Web 2.0 in which members of the organization interact to transfer knowledge; b) Storage of documents in which the construction of codified knowledge is in process, so storage is transitory; c) Digital library is the site in which is preserved the stock of formalized knowledge of the organization; and d) Search engine that goes across the diverse system modules and that allows use.
ER  - 

TY  - JOUR
T1  - Clustering and classification of email contents
JO  - Journal of King Saud University - Computer and Information Sciences
VL  - 27
IS  - 1
SP  - 46
EP  - 57
PY  - 2015/1//
T2  - 
AU  - Alsmadi, Izzat
AU  - Alhami, Ikdam
SN  - 1319-1578
DO  - http://dx.doi.org/10.1016/j.jksuci.2014.03.014
UR  - http://www.sciencedirect.com/science/article/pii/S1319157814000573
KW  - Emails classification
KW  - Document similarity
KW  - Document classification
KW  - Feature extraction
KW  - Subject classification
KW  - Content classification
AB  - Abstract
Information users depend heavily on emails’ system as one of the major sources of communication. Its importance and usage are continuously growing despite the evolution of mobile applications, social networks, etc. Emails are used on both the personal and professional levels. They can be considered as official documents in communication among users. Emails’ data mining and analysis can be conducted for several purposes such as: Spam detection and classification, subject classification, etc. In this paper, a large set of personal emails is used for the purpose of folder and subject classifications. Algorithms are developed to perform clustering and classification for this large text collection. Classification based on NGram is shown to be the best for such large text collection especially as text is Bi-language (i.e. with English and Arabic content).
ER  - 

TY  - JOUR
T1  - An adaptive meta-search engine considering the user’s field of interest
JO  - Journal of King Saud University - Computer and Information Sciences
VL  - 24
IS  - 1
SP  - 71
EP  - 81
PY  - 2012/1//
T2  - 
AU  - Hassanpour, Hamid
AU  - Zahmatkesh, Farzaneh
SN  - 1319-1578
DO  - http://dx.doi.org/10.1016/j.jksuci.2011.10.004
UR  - http://www.sciencedirect.com/science/article/pii/S1319157811000334
KW  - Clustering
KW  - Meta-search engine
KW  - Ranking
KW  - Search relevance
KW  - Social information
AB  - Existing meta-search engines return web search results based on the page relevancy to the query, their popularity and content. It is necessary to provide a meta-search engine capable of ranking results considering the user’s field of interest. Social networks can be useful to find the users’ tendencies, favorites, skills, and interests. In this paper we propose MSE, a meta-search engine for document retrieval utilizing social information of the user. In this approach, each user is assumed to have a profile containing his fields of interest. MSE extracts main phrases from the title and short description of receiving results from underlying search engines. Then it clusters the main phrases by a Self-Organizing Map neural network. Generated clusters are then ranked on the basis of the user’s field of interest. We have compared the proposed MSE against two other meta-search engines. The experimental results show the efficiency and effectiveness of the proposed method.
ER  - 

TY  - JOUR
T1  - BARTMAP: A viable structure for biclustering
JO  - Neural Networks
VL  - 24
IS  - 7
SP  - 709
EP  - 716
PY  - 2011/9//
T2  - 
AU  - Xu, Rui
AU  - Wunsch II, Donald C.
SN  - 0893-6080
DO  - http://dx.doi.org/10.1016/j.neunet.2011.03.020
UR  - http://www.sciencedirect.com/science/article/pii/S0893608011001043
KW  - Adaptive resonance theory (ART)
KW  - Fuzzy
KW  - ARTMAP
KW  - Clustering
KW  - Biclustering
KW  - Subspace clustering
KW  - Heteroassociative
KW  - Gene expression
KW  - Bioinformatics
KW  - Microarray
KW  - Data mining
KW  - Knowledge discovery
AB  - Clustering has been used extensively in the analysis of high-throughput messenger RNA (mRNA) expression profiling with microarrays. Furthermore, clustering has proven elemental in microRNA expression profiling, which demonstrates enormous promise in the areas of cancer diagnosis and treatment, gene function identification, therapy development and drug testing, and genetic regulatory network inference. However, such a practice is inherently limited due to the existence of many uncorrelated genes with respect to sample or condition clustering, or many unrelated samples or conditions with respect to gene clustering. Biclustering offers a solution to such problems by performing simultaneous clustering on both dimensions, or automatically integrating feature selection to clustering without any prior information, so that the relations of clusters of genes (generally, features) and clusters of samples or conditions (data objects) are established. However, the NP-complete computational complexity raises a great challenge to computational methods for identifying such local relations. Here, we propose and demonstrate that a neural-based classifier, ARTMAP, can be modified to perform biclustering in an efficient way, leading to a biclustering algorithm called Biclustering ARTMAP (BARTMAP). Experimental results on multiple human cancer data sets show that BARTMAP can achieve clustering structures with higher qualities than those achieved with other commonly used biclustering or clustering algorithms, and with fast run times.
ER  - 

TY  - JOUR
T1  - Chinese text classification for small sample set
JO  - The Journal of China Universities of Posts and Telecommunications
VL  - 18, Supplement 1
IS  - 
SP  - 83
EP  - 89
PY  - 2011/9//
T2  - 
AU  - LI, Lei
AU  - HUANG, Yu-guang
AU  - LIU, Zhong-wan
SN  - 1005-8885
DO  - http://dx.doi.org/10.1016/S1005-8885(10)60205-1
UR  - http://www.sciencedirect.com/science/article/pii/S1005888510602051
KW  - Chinese text classification
KW  - small sample set
KW  - Naïve Bayes
KW  - Poisson distribution
KW  - feature selection
AB  - Text classification is one of the most important topics in the fields of Internet information management and natural language processing. Machine learning based text classification methods are currently most popular ones with better performance than rule based ones. But they always need lots of training samples, which not only brings heavy work for previous manual classification, but also puts forward a higher request for storage and computing resources during the computer post-processing. Naïve Bayes algorithm is one of the most effective methods for text classification with the same problem. Only in the large training sample set can it get a more accurate result. This paper mainly studies Naïve Bayes classification algorithm for Chinese text based on Poisson distribution model and feature selection. The experimental results have shown that this method keeps high classification accuracy even in a small sample set.
ER  - 

TY  - JOUR
T1  - RSQRT: An heuristic for estimating the number of clusters to report
JO  - Electronic Commerce Research and Applications
VL  - 11
IS  - 2
SP  - 152
EP  - 158
PY  - 2012/3//
Y2  - 2012/4//
T2  - The Role of Business Analytics in E-Commerce
AU  - Carlis, John
AU  - Bruso, Kelsey
SN  - 1567-4223
DO  - http://dx.doi.org/10.1016/j.elerap.2011.12.006
UR  - http://www.sciencedirect.com/science/article/pii/S1567422312000026
KW  - Bayesian information criterion
KW  - Clustering
KW  - Data analytics
KW  - E-commerce
KW  - Heuristic
KW  - Spiral visualization
AB  - Clustering can be a valuable tool for analyzing large data sets, such as in e-commerce applications. Anyone who clusters must choose how many item clusters, K, to report. Unfortunately, one must guess at K or some related parameter. Elsewhere we introduced a strongly-supported heuristic, RSQRT, which predicts K as a function of the attribute or item count, depending on attribute scales. We conducted a second analysis where we sought confirmation of the heuristic, analyzing data sets from the UCI machine learning benchmark repository. For the 25 studies where sufficient detail was available, we again found strong support. Also, in a side-by-side comparison of 28 studies, RSQRT best-predicted K and the Bayesian information criterion (BIC) predicted K are the same. RSQRT has a lower cost of O(log log n) versus O(n2) for BIC, and is more widely applicable. Using RSQRT prospectively could be much better than merely guessing.
ER  - 

TY  - JOUR
T1  - Recurrent neural network for approximate nonnegative matrix factorization
JO  - Neurocomputing
VL  - 138
IS  - 
SP  - 238
EP  - 247
PY  - 2014/8/22/
T2  - 
AU  - Costantini, Giovanni
AU  - Perfetti, Renzo
AU  - Todisco, Massimiliano
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2014.02.007
UR  - http://www.sciencedirect.com/science/article/pii/S0925231214002525
KW  - Recurrent neural networks
KW  - Lagrangian networks
KW  - Nonnegative matrix factorization
KW  - Features extraction
KW  - Clustering
AB  - Abstract
A recurrent neural network solving the approximate nonnegative matrix factorization (NMF) problem is presented in this paper. The proposed network is based on the Lagrangian approach, and exploits a partial dual method in order to limit the number of dual variables. Sparsity constraints on basis or activation matrices are included by adding a weighted sum of constraint functions to the least squares reconstruction error. However, the corresponding Lagrange multipliers are computed by the network dynamics itself, avoiding empirical tuning or a validation process. It is proved that local solutions of the NMF optimization problem correspond to as many stable steady-state points of the network dynamics. The validity of the proposed approach is verified through several simulation examples concerning both synthetic and real-world datasets for feature extraction and clustering applications.
ER  - 

TY  - JOUR
T1  - Large margin clustering on uncertain data by considering probability distribution similarity
JO  - Neurocomputing
VL  - 158
IS  - 
SP  - 81
EP  - 89
PY  - 2015/6/22/
T2  - 
AU  - Xu, Lei
AU  - Hu, Qinghua
AU  - Hung, Edward
AU  - Chen, Baowen
AU  - Tan, Xu
AU  - Liao, Changrui
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2015.02.002
UR  - http://www.sciencedirect.com/science/article/pii/S0925231215001125
KW  - Clustering
KW  - Uncertain data
KW  - Probability density function
KW  - Large margin
KW  - Histogram intersection kernel
AB  - Abstract
In this paper, the problem of clustering uncertain objects whose locations are uncertain and described by probability density functions (pdf) is studied. Though some existing methods (i.e. K-means, DBSCAN) have been extended to handle uncertain object clustering, there are still some limitations to be solved. K-means assumes that the objects are described by reasonably separated spherical balls. Thus, UK-means based on K-means is limited in handling objects which are in non-spherical shape. On the other hand, the probability density function is an important characteristic of uncertain data, but few existing clustering methods consider the difference between objects relying on probability density functions. Therefore, in this article, a clustering algorithm based on probability distribution similarity is proposed. Our method aims at finding the largest margin between clusters to overcome the limitation of UK-means. Extensively experimental results verify the performance of our method by effectiveness, efficiency and scalability on both synthetic and real data sets.
ER  - 

TY  - JOUR
T1  - Discriminative concept factorization for data representation
JO  - Neurocomputing
VL  - 74
IS  - 18
SP  - 3800
EP  - 3807
PY  - 2011/11//
T2  - 
AU  - Hua, Wei
AU  - He, Xiaofei
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2011.07.020
UR  - http://www.sciencedirect.com/science/article/pii/S0925231211004498
KW  - Concept factorization
KW  - Dimensionality reduction
KW  - Semi-supervised learning
AB  - Non-negative matrix factorization (NMF) has become a popular technique for finding low-dimensional representations of data. While the standard NMF can only be performed in the original feature space, one variant of NMF, named concept factorization, can be naturally kernelized and inherits all the strengths of NMF. To make use of label information, we propose a semi-supervised concept factorization technique called discriminative concept factorization (DCF) for data representation in this paper. DCF adopts a unified objective to combine the task of data reconstruction with the task of classification. These two tasks have mutual impacts on each other, which results in a concept factorization adapted to the classification task and a classifier built on the low-dimensional representations. Furthermore, we develop an iterative algorithm to solve the optimization problem through alternative convex programming. Experimental results on three real-word classification tasks demonstrate the effectiveness of DCF.
ER  - 

TY  - JOUR
T1  - Video analysis based on Multi-Kernel Representation with automatic parameter choice
JO  - Neurocomputing
VL  - 100
IS  - 
SP  - 117
EP  - 126
PY  - 2013/1/16/
T2  - Special issue: Behaviours in video
AU  - Álvarez-Meza, A.M.
AU  - Valencia-Aguirre, J.
AU  - Daza-Santacoloma, G.
AU  - Acosta-Medina, C.D.
AU  - Castellanos-Domínguez, G.
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2011.10.034
UR  - http://www.sciencedirect.com/science/article/pii/S0925231212003207
KW  - Video analysis
KW  - Manifold learning
KW  - Multi-Kernel Representation
KW  - Automatic parameter selection
KW  - Multiple Manifold Learning
AB  - In this work, we analyze video data by learning both the spatial and temporal relationships among frames. For this purpose, the nonlinear dimensionality reduction algorithm, Laplacian Eigenmaps, is improved using a multiple kernel learning framework, and it is assumed that the data can be modeled by means of two different graphs: one considering the spatial information (i.e., the pixel intensity similarities) and the other one based on the frame temporal order. In addition, a formulation for automatic tuning of the required free parameters is stated, which is based on a tradeoff between the contribution of each information source (spatial and temporal). Moreover, we proposed a scheme to compute a common representation in a low-dimensional space for data lying in several manifolds, such as multiple videos of similar behaviors. The proposed algorithm is tested on real-world datasets, and the obtained results allow us to confirm visually the quality of the attained embedding. Accordingly, discussed approach is suitable for data representability when considering cyclic movements.
ER  - 

TY  - JOUR
T1  - Dynamic filter weights neural network model integrated with differential evolution for day-ahead price forecasting in energy market
JO  - Expert Systems with Applications
VL  - 38
IS  - 9
SP  - 10974
EP  - 10982
PY  - 2011/9//
T2  - 
AU  - Chakravarty, S.
AU  - Dash, P.K.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2011.02.141
UR  - http://www.sciencedirect.com/science/article/pii/S0957417411003629
KW  - Dynamic filter weights neuron
KW  - Energy market
KW  - Sliding mode control
KW  - Local linear wavelet neural network
KW  - Differential evolution
AB  - In this paper a new dynamic model for forecasting electricity prices from 1 to 24 h in advance is proposed. The model is a dynamic filter weight Adaline using a sliding mode weight adaptation technique. The filter weights for this neuron constitute of first order dynamic filter with adjustable parameters. Sliding mode invariance conditions determine a least square characterization of the adaptive weights average dynamics whose stability features may be studied using standard time varying linear system results. The approach is found to exhibit robustness characteristics and first convergence properties. Comparison of results with a local linear wavelet neural network model is also presented in this paper. The hourly electricity prices of California and Spanish energy markets are taken as experimental data and the Mean Absolute Percentage Error (MAPE) and Root Mean Square Error (RMSE) are computed to find out the forecasting performance of both the models. In both the cases the MAPE and RMSE are found to be within the tolerable limits. As dynamic filter weight neural network gives better results in comparison to local linear wavelet neural network, the former has been further integrated with differential evolution algorithm to enhance the performance.
ER  - 

TY  - JOUR
T1  - Integrating spatial and color information in images using a statistical framework
JO  - Expert Systems with Applications
VL  - 37
IS  - 2
SP  - 1542
EP  - 1549
PY  - 2010/3//
T2  - 
AU  - Bouguila, Nizar
AU  - ElGuebaly, Walid
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2009.06.096
UR  - http://www.sciencedirect.com/science/article/pii/S0957417409006186
KW  - Color histograms
KW  - Spatial information
KW  - Multiple-Bernoulli mixture
KW  - MAP
KW  - EM
KW  - DAEM
KW  - Image classification
AB  - Color histograms have been widely used successfully in many computer vision and image processing applications. However, they do not include any spatial information. In this paper, we propose a statistical model to integrate both color and spatial information. Our model is based on finite multiple-Bernoulli mixtures. For the estimation of the model’s parameters, we use a maximum a posteriori (MAP) approach through deterministic annealing expectation maximization (DAEM). Smoothing priors on the components parameters are introduced to stabilize the estimation. The selection of the number of clusters is based on stochastic complexity. The results show that our model achieves good performance in some image classification problems.
ER  - 

TY  - JOUR
T1  - Multi-grain hierarchical topic extraction algorithm for text mining
JO  - Expert Systems with Applications
VL  - 37
IS  - 4
SP  - 3202
EP  - 3208
PY  - 2010/4//
T2  - 
AU  - Zeng, Jianping
AU  - Wu, Chengrong
AU  - Wang, Wei
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2009.09.061
UR  - http://www.sciencedirect.com/science/article/pii/S0957417409008422
KW  - Hierarchical topic
KW  - Topic grain
KW  - Feature selection
KW  - Text mining
AB  - Topic extraction from text corpus is the fundamental of many topic analysis tasks, such as topic trend prediction, opinion extraction. Since hierarchical structure is characteristics of topics, it is preferential for a topic extraction algorithm to output the topics description with this kind of structure. However, the hierarchical topic structure that is extracted by most of the current topic analysis algorithms cannot provide a meaningful description for all subtopics in the hierarchical tree. Here, we propose a new hierarchical topic extraction algorithm based on topic grain computation. By considering the distribution of word document frequency as a mixture Gaussian, an EM-like algorithm is employed to achieve the best number of mixture components, and the mean value of each component. Then topic grain is defined based on the mixture Gaussian parameters, and feature words are selected for the grain. A clustering algorithm is employed to the converted text set based on the feature words. After repeatedly applying the clustering algorithm to different converted text set, a multi-grain hierarchical topic structure with different subtopic feature words description is extracted. Experiments on two real world datasets which are collected from a news website show that the proposed algorithm can generate more meaningful multi-grain topic structure, by comparing with the current hierarchical topic clustering algorithms.
ER  - 

TY  - JOUR
T1  - Text Analytics for Android Project
JO  - Procedia Economics and Finance
VL  - 18
IS  - 
SP  - 610
EP  - 617
PY  - 2014///
T2  - 4th International Conference on Building Resilience, Incorporating the 3rd Annual Conference of the ANDROID Disaster Resilience Network, 8th – 11th September 2014, Salford Quays, United Kingdom
AU  - Kaklauskas, Arturas
AU  - Seniut, Mark
AU  - Amaratunga, Dilanthi
AU  - Lill, Irene
AU  - Safonov, Andrej
AU  - Vatin, Nikolai
AU  - Cerkauskas, Justas
AU  - Jackute, Ieva
AU  - Kuzminske, Agne
AU  - Peciure, Lina
SN  - 2212-5671
DO  - http://dx.doi.org/10.1016/S2212-5671(14)00982-4
UR  - http://www.sciencedirect.com/science/article/pii/S2212567114009824
KW  - text analytics
KW  - text mining
KW  - Text Analytics for Android Project
KW  - qualitative and quantitative analysis
AB  - Abstract
Most advanced text analytics and text mining tasks include text classification, text clustering, building ontology, concept/entity extraction, summarization, deriving patterns within the structured data, production of granular taxonomies, sentiment and emotion analysis, document summarization, entity relation modelling, interpretation of the output. Already existing text analytics and text mining cannot develop text material alternatives (perform a multivariant design), perform multiple criteria analysis, automatically select the most effective variant according to different aspects (citation index of papers (Scopus, ScienceDirect, Google Scholar) and authors (Scopus, ScienceDirect, Google Scholar), Top 25 papers, impact factor of journals, supporting phrases, document name and contents, density of keywords), calculate utility degree and market value. However, the Text Analytics for Android Project can perform the aforementioned functions. To the best of the knowledge herein, these functions have not been previously implemented; thus this is the first attempt to do so. The Text Analytics for Android Project is briefly described in this article.
ER  - 

TY  - JOUR
T1  - A new pivoting and iterative text detection algorithm for biomedical images
JO  - Journal of Biomedical Informatics
VL  - 43
IS  - 6
SP  - 924
EP  - 931
PY  - 2010/12//
T2  - 
AU  - Xu, Songhua
AU  - Krauthammer, Michael
SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2010.09.006
UR  - http://www.sciencedirect.com/science/article/pii/S1532046410001383
KW  - Text detection
KW  - Histogram analysis for text detection
KW  - Pivoting and iterative text region detection
KW  - Biomedical image mining
AB  - There is interest to expand the reach of literature mining to include the analysis of biomedical images, which often contain a paper’s key findings. Examples include recent studies that use Optical Character Recognition (OCR) to extract image text, which is used to boost biomedical image retrieval and classification. Such studies rely on the robust identification of text elements in biomedical images, which is a non-trivial task. In this work, we introduce a new text detection algorithm for biomedical images based on iterative projection histograms. We study the effectiveness of our algorithm by evaluating the performance on a set of manually labeled random biomedical images, and compare the performance against other state-of-the-art text detection algorithms. We demonstrate that our projection histogram-based text detection approach is well suited for text detection in biomedical images, and that the iterative application of the algorithm boosts performance to an F score of .60. We provide a C++ implementation of our algorithm freely available for academic use.
ER  - 

TY  - JOUR
T1  - K-Means clustering technique applied to availability of micro hydro power
JO  - Sustainable Energy Technologies and Assessments
VL  - 8
IS  - 
SP  - 191
EP  - 201
PY  - 2014/12//
T2  - 
AU  - Adhau, S.P.
AU  - Moharil, R.M.
AU  - Adhau, P.G.
SN  - 2213-1388
DO  - http://dx.doi.org/10.1016/j.seta.2014.09.001
UR  - http://www.sciencedirect.com/science/article/pii/S2213138814000782
KW  - Micro hydro power
KW  - k-mean clustering technique
KW  - Discharge cluster
KW  - Power cluster
KW  - Silhouette plot
AB  - Abstract
Hydro power generation can be planned on small-scale on existing small rivers, canals etc. The Government of India has declared the revised policy for development of small hydro power up to 25 MW capacities through private sector participation. Hydro power project on the canal water can be planned under Independent Power Producer’s Policy and developed as the independent power generation plant. K-Means clustering has been used to classify discharge and power data of ten years with the greatest possible distinction. The results are presented in a table that shows members of clusters and their distances from respective cluster centers. From the cluster analysis, the expected discharge and its probability have been computed and the plant capacity has been fixed. Various graphs are plotted for a typical river data. This paper can be well utilized for accelerating the development of micro hydro resources and deciding the capacity of plant by the use of clustering technique.
ER  - 

TY  - JOUR
T1  - Research on Mechanism of the Information Retrieval Based on Ontology Label
JO  - Procedia Engineering
VL  - 29
IS  - 
SP  - 4259
EP  - 4266
PY  - 2012///
T2  - 2012 International Workshop on Information and Electronics Engineering
AU  - Zhou, Hong
AU  - Liu, Bing-wu
AU  - Liu, Jun
SN  - 1877-7058
DO  - http://dx.doi.org/10.1016/j.proeng.2012.01.654
UR  - http://www.sciencedirect.com/science/article/pii/S1877705812006649
KW  - Information retrieval
KW  - Ontology
KW  - Label
KW  - Semantics ;
AB  - The problem of simple interaction between semantic retrieval and the retrieval result information und the context of the Chinese can not be solved effectively through the traditional information retrieval mechanism. The research into the methods of information retrieval is carried out by introducing ontology and label mechanism in this paper. The relevant research into the ontology label extraction methods and ontology label construction mechanism based on KowNet is carried out, the information retrieval mechanism and relevant retrieval model based on ontology label is put forward and the corresponding work of the combination of label phrase and ontology modularization is dealt with.
ER  - 

TY  - JOUR
T1  - ICD9-based Text Mining Approach to Children Epilepsy Classification
JO  - Procedia Technology
VL  - 9
IS  - 
SP  - 1351
EP  - 1360
PY  - 2013///
T2  - CENTERIS 2013 - Conference on ENTERprise Information Systems / ProjMAN 2013 - International Conference on Project MANagement/ HCIST 2013 - International Conference on Health and Social Care Information Systems and Technologies
AU  - Pereira, Luis
AU  - Rijo, Rui
AU  - Silva, Catarina
AU  - Agostinho, Margarida
SN  - 2212-0173
DO  - http://dx.doi.org/10.1016/j.protcy.2013.12.152
UR  - http://www.sciencedirect.com/science/article/pii/S221201731300306X
KW  - data mining
KW  - text mining
KW  - electronic medical records
KW  - ICD codes
KW  - machine learning
KW  - epilepsy
AB  - Abstract
According with the World Health Organization, around 50 million people in the world have epilepsy. After the diagnosis process, physicians classify epilepsy according to the International Classification of Diseases, Ninth Revision (ICD-9). Often exams as electroencephalograms and magnetic resonances are used to create a more accurate diagnosis in a short amount of time. The classification process is time consuming and demands the realization of complementary exams. To circumvent this laborious process we propose an automatic process of classifying epileptic diagnoses based on ICD-9. We put forward a text mining approach, using processed electronic medical records and a K-Nearest Neighbor is applied as a white-box multi classifier approach to classify each instance mapping into the corresponding standard code.

Results suggests a good performance proposing a diagnosis from electronic medical records, despite of the reduced volume of available training data.
ER  - 

TY  - JOUR
T1  - Data Mining – Past, Present and Future – A Typical Survey on Data Streams
JO  - Procedia Technology
VL  - 12
IS  - 
SP  - 255
EP  - 263
PY  - 2014///
T2  - The 7th International Conference Interdisciplinarity in Engineering, INTER-ENG 2013, 10-11 October 2013, Petru Maior University of Tirgu Mures, Romania
AU  - PhridviRaj, M.S.B.
AU  - GuruRao, C.V.
SN  - 2212-0173
DO  - http://dx.doi.org/10.1016/j.protcy.2013.12.483
UR  - http://www.sciencedirect.com/science/article/pii/S2212017313006683
KW  - Clustering
KW  - Streams
KW  - Mining
KW  - Dimensionality reduction
KW  - Text stream
KW  - Data streams
AB  - Abstract
Data Stream Mining is one of the area gaining lot of practical significance and is progressing at a brisk pace with new methods, methodologies and findings in various applications related to medicine, computer science, bioinformatics and stock market prediction, weather forecast, text, audio and video processing to name a few. Data happens to be the key concern in data mining. With the huge online data generated from several sensors, Internet Relay Chats, Twitter, Face book, Online Bank or ATM Transactions, the concept of dynamically changing data is becoming a key challenge, what we call as data streams. In this paper, we give the algorithm for finding frequent patterns from data streams with a case study and identify the research issues in handling data streams.
ER  - 

TY  - JOUR
T1  - Image clustering based on sparse patch alignment framework
JO  - Pattern Recognition
VL  - 47
IS  - 11
SP  - 3512
EP  - 3519
PY  - 2014/11//
T2  - 
AU  - Yu, Jun
AU  - Hong, Richang
AU  - Wang, Meng
AU  - You, Jane
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2014.05.002
UR  - http://www.sciencedirect.com/science/article/pii/S0031320314001873
KW  - Image clustering
KW  - Manifold learning
KW  - Sparse representation
AB  - Abstract
Image clustering methods are efficient tools for applications such as content-based image retrieval and image annotation. Recently, graph based manifold learning methods have shown promising performance in extracting features for image clustering. Typical manifold learning methods adopt appropriate neighborhood size to construct the neighborhood graph, which captures local geometry of data distribution. Because the density of data points’ distribution may be different in different regions of the manifold, a fixed neighborhood size may be inappropriate in building the manifold. In this paper, we propose a novel algorithm, named sparse patch alignment framework, for the embedding of data lying in multiple manifolds. Specifically, we assume that for each data point there exists a small neighborhood in which only the points that come from the same manifold lie approximately in a low-dimensional affine subspace. Based on the patch alignment framework, we propose an optimization strategy for constructing local patches, which adopt sparse representation to select a few neighbors of each data point that span a low-dimensional affine subspace passing near that point. After that, the whole alignment strategy is utilized to build the manifold. Experiments are conducted on four real-world datasets, and the results demonstrate the effectiveness of the proposed method.
ER  - 

TY  - JOUR
T1  - A Method for Refining a Taxonomy by Using Annotated Suffix Trees and Wikipedia Resources
JO  - Procedia Computer Science
VL  - 31
IS  - 
SP  - 193
EP  - 200
PY  - 2014///
T2  - 2nd International Conference on Information Technology and Quantitative Management, ITQM 2014
AU  - Chernyak, Ekaterina
AU  - Mirkin, Boris
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2014.05.260
UR  - http://www.sciencedirect.com/science/article/pii/S1877050914004372
KW  - taxonomy refinement
KW  - string-to-text relevance
KW  - utilizing Wikipedia
KW  - suffix trees.
AB  - Abstract
A two-step approach to taxonomy construction is presented. On the first step the frame of taxonomy is built manually according to some representative educational materials. On the second step, the frame is refined using the Wikipedia category tree and articles. Since the structure of Wikipedia is rather noisy, a procedure to clear the Wikipedia category tree is suggested. A string-to-text relevance score, based on annotated suffix trees, is used several times to 1) clear the Wikipedia data from noise; 2) to assign Wikipedia categories to taxonomy topics; 3) to choose whether the category should be assigned to the taxonomy topic or stay on intermediate levels. The resulting taxonomy consists of three parts: the manully set upper levels, the adopted Wikipedia category tree and the Wikipedia articles as leaves.Also, a set of so-called descriptors is assigned to every leaf; these are phrases explaining aspects of the leaf topic. The method is illustrated by its application to two domains: a) Probability theory and mathematical statistics, b) “Numerical analysis” (both in Russian).
ER  - 

TY  - JOUR
T1  - Generalized canonical correlation analysis for disparate data fusion
JO  - Pattern Recognition Letters
VL  - 34
IS  - 2
SP  - 194
EP  - 200
PY  - 2013/1/15/
T2  - 
AU  - Sun, Ming
AU  - Priebe, Carey E.
AU  - Tang, Minh
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2012.09.018
UR  - http://www.sciencedirect.com/science/article/pii/S0167865512003030
KW  - Manifold matching
KW  - Canonical correlation analysis
KW  - Reduced rank regression
KW  - Efficiency
KW  - Classification
AB  - Manifold matching works to identify embeddings of multiple disparate data spaces into the same low-dimensional space, where joint inference can be pursued. It is an enabling methodology for fusion and inference from multiple and massive disparate data sources. In this paper we focus on a method called Canonical Correlation Analysis (CCA) and its generalization Generalized Canonical Correlation Analysis (GCCA), which belong to the more general Reduced Rank Regression (RRR) framework. We present an efficiency investigation of CCA and GCCA under different training conditions for a particular text document classification task.
ER  - 

TY  - JOUR
T1  - AlmaNebula: A Computer Forensics Framework for the Cloud
JO  - Procedia Computer Science
VL  - 19
IS  - 
SP  - 139
EP  - 146
PY  - 2013///
T2  - The 4th International Conference on Ambient Systems, Networks and Technologies (ANT 2013), the 3rd International Conference on Sustainable Energy Information Technology (SEIT-2013)
AU  - Federici, Corrado
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2013.06.023
UR  - http://www.sciencedirect.com/science/article/pii/S1877050913006315
KW  - Forensics as a service
KW  - Computer forensics framework
KW  - Commodity computing
KW  - Big data
KW  - Web scale
KW  - Distributed processing
AB  - Abstract
Scalability, fault tolerance and collaborative processing across possibly dispersed sites are key enablers of modern computer forensics applications, that must be able to elastically accommodate all kinds of digital investigations, without wasting resources or fail to deliver timely outcomes. Traditional tools running in a standalone or client- server setups may fall short when handling the multi terabyte scale of a case just above average or, conversely, lie mainly underutilized when dealing with few digital evidences. A new category of applications that leverage the opportunities offered by modern Cloud Computing (CC) platforms, where scalable computational power and storage capacity can be engaged and decommissioned on demand, allow one to conveniently master huge amounts of information that otherwise could be impossible to wield. This paper discusses the design goals, technical requirements and architecture of AlmaNebula, a conceptual framework for the analysis of digital evidences built on top of a Cloud infrastructure, which aims to embody the concept of “Forensics as a service”.
ER  - 

TY  - JOUR
T1  - Direct decomposition of three-way arrays using a non-negative approximation
JO  - Talanta
VL  - 83
IS  - 2
SP  - 541
EP  - 548
PY  - 2010/12/15/
T2  - 
AU  - Sun, Jiangming
AU  - Li, Tonghua
AU  - Cong, Peisheng
AU  - Xiong, Wenwei
AU  - Tang, Shengnan
AU  - Zhu, Li
SN  - 0039-9140
DO  - http://dx.doi.org/10.1016/j.talanta.2010.09.035
UR  - http://www.sciencedirect.com/science/article/pii/S0039914010007496
KW  - Non-negative matrix approximation
KW  - Second-order calibration
KW  - PARAFAC
KW  - Kinetics
AB  - Non-negative matrix approximation (NNMA) has been used in diverse scientific fields, but it still has some major limitations. In the present study a novel trilinear decomposition method, termed three-way NNMA (TWNNMA), was developed. The method decomposes three-way arrays directly without unfolding and overcomes the restriction of locking zero elements in the deduced multiplicative update rules by adding a positive symmetric matrix. Direct trilinear decomposition was used as the TWNNMA initialization method and experimental results confirm that this greatly accelerated the convergence. An obvious advantage of TWNNMA is the uniqueness of the non-negative solution, which facilitates a better understanding of the underlying physical realities of complex data. TWNNMA was applied in complex systems such as chemical kinetics, second-order calibration and analysis of GC–MS data. The results demonstrate that TWNNMA, differing from previous trilinear decomposition methods, is comparable to existing second-order calibration methods and represents a promising resolution method for complex systems.
ER  - 

TY  - JOUR
T1  - Automated Message Filtering System in Online Social Network
JO  - Procedia Computer Science
VL  - 50
IS  - 
SP  - 466
EP  - 475
PY  - 2015///
T2  - Big Data, Cloud and Computing Challenges
AU  - Subramaniyaswamy, V.
AU  - Logesh, R.
AU  - Vijayakumar, V.
AU  - Indragandhi, V.
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.04.016
UR  - http://www.sciencedirect.com/science/article/pii/S1877050915005177
KW  - OSN (Online Social Network)
KW  - Expert analysis
KW  - Text classification
KW  - Text mining
AB  - Abstract
In this generation, using online social network (OSN) is an unavoidable powerful weapon to exhibit peoples’ views and ideas. The users depending upon their interests can select the persons who must post/comment messages in their wall. The present excavation in OSN user wall is “No filtering of abusive messages”. That is the selected persons can post any sort of messages in their wall. So in this paper, we propose a filtered wall to permeate offensive messages using rule based and text classification techniques. We have evaluated the performance using metrics, from which it is shown that proposed method is better.
ER  - 

TY  - JOUR
T1  - Adaptive Preshuffling in Hadoop Clusters
JO  - Procedia Computer Science
VL  - 18
IS  - 
SP  - 2458
EP  - 2467
PY  - 2013///
T2  - 2013 International Conference on Computational Science
AU  - Xie, Jiong
AU  - Tian, Yun
AU  - Yin, Shu
AU  - Zhang, Ji
AU  - Ruan, Xiaojun
AU  - Qin, Xiao
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2013.05.422
UR  - http://www.sciencedirect.com/science/article/pii/S1877050913005656
AB  - Abstract
MapReduce has become an important distributed processing model for large-scale data-intensive applications like data mining and web indexing. Hadoop–an open-source imple- mentation of MapReduce is widely used for short jobs requiring low response time. In this paper, We proposed a new preshuffling strategy in Hadoop to reduce high network loads imposed by shuffle-intensive applications. Designing new shuffling strategies is very appealing for Hadoop clusters where network intercon- nects are performance bottleneck when the clusters are shared among a large number of applications. The network interconnects are likely to become scarce resource when many shuffle-intensive applications are sharing a Hadoop cluster. We implemented the push model along with the preshuffling scheme in the Hadoop system, where the 2-stage pipeline was incorporated with the preshuffling scheme. We implemented the push model and a pipeline along with the preshuffling scheme in the Hadoop system. Using two Hadoop benchmarks running on the 10-node cluster, we conducted experiments to show that preshuffling-enabled Hadoop clusters are faster than native Hadoop clusters. For example, the push model and the preshuffling scheme powered by the 2-stage pipeline can shorten the execution times of the WordCount and Sort Hadoop applications by an average of 10% and 14%, respectively.
ER  - 

TY  - JOUR
T1  - Fast window fusion using fuzzy equivalence relation
JO  - Pattern Recognition Letters
VL  - 34
IS  - 6
SP  - 670
EP  - 677
PY  - 2013/4/15/
T2  - 
AU  - Fang, Xianyong
AU  - Zhang, Hu
AU  - Zhou, Jian
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2013.01.014
UR  - http://www.sciencedirect.com/science/article/pii/S0167865513000184
KW  - Sliding window
KW  - Human detection
KW  - Window fusion
KW  - Fuzzy equivalence relation
AB  - Current window fusion of the sliding window based human detection is rather slow. This paper proposes a fast fuzzy equivalence relation based method (FER). It merges candidate windows based on the fuzzy equivalence relation structured from the normal fuzzy similarity relation. Experimental results demonstrate that the method can merge candidate windows faster than the popular non-maximum suppression based method (NMS) and the bounding region method (BR), while maintaining the detection quality.
ER  - 

TY  - JOUR
T1  - Automatically generating the weather news summary based on fuzzy reasoning and ontology techniques
JO  - Information Sciences
VL  - 279
IS  - 
SP  - 746
EP  - 763
PY  - 2014/9/20/
T2  - 
AU  - Chen, Shyi-Ming
AU  - Huang, Ming-Hung
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2014.04.027
UR  - http://www.sciencedirect.com/science/article/pii/S0020025514004745
KW  - Weather news summary
KW  - Domain ontology
KW  - Fuzzy reasoning
KW  - Fuzzy rule
AB  - Abstract
In this paper, we present a new method for automatically generating the weather news summary based on fuzzy reasoning and ontology techniques, where the weather ontology, the time ontology and the geography ontology are predefined by domain experts. We slice the original weather news articles into a set of terms. Then, we use two ontological features (i.e., the degree of depth of the ontology and the degree of width of the ontology) and one statistical feature (i.e., frequency) as inputs to the system. The values of those features are represented by fuzzy sets. Then, the fuzzy reasoning algorithm infers the score of each sentence. The summary is composed of candidate sentences which have higher scores, where the experimental data are adopted from the weather news website of Taiwan. The experimental results show that the proposed method outperforms the methods presented in [14,15] for automatically generating the weather news summary.
ER  - 

TY  - JOUR
T1  - Black hole: A new heuristic optimization approach for data clustering
JO  - Information Sciences
VL  - 222
IS  - 
SP  - 175
EP  - 184
PY  - 2013/2/10/
T2  - Including Special Section on New Trends in Ambient Intelligence and Bio-inspired Systems
AU  - Hatamlou, Abdolreza
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2012.08.023
UR  - http://www.sciencedirect.com/science/article/pii/S0020025512005762
KW  - Nature-inspired algorithm
KW  - Black hole phenomenon
KW  - Data clustering
AB  - Nature has always been a source of inspiration. Over the last few decades, it has stimulated many successful algorithms and computational tools for dealing with complex and optimization problems. This paper proposes a new heuristic algorithm that is inspired by the black hole phenomenon. Similar to other population-based algorithms, the black hole algorithm (BH) starts with an initial population of candidate solutions to an optimization problem and an objective function that is calculated for them. At each iteration of the black hole algorithm, the best candidate is selected to be the black hole, which then starts pulling other candidates around it, called stars. If a star gets too close to the black hole, it will be swallowed by the black hole and is gone forever. In such a case, a new star (candidate solution) is randomly generated and placed in the search space and starts a new search. To evaluate the performance of the black hole algorithm, it is applied to solve the clustering problem, which is a NP-hard problem. The experimental results show that the proposed black hole algorithm outperforms other traditional heuristic algorithms for several benchmark datasets.
ER  - 

TY  - JOUR
T1  - A hybrid intelligent model of analyzing clinical breast cancer data using clustering techniques with feature selection
JO  - Applied Soft Computing
VL  - 20
IS  - 
SP  - 4
EP  - 14
PY  - 2014/7//
T2  - Hybrid intelligent methods for health technologies
AU  - Chen, Chien-Hsing
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2013.10.024
UR  - http://www.sciencedirect.com/science/article/pii/S156849461300358X
KW  - Breast cancer diagnoses
KW  - Feature selection
KW  - Cluster analysis
KW  - Filter model
KW  - Wrapper model
AB  - Abstract
Models based on data mining and machine learning techniques have been developed to detect the disease early or assist in clinical breast cancer diagnoses. Feature selection is commonly applied to improve the performance of models. There are numerous studies on feature selection in the literature, and most of the studies focus on feature selection in supervised learning. When class labels are absent, feature selection methods in unsupervised learning are required. However, there are few studies on these methods in the literature. Our paper aims to present a hybrid intelligence model that uses the cluster analysis techniques with feature selection for analyzing clinical breast cancer diagnoses. Our model provides an option of selecting a subset of salient features for performing clustering and comprehensively considers the use of most existing models that use all the features to perform clustering. In particular, we study the methods by selecting salient features to identify clusters using a comparison of coincident quantitative measurements. When applied to benchmark breast cancer datasets, experimental results indicate that our method outperforms several benchmark filter- and wrapper-based methods in selecting features used to discover natural clusters, maximizing the between-cluster scatter and minimizing the within-cluster scatter toward a satisfactory clustering quality.
ER  - 

TY  - JOUR
T1  - Extracting easy to understand summary using differential evolution algorithm
JO  - Swarm and Evolutionary Computation
VL  - 16
IS  - 
SP  - 19
EP  - 27
PY  - 2014/6//
T2  - 
AU  - Nandhini, K.
AU  - Balasundaram, S.R.
SN  - 2210-6502
DO  - http://dx.doi.org/10.1016/j.swevo.2013.12.004
UR  - http://www.sciencedirect.com/science/article/pii/S2210650213000801
KW  - Extractive summarization
KW  - Differential evolution
KW  - Reading difficulties
KW  - Evolutionary computing
KW  - Combinatorial optimization
AB  - Abstract
This paper describes an optimization method based on differential evolution algorithm and its novel application to extract easy to understand summary for improving text readability. The idea is to improve the readability of the given text for reading difficulties using assistive summary. In order to extract easy to understand summary from the given text, an improved differential evolution algorithm is proposed. A new chromosome representation that considers ordering and similarity for extracting cohesive summary. Also a modified crossover operator and mutation operator are designed to generate potential offspring. The application of differential evolution algorithm for maximizing the average similarity and informative score in the candidate summary sentences is proposed. We applied the proposed algorithm in a corpus of educational text from ESL text books and in graded text. The results show that the summary generated using Differential Evolution algorithm performs better in accuracy, readability and lexical cohesion than existing techniques. The task based evaluation done by target audience also favors the significant effect of assistive summary in improving readability.
ER  - 

TY  - JOUR
T1  - Soft computing based imputation and hybrid data and text mining: The case of predicting the severity of phishing alerts
JO  - Expert Systems with Applications
VL  - 39
IS  - 12
SP  - 10583
EP  - 10589
PY  - 2012/9/15/
T2  - 
AU  - Nishanth, Kancherla Jonah
AU  - Ravi, Vadlamani
AU  - Ankaiah, Narravula
AU  - Bose, Indranil
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2012.02.138
UR  - http://www.sciencedirect.com/science/article/pii/S0957417412004010
KW  - Data imputation
KW  - K-means clustering
KW  - Multilayer perceptron
KW  - Phishing alerts
KW  - Probabilistic neural networks
KW  - Text mining
AB  - In this paper, we employ a novel two-stage soft computing approach for data imputation to assess the severity of phishing attacks. The imputation method involves K-means algorithm and multilayer perceptron (MLP) working in tandem. The hybrid is applied to replace the missing values of financial data which is used for predicting the severity of phishing attacks in financial firms. After imputing the missing values, we mine the financial data related to the firms along with the structured form of the textual data using multilayer perceptron (MLP), probabilistic neural network (PNN) and decision trees (DT) separately. Of particular significance is the overall classification accuracy of 81.80%, 82.58%, and 82.19% obtained using MLP, PNN, and DT respectively. It is observed that the present results outperform those of prior research. The overall classification accuracies for the three risk levels of phishing attacks using the classifiers MLP, PNN, and DT are also superior.
ER  - 

TY  - JOUR
T1  - Exploring online support spaces: Using cluster analysis to examine breast cancer, diabetes and fibromyalgia support groups
JO  - Patient Education and Counseling
VL  - 87
IS  - 2
SP  - 250
EP  - 257
PY  - 2012/5//
T2  - 
AU  - Chen, Annie T.
SN  - 0738-3991
DO  - http://dx.doi.org/10.1016/j.pec.2011.08.017
UR  - http://www.sciencedirect.com/science/article/pii/S073839911100468X
KW  - Support groups
KW  - Interface design
KW  - Cluster analysis
KW  - Fibromyalgia
KW  - Diabetes
KW  - Breast cancer
AB  - Objective
This study sought to characterize and compare online discussion forums for three conditions: breast cancer, type 1 diabetes and fibromyalgia. Though there has been considerable work examining online support groups, few studies have considered differences in discussion content between health conditions. In addition, in contrast to the extant literature, this study sought to employ a semi-automated approach to examine health-related online communities.
Methods
Online discussion content for the three conditions was compiled, pre-processed, and clustered at the thread level using the bisecting k-means algorithm.
Results
Though the clusters for each condition differed, the clusters fell into a set of common categories: Generic, Support, Patient-Centered, Experiential Knowledge, Treatments/Procedures, Medications, and Condition Management.
Conclusion
The cluster analyses facilitate an increased understanding of various aspects of patient experience, including significant emotional and temporal aspects of the illness experience.
Practice implications
The clusters highlighted the changing nature of patients’ information needs. Information provided to patients should be tailored to address their needs at various points during their illness. In addition, cluster analysis may be integrated into online support groups or other types of online interventions to assist patients in finding information.
ER  - 

TY  - JOUR
T1  - CloudExp: A comprehensive cloud computing experimental framework
JO  - Simulation Modelling Practice and Theory
VL  - 49
IS  - 
SP  - 180
EP  - 192
PY  - 2014/12//
T2  - 
AU  - Jararweh, Yaser
AU  - Jarrah, Moath
AU  - kharbutli, Mazen
AU  - Alshara, Zakarea
AU  - Alsaleh, Mohammed Noraden
AU  - Al-Ayyoub, Mahmoud
SN  - 1569-190X
DO  - http://dx.doi.org/10.1016/j.simpat.2014.09.003
UR  - http://www.sciencedirect.com/science/article/pii/S1569190X14001464
KW  - Cloud computing
KW  - Cloud computing modeling and simulation
KW  - CloudSim
KW  - Network topologies
KW  - MapReduce
KW  - SLA management
KW  - Rain workload generator
AB  - Abstract
Cloud computing is an emerging and fast-growing computing paradigm that has gained great interest from both industry and academia. Consequently, many researchers are actively involved in cloud computing research projects. One major challenge facing cloud computing researchers is the lack of a comprehensive cloud computing experimental tool to use in their studies. This paper introduces CloudExp, a modeling and simulation environment for cloud computing. CloudExp can be used to evaluate a wide spectrum of cloud components such as processing elements, data centers, storage, networking, Service Level Agreement (SLA) constraints, web-based applications, Service Oriented Architecture (SOA), virtualization, management and automation, and Business Process Management (BPM). Moreover, CloudExp introduces the Rain workload generator which emulates real workloads in cloud environments. Also, MapReduce processing model is integrated in CloudExp in order to handle the processing of big data problems.
ER  - 

TY  - JOUR
T1  - Multimedia search capabilities of Chinese language search engines
JO  - Information Processing & Management
VL  - 46
IS  - 3
SP  - 308
EP  - 319
PY  - 2010/5//
T2  - 
AU  - Chang, Yun-Ke
AU  - Morales-Arroyo, Miguel A.
AU  - Spink, Amanda
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2009.07.003
UR  - http://www.sciencedirect.com/science/article/pii/S0306457309000843
KW  - Search engine
KW  - Chinese language
KW  - Multimedia
KW  - MDS
AB  - This paper reports results from a study exploring the multimedia search functionality of Chinese language search engines. Web searching in Chinese (Mandarin) is a growing research area and a technical challenge for popular commercial Web search engines. Few studies have been conducted on Chinese language search engines. We investigate two research questions: which Chinese language search engines provide multimedia searching, and what multimedia search functionalities are available in Chinese language Web search engines. Specifically, we examine each Web search engine’s (1) features permitting Chinese language multimedia searches, (2) extent of search personalization and user control of multimedia search variables, and (3) the relationships between Web search engines and their features in the Chinese context. Key findings show that Chinese language Web search engines offer limited multimedia search functionality, and general search engines provide a wider range of features than specialized multimedia search engines. Study results have implications for Chinese Web users, Website designers and Web search engine developers.
ER  - 

TY  - JOUR
T1  - The diffusion of H-related literature
JO  - Journal of Informetrics
VL  - 5
IS  - 4
SP  - 583
EP  - 593
PY  - 2011/10//
T2  - 
AU  - Zhang, Lin
AU  - Thijs, Bart
AU  - Glänzel, Wolfgang
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2011.05.004
UR  - http://www.sciencedirect.com/science/article/pii/S1751157711000605
KW  - H-index
KW  - Knowledge diffusion
KW  - Clustering analysis
KW  - Core-documents
AB  - In the present study we attempt to trace the diffusion of h-related literature over a five-year period beginning with the introduction of the h-index. The study is based on a reliable and representative publication set of 755 papers retrieved from the Web of Science database using keywords and citation links. In the course of the study we analyse several aspects of the emergence of this topic, the differentiation of methodological research, its application within and outside the field and the dissemination process of information among different disciplines in the sciences and social sciences. Finally, a cluster analysis of h-related literature is conducted. The hybrid clustering algorithm results in four clusters, which depict two different aspects each of basic and applied research related to the h-index and its derivatives.
ER  - 

TY  - JOUR
T1  - Combining commercial citation indexes and open-access bibliographic databases to delimit highly interdisciplinary research fields for citation analysis
JO  - Journal of Informetrics
VL  - 4
IS  - 2
SP  - 194
EP  - 200
PY  - 2010/4//
T2  - The ASIS&amp;T–ISSI "metrics" pre-conference seminar and the Global Alliance
AU  - Strotmann, Andreas
AU  - Zhao, Dangzhi
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2009.12.001
UR  - http://www.sciencedirect.com/science/article/pii/S1751157709000972
KW  - Field delimitation
KW  - Citation analysis
KW  - Bibliometrics
KW  - Information science
KW  - Multiple databases
AB  - Field delimitation for citation analysis, the process of collecting a set of bibliographic records with cited-reference information of research articles that represent a research field, is the first step in any citation analysis study of a research field. Due to a number of limitations, the commercial citation indexes have long made it difficult to obtain a comprehensive dataset in this step. This paper discusses some of the limitations imposed by these databases, and reports on a method to overcome some of these limitations that was used with great success to delimit an emerging and highly interdisciplinary biomedical research field, stem cell research. The resulting field delimitation and the citation network it induces are both excellent. This multi-database method relies on using PubMed for the actual field delimitation, and on mapping between Scopus and PubMed records for obtaining comprehensive information about cited-references contained in the resulting literature. This method provides high-quality field delimitations for citation studies that can be used as benchmarks for studies of the impact of data collection biases on citation metrics, and may help improve confidence in results of scientometric studies for an increased impact of scientometrics on research policy.
ER  - 

TY  - JOUR
T1  - High-speed idea filtering with the bag of lemons
JO  - Decision Support Systems
VL  - 78
IS  - 
SP  - 39
EP  - 50
PY  - 2015/10//
T2  - 
AU  - Klein, Mark
AU  - Garcia, Ana Cristina Bicharra
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2015.06.005
UR  - http://www.sciencedirect.com/science/article/pii/S0167923615001190
KW  - Collective intelligence
KW  - Open innovation
KW  - Social computing
KW  - Idea filtering
AB  - Abstract
Open innovation platforms (web sites where crowds post ideas in a shared space) enable us to elicit huge volumes of potentially valuable solutions for problems we care about, but identifying the best ideas in these collections can be prohibitively expensive and time-consuming. This paper presents an approach, called the “bag of lemons”, which enables crowd to filter ideas with accuracy superior to conventional (Likert scale) rating approaches, but in only a fraction of the time. The key insight behind this approach is that crowds are much better at eliminating bad ideas than at identifying good ones.
ER  - 

TY  - JOUR
T1  - Smart Waste Collection System Based on Location Intelligence
JO  - Procedia Computer Science
VL  - 61
IS  - 
SP  - 120
EP  - 127
PY  - 2015///
T2  - Complex Adaptive Systems San Jose, CA November 2-4, 2015
AU  - Gutierrez, Jose M.
AU  - Jensen, Michael
AU  - Henius, Morten
AU  - Riaz, Tahir
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.09.170
UR  - http://www.sciencedirect.com/science/article/pii/S1877050915030008
KW  - Location Intelligence
KW  - Smart City
KW  - Internet of Things
KW  - Graph Optimization
KW  - Dynamic Logistic Management.
AB  - Abstract
Cities around the world are on the run to become smarter. Some of these have seen an opportunity on deploying dedicated municipal access networks to support all types of city management and maintenance services requiring a data connection. This paper practically demonstrates how Internet of Things (IoT) integration with data access networks, Geographic Information Systems (GIS), combinatorial optimization, and electronic engineering can contribute to improve cities’ management systems. We present a waste collection solution based on providing intelligence to trashcans, by using an IoT prototype embedded with sensors, which can read, collect, and transmit trash volume data over the Internet. This data put into a spatio-temporal context and processed by graph theory optimization algorithms can be used to dynamically and efficiently manage waste collection strategies. Experiments are carried out to investigate the benefits of such a system, in comparison to a traditional sectorial waste collection approaches, also including economic factors. A realistic scenario is set up by using Open Data from the city of Copenhagen, highlighting the opportunities created by this type of initiatives for third parties to contribute and develop Smart city solutions.
ER  - 

TY  - JOUR
T1  - A Novel Gaussian Based Similarity Measure for Clustering Customer Transactions Using Transaction Sequence Vector
JO  - Procedia Technology
VL  - 19
IS  - 
SP  - 880
EP  - 887
PY  - 2015///
T2  - 8th International Conference Interdisciplinarity in Engineering, INTER-ENG 2014, 9-10 October 2014, Tirgu Mures, Romania
AU  - Phridviraj, M.S.B.
AU  - RadhaKrishna, Vangipuram
AU  - Srinivas, Chintakindi
AU  - GuruRao, C.V.
SN  - 2212-0173
DO  - http://dx.doi.org/10.1016/j.protcy.2015.02.126
UR  - http://www.sciencedirect.com/science/article/pii/S2212017315001279
KW  - Transaction
KW  - Transaction Sequence vector
KW  - Transaction vector
KW  - feature distribution ;
AB  - Abstract
Clustering transactions in sequence databases, temporal databases, and time series databases is achieving an important attention from the database researchers. There is a significant research being carried towards defining and validating the suitability of new similarity measures for sequence databases, temporal databases, time series databases which can accurately and efficiently find the similarity between any two given user transactions in the database of transactions to predict the user behavior. The distribution of items present in the transactions contributes to a great extent in finding the degree of similarity between them. This forms the key idea for the design of the proposed similarity measure. The main objective of this research is to design similarity function to find similarity between two user transactions by defining two terms called transaction sequence vector and transaction vector and use them for defining the proposed measure. We then carry out the analysis for worst case, average case and best case situations. The Similarity measure designed is Gaussian based and preserves the properties of Gaussian function.
ER  - 

TY  - JOUR
T1  - Penalty Parameter Selection for Hierarchical Data Stream Clustering
JO  - Procedia Computer Science
VL  - 79
IS  - 
SP  - 24
EP  - 31
PY  - 2016///
T2  - Proceedings of International Conference on Communication, Computing and Virtualization (ICCCV) 2016
AU  - Bhagat, Amol
AU  - Kshirsagar, Nilesh
AU  - Khodke, Priti
AU  - Dongre, Kiran
AU  - Ali, Sadique
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2016.03.005
UR  - http://www.sciencedirect.com/science/article/pii/S1877050916001368
KW  - Clustering algorithms
KW  - data mining
KW  - data streams clustering
KW  - hierarchical clustering
KW  - penalty parameter selection
AB  - Abstract
Extracting useful information from large sets of data is the main task of data mining. Clustering is one of the most commonly used data mining technique. Data streams are sequences of data elements continuously generated at high rate from various sources. Data streams are everywhere and are generated by the applications like cell-phones, cars, security sensors, televisions and so on. Partitioning data streams into sets of meaningful subclasses is required for proper and efficient mining of intended data. Identifying the number of clusters required for the precise clustering of data streams is an open research area. This paper gives the overview of the hierarchical data stream clustering algorithms. It also compares the performance analysis of the different algorithms under hierarchical clustering techniques for data streams. Different data clustering tools are also explained and compared in this paper. It also applies the proper hierarchical clustering algorithm to the standard datasets taken as input and the expected result must be the clustered data which is well versed, properly arranged. This paper addresses the issue of identifying the number of clusters by proposed penalty parameter selection approach. The approaches presented in this paper are helpful for the researchers in the field of data stream clustering and data mining.
ER  - 

TY  - JOUR
T1  - Incorporating self-organizing map with text mining techniques for text hierarchy generation
JO  - Applied Soft Computing
VL  - 34
IS  - 
SP  - 251
EP  - 259
PY  - 2015/9//
T2  - 
AU  - Yang, Hsin-Chang
AU  - Lee, Chung-Hong
AU  - Hsiao, Han-Wei
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2015.05.005
UR  - http://www.sciencedirect.com/science/article/pii/S1568494615003051
KW  - Text mining
KW  - Self-organizing map
KW  - Topic identification
KW  - Hierarchy generation
AB  - Abstract
Self-organizing maps (SOM) have been applied on numerous data clustering and visualization tasks and received much attention on their success. One major shortage of classical SOM learning algorithm is the necessity of predefined map topology. Furthermore, hierarchical relationships among data are also difficult to be found. Several approaches have been devised to conquer these deficiencies. In this work, we propose a novel SOM learning algorithm which incorporates several text mining techniques in expanding the map both laterally and hierarchically. On training a set of text documents, the proposed algorithm will first cluster them using classical SOM algorithm. We then identify the topics of each cluster. These topics are then used to evaluate the criteria on expanding the map. The major characteristic of the proposed approach is to combine the learning process with text mining process and makes it suitable for automatic organization of text documents. We applied the algorithm on the Reuters-21578 dataset in text clustering and categorization tasks. Our method outperforms two comparing models in hierarchy quality according to users’ evaluation. It also receives better F1-scores than two other models in text categorization task.
ER  - 

TY  - JOUR
T1  - Multicriteria Decision Making Approach for Cluster Validation
JO  - Procedia Computer Science
VL  - 9
IS  - 
SP  - 1283
EP  - 1291
PY  - 2012///
T2  - Proceedings of the International Conference on Computational Science, ICCS 2012
AU  - Peng, Yi
AU  - Zhang, Yong
AU  - Kou, Gang
AU  - Li, Jun
AU  - Shi, Yong
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2012.04.140
UR  - http://www.sciencedirect.com/science/article/pii/S187705091200261X
KW  - clustering algorithm
KW  - cluster validation
KW  - multiple criteria decision making (MCDM)
AB  - This paper proposes a multiple criteria decision making (MCDM)-based framework to address two fundamental issues in cluster validation: 1) evaluation of clustering algorithms and 2) estimation of the optimal cluster number for a given data set. Since both issues involve more than one criterion, they can be modeled as multiple criteria decision making (MCDM) problems. The proposed framework is examined by an experimental study. The results suggest that MCDM methods are practical tools for the evaluation of clustering algorithms. In addition, the selected MCDM method, PROMETHEE II can estimate the optimal numbers of clusters for ten out of fifteen datasets by adjusting the weights of criteria.
ER  - 

TY  - JOUR
T1  - Effect of climate and seasonality on depressed mood among twitter users
JO  - Applied Geography
VL  - 63
IS  - 
SP  - 184
EP  - 191
PY  - 2015/9//
T2  - 
AU  - Yang, Wei
AU  - Mu, Lan
AU  - Shen, Ye
SN  - 0143-6228
DO  - http://dx.doi.org/10.1016/j.apgeog.2015.06.017
UR  - http://www.sciencedirect.com/science/article/pii/S0143622815001617
KW  - Climate
KW  - Depression
KW  - GIS
KW  - Seasonality
KW  - Social media
KW  - Twitter
AB  - Abstract
Location-based social media provide an enormous stream of data about humans' life and behavior. With geospatial methods, those data can offer rich insights into public health. In this research, we study the effect of climate and seasonality on the prevalence of depression in Twitter users in the U.S. Text mining and geospatial methods are used to detect tweets related to depression and their spatiotemporal patterns at the scale of Metropolitan Statistical Area. We find the relationship between depression rates, climate risk factors and seasonality are varied and geographically localized. The same climate measure may have opposite association with depression rates at different places. Relative humidity, temperature, sea level pressure, precipitation, snowfall, weed speed, globe solar radiation, and length of day all contribute to the geographic variations of depression rates. A conceptual compact map is designed to visualize scattered geographic phenomena in a large area. We also propose a three-stage framework that semi-automatically detects and analyzes geographically distributed health issues using location-based social media data.
ER  - 

TY  - JOUR
T1  - Multi-view clustering via spectral partitioning and local refinement
JO  - Information Processing & Management
VL  - 52
IS  - 4
SP  - 618
EP  - 627
PY  - 2016/7//
T2  - 
AU  - Chikhi, Nacim Fateh
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2015.12.007
UR  - http://www.sciencedirect.com/science/article/pii/S0306457315001442
KW  - Multi-view clustering
KW  - Spectral clustering
KW  - Local refinement
KW  - Normalized cuts
AB  - Abstract
Cluster analysis using multiple representations of data is known as multi-view clustering and has attracted much attention in recent years. The major drawback of existing multi-view algorithms is that their clustering performance depends heavily on hyperparameters which are difficult to set.

 In this paper, we propose the Multi-View Normalized Cuts (MVNC) approach, a two-step algorithm for multi-view clustering. In the first step, an initial partitioning is performed using a spectral technique. In the second step, a local search procedure is used to refine the initial clustering.

 MVNC has been evaluated and compared to state-of-the-art multi-view clustering approaches using three real-world datasets. Experimental results have shown that MVNC significantly outperforms existing algorithms in terms of clustering quality and computational efficiency. In addition to its superior performance, MVNC is parameter-free which makes it easy to use.
ER  - 

TY  - JOUR
T1  - Semi-supervised sparse feature selection based on multi-view Laplacian regularization
JO  - Image and Vision Computing
VL  - 41
IS  - 
SP  - 1
EP  - 10
PY  - 2015/9//
T2  - 
AU  - Shi, Caijuan
AU  - Ruan, Qiuqi
AU  - An, Gaoyun
AU  - Ge, Chao
SN  - 0262-8856
DO  - http://dx.doi.org/10.1016/j.imavis.2015.06.006
UR  - http://www.sciencedirect.com/science/article/pii/S0262885615000748
KW  - Multi-view learning
KW  - Laplacian regularization
KW  - Semi-supervised learning
KW  - Sparse feature selection
AB  - Abstract
Semi-supervised sparse feature selection, which can exploit the large number unlabeled data and small number labeled data simultaneously, has placed an important role in web image annotation. However, most of the semi-supervised sparse feature selection methods are developed for single-view data and these methods cannot naturally deal with the multi-view data, though it has shown that leveraging information contained in multiple views can dramatically improve the feature selection performance. Recently, multi-view learning has obtained much research attention because it can reveal and leverage the correlated and complementary information between different views. So in this paper, we apply multi-view learning into semi-supervised sparse feature selection and propose a semi-supervised sparse feature selection method based on multi-view Laplacian regularization, namely, multi-view Laplacian sparse feature selection (MLSFS).11
MLSFS: Multi-view Laplacian Sparse Feature Selection.
 MLSFS utilizes multi-view Laplacian regularization to boost semi-supervised sparse feature selection performance. A simple iterative method is proposed to solve the objective function of MLSFS. We apply MLSFS algorithm into image annotation task and conduct experiments on two web image datasets. The experimental results show that the proposed MLSFS outperforms the state-of-art single-view sparse feature selection methods.
ER  - 

TY  - JOUR
T1  - Generating synthetic test matrices as a benchmark for the computational behavior of typical testor-finding algorithms
JO  - Pattern Recognition Letters
VL  - 80
IS  - 
SP  - 46
EP  - 51
PY  - 2016/9/1/
T2  - 
AU  - Alba-Cabrera, Eduardo
AU  - Godoy-Calderon, Salvador
AU  - Ibarra-Fiallo, Julio
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2016.04.020
UR  - http://www.sciencedirect.com/science/article/pii/S0167865516300721
KW  - Feature selection
KW  - Testor theory
KW  - Typical testor algorithms
AB  - Abstract
Each typical testor-finding algorithm has a specific sensibility towards the number of rows, columns or typical testors within its input matrix. In this research a theoretical framework and a practical strategy for designing test matrices for typical testor-finding algorithms is presented. The core of the theoretical framework consists on a set of operators that allow the generation of basic matrices with controlled dimensions and for which the total number of typical testors is known in advance. After presenting the required theoretical foundation, and the logic for measuring a testor-finding algorithm’s computational behavior, the proposed strategy is used to assess the behavior of three well-known algorithms: BT, LEX, and FastCTExt. Unexpected behaviors, observed during the test experiments, are analyzed and discussed, revealing previously unknown characterizations of the tested algorithms that neither a complexity analysis, nor a random experimentation protocol could have revealed beforehand.
ER  - 

TY  - JOUR
T1  - Incorporating Text in Enterprise Information Systems
JO  - IFAC Proceedings Volumes
VL  - 46
IS  - 9
SP  - 590
EP  - 595
PY  - 2013///
T2  - 7th IFAC Conference on Manufacturing Modelling, Management, and Control
AU  - Wortmann, J.C. (“Hans”)
AU  - Ittoo, A.
SN  - 1474-6670
DO  - http://dx.doi.org/10.3182/20130619-3-RU-3018.00129
UR  - http://www.sciencedirect.com/science/article/pii/S1474667016343506
KW  - Enterprise Information Systems
KW  - ERP
KW  - Database Management Systems
KW  - Natural Language Processing
KW  - Text Miming
AB  - Abstract
Enterprise Information Systems (EIS), the core ICT backbone of organizations, are based on structured data, which are stored in relational databases. These databases may contain text fields as attributes of objects, but lack functionalities to analyze text data. As a result, the considerable amount of valuable texts that is contained in enterprise systems' database cannot be exploited to enrich corporate activities and processes. At the same time, Natural Language Processing (NLP) techniques have been developed to analyze texts from other sources, such as emails and social media. However, these techniques fail to leverage upon the high quality additional information that is inherent in the structure or schema of the EIS database in order to improve their performance. In this paper, we reconcile the seemingly dichotomous worlds of EIS and NLP. We posit that our approach allows to enrich and incorporate text in enterprise systems.
ER  - 

TY  - JOUR
T1  - Toward an enhanced Arabic text classification using cosine similarity and Latent Semantic Indexing
JO  - Journal of King Saud University - Computer and Information Sciences
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Al-Anzi, Fawaz S.
AU  - AbuZeina, Dia
SN  - 1319-1578
DO  - http://dx.doi.org/10.1016/j.jksuci.2016.04.001
UR  - http://www.sciencedirect.com/science/article/pii/S1319157816300210
KW  - Arabic text
KW  - Classification
KW  - Supervised learning
KW  - Cosine similarity
KW  - Latent Semantic Indexing
AB  - Abstract
Cosine similarity is one of the most popular distance measures in text classification problems. In this paper, we used this important measure to investigate the performance of Arabic language text classification. For textual features, vector space model (VSM) is generally used as a model to represent textual information as numerical vectors. However, Latent Semantic Indexing (LSI) is a better textual representation technique as it maintains semantic information between the words. Hence, we used the singular value decomposition (SVD) method to extract textual features based on LSI. In our experiments, we conducted comparison between some of the well-known classification methods such as Naïve Bayes, k-Nearest Neighbors, Neural Network, Random Forest, Support Vector Machine, and classification tree. We used a corpus that contains 4,000 documents of ten topics (400 document for each topic). The corpus contains 2,127,197 words with about 139,168 unique words. The testing set contains 400 documents, 40 documents for each topics. As a weighing scheme, we used Term Frequency.Inverse Document Frequency (TF.IDF). This study reveals that the classification methods that use LSI features significantly outperform the TF.IDF-based methods. It also reveals that k-Nearest Neighbors (based on cosine measure) and support vector machine are the best performing classifiers.
ER  - 

TY  - JOUR
T1  - Knowledge Based Summarization and Document Generation using Bayesian Network
JO  - Procedia Computer Science
VL  - 89
IS  - 
SP  - 333
EP  - 340
PY  - 2016///
T2  - Twelfth International Conference on Communication Networks, ICCN 2016, August 19– 21, 2016, Bangalore, India Twelfth International Conference on Data Mining and Warehousing, ICDMW 2016, August 19-21, 2016, Bangalore, India Twelfth International Conference on Image and Signal Processing, ICISP 2016, August 19-21, 2016, Bangalore, India
		
AU  - Malviya, Shrikant
AU  - Tiwary, Uma Shanker
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2016.06.080
UR  - http://www.sciencedirect.com/science/article/pii/S1877050916311450
KW  - Bayesian Network
KW  - Extractive Summarization
KW  - Information Retrieval
KW  - Multi Document Summarization (MDS)
KW  - Semantic Knowledge
KW  - Text Classification.
AB  - Abstract
In this paper an approach of Semantic Knowledge Extraction (SKE), from a set of research papers, is proposed to develop a system Summarized Research Article Generator (SRAG) which would generate a summarized research article based on the query given by a user. The SRAG stores the semantic knowledge extracted from the query relevant papers in the form of a semantic tree. Semantic Tree stores all the textual units with their score in nodes organized at different levels depending on their type such as at the bottom leaf nodes keep the words with its probability, the upper level of it represent sentences with its score, next to it paragraphs, segments and so on. Scores of all the entities are calculated in bottom to up manner, first score of words are calculated, based on words sentences are ranked and similarly all the higher levels of the knowledge tree would be scored. A method of Bayesian network is used to generate a probabilistic model which would extract the relevant information from the knowledge tree to generate a summarized article. To maintain coherency, the summarized document is generated segment-wise by combining the most relevant paragraphs. Abstract of a generated summary is shown as a sample result. To show the effectiveness of the algorithm, an intrinsic evaluation strategy, degree of representativeness (DOG) is used. DOG gives on average 50% of relevance of the summary with the source. It's been observed that the proposed approach generates a comprehensive and precise papers.
ER  - 

TY  - JOUR
T1  - Density-based geodesic distance for identifying the noisy and nonlinear clusters
JO  - Information Sciences
VL  - 360
IS  - 
SP  - 231
EP  - 243
PY  - 2016/9/10/
T2  - 
AU  - Yu, Jaehong
AU  - Kim, Seoung Bum
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2016.04.032
UR  - http://www.sciencedirect.com/science/article/pii/S002002551630281X
KW  - Geodesic distance
KW  - Mutual neighborhood-based density coefficient
KW  - Noisy data clustering
KW  - Nonlinearity
AB  - Abstract
Clustering analysis can facilitate the extraction of implicit patterns in a dataset and elicit its natural groupings without requiring prior classification information. For superior clustering analysis results, a number of distance measures have been proposed. Recently, geodesic distance has been widely applied to clustering algorithms for nonlinear groupings. However, geodesic distance is sensitive to noise and hence, geodesic distance-based clustering may fail to discover nonlinear clusters in the region of the noise. In this study, we propose a density-based geodesic distance that can identify clusters in nonlinear and noisy situations. Experiments on various simulation and benchmark datasets are conducted to examine the properties of the proposed geodesic distance and to compare its performance with that of existing distance measures. The experimental results confirm that a clustering algorithm with the proposed distance measure demonstrated superior performance compared to the competitors; this was especially true when the cluster structures in the data were inherently noisy and nonlinearly patterned.
ER  - 

TY  - JOUR
T1  - Literature-related discovery and innovation: Chronic kidney disease
JO  - Technological Forecasting and Social Change
VL  - 91
IS  - 
SP  - 341
EP  - 351
PY  - 2015/2//
T2  - 
AU  - Kostoff, Ronald N.
AU  - Patel, Uptal
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2014.09.013
UR  - http://www.sciencedirect.com/science/article/pii/S0040162514002832
KW  - Text mining
KW  - Literature-related discovery
KW  - Information technology
KW  - Chronic kidney disease
KW  - Chronic renal insufficiency
KW  - Chronic renal failure
KW  - CKD causes
KW  - CKD treatments
KW  - CKD prevention
AB  - Abstract
Different approaches for preventing, reducing, halting, and reversing chronic kidney disease (CKD) have been described in the medical literature. However, all related factors have not been identified together. To overcome these limitations, we used an LRDI-based methodology (potentially applicable to any disease) based on the following holistic principle: a necessary, but not sufficient, condition for restorative treatment effectiveness is that potential causes must be removed initially or in parallel with treatment. Literature-Related Discovery and Innovation (LRDI) is a text mining approach that integrates discovery generation from disparate literatures with the wealth of knowledge contained in prior scientific publications. To support the central requirement of the holistic principle above, LRDI seeks to identify foundational causes that, if eliminated, could potentially reverse chronic and infectious diseases.

The LRDI findings would be implemented in three steps by: 1) identifying major symptoms of CKD, 2) identifying and removing foundational causes that drive the symptoms identified, then 3) identifying treatment(s) to reduce, halt, or reverse the progression of CKD and eliminate the remaining symptoms and damage caused by CKD (if not irreversible). We presumed that identifying and eliminating all of the foundational causes as comprehensively, thoroughly, and rapidly as possible may potentially achieve the desired medical goals and obviate the need for any pharmacologic treatments in selected patients. If treatments are required, eliminating the wide spectrum of potential causes identified in this study should enhance their effectiveness.

There were two major types of advances made in this study: information technology and medical. The major information technology advance was development of a query to identify the full-spectrum of foundational causes for CKD, and substantially upgrading a query used previously to identify the full spectrum of treatments. The major medical advance was identification of over 900 potential CKD direct and indirect foundational causes that encompass discovery and innovation, along with over 900 CKD direct and indirect treatments that encompass discovery and innovation. The foundational causes were comprised of environmental and occupational exposures, biotoxins, iatrogenic, and lifestyle factors. The myriad treatments ranged from foods, food extracts, drugs, biological, biophysical, and lifestyle changes. A limitation of the LRDI method is that the magnitude of these associations cannot be determined. Nonetheless, after prioritizing potentially relevant factors, eliminating as many upstream or foundational causes as possible may provide benefits to patients with CKD beyond the current emphasis on downstream pharmacologic approaches.
ER  - 

TY  - JOUR
T1  - Analysis of multi-dimensional contemporaneous EHR data to refine delirium assessments
JO  - Computers in Biology and Medicine
VL  - 75
IS  - 
SP  - 267
EP  - 274
PY  - 2016/8/1/
T2  - 
AU  - Corradi, John P.
AU  - Chhabra, Jyoti
AU  - Mather, Jeffrey F.
AU  - Waszynski, Christine M.
AU  - Dicks, Robert S.
SN  - 0010-4825
DO  - http://dx.doi.org/10.1016/j.compbiomed.2016.06.013
UR  - http://www.sciencedirect.com/science/article/pii/S0010482516301512
KW  - Clustering
KW  - Controlled vocabulary
KW  - Delirium
KW  - Unable-to-assess
KW  - Patient outcomes
KW  - Electronic health records
AB  - Abstract
Delirium is a potentially lethal condition of altered mental status, attention, and level of consciousness with an acute onset and fluctuating course. Its causes are multi-factorial, and its pathophysiology is not well understood; therefore clinical focus has been on prevention strategies and early detection. One patient evaluation technique in routine use is the Confusion Assessment Method (CAM): a relatively simple test resulting in 'positive’, ‘negative’ or ‘unable-to-assess’ (UTA) ratings. Hartford Hospital nursing staff use the CAM regularly on all non-critical care units, and a high frequency of UTA was observed after reviewing several years of records. In addition, patients with UTA ratings displayed poor outcomes such as in-hospital mortality, longer lengths of stay, and discharge to acute and long term care facilities. We sought to better understand the use of UTA, especially outside of critical care environments, in order to improve delirium detection throughout the hospital. An unsupervised clustering approach was used with additional, concurrent assessment data available in the EHR to categorize patient visits with UTA CAMs. The results yielded insights into the most common situations in which the UTA rating was used (e.g. impaired verbal communication, dementia), suggesting potentially inappropriate ratings that could be refined with further evaluation and remedied with updated clinical training. Analysis of the patient clusters also suggested that unrecognized delirium may contribute to the poor outcomes associated with the use of UTA. This method of using temporally related high dimensional EHR data to illuminate a dynamic medical condition could have wider applicability.
ER  - 

TY  - JOUR
T1  - Class-driven concept factorization for image representation
JO  - Neurocomputing
VL  - 190
IS  - 
SP  - 197
EP  - 208
PY  - 2016/5/19/
T2  - 
AU  - Li, Huirong
AU  - Zhang, Jiangshe
AU  - Liu, Junmin
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2016.01.017
UR  - http://www.sciencedirect.com/science/article/pii/S0925231216000643
KW  - Concept factorization
KW  - Semi-supervised learning
KW  - Label information
KW  - Class-driven constraint
AB  - Abstract
Recently, concept factorization (CF), which is a variant of nonnegative matrix factorization, has attracted great attentions in image representation. In CF, each concept is modeled as a nonnegative linear combination of the data points, and each data point as a linear combination of the concepts. CF has impressive performances in data representation. However, it is an unsupervised learning method without considering the label information of the data points. In this paper, we propose a novel semi-supervised CF method, called class-driven concept factorization (CDCF), which associates the class labels of data points with their representations by introducing a class-driven constraint. This constraint forces the representations of data points to be more similar within the same class while different between classes. Thus, the discriminative abilities of the representations are enhanced in the image representation. Experimental results on several databases have shown the effectiveness of our proposed method in terms of clustering accuracy and mutual information.
ER  - 

TY  - JOUR
T1  - Graph clustering using k-Neighbourhood Attribute Structural similarity
JO  - Applied Soft Computing
VL  - 47
IS  - 
SP  - 216
EP  - 223
PY  - 2016/10//
T2  - 
AU  - Boobalan, M. Parimala
AU  - Lopez, Daphne
AU  - Gao, X.Z.
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2016.05.028
UR  - http://www.sciencedirect.com/science/article/pii/S1568494616302381
KW  - Clustering
KW  - graph
KW  - k-Neighbourhood
KW  - Structural
KW  - Attribute similarity
AB  - Abstract
A simple and novel approach to identify the clusters based on structural and attribute similarity in graph network is proposed which is a fundamental task in community detection. We identify the dense nodes using Local Outlier Factor (LOF) approach that measures the degree of outlierness, forms a basic intuition for generating the initial core nodes for the clusters. Structural Similarity is identified using k-neighbourhood and Attribute similarity is estimated through Similarity Score among the nodes in the group of structural clusters. An objective function is defined to have quick convergence in the proposed algorithm. Through extensive experiments on dataset (DBLP) with varying sizes, we demonstrate the effectiveness and efficiency of our proposed algorithm k-Neighbourhood Attribute Structural (kNAS) over state-of-the-art methods which attempt to partition the graph based on structural and attribute similarity in field of community detection. Additionally, we find the qualitative and quantitative benefit of combining both the similarities in graph.
ER  - 

TY  - JOUR
T1  - Improving the utility of MeSH® terms using the TopicalMeSH representation
JO  - Journal of Biomedical Informatics
VL  - 61
IS  - 
SP  - 77
EP  - 86
PY  - 2016/6//
T2  - 
AU  - Yu, Zhiguo
AU  - Bernstam, Elmer
AU  - Cohen, Trevor
AU  - Wallace, Byron C.
AU  - Johnson, Todd R.
SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2016.03.013
UR  - http://www.sciencedirect.com/science/article/pii/S1532046416300041
KW  - Topic models
KW  - MeSH
KW  - PubMed
KW  - Document retrieval
KW  - Document classification
AB  - AbstractObjective
To evaluate whether vector representations encoding latent topic proportions that capture similarities to MeSH terms can improve performance on biomedical document retrieval and classification tasks, compared to using MeSH terms.
Materials and methods
We developed the TopicalMeSH representation, which exploits the ‘correspondence’ between topics generated using latent Dirichlet allocation (LDA) and MeSH terms to create new document representations that combine MeSH terms and latent topic vectors. We used 15 systematic drug review corpora to evaluate performance on information retrieval and classification tasks using this TopicalMeSH representation, compared to using standard encodings that rely on either (1) the original MeSH terms, (2) the text, or (3) their combination. For the document retrieval task, we compared the precision and recall achieved by ranking citations using MeSH and TopicalMeSH representations, respectively. For the classification task, we considered three supervised machine learning approaches, Support Vector Machines (SVMs), logistic regression, and decision trees. We used these to classify documents as relevant or irrelevant using (independently) MeSH, TopicalMeSH, Words (i.e., n-grams extracted from citation titles and abstracts, encoded via bag-of-words representation), a combination of MeSH and Words, and a combination of TopicalMeSH and Words. We also used SVM to compare the classification performance of tf-idf weighted MeSH terms, LDA Topics, a combination of Topics and MeSH, and TopicalMeSH to supervised LDA’s classification performance.
Results
For the document retrieval task, using the TopicalMeSH representation resulted in higher precision than MeSH in 11 of 15 corpora while achieving the same recall. For the classification task, use of TopicalMeSH features realized a higher F1 score in 14 of 15 corpora when used by SVMs, 12 of 15 corpora using logistic regression, and 12 of 15 corpora using decision trees. TopicalMeSH also had better document classification performance on 12 of 15 corpora when compared to Topics, tf-idf weighted MeSH terms, and a combination of Topics and MeSH using SVMs. Supervised LDA achieved the worst performance in most of the corpora.
Conclusion
The proposed TopicalMeSH representation (which combines MeSH terms with latent topics) consistently improved performance on document retrieval and classification tasks, compared to using alternative standard representations using MeSH terms alone, as well as, several standard alternative approaches.
ER  - 

TY  - JOUR
T1  - Evaluating information retrieval using document popularity: An implementation on MapReduce
JO  - Engineering Applications of Artificial Intelligence
VL  - 51
IS  - 
SP  - 16
EP  - 23
PY  - 2016/5//
T2  - Mining the Humanities: Technologies and Applications
AU  - Evangelopoulos, Xenophon
AU  - Giannakouris-Salalidis, Victor
AU  - Iliadis, Lazaros
AU  - Makris, Christos
AU  - Plegas, Yannis
AU  - Plerou, Antonia
AU  - Sioutas, Spyros
SN  - 0952-1976
DO  - http://dx.doi.org/10.1016/j.engappai.2016.01.023
UR  - http://www.sciencedirect.com/science/article/pii/S0952197616000270
KW  - Information retrieval
KW  - Evaluation
KW  - Metrics
KW  - User behaviour
KW  - MapReduce
KW  - Cosine similarity
AB  - Abstract
Over the last few years, one major research direction of information retrieval includes user behaviour prediction. For that reason many models have been proposed aiming at the accurate evaluation of information retrieval systems and the best prediction of web search users׳ behaviour. In this paper we propose a new evaluation metric for information retrieval systems which employs two relevance factors; a relevance judgement grade and a popularity grade that represents users׳ vote for a document. We show that this new metric performs better than other evaluation metrics when expressing user behaviour. Moreover, in order to test the performance of our metric on different and scalable ranking algorithms, we develop a pairwise text similarity algorithm using cosine similarity, implemented on the MapReduce model, and then perform experiments on rankings generated by the algorithm.
ER  - 

TY  - JOUR
T1  - Editorial Board
JO  - Journal of Informetrics
VL  - 5
IS  - 3
SP  - CO2
EP  - 
PY  - 2011/7//
T2  - 

SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/S1751-1577(11)00054-X
UR  - http://www.sciencedirect.com/science/article/pii/S175115771100054X
ER  - 

TY  - JOUR
T1  - Cultivating Life-Long Learning Skills in Undergraduate Students through the Collaborative Creation of Digital Knowledge Maps
JO  - Procedia - Social and Behavioral Sciences
VL  - 69
IS  - 
SP  - 847
EP  - 853
PY  - 2012/12/24/
T2  - International Conference on Education &amp; Educational Psychology (ICEEPSY 2012)
AU  - Hanewald, Ria
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2012.12.007
UR  - http://www.sciencedirect.com/science/article/pii/S1877042812054675
KW  - Digital knowledge maps
KW  - undergraduates
KW  - collaborative learning
KW  - life-long learning skills
AB  - This study was conducted during 2011 at an Australia university with a cohort of 93 undergraduate science communication students. Students worked in small groups of three or four to develop their knowledge in Biotechnology, Genetics,.Virology and Ecology by constructing digital knowledge maps, which are visual representations that show ‘at-ag-lance’ the key ideas and their connections of any given topic. Their construction necessitates subject matter knowledge and conceptual understanding, with students required to use analytical, provlem solving, negotiation, communication and team working skills. Findings indicate that the open-ended nature of the mapping activity gave students great control and ownership while cultivating life-long learning skills.
ER  - 

TY  - JOUR
T1  - Pairwise constrained concept factorization for data representation
JO  - Neural Networks
VL  - 52
IS  - 
SP  - 1
EP  - 17
PY  - 2014/4//
T2  - 
AU  - He, Yangcheng
AU  - Lu, Hongtao
AU  - Huang, Lei
AU  - Xie, Saining
SN  - 0893-6080
DO  - http://dx.doi.org/10.1016/j.neunet.2013.12.007
UR  - http://www.sciencedirect.com/science/article/pii/S0893608013003122
KW  - Concept factorization
KW  - Clustering
KW  - Pairwise constraints
KW  - Data representation
AB  - Abstract
Concept factorization (CF) is a variant of non-negative matrix factorization (NMF). In CF, each concept is represented by a linear combination of data points, and each data point is represented by a linear combination of concepts. More specifically, each concept is represented by more than one data point with different weights, and each data point carries various weights called membership to represent their degrees belonging to that concept. However, CF is actually an unsupervised method without making use of prior information of the data. In this paper, we propose a novel semi-supervised concept factorization method, called Pairwise Constrained Concept Factorization (PCCF), which incorporates pairwise constraints into the CF framework. We expect that data points which have pairwise must-link constraints should have the same class label as much as possible, while data points with pairwise cannot-link constraints will have different class labels as much as possible. Due to the incorporation of the pairwise constraints, the learning quality of the CF has been significantly enhanced. Experimental results show the effectiveness of our proposed novel method in comparison to the state-of-the-art algorithms on several real world applications.
ER  - 

TY  - JOUR
T1  - A fuzzy anomaly detection system based on hybrid PSO-Kmeans algorithm in content-centric networks
JO  - Neurocomputing
VL  - 149, Part C
IS  - 
SP  - 1253
EP  - 1269
PY  - 2015/2/3/
T2  - 
AU  - Karami, Amin
AU  - Guerrero-Zapata, Manel
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2014.08.070
UR  - http://www.sciencedirect.com/science/article/pii/S0925231214011588
KW  - Content-centric networks
KW  - Anomaly detection
KW  - Particle swarm optimization
KW  - K-means
KW  - Clustering analysis
KW  - Fuzzy set
AB  - Abstract
In Content-Centric Networks (CCNs) as a possible future Internet, new kinds of attacks and security challenges – from Denial of Service (DoS) to privacy attacks – will arise. An efficient and effective security mechanism is required to secure content and defense against unknown and new forms of attacks and anomalies. Usually, clustering algorithms would fit the requirements for building a good anomaly detection system. K-means is a popular anomaly detection method to classify data into different categories. However, it suffers from the local convergence and sensitivity to selection of the cluster centroids. In this paper, we present a novel fuzzy anomaly detection system that works in two phases. In the first phase – the training phase – we propose an hybridization of Particle Swarm Optimization (PSO) and K-means algorithm with two simultaneous cost functions as well-separated clusters and local optimization to determine the optimal number of clusters. When the optimal placement of clusters centroids and objects are defined, it starts the second phase. In this phase – the detection phase – we employ a fuzzy approach by the combination of two distance-based methods as classification and outlier to detect anomalies in new monitoring data. Experimental results demonstrate that the proposed algorithm can achieve to the optimal number of clusters, well-separated clusters, as well as increase the high detection rate and decrease the false positive rate at the same time when compared to some other well-known clustering algorithms.
ER  - 

TY  - JOUR
T1  - OClustR: A new graph-based algorithm for overlapping clustering
JO  - Neurocomputing
VL  - 121
IS  - 
SP  - 234
EP  - 247
PY  - 2013/12/9/
T2  - Advances in Artificial Neural Networks and Machine LearningSelected papers from the 2011 International Work Conference on Artificial Neural Networks (IWANN 2011)
AU  - Pérez-Suárez, Airel
AU  - Martínez-Trinidad, José F.
AU  - Carrasco-Ochoa, Jesús A.
AU  - Medina-Pagola, José E.
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2013.04.025
UR  - http://www.sciencedirect.com/science/article/pii/S0925231213005432
KW  - Data mining
KW  - Overlapping clustering
KW  - Graph-based algorithms
AB  - Abstract
Clustering is a Data Mining technique, which has been widely used in many practical applications. From these applications, there are some, like social network analysis, topic detection and tracking, information retrieval, categorization of digital libraries, among others, where objects may belong to more than one cluster; however, most clustering algorithms build disjoint clusters. In this work, we introduce OClustR, a new graph-based clustering algorithm for building overlapping clusters. The proposed algorithm introduces a new graph-covering strategy and a new filtering strategy, which together allow to build overlapping clusterings more accurately than those built by previous algorithms. The experimental evaluation, conducted over several standard collections, showed that our proposed algorithm builds less clusters than those built by the previous related algorithms. Additionally, OClustR builds clusters with overlapping closer to the real overlapping in the collections than the overlapping generated by other clustering algorithms.
ER  - 

TY  - JOUR
T1  - An ontology based text mining system for knowledge discovery from the diagnosis data in the automotive domain
JO  - Computers in Industry
VL  - 64
IS  - 5
SP  - 565
EP  - 580
PY  - 2013/6//
T2  - 
AU  - Rajpathak, Dnyanesh G.
SN  - 0166-3615
DO  - http://dx.doi.org/10.1016/j.compind.2013.03.001
UR  - http://www.sciencedirect.com/science/article/pii/S0166361513000456
KW  - Text mining
KW  - Clustering
KW  - Fault diagnosis
KW  - Ontology
KW  - Automotive
AB  - Abstract
In automotive domain, overwhelming volume of textual data is recorded in the form of repair verbatim collected during the fault diagnosis (FD) process. Here, the aim of knowledge discovery using text mining (KDT) task is to discover the best-practice repair knowledge from millions of repair verbatim enabling accurate FD. However, the complexity of KDT problem is largely due to the fact that a significant amount of relevant knowledge is buried in noisy and unstructured verbatim. In this paper, we propose a novel ontology-based text mining system, which uses the diagnosis ontology for annotating key terms recorded in the repair verbatim. The annotated terms are extracted in different tuples, which are used to identify the field anomalies. The extracted tuples are further used by the frequently co-occurring clustering algorithm to cluster the repair verbatim data such that the best-practice repair actions used to fix commonly observed symptoms associated with the faulty parts can be discovered. The performance of our system has been validated by using the real world data and it has been successfully implemented in a web based distributed architecture in real life industry.
ER  - 

TY  - JOUR
T1  - Design patterns selection: An automatic two-phase method
JO  - Journal of Systems and Software
VL  - 85
IS  - 2
SP  - 408
EP  - 424
PY  - 2012/2//
T2  - Special issue with selected papers from the 23rd Brazilian Symposium on Software Engineering
AU  - Hasheminejad, Seyed Mohammad Hossein
AU  - Jalili, Saeed
SN  - 0164-1212
DO  - http://dx.doi.org/10.1016/j.jss.2011.08.031
UR  - http://www.sciencedirect.com/science/article/pii/S0164121211002317
KW  - Software design pattern
KW  - Text classification
KW  - Machine learning
KW  - Automatic pattern selection
AB  - Over many years of research and practices in software development, hundreds of software design patterns have been invented and published. Now, a question which naturally arises is how software developers select the right design patterns from all relevant patterns to solve design problems in the software design phase. To address this issue, in this paper, we propose a two-phase method to select a right design pattern. The proposed method is based on a text classification approach that aims to show an appropriate way to suggest the right design pattern(s) to developers for solving each given design problem. There are two advantages of the proposed method in comparison to previous works. First, there is no need for semi-formal specifications of design patterns and second, the suitable design patterns are suggested with their degree of similarity to the design problem. To evaluate the proposed method, we apply it on real problems and several case studies. The experimental results show that the proposed method is promising and effective.
ER  - 

TY  - JOUR
T1  - Approximate TF–IDF based on topic extraction from massive message stream using the GPU
JO  - Information Sciences
VL  - 292
IS  - 
SP  - 143
EP  - 161
PY  - 2015/1/20/
T2  - 
AU  - Erra, Ugo
AU  - Senatore, Sabrina
AU  - Minnella, Fernando
AU  - Caggianese, Giuseppe
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2014.08.062
UR  - http://www.sciencedirect.com/science/article/pii/S0020025514008676
KW  - Twitter
KW  - TF–IDF
KW  - GPU
KW  - Topic extraction
KW  - Frequent items
KW  - Massive data stream
AB  - Abstract
The Web is a constantly expanding global information space that includes disparate types of data and resources. Recent trends demonstrate the urgent need to manage the large amounts of data stream, especially in specific domains of application such as critical infrastructure systems, sensor networks, log file analysis, search engines and more recently, social networks. All of these applications involve large-scale data-intensive tasks, often subject to time constraints and space complexity. Algorithms, data management and data retrieval techniques must be able to process data stream, i.e., process data as it becomes available and provide an accurate response, based solely on the data stream that has already been provided. Data retrieval techniques often require traditional data storage and processing approach, i.e., all data must be available in the storage space in order to be processed. For instance, a widely used relevance measure is Term Frequency–Inverse Document Frequency (TF–IDF), which can evaluate how important a word is in a collection of documents and requires to a priori know the whole dataset.

To address this problem, we propose an approximate version of the TF–IDF measure suitable to work on continuous data stream (such as the exchange of messages, tweets and sensor-based log files). The algorithm for the calculation of this measure makes two assumptions: a fast response is required, and memory is both limited and infinitely smaller than the size of the data stream. In addition, to face the great computational power required to process massive data stream, we present also a parallel implementation of the approximate TF–IDF calculation using Graphical Processing Units (GPUs).

This implementation of the algorithm was tested on generated and real data stream and was able to capture the most frequent terms. Our results demonstrate that the approximate version of the TF–IDF measure performs at a level that is comparable to the solution of the precise TF–IDF measure.
ER  - 

TY  - JOUR
T1  - A coarse-to-fine framework to efficiently thwart plagiarism
JO  - Pattern Recognition
VL  - 44
IS  - 2
SP  - 471
EP  - 487
PY  - 2011/2//
T2  - 
AU  - Zhang, Haijun
AU  - Chow, Tommy W.S.
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2010.08.023
UR  - http://www.sciencedirect.com/science/article/pii/S0031320310004097
KW  - Document retrieval
KW  - Plagiarism detection
KW  - EMD
KW  - Multilevel matching
AB  - This paper presents a systematic framework using multilevel matching approach for plagiarism detection (PD). A multilevel structure, i.e. document–paragraph–sentence, is used to represent each document. In document and paragraph level, we use traditional dimensionality reduction technique to project high dimensional histograms into latent semantic space. The Earth Mover’s Distance (EMD), instead of exhaustive matching, is employed to retrieve relevant documents, which enables us to markedly shrink the searching domain. Two PD algorithms are designed and implemented to efficiently flag the suspected plagiarized document sources. We conduct extensive experimental verifications including document retrieval, PD, the study of the effects of parameters, and the empirical study of the system response. The results corroborate that the proposed approach is accurate and computationally efficient for performing PD.
ER  - 

TY  - JOUR
T1  - Data clustering: 50 years beyond K-means
JO  - Pattern Recognition Letters
VL  - 31
IS  - 8
SP  - 651
EP  - 666
PY  - 2010/6/1/
T2  - Award winning papers from the 19th International Conference on Pattern Recognition (ICPR)19th International Conference in Pattern Recognition (ICPR)
AU  - Jain, Anil K.
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2009.09.011
UR  - http://www.sciencedirect.com/science/article/pii/S0167865509002323
KW  - Data clustering
KW  - User’s dilemma
KW  - Historical developments
KW  - Perspectives on clustering
KW  - King-Sun Fu prize
AB  - Organizing data into sensible groupings is one of the most fundamental modes of understanding and learning. As an example, a common scheme of scientific classification puts organisms into a system of ranked taxa: domain, kingdom, phylum, class, etc. Cluster analysis is the formal study of methods and algorithms for grouping, or clustering, objects according to measured or perceived intrinsic characteristics or similarity. Cluster analysis does not use category labels that tag objects with prior identifiers, i.e., class labels. The absence of category information distinguishes data clustering (unsupervised learning) from classification or discriminant analysis (supervised learning). The aim of clustering is to find structure in data and is therefore exploratory in nature. Clustering has a long and rich history in a variety of scientific fields. One of the most popular and simple clustering algorithms, K-means, was first published in 1955. In spite of the fact that K-means was proposed over 50 years ago and thousands of clustering algorithms have been published since then, K-means is still widely used. This speaks to the difficulty in designing a general purpose clustering algorithm and the ill-posed problem of clustering. We provide a brief overview of clustering, summarize well known clustering methods, discuss the major challenges and key issues in designing clustering algorithms, and point out some of the emerging and useful research directions, including semi-supervised clustering, ensemble clustering, simultaneous feature selection during data clustering, and large scale data clustering.
ER  - 

TY  - JOUR
T1  - An algorithm based on density and compactness for dynamic overlapping clustering
JO  - Pattern Recognition
VL  - 46
IS  - 11
SP  - 3040
EP  - 3055
PY  - 2013/11//
T2  - 
AU  - Pérez-Suárez, Airel
AU  - Martínez-Trinidad, José Fco.
AU  - Carrasco-Ochoa, Jesús A.
AU  - Medina-Pagola, José E.
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2013.03.022
UR  - http://www.sciencedirect.com/science/article/pii/S0031320313001519
KW  - Data mining
KW  - Clustering
KW  - Overlapping clustering algorithms
KW  - Dynamic clustering algorithms
AB  - Abstract
Most clustering algorithms organize a collection of objects into a set of disjoint clusters. Although this approach has been successfully applied in unsupervised learning, there are several applications where objects could belong to more than one cluster. Overlapping clustering is an alternative in those contexts like social network analysis, information retrieval and bioinformatics, among other problems where non-disjoint clusters appear. In addition, there are environments where the collection changes frequently and the clustering must be updated; however, most of the existing overlapping clustering algorithms are not able to efficiently update the clustering. In this paper, we introduce a new overlapping clustering algorithm, called DClustR, which is based on the graph theory approach and it introduces a new strategy for building more accurate overlapping clusters than those built by state-of-the-art algorithms. Moreover, our algorithm introduces a new strategy for efficiently updating the clustering when the collection changes. The experimentation conducted over several standard collections shows the good performance of the proposed algorithm, wrt. accuracy and efficiency.
ER  - 

TY  - JOUR
T1  - Concept comparison engines: A new frontier of search
JO  - Decision Support Systems
VL  - 54
IS  - 2
SP  - 904
EP  - 918
PY  - 2013/1//
T2  - 
AU  - Abrahams, Alan S.
AU  - Barkhi, Reza
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2012.09.014
UR  - http://www.sciencedirect.com/science/article/pii/S0167923612002497
KW  - Preferential choice
KW  - Search engine
KW  - Text mining
AB  - In a traditional search engine interaction scenario, a user begins with a certain concept and finds documents that are similar to their concept. However, the user may wish to compare alternatives and a search capability should compare concepts and present the best alternatives. This task can be difficult without proper decision aids. We propose a concept comparison engine as a decision support tool that may be used to compare attributes of different alternatives and aid in making an informed selection. We describe an architecture and an interaction scenario and implement a prototype. We propose a number of evaluation metrics for measuring the viability of different terms for the purpose of comparing concepts. In scripted experiments, orderings for candidate terms from the prototype are compared to gold standard ranking lists from structured external sources. Our results indicate that a Rankor analysis may be promising as a measure of the differentiating power of candidate terms a user might choose to support concept comparison.
ER  - 

TY  - JOUR
T1  - Graph modularity maximization as an effective method for co-clustering text data
JO  - Knowledge-Based Systems
VL  - 109
IS  - 
SP  - 160
EP  - 173
PY  - 2016/10/1/
T2  - 
AU  - Ailem, Melissa
AU  - Role, François
AU  - Nadif, Mohamed
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2016.07.002
UR  - http://www.sciencedirect.com/science/article/pii/S0950705116302064
KW  - Co-clustering
KW  - Modularity
AB  - Abstract
In this paper we show how the modularity measure can serve as a useful criterion for co-clustering document-term matrices. We present and investigate the performance of CoClus, a novel, effective block-diagonal co-clustering algorithm which directly maximizes this modularity measure. The maximization is performed using an iterative alternating optimization procedure, in contrast to algorithms that use spectral relaxations of the discrete optimization problems. Extensive comparative experiments performed on various document-term datasets demonstrate that this approach is very effective, stable, and outperforms other block-diagonal co-clustering algorithms devoted to the same task. Another important advantage of using modularity in the co-clustering context is that it provides a novel, simple way of determining the appropriate number of co-clusters.

Availability: an implementation of CoClus is available as part of the recently released coclust Python package which is available at: https://pypi.python.org/pypi/coclust
ER  - 

TY  - JOUR
T1  - Fast and reliable inference of semantic clusters
JO  - Knowledge-Based Systems
VL  - 111
IS  - 
SP  - 133
EP  - 143
PY  - 2016/11/1/
T2  - 
AU  - Fiorini, Nicolas
AU  - Harispe, Sébastien
AU  - Ranwez, Sylvie
AU  - Montmain, Jacky
AU  - Ranwez, Vincent
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2016.08.008
UR  - http://www.sciencedirect.com/science/article/pii/S0950705116302684
KW  - Clustering
KW  - Cluster labeling
KW  - Semantic indexing
KW  - Neighbor joining
KW  - Complexity analysis
AB  - Abstract
Document Indexing is but not limited to summarizing document contents with a small set of keywords or concepts of a knowledge base. Such a compact representation of document contents eases their use in numerous processes such as content-based information retrieval, corpus-mining and classification. An important effort has been devoted in recent years to (partly) automate semantic indexing, i.e. associating concepts to documents, leading to the availability of large corpora of semantically indexed documents. In this paper we introduce a method that hierarchically clusters documents based on their semantic indices while providing the proposed clusters with semantic labels. Our approach follows a neighbor joining strategy. Starting from a distance matrix reflecting the semantic similarity of documents, it iteratively selects the two closest clusters to merge them in a larger one. The similarity matrix is then updated. This is usually done by combining similarity of the two merged clusters, e.g. using the average similarity. We propose in this paper an alternative approach where the new cluster is first semantically annotated and the similarity matrix is then updated using the semantic similarity of this new annotation with those of the remaining clusters. The hierarchical clustering so obtained is a binary tree with branch lengths that convey semantic distances of clusters. It is then post-processed by using the branch lengths to keep only the most relevant clusters. Such a tool has numerous practical applications as it automates the organization of documents in meaningful clusters (e.g. papers indexed by MeSH terms, bookmarks or pictures indexed by WordNet) which is a tedious everyday task for many people. We assess the quality of the proposed methods using a specific benchmark of annotated clusters of bookmarks that were built manually. Each dataset of this benchmark has been clustered independently by several users. Remarkably, the clusters automatically built by our method are congruent with the clusters proposed by experts. All resources of this work, including source code, jar file, benchmark files and results are available at this address: http://sc.nicolasfiorini.info.
ER  - 

TY  - JOUR
T1  - A business intelligence approach using web search tools and online data reduction techniques to examine the value of product-enabled services
JO  - Expert Systems with Applications
VL  - 42
IS  - 21
SP  - 7582
EP  - 7600
PY  - 2015/11/30/
T2  - 
AU  - Tanev, Stoyan
AU  - Liotta, Giacomo
AU  - Kleismantas, Andrius
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2015.06.006
UR  - http://www.sciencedirect.com/science/article/pii/S0957417415004005
KW  - Product-enabled services
KW  - Service value attributes
KW  - Principal component analysis
KW  - K-means clustering
KW  - Latent semantic analysis
KW  - Online textual data
AB  - Abstract
This article summarizes the results of an empirical study focusing on the value of product-enabled services in intensive R&amp;D spenders. The focus is on product-driven firms for which new service development is expected to be particularly promising but also quite challenging. Part of the motivation is based on the fact that existing studies on the value attributes of hybrid offerings are mostly conceptual and need to be further substantiated through more systematic empirical studies. The research includes two samples with a total of 83 product-driven firms selected among the top R&amp;D spenders in Canada and Europe. It adopts an innovative methodology based on online textual data that could be implemented in advanced business intelligence tools aiming at the facilitation of innovation, marketing and business decision making. Combinations of keywords referring to different aspects of service value were designed and used in a web search resulting in the frequency of their use on companies’ websites. Principal component analysis was applied to identify distinctive groups of keyword combinations that were interpreted in terms of specific service value attributes. Finally, the firms were classified by means of K-means cluster analysis in order to identify the firms with a high degree of articulation of their service value attributes. This work articulates a relatively simple and intuitive method for quantitative and qualitative semantic analysis of online textual data that is similar to latent semantic analysis but could be used as part of more user-friendly expert system solutions and business intelligence tools based on easily accessible business statistics packages. The results show that the main service value attributes of the Canadian firms are: better service effectiveness, higher market share, higher service quality, and customer satisfaction. The service value attributes for the European firms include, among others, product added-value, product modernization and optimization of customer time and efforts. Canadian firms focus on collaboration and co-creation with suppliers and customers for the sake of product–service innovation as a competitive advantage on the marketplace. On the other hand, the focus of EU firms on innovative hybrid offerings is not explicitly related to business differentiation and competitiveness.
ER  - 

TY  - JOUR
T1  - On retrieving intelligently plagiarized documents using semantic similarity
JO  - Engineering Applications of Artificial Intelligence
VL  - 45
IS  - 
SP  - 246
EP  - 258
PY  - 2015/10//
T2  - 
AU  - Hussain, Syed Fawad
AU  - Suryani, Asif
SN  - 0952-1976
DO  - http://dx.doi.org/10.1016/j.engappai.2015.07.011
UR  - http://www.sciencedirect.com/science/article/pii/S095219761500158X
KW  - Plagiarism detection
KW  - Semantic similarity
KW  - Support Vector Machine
KW  - Information retrieval
AB  - Abstract
Plagiarism in text documents can be done in many ways. The most common form of plagiarizing a text document is to copy a chunk of text and alter it intelligently, thereby making it look original. Such cases are hard to detect since they require semantic analysis of the document. External sources of knowledge such as WordNet have been employed to help detect such cases. However, such an approach might often miss the contextual significance of the employed words, as well as suffer from the issue of synonymy and polysemy. We propose an architecture that uses a semantic similarity measure that exploits the semantic similarity of words, as mined from within the data corpus, thereby using localized contextual information. In this work, an approach for detecting plagiarism in text document has been proposed using a semantic similarity measure with a Nearest Neighbor (NN) search, and using a kernel in multiclass support vector machine. We test our approach on a plagiarism dataset specially developed to test the efficacy of the solution with varying level of plagiarism. The results have been compared with that of well-known commercial software, Turnitin®, having access to a large database. Our experiments suggest that using semantic kernels can help detect plagiarism, which can outsmart available techniques.
ER  - 

TY  - JOUR
T1  - Fuzzy evolutionary cellular learning automata model for text summarization
JO  - Swarm and Evolutionary Computation
VL  - 30
IS  - 
SP  - 11
EP  - 26
PY  - 2016/10//
T2  - 
AU  - Abbasi-ghalehtaki, Razieh
AU  - Khotanlou, Hassan
AU  - Esmaeilpour, Mansour
SN  - 2210-6502
DO  - http://dx.doi.org/10.1016/j.swevo.2016.03.004
UR  - http://www.sciencedirect.com/science/article/pii/S2210650216300049
KW  - Text summarization
KW  - Cellular learning automata
KW  - Artificial bee colony
KW  - Particle swarm optimization
KW  - Genetic algorithm
KW  - Fuzzy Logic
AB  - Abstract
Text summarization is the automatic process of creating a short form of an original text. The main goal of an automatic text summarization system is production of a summary which satisfies the user's needs. In this paper, a new model for automatic text summarization is introduced which is based on fuzzy logic system, evolutionary algorithms and cellular learning automata. First, the most important features including word features, similarity measure, and the position and the length of a sentence are extracted. A linear combination of these features shows the importance of each sentence. To calculate similarity measure, a combined method based on artificial bee colony algorithm and cellular learning automata are used. In this method, joint n-grams among sentences are extracted by cellular learning automata and then an artificial bee colony algorithm classifies n-friends in order to extract data and optimize the similarity measure as fitness function. Moreover, a new approach is proposed to adjust the best weights of the text features using particle swarm optimization and genetic algorithm. This method discovers more important and less important text features and then assigns fair weights to them. At last, a fuzzy logic system is used to perform the final scoring. The results of the proposed approach were compared with the other methods including Msword, System19, System21, System28, System31, FSDH, FEOM, NetSum, CRF, SVM, DE, MA-SingleDocSum, Unified Rank and Manifold Ranking using ROUGE-l and ROUGE-2 measures on the DUC2002 dataset. The results show that proposed method outperforms the aforementioned methods.
ER  - 

TY  - JOUR
T1  - Themes and Trends in Korean Educational Technology Research: A Social Network Analysis of Keywords
JO  - Procedia - Social and Behavioral Sciences
VL  - 131
IS  - 
SP  - 171
EP  - 176
PY  - 2014/5/15/
T2  - 3rd World Conference on Educational Technology Researches 2013, WCETR 2013, 7-9 November 2013, Antalya, Turkey
AU  - Jaewoo, Choi
AU  - Woonsun, Kang
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2014.04.099
UR  - http://www.sciencedirect.com/science/article/pii/S1877042814030092
KW  - co-word analysis
KW  - social network analysis
KW  - theme and trends of educational technology research ;
AB  - Abstract
The aim of this study is to identify themes and trends of Korean educational technology by examining 645 papers authored by Korean researchers in Journal of Educational Technology (JET) between 1985 and June, 2013. In addition to the keywords included in abstract, other important keywords were extracted from titles and abstracts manually. Co-word analysis was employed to reveal patterns and trends in the research by measuring the association strength of terms representative of relevant publications produced in ET field. Social network techniques were applied using UCINET for Windows to get keywords network, and Net-draw were utilized to visualize network. In order to trace dynamic changes of the ET field, the whole 29 year was further separated three consecutive periods: 1985-1994, 1995-2004, and 2005-2013. Results indicate that educational technology research in Korea has been strongly influenced by new media, design theory, educational epistemology, and educational assessment. Instructional design revealed to be most important keywords by centrality measures for among time periods, and it has received consistent and high attention over the last decade. Constructivism related keywords and network- based learning have also received growing attention since 1996. Social media related keywords (knowledge sharing, social capital, and social media etc) is emerging theme since 2005 year. The findings contribute to predict future trends of ET field and to understand the discourse about the epistemology of educational technology research by using social network techniques. The results show that ET fields have some established research themes and it also changes rapidly to embrace new themes.
ER  - 

TY  - JOUR
T1  - Positional and confidence voting-based consensus functions for fuzzy cluster ensembles
JO  - Fuzzy Sets and Systems
VL  - 193
IS  - 
SP  - 1
EP  - 32
PY  - 2012/4/16/
T2  - Theme : Data Analysis
AU  - Sevillano, Xavier
AU  - Alías, Francesc
AU  - Claudi Socoró, Joan
SN  - 0165-0114
DO  - http://dx.doi.org/10.1016/j.fss.2011.09.007
UR  - http://www.sciencedirect.com/science/article/pii/S0165011411004416
KW  - Information sciences
KW  - Fuzzy clustering
KW  - Group decision-making
KW  - Pattern recognition
AB  - Consensus clustering, i.e. the task of combining the outcomes of several clustering systems into a single partition, has lately attracted the attention of researchers in the unsupervised classification field, as it allows the creation of clustering committees that can be applied with multiple interesting purposes, such as knowledge reuse or distributed clustering. However, little attention has been paid to the development of algorithms, known as consensus functions, especially designed for consolidating the outcomes of multiple fuzzy (or soft) clustering systems into a single fuzzy partition—despite the fact that fuzzy clustering is far more informative than its crisp counterpart, as it provides information regarding the degree of association between objects and clusters that can be helpful for deriving richer descriptive data models. For this reason, this paper presents a set of fuzzy consensus functions capable of creating soft consensus partitions by fusing a collection of fuzzy clusterings. Our proposals base clustering combination on a cluster disambiguation process followed by the application of positional and confidence voting techniques. The modular design of these algorithms makes it possible to sequence their constituting steps in different manners, which allows to derive versions of the proposed consensus functions optimized from a computational standpoint. The proposed consensus functions have been evaluated in terms of the quality of the consensus partitions they deliver and in terms of their running time on multiple benchmark data sets. A comparison against several representative state-of-the-art consensus functions reveals that our proposals constitute an appealing alternative for conducting fuzzy consensus clustering, as they are capable of yielding high quality consensus partitions at a low computational cost.
ER  - 

TY  - JOUR
T1  - Consensus in a Fuzzy Environment: A Bibliometric Study
JO  - Procedia Computer Science
VL  - 55
IS  - 
SP  - 660
EP  - 667
PY  - 2015///
T2  - 3rd International Conference on Information Technology and Quantitative Management, ITQM 2015
AU  - Cabrerizo, F.J.
AU  - Mart́ınez, M.A.
AU  - Herrera, M.
AU  - Herrera-Viedma, E.
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.07.065
UR  - http://www.sciencedirect.com/science/article/pii/S1877050915015409
KW  - Consensus
KW  - bibliometric study
KW  - fuzzy environment.
AB  - Abstract
In today's organizations, group decision making has become a part of everyday organizational life. It involves multiple indi- viduals interacting to reach a decision. An important question here is the level of agreement or consensus achieved among the individuals before making the decision. Traditionally, consensus has been meant to be a full and unanimous agreement. How- ever, it is often not reachable in practice. A more reasonable approach is the use of softer consensus measures, which assess the consensus in a more flexible way, reflecting the large spectrum of possible partial agreements and guiding the discussion process until widespread agreement is achieved. As soft consensus measures are more human-consistent in the sense that they better reflect a real human perception of the essence of consensus, consensus models based on these kind of measures have been widely proposed. The aim of this contribution is to present a bibliometric study performed on the consensus approaches that have been proposed in a fuzzy environment. It gives an overview about the research products gathered in this research field. To do so, several points have been studied, among others: countries, journals, top contributing authors, most cited keywords, papers and authors. This allows us to show a quick shot of the state of the art in this research area.
ER  - 

TY  - JOUR
T1  - A diagnostic ontological model for damages to historical constructions
JO  - Journal of Cultural Heritage
VL  - 16
IS  - 1
SP  - 40
EP  - 48
PY  - 2015/1//
Y2  - 2015/2//
T2  - 
AU  - Cacciotti, Riccardo
AU  - Blaško, Miroslav
AU  - Valach, Jaroslav
SN  - 1296-2074
DO  - http://dx.doi.org/10.1016/j.culher.2014.02.002
UR  - http://www.sciencedirect.com/science/article/pii/S1296207414000259
KW  - Historical constructions
KW  - Conservation
KW  - Ontologies
KW  - Damage
KW  - Diagnosis
AB  - Abstract
Understanding damages to cultural heritage represents a very complex task based on a multidisciplinary interpretation of gathered information. Integrating the knowledge of different branches of science related to cultural heritage protection into a comprehensive knowledge-based system allows endorsing professional decision-making processes with the particular scope to mitigate the challenge posed by damage diagnosis to both expert and non-expert users. This paper proposes a model attempting to convey the benefits of modern ontological know-how to the management and processing of information concerning the diagnostic phase. The methodology consists in translating the professional approach to diagnosis of damages into a computer readable form able to replicate the assessment procedure, step by step, towards a feasible intervention. An overview of possible applications to conservation practice, such as the development of a mobile application dedicated to damage surveying and assessment, is also presented.
ER  - 

TY  - JOUR
T1  - Development of English Reading Comprehension by Using Concept Maps
JO  - Procedia - Social and Behavioral Sciences
VL  - 116
IS  - 
SP  - 497
EP  - 501
PY  - 2014/2/21/
T2  - 5th World Conference on Educational Sciences
AU  - Phantharakphong, Phatchara
AU  - Pothitha, Suteera
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2014.01.247
UR  - http://www.sciencedirect.com/science/article/pii/S1877042814002481
KW  - Language learning
KW  - teaching methods
KW  - secondary level
KW  - reading difficulty
AB  - Abstract
Reading is the single most important fundamental skill a person can acquire. However, in Thailand, English language learning, especially in reading skill, seems to be the big problem to students because most of them find English reading difficult and lack of motivation in doing so. As a result, the purpose of this study were to study the development of English reading comprehension by using concept maps, and to study the student's attitudes towards learning English reading comprehension by using concept maps. This study conducted through the use of scores from concept map retelling based on the redeveloped rubrics and comprehension test. The interview was also conducted. The results showed that the percentage of retelling and comprehension test were 81.25 percent and 86.50 percent respectively. Student stated that concept maps helped them understand English reading better. This could be concluded that the use of concept maps could enhance the student's English reading comprehension.
ER  - 

TY  - JOUR
T1  - Domain Ontologies Integration for Virtual Modelling and Simulation Environments
JO  - Procedia Computer Science
VL  - 29
IS  - 
SP  - 2507
EP  - 2514
PY  - 2014///
T2  - 2014 International Conference on Computational Science
AU  - Smirnov, Pavel A.
AU  - Kovalchuk, Sergey V.
AU  - Dukhanov, Alexey V.
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2014.05.234
UR  - http://www.sciencedirect.com/science/article/pii/S1877050914004116
KW  - Virtual simulation objects
KW  - semantic technologies
KW  - computational experiment
KW  - knowledge base
AB  - Abstract
This paper presents a model of semantic ontologies integration into workflow co mposition design process via Virtual Simu lation Objects (VSO) concept and technology. Doma in knowledge distributed over open linked data sources may be usefully applied for new VSO-images design and used for organization co mputational-intensive simulation e xpe riments. In this paper we describe the VSO- architecture e xtended with novel functionality regarding integration with lin ked open data sources. We also provide a computational-scientific e xa mp le of do ma in-specific use-case offering a solution for some public-transportation domain problem.
ER  - 

TY  - JOUR
T1  - A decision support system: Automated crime report analysis and classification for e-government
JO  - Government Information Quarterly
VL  - 31
IS  - 4
SP  - 534
EP  - 544
PY  - 2014/10//
T2  - 
AU  - Ku, Chih-Hao
AU  - Leroy, Gondy
SN  - 0740-624X
DO  - http://dx.doi.org/10.1016/j.giq.2014.08.003
UR  - http://www.sciencedirect.com/science/article/pii/S0740624X14001282
KW  - Natural language processing
KW  - Similarity measures
KW  - Classification
KW  - Algorithms
KW  - Measurement
KW  - E-government
AB  - Abstract
This paper investigates how text analysis and classification techniques can be used to enhance e-government, typically law enforcement agencies' efficiency and effectiveness by analyzing text reports automatically and provide timely supporting information to decision makers. With an increasing number of anonymous crime reports being filed and digitized, it is generally difficult for crime analysts to process and analyze crime reports efficiently. Complicating the problem is that the information has not been filtered or guided in a detective-led interview resulting in much irrelevant information. We are developing a decision support system (DSS), combining natural language processing (NLP) techniques, similarity measures, and machine learning, i.e., a Naïve Bayes' classifier, to support crime analysis and classify which crime reports discuss the same and different crime. We report on an algorithm essential to the DSS and its evaluations. Two studies with small and big datasets were conducted to compare the system with a human expert's performance. The first study includes 10 sets of crime reports discussing 2 to 5 crimes. The highest algorithm accuracy was found by using binary logistic regression (89%) while Naive Bayes' classifier was only slightly lower (87%). The expert achieved still better performance (96%) when given sufficient time. The second study includes two datasets with 40 and 60 crime reports discussing 16 different types of crimes for each dataset. The results show that our system achieved the highest classification accuracy (94.82%), while the crime analyst's classification accuracy (93.74%) is slightly lower.
ER  - 

TY  - JOUR
T1  - A multi-level matching method with hybrid similarity for document retrieval
JO  - Expert Systems with Applications
VL  - 39
IS  - 3
SP  - 2710
EP  - 2719
PY  - 2012/2/15/
T2  - 
AU  - Zhang, Haijun
AU  - Chow, Tommy W.S.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2011.08.128
UR  - http://www.sciencedirect.com/science/article/pii/S0957417411012590
KW  - Document retrieval
KW  - EMD
KW  - Multi-level matching
KW  - Hybrid similarity
KW  - Multi-level structure
AB  - This paper presents a multi-level matching method for document retrieval (DR) using a hybrid document similarity. Documents are represented by multi-level structure including document level and paragraph level. This multi-level-structured representation is designed to model underlying semantics in a more flexible and accurate way that the conventional flat term histograms find it hard to cope with. The matching between documents is then transformed into an optimization problem with Earth Mover’s Distance (EMD). A hybrid similarity is used to synthesize the global and local semantics in documents to improve the retrieval accuracy. In this paper, we have performed extensive experimental study and verification. The results suggest that the proposed method works well for lengthy documents with evident spatial distributions of terms.
ER  - 

TY  - JOUR
T1  - Cloud-DLS: Dynamic trusted scheduling for Cloud computing
JO  - Expert Systems with Applications
VL  - 39
IS  - 3
SP  - 2321
EP  - 2329
PY  - 2012/2/15/
T2  - 
AU  - Wang, Wei
AU  - Zeng, Guosun
AU  - Tang, Daizhong
AU  - Yao, Jing
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2011.08.048
UR  - http://www.sciencedirect.com/science/article/pii/S0957417411011596
KW  - Cloud computing
KW  - Bayesian
KW  - Cognitive model
KW  - Scheduling
KW  - Trust
AB  - Clouds are rapidly becoming an important platform for scientific applications. In the Cloud environment with uncountable numeric nodes, resource is inevitably unreliable, which has a great effect on task execution and scheduling. In this paper, inspired by Bayesian cognitive model and referring to the trust relationship models of sociology, we first propose a novel Bayesian method based cognitive trust model, and then we proposed a trust dynamic level scheduling algorithm named Cloud-DLS by integrating the existing DLS algorithm. Moreover, a benchmark is structured to span a range of Cloud computing characteristics for evaluation of the proposed method. Theoretical analysis and simulations prove that the Cloud-DLS algorithm can efficiently meet the requirement of Cloud computing workloads in trust, sacrificing fewer time costs, and assuring the execution of tasks in a security way.
ER  - 

TY  - JOUR
T1  - A framework for multi-document abstractive summarization based on semantic role labelling
JO  - Applied Soft Computing
VL  - 30
IS  - 
SP  - 737
EP  - 747
PY  - 2015/5//
T2  - 
AU  - Khan, Atif
AU  - Salim, Naomie
AU  - Jaya Kumar, Yogan
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2015.01.070
UR  - http://www.sciencedirect.com/science/article/pii/S1568494615001039
KW  - Abstractive summary
KW  - Semantic role labeling
KW  - Semantic similarity measure
KW  - Language generation
KW  - Genetic algorithm
AB  - Abstract
We propose a framework for abstractive summarization of multi-documents, which aims to select contents of summary not from the source document sentences but from the semantic representation of the source documents. In this framework, contents of the source documents are represented by predicate argument structures by employing semantic role labeling. Content selection for summary is made by ranking the predicate argument structures based on optimized features, and using language generation for generating sentences from predicate argument structures. Our proposed framework differs from other abstractive summarization approaches in a few aspects. First, it employs semantic role labeling for semantic representation of text. Secondly, it analyzes the source text semantically by utilizing semantic similarity measure in order to cluster semantically similar predicate argument structures across the text; and finally it ranks the predicate argument structures based on features weighted by genetic algorithm (GA). Experiment of this study is carried out using DUC-2002, a standard corpus for text summarization. Results indicate that the proposed approach performs better than other summarization systems.
ER  - 

TY  - JOUR
T1  - Concept extraction and e-commerce applications
JO  - Electronic Commerce Research and Applications
VL  - 12
IS  - 4
SP  - 289
EP  - 296
PY  - 2013/7//
Y2  - 2013/8//
T2  - Social Commerce- Part 2
AU  - Zhang, Yongzheng
AU  - Mukherjee, Rajyashree
AU  - Soetarman, Benny
SN  - 1567-4223
DO  - http://dx.doi.org/10.1016/j.elerap.2013.03.008
UR  - http://www.sciencedirect.com/science/article/pii/S1567422313000227
KW  - Concept extraction
KW  - Automatic keyphrase extraction
KW  - e-Commerce
KW  - Product matching
KW  - Topic-based opinion mining
AB  - Abstract
Concept extraction is the technique of mining the most important topic of a document. In the e-commerce context, concept extraction can be used to identify what a shopping related Web page is talking about. This is practically useful in applications like search relevance and product matching. In this paper, we investigate two concept extraction methods: Automatic Concept Extractor (ACE) and Automatic Keyphrase Extraction (KEA). ACE is an unsupervised method that looks at both text and HTML tags. We upgrade ACE into Improved Concept Extractor (ICE) with significant improvements. KEA is a supervised learning system. We evaluate the methods by comparing automatically generated concepts to a gold standard. The experimental results demonstrate that ICE significantly outperforms ACE and also outperforms KEA in concept extraction. To demonstrate the practical use of concept extraction in the e-commerce context, we use ICE and KEA to showcase two e-commerce applications, i.e. product matching and topic-based opinion mining.
ER  - 

TY  - JOUR
T1  - Discriminant non-negative graph embedding for face recognition
JO  - Neurocomputing
VL  - 149, Part C
IS  - 
SP  - 1451
EP  - 1460
PY  - 2015/2/3/
T2  - 
AU  - Cui, Jinrong
AU  - Wen, Jiajun
AU  - Li, Zhengming
AU  - Bin, Li
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2014.08.047
UR  - http://www.sciencedirect.com/science/article/pii/S0925231214010911
KW  - Non-Negative Matrix Factorization (NMF)
KW  - Graph preserve embedding
KW  - Feature extraction
KW  - Face recognition
KW  - Manifold learning
KW  - Sparse subspace
AB  - Abstract
Non-negative Matrix Factorization (NMF) is an unsupervised algorithm for low-rank approximation of non-negative data and has been widely used in many fields, but its performance in feature extraction is not satisfactory. The main reason is that the model of NMF and its variants did not take into account the label information of the samples, which can add the discriminant ability of the methods. In this paper, we proposed a novel method, called discriminant non-negative graph embedding (DNGE) algorithm in which the label information of the samples and the local geometric structure are all integrated in the objective function. Furthermore, we incorporated the between-class graph and within-class graph into the objective functions to indicate that we not only used the local separability but also used the whole separability of the samples. To guarantee convergence, we use the KKT condition to calculate the non-negative solution of the DNGE. A convergent multiplicative non-negative updating rule is then derived to learn the transformation matrix. Experiments are conducted on the CMU PIE, ORL, Yale, FERET and AR database. The results show that the DNGE algorithm provides better facial representation and achieves higher recognition rates than naïve Non-Negative Matrix Factorization and its extension methods.
ER  - 

TY  - JOUR
T1  - K-means algorithms for functional data
JO  - Neurocomputing
VL  - 151, Part 1
IS  - 
SP  - 231
EP  - 245
PY  - 2015/3/3/
T2  - 
AU  - Luz López García, María
AU  - García-Ródenas, Ricardo
AU  - González Gómez, Antonia
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2014.09.048
UR  - http://www.sciencedirect.com/science/article/pii/S0925231214012521
KW  - Functional data
KW  - K-means
KW  - Reproducing Kernel Hilbert Space
KW  - Tikhonov regularization theory
KW  - Dimensionality reduction
AB  - Abstract
Cluster analysis of functional data considers that the objects on which you want to perform a taxonomy are functions f : X ⊂ R p ↦ R and the available information about each object is a sample in a finite set of points f n = { ( x i , y i ) ∈ X × R } i = 1 n . The aim is to infer the meaningful groups by working explicitly with its infinite-dimensional nature.

In this paper the use of K-means algorithms to solve this problem is analysed. A comparative study of three K-means algorithms has been conducted. The K-means algorithm for raw data, a kernel K-means algorithm for raw data and a K-means algorithm using two distances for functional data are tested. These distances, called d V n and d ϕ , are based on projections onto Reproducing Kernel Hilbert Spaces (RKHS) and Tikhonov regularization theory. Although it is shown that both distances are equivalent, they lead to two different strategies to reduce the dimensionality of the data. In the case of d V n distance the most suitable strategy is Johnson–Lindenstrauss random projections. The dimensionality reduction for d ϕ is based on spectral methods.

A key aspect that has been analysed is the effect of the sampling { x i } i = 1 n on the K-means algorithm performance. In the numerical study an ex professo example is given to show that if the sampling is not uniform in X, then a K-means algorithm that ignores the functional nature of the data can reduce its performance. It is numerically shown that the original K-means algorithm and that suggested here lead to similar performance in the examples when X is uniformly sampled, but the computational cost when working with the original set of observations is higher than the K-means algorithms based on d ϕ or d V n , as they use strategies to reduce the dimensionality of the data.

The numerical tests are completed with a case study to analyse what kind of problem the K-means algorithm for functional data must face.
ER  - 

TY  - JOUR
T1  - Literature listing
JO  - World Patent Information
VL  - 35
IS  - 3
SP  - 281
EP  - 288
PY  - 2013/9//
T2  - 
AU  - Newton, David
SN  - 0172-2190
DO  - http://dx.doi.org/10.1016/j.wpi.2013.04.003
UR  - http://www.sciencedirect.com/science/article/pii/S0172219013000604
ER  - 

TY  - JOUR
T1  - Color segmentation by fuzzy co-clustering of chrominance color features
JO  - Neurocomputing
VL  - 120
IS  - 
SP  - 235
EP  - 249
PY  - 2013/11/23/
T2  - Image Feature Detection and Description
AU  - Hanmandlu, Madasu
AU  - Verma, Om Prakash
AU  - Susan, Seba
AU  - Madasu, V.K.
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2012.09.043
UR  - http://www.sciencedirect.com/science/article/pii/S0925231213003366
KW  - Fuzzy Co-clustering
KW  - Object membership
KW  - Feature membership
KW  - Validity measure
KW  - Bacterial Foraging
KW  - Color segmentation
AB  - Abstract
This paper presents a novel color segmentation technique using fuzzy co-clustering approach in which both the objects and the features are assigned membership functions. An objective function which includes a multi-dimensional distance function as the dissimilarity measure and entropy as the regularization term is formulated in the proposed fuzzy co-clustering for images (FCCI) algorithm. The chrominance color cues a⁎ and b⁎ of CIELAB color space are used as the feature variables for co-clustering. The experiments are conducted on 100 natural images obtained from the Berkeley segmentation database. It is observed from the experimental results that the proposed FCCI yields well formed, valid and high quality clusters, as verified from Liu’s F-measure and Normalized Probabilistic RAND index. The proposed color segmentation method is also compared with other segmentation methods namely Mean-Shift, NCUT, GMM, FCM and is found to outperform all the methods. The bacterial foraging global optimization algorithm gives image specific values to the parameters involved in the algorithm.
ER  - 

TY  - JOUR
T1  - Subspace learning via Locally Constrained A-optimal nonnegative projection
JO  - Neurocomputing
VL  - 115
IS  - 
SP  - 49
EP  - 62
PY  - 2013/9/4/
T2  - 
AU  - Li, Ping
AU  - Bu, Jiajun
AU  - Chen, Chun
AU  - Wang, Can
AU  - Cai, Deng
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2012.12.029
UR  - http://www.sciencedirect.com/science/article/pii/S0925231213000970
KW  - Subspace clustering
KW  - Nonnegative projection
KW  - Semi-supervised learning
KW  - Structured information
KW  - Label constraints
AB  - For decades, subspace learning has received considerable interests in the pattern recognition and computer vision communities. Many promising methods have emerged to capture a better subspace from different perspectives. As a popular learning paradigm, matrix factorization is actively utilized to learn a new subspace from high-dimensional data space. Very recently, some work attempts to consider the decomposed matrix from a statistical point of view, which models the data points via ridge regression and minimizes the variance of the parameter. However, they neglect the structured information embedded in the local neighborhoods of each data point and fail to exploit the prior knowledge. To address these problems, we present a novel subspace learning approach named Locally Constrained A-optimal nonnegative projection, termed as LCA in short. This method strives to preserve the locally geometrical structure of the obtained subspace via neighborhood patches while projecting the nonnegative data points with the high dimension onto a low-dimensional subspace. Besides, we incorporate some supervised information as constraints to guide subspace learning, such that the discriminating power of the new subspace can be much more strengthened. Therefore, the column vectors derived from the nonnegative projection span a new subspace that characterizes local consistency and better discriminative ability. The favorable experimental results have verified the effectiveness of the proposed approach compared to some competitive methods.
ER  - 

TY  - JOUR
T1  - Semi-supervised dimensionality reduction for analyzing high-dimensional data with constraints
JO  - Neurocomputing
VL  - 76
IS  - 1
SP  - 114
EP  - 124
PY  - 2012/1/15/
T2  - Seventh International Symposium on Neural Networks (ISNN 2010)Advances in Web Intelligence
AU  - Yan, Su
AU  - Bouaziz, Sofien
AU  - Lee, Dongwon
AU  - Barlow, Jesse
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2011.03.057
UR  - http://www.sciencedirect.com/science/article/pii/S0925231211004280
KW  - Dimensionality reduction
KW  - Semi-supervised learning
KW  - Clustering
KW  - Kernel methods
KW  - Linear transformation
KW  - Generalized eigenproblem
AB  - In this paper, we present a novel semi-supervised dimensionality reduction technique to address the problems of inefficient learning and costly computation in coping with high-dimensional data. Our method named the dual subspace projections (DSP) embeds high-dimensional data in an optimal low-dimensional space, which is learned with a few user-supplied constraints and the structure of input data. The method projects data into two different subspaces respectively the kernel space and the original input space. Each projection is designed to enforce one type of constraints and projections in the two subspaces interact with each other to satisfy constraints maximally and preserve the intrinsic data structure. Compared to existing techniques, our method has the following advantages: (1) it benefits from constraints even when only a few are available; (2) it is robust and free from overfitting; and (3) it handles nonlinearly separable data, but learns a linear data transformation. As a conclusion, our method can be easily generalized to new data points and is efficient in dealing with large datasets. An empirical study using real data validates our claims so that significant improvements in learning accuracy can be obtained after the DSP-based dimensionality reduction is applied to high-dimensional data.
ER  - 

TY  - JOUR
T1  - Sparse nonnegative matrix factorization with ℓ0-constraints
JO  - Neurocomputing
VL  - 80
IS  - 
SP  - 38
EP  - 46
PY  - 2012/3/15/
T2  - Special Issue on Machine Learning for Signal Processing 2010
AU  - Peharz, Robert
AU  - Pernkopf, Franz
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2011.09.024
UR  - http://www.sciencedirect.com/science/article/pii/S0925231211006370
KW  - NMF
KW  - Sparse coding
KW  - Nonnegative least squares
AB  - Although nonnegative matrix factorization (NMF) favors a sparse and part-based representation of nonnegative data, there is no guarantee for this behavior. Several authors proposed NMF methods which enforce sparseness by constraining or penalizing the ℓ 1 - norm of the factor matrices. On the other hand, little work has been done using a more natural sparseness measure, the ℓ 0 - pseudo - norm . In this paper, we propose a framework for approximate NMF which constrains the ℓ 0 - norm of the basis matrix, or the coefficient matrix, respectively. For this purpose, techniques for unconstrained NMF can be easily incorporated, such as multiplicative update rules, or the alternating nonnegative least-squares scheme. In experiments we demonstrate the benefits of our methods, which compare to, or outperform existing approaches.
ER  - 

TY  - JOUR
T1  - Normalized dimensionality reduction using nonnegative matrix factorization
JO  - Neurocomputing
VL  - 73
IS  - 10–12
SP  - 1783
EP  - 1793
PY  - 2010/6//
T2  - Subspace Learning / Selected papers from the European Symposium on Time Series Prediction
AU  - Zhu, Zhenfeng
AU  - Guo, Yue-Fei
AU  - Zhu, Xingquan
AU  - Xue, Xiangyang
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2009.11.046
UR  - http://www.sciencedirect.com/science/article/pii/S0925231210001384
KW  - Subspace learning
KW  - Nonnegative matrix factorization
KW  - Dimensionality reduction
KW  - Normalization
KW  - Sparsity
AB  - In this paper, we propose an iterative normalized compression method for dimensionality reduction using non-negative matrix factorization (NCMF). To factorize the instance matrix X into C × M , an objective function is defined to impose the normalization constraints to the basis matrix C and the coefficient matrix M. We argue that in many applications, instances are often normalized in one way or the other. By integrating data normalization constraints into the objective function and transposing the instance matrix, one can directly discover relations among different dimensions and devise effective and efficient procedure for matrix factorization. In the paper, we assume that feature dimensions in instance matrix are normalized, and propose an iterative solution NCMF to achieve rapid matrix factorization for dimensionality reduction. As a result, the basis matrix can be viewed as a compression matrix and the coefficient matrix becomes a mapping matrix. NCMF is simple, effective, and only needs to initialize the mapping matrix. Experimental comparisons on text, biological and image data demonstrate that NCMF gains 21.02% computational time reduction, 39.60% sparsity improvement for mapping matrix, and 8.59% clustering accuracy improvement.
ER  - 

TY  - JOUR
T1  - Cluster-discovery of Twitter messages for event detection and trending
JO  - Journal of Computational Science
VL  - 6
IS  - 
SP  - 47
EP  - 57
PY  - 2015/1//
T2  - 
AU  - Kaleel, Shakira Banu
AU  - Abhari, Abdolreza
SN  - 1877-7503
DO  - http://dx.doi.org/10.1016/j.jocs.2014.11.004
UR  - http://www.sciencedirect.com/science/article/pii/S1877750314001604
KW  - Web social networking
KW  - Data mining
KW  - Event detection
KW  - Event trending
KW  - Locality sensitive hashing
KW  - Cluster-discovery
KW  - Term frequency–inverse document frequency
AB  - Abstract
Social media data carries abundant hidden occurrences of real-time events. In this paper, a novel methodology is proposed for detecting and trending events from tweet clusters that are discovered by using locality sensitive hashing (LSH) technique. Key challenges include: (1) construction of dictionary using incremental term frequency–inverse document frequency (TF–IDF) in high-dimensional data to create tweet feature vector, (2) leveraging LSH to find truly interesting events, (3) trending the behavior of event based on time, geo-locations and cluster size, and (4) speed-up the cluster-discovery process while retaining the cluster quality. Experiments are conducted for a specific event and the clusters discovered using LSH and K-means are compared with group average agglomerative clustering technique.
ER  - 

TY  - JOUR
T1  - Multi-view learning via probabilistic latent semantic analysis
JO  - Information Sciences
VL  - 199
IS  - 
SP  - 20
EP  - 30
PY  - 2012/9/15/
T2  - 
AU  - Zhuang, Fuzhen
AU  - Karypis, George
AU  - Ning, Xia
AU  - He, Qing
AU  - Shi, Zhongzhi
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2012.02.058
UR  - http://www.sciencedirect.com/science/article/pii/S0020025512001788
KW  - Multi-view learning
KW  - Generative model
KW  - Probabilistic Latent Semantic Analysis (PLSA)
AB  - Multi-view learning arouses vast amount of interest in the past decades with numerous real-world applications in web page analysis, bioinformatics, image processing and so on. Unlike the most previous works following the idea of co-training, in this paper we propose a new generative model for Multi-view Learning via Probabilistic Latent Semantic Analysis, called MVPLSA. In this model, we jointly model the co-occurrences of features and documents from different views. Specifically, in the model there are two latent variables y for the latent topic and z for the document cluster, and three visible variables d for the document, f for the feature, and v for the view label. The conditional probability p(z∣d), which is independent of v, is used as the bridge to share knowledge among multiple views. Also, we have p(y∣z, v) and p(f∣y, v), which are dependent of v, to capture the specifical structures inside each view. Experiments are conducted on four real-world data sets to demonstrate the effectiveness and superiority of our model.
ER  - 

TY  - JOUR
T1  - A parallel method for computing rough set approximations
JO  - Information Sciences
VL  - 194
IS  - 
SP  - 209
EP  - 223
PY  - 2012/7/1/
T2  - Intelligent Knowledge-Based Models and Methodologies for Complex Information Systems
AU  - Zhang, Junbo
AU  - Li, Tianrui
AU  - Ruan, Da
AU  - Gao, Zizhe
AU  - Zhao, Chengbing
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2011.12.036
UR  - http://www.sciencedirect.com/science/article/pii/S0020025512000163
KW  - Rough sets
KW  - Data mining
KW  - Approximations
KW  - Hadoop
KW  - MapReduce
AB  - Massive data mining and knowledge discovery present a tremendous challenge with the data volume growing at an unprecedented rate. Rough set theory has been successfully applied in data mining. The lower and upper approximations are basic concepts in rough set theory. The effective computation of approximations is vital for improving the performance of data mining or other related tasks. The recently introduced MapReduce technique has gained a lot of attention from the scientific community for its applicability in massive data analysis. This paper proposes a parallel method for computing rough set approximations. Consequently, algorithms corresponding to the parallel method based on the MapReduce technique are put forward to deal with the massive data. An extensive experimental evaluation on different large data sets shows that the proposed parallel method is effective for data mining.
ER  - 

TY  - JOUR
T1  - A hybrid approach for data clustering based on modified cohort intelligence and K-means
JO  - Expert Systems with Applications
VL  - 41
IS  - 13
SP  - 6009
EP  - 6016
PY  - 2014/10/1/
T2  - 
AU  - Krishnasamy, Ganesh
AU  - Kulkarni, Anand J.
AU  - Paramesran, Raveendran
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2014.03.021
UR  - http://www.sciencedirect.com/science/article/pii/S095741741400150X
KW  - Clustering
KW  - Cohort intelligence
KW  - Meta-heuristic algorithm
AB  - Abstract
Clustering is an important and popular technique in data mining. It partitions a set of objects in such a manner that objects in the same clusters are more similar to each another than objects in the different cluster according to certain predefined criteria. K-means is simple yet an efficient method used in data clustering. However, K-means has a tendency to converge to local optima and depends on initial value of cluster centers. In the past, many heuristic algorithms have been introduced to overcome this local optima problem. Nevertheless, these algorithms too suffer several short-comings. In this paper, we present an efficient hybrid evolutionary data clustering algorithm referred to as K-MCI, whereby, we combine K-means with modified cohort intelligence. Our proposed algorithm is tested on several standard data sets from UCI Machine Learning Repository and its performance is compared with other well-known algorithms such as K-means, K-means++, cohort intelligence (CI), modified cohort intelligence (MCI), genetic algorithm (GA), simulated annealing (SA), tabu search (TS), ant colony optimization (ACO), honey bee mating optimization (HBMO) and particle swarm optimization (PSO). The simulation results are very promising in the terms of quality of solution and convergence speed of algorithm.
ER  - 

TY  - JOUR
T1  - Comparing methods to extract technical content for technological intelligence
JO  - Journal of Engineering and Technology Management
VL  - 32
IS  - 
SP  - 97
EP  - 109
PY  - 2014/4//
Y2  - 2014/6//
T2  - Special Issue on Emergence of Technologies: Methods and Tools for Management
AU  - Newman, Nils C.
AU  - Porter, Alan L.
AU  - Newman, David
AU  - Trumbach, Cherie Courseault
AU  - Bolan, Stephanie D.
SN  - 0923-4748
DO  - http://dx.doi.org/10.1016/j.jengtecman.2013.09.001
UR  - http://www.sciencedirect.com/science/article/pii/S0923474813000556
KW  - Tech mining
KW  - Topic modeling
KW  - Term clustering
KW  - Technological emergence
KW  - Dye-sensitized solar cells
AB  - Abstract
We are developing indicators for the emergence of science and technology (S&amp;T) topics. To do so, we extract information from various S&amp;T information resources. This paper compares alternative ways of consolidating messy sets of key terms [e.g., using Natural Language Processing on abstracts and titles, together with various keyword sets]. Our process includes combinations of stopword removal, fuzzy term matching, association rules, and term commonality weighting. We compare topic modeling to Principal Components Analysis for a test set of 4104 abstract records on Dye-Sensitized Solar Cells. Results suggest potential to enhance understanding regarding technological topics to help track technological emergence.
ER  - 

TY  - JOUR
T1  - A knowledge-driven approach to biomedical document conceptualization
JO  - Artificial Intelligence in Medicine
VL  - 49
IS  - 2
SP  - 67
EP  - 78
PY  - 2010/6//
T2  - 
AU  - Zheng, Hai-Tao
AU  - Borchert, Charles
AU  - Jiang, Yong
SN  - 0933-3657
DO  - http://dx.doi.org/10.1016/j.artmed.2010.02.005
UR  - http://www.sciencedirect.com/science/article/pii/S0933365710000266
KW  - Ontology
KW  - Conceptualization
KW  - Knowledge-driven approach
KW  - Latent semantic analysis
KW  - Medical Subject Heading
KW  - Gene ontology
AB  - Objective
Biomedical document conceptualization is the process of clustering biomedical documents based on ontology-represented domain knowledge. The result of this process is the representation of the biomedical documents by a set of key concepts and their relationships. Most of clustering methods cluster documents based on invariant domain knowledge. The objective of this work is to develop an effective method to cluster biomedical documents based on various user-specified ontologies, so that users can exploit the concept structures of documents more effectively.
Methods
We develop a flexible framework to allow users to specify the knowledge bases, in the form of ontologies. Based on the user-specified ontologies, we develop a key concept induction algorithm, which uses latent semantic analysis to identify key concepts and cluster documents. A corpus-related ontology generation algorithm is developed to generate the concept structures of documents.
Results
Based on two biomedical datasets, we evaluate the proposed method and five other clustering algorithms. The clustering results of the proposed method outperform the five other algorithms, in terms of key concept identification. With respect to the first biomedical dataset, our method has the F-measure values 0.7294 and 0.5294 based on the MeSH ontology and gene ontology (GO), respectively. With respect to the second biomedical dataset, our method has the F-measure values 0.6751 and 0.6746 based on the MeSH ontology and GO, respectively. Both results outperforms the five other algorithms in terms of F-measure. Based on the MeSH ontology and GO, the generated corpus-related ontologies show informative conceptual structures.
Conclusions
The proposed method enables users to specify the domain knowledge to exploit the conceptual structures of biomedical document collections. In addition, the proposed method is able to extract the key concepts and cluster the documents with a relatively high precision.
ER  - 

TY  - JOUR
T1  - An ontology-based measure to compute semantic similarity in biomedicine
JO  - Journal of Biomedical Informatics
VL  - 44
IS  - 1
SP  - 118
EP  - 125
PY  - 2011/2//
T2  - Ontologies for Clinical and Translational Research
AU  - Batet, Montserrat
AU  - Sánchez, David
AU  - Valls, Aida
SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2010.09.002
UR  - http://www.sciencedirect.com/science/article/pii/S1532046410001346
KW  - Semantic similarity
KW  - Ontologies
KW  - SNOMED CT
KW  - Biomedicine
KW  - Data mining
AB  - Proper understanding of textual data requires the exploitation and integration of unstructured and heterogeneous clinical sources, healthcare records or scientific literature, which are fundamental aspects in clinical and translational research. The determination of semantic similarity between word pairs is an important component of text understanding that enables the processing, classification and structuring of textual resources. In the past, several approaches for assessing word similarity by exploiting different knowledge sources (ontologies, thesauri, domain corpora, etc.) have been proposed. Some of these measures have been adapted to the biomedical field by incorporating domain information extracted from clinical data or from medical ontologies (such as MeSH or SNOMED CT). In this paper, these approaches are introduced and analyzed in order to determine their advantages and limitations with respect to the considered knowledge bases. After that, a new measure based on the exploitation of the taxonomical structure of a biomedical ontology is proposed. Using SNOMED CT as the input ontology, the accuracy of our proposal is evaluated and compared against other approaches according to a standard benchmark of manually ranked medical terms. The correlation between the results of the evaluated measures and the human experts’ ratings shows that our proposal outperforms most of the previous measures avoiding, at the same time, some of their limitations.
ER  - 

TY  - JOUR
T1  - Frequent approximate subgraphs as features for graph-based image classification
JO  - Knowledge-Based Systems
VL  - 27
IS  - 
SP  - 381
EP  - 392
PY  - 2012/3//
T2  - 
AU  - Acosta-Mendoza, Niusvel
AU  - Gago-Alonso, Andrés
AU  - Medina-Pagola, José E.
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2011.12.002
UR  - http://www.sciencedirect.com/science/article/pii/S0950705111002668
KW  - Approximate graph mining
KW  - Approximate graph matching
KW  - Image representation
KW  - Image classification
KW  - Feature selection
AB  - The use of approximate graph matching for frequent subgraph mining has been identified in different applications as a need. To meet this need, several algorithms have been developed, but there are applications where it has not been used yet, for example image classification. In this paper, a new algorithm for mining frequent connected subgraphs over undirected and labeled graph collections VEAM (Vertex and Edge Approximate graph Miner) is presented. Slight variations of the data, keeping the topology of the graphs, are allowed in this algorithm. Approximate matching in existing algorithm (APGM) is only performed on vertex label set. In VEAM, the approximate matching between edge label set in frequent subgraph mining is included in the mining process. Also, a framework for graph-based image classification is introduced. The approximate method of VEAM was tested on an artificial image collection using a graph-based image representation proposed in this paper. The experimentation on this collection shows that our proposal gets better results than graph-based image classification using some algorithms reported in related work.
ER  - 

TY  - JOUR
T1  - A modification of the k-means method for quasi-unsupervised learning
JO  - Knowledge-Based Systems
VL  - 37
IS  - 
SP  - 176
EP  - 185
PY  - 2013/1//
T2  - 
AU  - Rebollo-Monedero, David
AU  - Solé, Marc
AU  - Nin, Jordi
AU  - Forné, Jordi
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2012.07.024
UR  - http://www.sciencedirect.com/science/article/pii/S0950705112002122
KW  - k-Means method
KW  - Quasi-unsupervised learning
KW  - Constrained clustering
KW  - Size constraints
KW  - Loyd algorithm
KW  - Clustering
AB  - Since the advent of data clustering, the original formulation of the clustering problem has been enriched to incorporate a number of twists to widen its range of application. In particular, recent heuristic approaches have proposed to incorporate restrictions on the size of the clusters, while striving to minimize a measure of dissimilarity within them. Such size constraints effectively constitute a way to exploit prior knowledge, readily available in many scenarios, which can lead to an improved performance in the clustering obtained.

In this paper, we build upon a modification of the celebrated k-means method resorting to a similar alternating optimization procedure, endowed with additive partition weights controlling the size of the partitions formed, adjusted by means of the Levenberg–Marquardt algorithm. We propose several further variations on this modification, in which different kinds of additional information are present. We report experimental results on various standardized datasets, demonstrating that our approaches outperform existing heuristics for size-constrained clustering. The running-time complexity of our proposal is assessed experimentally by means of a power-law regression analysis.
ER  - 

TY  - JOUR
T1  - Collaboratively built semi-structured content and Artificial Intelligence: The story so far
JO  - Artificial Intelligence
VL  - 194
IS  - 
SP  - 2
EP  - 27
PY  - 2013/1//
T2  - Artificial Intelligence, Wikipedia and Semi-Structured Resources
AU  - Hovy, Eduard
AU  - Navigli, Roberto
AU  - Ponzetto, Simone Paolo
SN  - 0004-3702
DO  - http://dx.doi.org/10.1016/j.artint.2012.10.002
UR  - http://www.sciencedirect.com/science/article/pii/S0004370212001245
KW  - Knowledge acquisition
KW  - Semantic networks
KW  - Knowledge-rich methods
AB  - Recent years have seen a great deal of work that exploits collaborative, semi-structured content for Artificial Intelligence (AI) and Natural Language Processing (NLP). This special issue of the Artificial Intelligence Journal presents a variety of state-of-the-art contributions, each of which illustrates the substantial impact that work on leveraging semi-structured content is having on AI and NLP as it continuously fosters new directions of cutting-edge research. We contextualize the papers collected in this special issue by providing a detailed overview of previous work on collaborative, semi-structured resources. The survey is made up of two main logical parts: in the first part, we present the main characteristics of collaborative resources that make them attractive for AI and NLP research; in the second part, we present an overview of how these features have been exploited to tackle a variety of long-standing issues in the two fields, in particular the acquisition of large amounts of machine-readable knowledge, and its application to a wide range of tasks. The overall picture shows that not only are semi-structured resources enabling a renaissance of knowledge-rich AI techniques, but also that significant advances in high-end applications that require deep understanding capabilities can be achieved by synergistically exploiting large amounts of machine-readable structured knowledge in combination with sound statistical AI and NLP techniques.
ER  - 

TY  - JOUR
T1  - Adjusting Fuzzy Similarity Functions for use with standard data mining tools
JO  - Journal of Systems and Software
VL  - 84
IS  - 12
SP  - 2374
EP  - 2383
PY  - 2011/12//
T2  - 
AU  - Meged, Avichai
AU  - Gelbard, Roy
SN  - 0164-1212
DO  - http://dx.doi.org/10.1016/j.jss.2011.07.009
UR  - http://www.sciencedirect.com/science/article/pii/S0164121211001841
KW  - Data representation
KW  - Data mining
KW  - Data segmentation
KW  - Classification
KW  - Clustering
KW  - Similarity function
KW  - Similarity measure
AB  - Data mining is crucial in many areas and there are ongoing efforts to improve its effectiveness in both the scientific and the business world. There is an obvious need to improve the outcomes of mining techniques such as clustering and other classifiers without abandoning the standard mining tools that are popular with researchers and practitioners alike. Currently, however, standard tools do not have the flexibility to control similarity relations between attribute values, a critical feature in improving mining-clustering results. The study presented here introduces the Similarity Adjustment Model (SAM) where adjusted Fuzzy Similarity Functions (FSF) control similarity relations between attribute values and hence ameliorate clustering results obtained with standard data mining tools such as SPSS and SAS. The SAM draws on principles of binary database representation models and employs FSF adjusted via an iterative learning process that yields improved segmentation regardless of the choice of mining-clustering algorithm. The SAM model is illustrated and evaluated on three common datasets with the standard SPSS package. The datasets were run with several clustering algorithms. Comparison of “Naïve” runs (which used original data) and “Fuzzy” runs (which used SAM) shows that the SAM improves segmentation in all cases.
ER  - 

TY  - JOUR
T1  - Nonnegative sparse locality preserving hashing
JO  - Information Sciences
VL  - 281
IS  - 
SP  - 714
EP  - 725
PY  - 2014/10/10/
T2  - Multimedia Modeling
AU  - Liu, Cong
AU  - Ling, Hefei
AU  - Zou, Fuhao
AU  - Sarem, Mudar
AU  - Yan, Lingyu
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2014.03.107
UR  - http://www.sciencedirect.com/science/article/pii/S0020025514004046
KW  - Approximate similarity search
KW  - Locality preserving projection
KW  - Sparse representation
KW  - Multiplicative updating
KW  - Nonnegative sparse locality preserving hashing
AB  - Abstract
It is a NP-hard problem to optimize the objective function of hash-based similarity search algorithms, such as Spectral Hashing and Self-Taught Hashing. To make the problem solvable, existing methods have relaxed the constraints on hash codes from binary values (discrete) to real values (continuous). Then eigenvalue decomposition was employed to achieve the relaxed real solution. The main problem is that the signs of the relaxed continuous solution are mixed. Such results may deviate severely from the true solution, which has lead to significant semantic loss. Moreover, eigenvalue decomposition confronts singularity problem when the dimension of the data is larger than the sample size. To address these problems, we propose a novel method named Nonnegative Sparse Locality Preserving Hashing (NSLPH). Nonnegative and sparse constraints are imposed for a more accurate solution which preserves semantic information well. Then, we have applied nonnegative quadratic programming and multiplicative updating to solve the optimization problem, which successfully avoids the singularity problem of the eigenvalue decomposition. The extensive experiments presented in this paper demonstrate that the proposed approach outperforms the state-of-the-art algorithms.
ER  - 

TY  - JOUR
T1  - A top-down information theoretic word clustering algorithm for phrase recognition
JO  - Information Sciences
VL  - 275
IS  - 
SP  - 213
EP  - 225
PY  - 2014/8/10/
T2  - 
AU  - Wu, Yu-Chieh
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2014.02.033
UR  - http://www.sciencedirect.com/science/article/pii/S002002551400139X
KW  - Large-scale word clustering
KW  - Phrase chunking
KW  - Support vector machine
AB  - Abstract
Semi-supervised machine learning methods have the features of both, integrating labeled and unlabeled training data. In most structural problems, such as natural language processing and image processing, developing labeled data for a specific domain requires considerable amount of human resources. In this paper, we present a cluster-based method to fuse labeled training and unlabeled raw data. We design a top-down divisive clustering algorithm that ensures maximal information gain in the use of unlabeled data via clustering similar words. To implement this idea, we design a top-down iterative K-means clustering algorithm to merge word clusters. Differently, the derived term groups are then encoded as new features for the supervised learners in order to improve the coverage of lexical information. Without additional training data or external materials, this approach yields state-of-the-art performance on the shallow parsing and base-chunking benchmark datasets (94.50 and 93.12 in F(β) rates).
ER  - 

TY  - JOUR
T1  - Analyzing firm-specific social media and market: A stakeholder-based event analysis framework
JO  - Decision Support Systems
VL  - 67
IS  - 
SP  - 30
EP  - 39
PY  - 2014/11//
T2  - 
AU  - Jiang, Shan
AU  - Chen, Hsinchun
AU  - Nunamaker, Jay F.
AU  - Zimbra, David
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2014.08.001
UR  - http://www.sciencedirect.com/science/article/pii/S016792361400205X
KW  - Social media
KW  - Stakeholder
KW  - Community identification
KW  - Market prediction
AB  - Abstract
Discussion content in firm-specific social media helps managers understand stakeholders' concerns and make informed decisions. Despite such benefits, the over-abundance of information online makes it difficult to identify and focus on the most important stakeholder groups. In this study, we propose a novel stakeholder-based event analysis framework that uses online stylometric analysis to segment the forum participants by stakeholder groups, and partitions their messages into different time periods of major firm events to examine how important stakeholders evolve over time. With this approach, we identified stakeholder groups from a sample of six companies in the petrochemical and banking industries, using more than 500,000 online message postings. To evaluate the proposed system, we conducted market prediction within the identified groups, and compared the prediction performance with traditional approaches that did not account for stakeholder groups or events. Results showed that some stakeholder groups identified by our system had stronger relationships with firms' market performance, compared to the entire set of web forum participants. Incorporating event-induced temporal dynamics further improved the prediction performance.
ER  - 

TY  - JOUR
T1  - Independent component analysis for near-synonym choice
JO  - Decision Support Systems
VL  - 55
IS  - 1
SP  - 146
EP  - 155
PY  - 2013/4//
T2  - 
AU  - Yu, Liang-Chih
AU  - Chien, Wei-Nan
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2012.12.038
UR  - http://www.sciencedirect.com/science/article/pii/S0167923613000080
KW  - Near-synonym choice
KW  - Independent component analysis
KW  - Information retrieval
KW  - Natural language processing
AB  - Abstract
Despite their similar meanings, near-synonyms may have different usages in different contexts, and the development of algorithms that can verify whether near-synonyms do match their given contexts has been the focus of increasing concern. Such algorithms have many applications such as query expansion for information retrieval (IR), alternative word selection for writing support systems, and (near-)duplicate detection for text summarization. In this paper, we propose a framework that incorporates latent semantic analysis (LSA) and independent component analysis (ICA) to automatically select suitable near-synonyms according to the given context. LSA is used to discover useful latent features that do not frequently occur in the contexts of near-synonyms, and ICA is used to estimate a set of independent components by minimizing the dependence between features. An SVM classifier is then trained with the independent components for best near-synonym prediction. In experiments, we evaluate the proposed method on both Chinese and English sentences, and compare its performance to state-of-the-art supervised and unsupervised methods. Experimental results show that training on the independent components that contain useful contextual features with minimized term dependence can improve the classifiers' ability to discriminate among near-synonyms, thus yielding better performance.
ER  - 

TY  - JOUR
T1  - Estimating Traffic Flow Profiles According to a Relative Attractiveness Factor
JO  - Procedia - Social and Behavioral Sciences
VL  - 54
IS  - 
SP  - 1115
EP  - 1124
PY  - 2012/10/4/
T2  - Proceedings of EWGT2012 - 15th Meeting of the EURO Working Group on Transportation, September 2012, Paris
AU  - Caceres, Noelia
AU  - Romero, Luis M.
AU  - Benitez, Francisco G.
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2012.09.826
UR  - http://www.sciencedirect.com/science/article/pii/S1877042812042887
KW  - Traffic flow estimates
KW  - Clustering algorithms
KW  - Attractiveness factor
AB  - Traffic flow estimates play a key role for strategic and operational planning of transport networks. Although the amplitude and peak times in flows change from location to location, some consistent patterns emerge across a region. Clustering solutions appear as a powerful tool to reveal hidden trends that can easily be applied on historical traffic data to estimate traffic flows. However, these historical data traditionally are collected by detectors on only a limited number of road sections. This communication presents a methodology for estimating traffic flows using road features as clustering variables, so that it can be applied to any road section. In particular, a factor related to the attractiveness of road sections, in terms of characteristics of nearby areas, will be used to cluster road sections, deriving typical flow profiles of the resulting groups. To obtain these typical profiles, data collected by permanent detectors on a broad geographic distribution of sites across the Spanish road network have been studied. Then the flow prediction procedure for a given location is based on obtaining its attractiveness factor, finding its best match, and associating the typical flow pattern of such a group (weighted by a correction factor) to the location. The results show that the methodology make good use of historical data and, in most cases, the times of the main peaks are approximately determined. Although the prediction accuracy in the amplitude of the curves varies somewhat from location to location, the accuracy is acceptable for roads classified into groups with better similarity measurements. The applicability of the procedure to any road location makes this alternative attractive for practical applications when no detector data is available, besides no previous traffic information at the desired location is required to obtain its flow profile.
ER  - 

TY  - JOUR
T1  - Image representation using Laplacian regularized nonnegative tensor factorization
JO  - Pattern Recognition
VL  - 44
IS  - 10–11
SP  - 2516
EP  - 2526
PY  - 2011/10//
Y2  - 2011/11//
T2  - Semi-Supervised Learning for Visual Content Analysis and Understanding
AU  - Wang, Can
AU  - He, Xiaofei
AU  - Bu, Jiajun
AU  - Chen, Zhengguang
AU  - Chen, Chun
AU  - Guan, Ziyu
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2011.03.021
UR  - http://www.sciencedirect.com/science/article/pii/S0031320311001257
KW  - Image representation
KW  - Image clustering
KW  - Tensor
KW  - Graph Laplacian
KW  - Manifold
AB  - Tensor provides a better representation for image space by avoiding information loss in vectorization. Nonnegative tensor factorization (NTF), whose objective is to express an n-way tensor as a sum of k rank-1 tensors under nonnegative constraints, has recently attracted a lot of attentions for its efficient and meaningful representation. However, NTF only sees Euclidean structures in data space and is not optimized for image representation as image space is believed to be a sub-manifold embedded in high-dimensional ambient space. To avoid the limitation of NTF, we propose a novel Laplacian regularized nonnegative tensor factorization (LRNTF) method for image representation and clustering in this paper. In LRNTF, the image space is represented as a 3-way tensor and we explicitly consider the manifold structure of the image space in factorization. That is, two data points that are close to each other in the intrinsic geometry of image space shall also be close to each other under the factorized basis. To evaluate the performance of LRNTF in image representation and clustering, we compare our algorithm with NMF, NTF, NCut and GNMF methods on three standard image databases. Experimental results demonstrate that LRNTF achieves better image clustering performance, while being more insensitive to noise.
ER  - 

TY  - JOUR
T1  - Nonlinear nonnegative matrix factorization based on Mercer kernel construction
JO  - Pattern Recognition
VL  - 44
IS  - 10–11
SP  - 2800
EP  - 2810
PY  - 2011/10//
Y2  - 2011/11//
T2  - Semi-Supervised Learning for Visual Content Analysis and Understanding
AU  - Pan, Binbin
AU  - Lai, Jianhuang
AU  - Chen, Wen-Sheng
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2011.03.023
UR  - http://www.sciencedirect.com/science/article/pii/S0031320311001270
KW  - Nonnegative matrix factorization
KW  - Mercer kernel
KW  - Kernel mapping
KW  - Face recognition
AB  - Generalizations ofnonnegative matrix factorization (NMF) in kernel feature space, such as projected gradient kernel NMF (PGKNMF) and polynomial Kernel NMF (PNMF), have been developed for face and facial expression recognition recently. However, these existing kernel NMF approaches cannot guarantee the nonnegativity of bases in kernel feature space and thus are essentially semi-NMF methods. In this paper, we show that nonlinear semi-NMF cannot extract the localized components which offer important information in object recognition. Therefore, nonlinear NMF rather than semi-NMF is needed to be developed for extracting localized component as well as learning the nonlinear structure. In order to address the nonlinear problem of NMF and the semi-nonnegative problem of the existing kernel NMF methods, we develop the nonlinear NMF based on a self-constructed Mercer kernel which preserves the nonnegative constraints on both bases and coefficients in kernel feature space. Experimental results in face and expressing recognition show that the proposed approach outperforms the existing state-of-the-art kernel methods, such as KPCA, GDA, PNMF and PGKNMF.
ER  - 

TY  - JOUR
T1  - Improving Analytics in Urban Water Management: A Spectral Clustering-based Approach for Leakage Localization
JO  - Procedia - Social and Behavioral Sciences
VL  - 108
IS  - 
SP  - 235
EP  - 248
PY  - 2014/1/8/
T2  - Operational Research for Development, Sustainability and Local Economies
AU  - Candelieri, A.
AU  - Conti, D.
AU  - Archetti, F.
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2013.12.834
UR  - http://www.sciencedirect.com/science/article/pii/S1877042813054748
KW  - spectral clustering
KW  - partition clustering
KW  - leakage localization
KW  - urban water systems
KW  - water distribution network management
AB  - Abstract
Worldwide growing water demand has been forcing utilities to successfully manage their costs. Contemporarily, within an era of tight budgets in most economic and social sectors, it affects also Water Distribution Networks (WDN). So, an efficient urban water management is needed to get a balance between consumer satisfaction and infrastructural assets inherent to WDN. Particular case is referred to pipe networks which suffer for frequent leaks, failures and service disruptions. The ensuing costs due to inspection, repair and replacement, are a significant part of operational expenses and give rise to difficult decision making. Recently, the goal regarding the improvement of the traditional leakage management process through the development of analytical leakage localization tools has been brought to the forefront leading to the proposal of several approaches. The basis of all methods relies on the fact that leaks can be detected correlating changes in flow to the output of a simulation model whose parameters are related to both location and severity of the leak.

This paper, starting from a previous work of the authors, shows how the critical phases of leak localization can be accomplished through a combination of hydraulic simulation and clustering. The research deals with the benefits provided by Spectral Clustering which is usually adopted for network analysis tasks (e.g., community or sub-network discovery). A transformation from a data points dataset, consisting of leakage scenarios simulated through a hydraulic simulation model, to a similarity graph is presented. Spectral Clustering is then applied on the similarity graph and results are compared with those provided by traditional clustering techniques on the original data points dataset. The proposed spectral approach proved to be more effective with respect to traditional clustering, having a better performance to analytically localize leaks in a water distribution network and, consequently, reducing costs for intervention, inspection and rehabilitation.
ER  - 

TY  - JOUR
T1  - On-line learning parts-based representation via incremental orthogonal projective non-negative matrix factorization
JO  - Signal Processing
VL  - 93
IS  - 6
SP  - 1608
EP  - 1623
PY  - 2013/6//
T2  - Special issue on Machine Learning in Intelligent Image Processing
AU  - Wang, Dong
AU  - Lu, Huchuan
SN  - 0165-1684
DO  - http://dx.doi.org/10.1016/j.sigpro.2012.07.015
UR  - http://www.sciencedirect.com/science/article/pii/S0165168412002459
KW  - NMF
KW  - IOPNMF
KW  - Incremental learning
KW  - On-line learning
KW  - Parts-based representation
KW  - Visual tracking
KW  - Occlusion handling
AB  - This paper presents a novel incremental orthogonal projective non-negative matrix factorization (IOPNMF) algorithm, which is aimed to learn a parts-based subspace that reveals dynamic data streams. By assuming that the newly added samples only affect basis vectors but do not affect the coefficients of old samples, we propose an objective function for on-line learning and then present a multiplicative update rule to solve it. Compared with other non-negative matrix factorization (NMF) methods, our algorithm can guarantee to learn a linear parts-based subspace in an on-line fashion, which may facilitate some real applications. The facial analysis experiment shows that our IOPNMF method learns parts-based components successfully. In addition, we present an effective tracking method by integrating the IOPNMF method, the idea of sparse representation and the domain information of object tracking. The proposed tracker explicitly takes partial occlusion and mis-alignment into account for appearance model update and object tracking. The experimental results on some challenging image sequences demonstrate the proposed tracking algorithm performs favorably against several state-of-the-art methods.
ER  - 

TY  - JOUR
T1  - A knowledge centric methodology for dental implant technology assessment using ontology based patent analysis and clinical meta-analysis
JO  - Advanced Engineering Informatics
VL  - 28
IS  - 2
SP  - 153
EP  - 165
PY  - 2014/4//
T2  - 
AU  - Trappey, Charles V.
AU  - Trappey, Amy J.C.
AU  - Peng, Hsin-Yi
AU  - Lin, Li-Deh
AU  - Wang, Tong-Mei
SN  - 1474-0346
DO  - http://dx.doi.org/10.1016/j.aei.2014.03.001
UR  - http://www.sciencedirect.com/science/article/pii/S1474034614000172
KW  - Patent analysis
KW  - Ontology schema
KW  - Meta-analysis
KW  - Clinical trials
AB  - Abstract
The medical equipment industry has been one of the fastest growing sectors of the decade with predicted global sales reaching US$ 430 billion in 2017 [22]. During the period from 1995 to 2008, the patent applications in medical technology increased rapidly worldwide (World Intellectual Property Organization, 2012). Patent analysis, although useful in forecasting technology development trends, has posed a challenging analysis task since the volume and diversity of new patent applications has surpassed the ability of regular firms and research teams to process and identify relevant information. Further, medical related technologies rely on clinical trials to validate and gain regulatory approval for patient treatment even though patents, protecting the intellectual property rights of inventors, have been granted. This research focuses on developing a knowledge centric methodology and system to analyze and assess viable medical technology innovations and trends considering both patents and clinical reports. Specifically, the design innovations of dental implant connections are used as a case study. A novel and generic methodology combining ontology based patent analysis and clinical meta-analysis is developed to analyze and identify the most effective patented techniques in the dental implant field. The research establishes and verifies a computer supported analytical approach and system for the strategic prediction of medical technology development trends.
ER  - 

TY  - JOUR
T1  - Unsupervised data processing for classifier-based speech translator
JO  - Computer Speech & Language
VL  - 27
IS  - 2
SP  - 438
EP  - 454
PY  - 2013/2//
T2  - Special Issue on Speech-speech translation
AU  - Ettelaie, Emil
AU  - Georgiou, Panayiotis G.
AU  - Narayanan, Shrikanth S.
SN  - 0885-2308
DO  - http://dx.doi.org/10.1016/j.csl.2012.03.001
UR  - http://www.sciencedirect.com/science/article/pii/S0885230812000174
KW  - Speech to speech translation
KW  - Spoken language understanding
KW  - Concept classification
AB  - Concept classification has been used as a translation method and has shown notable benefits within the suite of speech-to-speech translation applications. However, the main bottleneck in achieving an acceptable performance with such classifiers is the cumbersome task of annotating large amounts of training data. Any attempt to develop a method to assist in, or to completely automate, data annotation needs a distance measure to compare sentences based on the concept they convey. Here, we introduce a new method of sentence comparison that is motivated from the translation point of view. In this method the imperfect translations produced by a phrase-based statistical machine translation system are used to compare the concepts of the source sentences. Three clustering methods are adapted to support the concept-base distance. These methods are applied to prepare groups of paraphrases and use them as training sets in concept classification tasks. The statistical machine translation is also used to enhance the training data for the classifier which is crucial when such data are sparse. Experiments show the effectiveness of the proposed methods.
ER  - 

TY  - JOUR
T1  - Character confidence based on N-best list for keyword spotting in online Chinese handwritten documents
JO  - Pattern Recognition
VL  - 47
IS  - 5
SP  - 1880
EP  - 1890
PY  - 2014/5//
T2  - 
AU  - Zhang, Heng
AU  - Wang, Da-Han
AU  - Liu, Cheng-Lin
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2013.12.001
UR  - http://www.sciencedirect.com/science/article/pii/S0031320313005189
KW  - Online Chinese handwritten documents
KW  - Keyword spotting
KW  - Posterior probability
KW  - N-best list
KW  - Confidence measure
KW  - Confusion network
AB  - Abstract
In keyword spotting from handwritten documents by text query, the word similarity is usually computed by combining character similarities, which are desired to approximate the logarithm of the character probabilities. In this paper, we propose to directly estimate the posterior probability (also called confidence) of candidate characters based on the N-best paths from the candidate segmentation-recognition lattice. On evaluating the candidate segmentation-recognition paths by combining multiple contexts, the scores of the N-best paths are transformed to posterior probabilities using soft-max. The parameter of soft-max (confidence parameter) is estimated from the character confusion network, which is constructed by aligning different paths using a string matching algorithm. The posterior probability of a candidate character is the summation of the probabilities of the paths that pass through the candidate character. We compare the proposed posterior probability estimation method with some reference methods including the word confidence measure and the text line recognition method. Experimental results of keyword spotting on a large database CASIA-OLHWDB of unconstrained online Chinese handwriting demonstrate the effectiveness of the proposed method.
ER  - 

TY  - JOUR
T1  - A graph-based multi-level linguistic representation for document understanding
JO  - Pattern Recognition Letters
VL  - 41
IS  - 
SP  - 93
EP  - 102
PY  - 2014/5/1/
T2  - Supervised and Unsupervised Classification Techniques and their Applications
AU  - Pinto, David
AU  - Gómez-Adorno, Helena
AU  - Vilariño, Darnes
AU  - Singh, Vivek Kumar
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2013.12.004
UR  - http://www.sciencedirect.com/science/article/pii/S0167865513004698
KW  - Text mining
KW  - Text representation
KW  - Graph-based representation
AB  - Abstract
Document understanding goal requires discovery of meaningful patterns in text, which in turn requires analyzing documents and extracting information useful for a purpose. The documents to be analyzed are expected to be represented in some way. It is true that different representations of the same piece of text might have different information extraction outcomes. Therefore, it is very important to propose a reliable text representation schema that may incorporate as many features as possible, and at the same time provides use of efficient document understanding algorithms. In this paper, we propose a graph-based representation of textual documents that employs different levels of formal representation of natural language. This schema takes into account different linguistic levels, such as lexical, morphological, syntactical and semantics. The representation schema proposed is accompanied with a proposal for a technique which allows to extract useful text patterns based on the idea of minimum paths in the graph. The efficiency of the representation schema proposed has been tested in one case of study (Question-Answering for machine Reading Evaluation – QA4MRE), and the results of experiments carried in it, are described. The results obtained show that the proposed graph-based multi-level linguistic representation schema may be successfully used in the broader framework of document understanding.
ER  - 

TY  - JOUR
T1  - Topic identification based on document coherence and spectral analysis
JO  - Information Sciences
VL  - 181
IS  - 18
SP  - 3783
EP  - 3797
PY  - 2011/9/15/
T2  - 
AU  - D’hondt, Joris
AU  - Verhaegen, Paul-Armand
AU  - Vertommen, Joris
AU  - Cattrysse, Dirk
AU  - Duflou, Joost R.
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2011.04.044
UR  - http://www.sciencedirect.com/science/article/pii/S0020025511002258
KW  - Topic identification
KW  - Spectral theory
KW  - Text mining
AB  - In a world with vast information overload, well-optimized retrieval of relevant information has become increasingly important. Dividing large, multiple topic spanning documents into sets of coherent subdocuments facilitates the information retrieval process. This paper presents a novel technique to automatically subdivide a textual document into consistent components based on a coherence quantification function. This function is based on stem or term chains linking document entities, such as sentences or paragraphs, based on the reoccurrences of stems or terms. Applying this function on a document results in a coherence graph of the document linking its entities. Spectral graph partitioning techniques are used to divide this coherence graph into a number of subdocuments. A novel technique is introduced to obtain the most suitable number of subdocuments. These subdocuments are an aggregation of (not necessarily adjacent) entities. Performance tests are conducted in test environments based on standardized datasets to prove the algorithm’s capabilities. The relevance of these techniques for information retrieval and text mining is discussed.
ER  - 

TY  - JOUR
T1  - A novel ant-based clustering algorithm using the kernel method
JO  - Information Sciences
VL  - 181
IS  - 20
SP  - 4658
EP  - 4672
PY  - 2011/10/15/
T2  - Special Issue on Interpretable Fuzzy Systems
AU  - Zhang, Lei
AU  - Cao, Qixin
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2010.11.005
UR  - http://www.sciencedirect.com/science/article/pii/S0020025510005505
KW  - Ant-based clustering
KW  - Kernel
KW  - Swarm intelligence
KW  - Kernel principal component analysis
AB  - A novel ant-based clustering algorithm integrated with the kernel (ACK) method is proposed. There are two aspects to the integration. First, kernel principal component analysis (KPCA) is applied to modify the random projection of objects when the algorithm is run initially. This projection can create rough clusters and improve the algorithm’s efficiency. Second, ant-based clustering is performed in the feature space rather than in the input space. The distance between the objects in the feature space, which is calculated by the kernel function of the object vectors in the input space, is applied as a similarity measure. The algorithm uses an ant movement model in which each object is viewed as an ant. The ant determines its movement according to the fitness of its local neighbourhood. The proposed algorithm incorporates the merits of kernel-based clustering into ant-based clustering. Comparisons with other classic algorithms using several synthetic and real datasets demonstrate that ACK method exhibits high performance in terms of efficiency and clustering quality.
ER  - 

TY  - JOUR
T1  - A short text modeling method combining semantic and statistical information
JO  - Information Sciences
VL  - 180
IS  - 20
SP  - 4031
EP  - 4041
PY  - 2010/10/15/
T2  - 
AU  - Wenyin, Liu
AU  - Quan, Xiaojun
AU  - Feng, Min
AU  - Qiu, Bite
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2010.06.021
UR  - http://www.sciencedirect.com/science/article/pii/S0020025510002823
KW  - Text similarity
KW  - Short text similarity
KW  - Information retrieval
KW  - Query expansion
KW  - Text mining
KW  - Question answering
AB  - A novel modeling method for a collection of short text snippets is presented in this paper to measure the similarity between pairs of snippets. The method takes account of both the semantic and statistical information within the short text snippets, and consists of three steps. Given a set of raw short text snippets, it first establishes the initial similarity between words by using a lexical database. The method then iteratively calculates both word similarity and short text similarity. Finally, a proximity matrix is constructed based on word similarity and used to convert the raw text snippets into vectors. Word similarity and text clustering experiments show that the proposed short text modeling method improves the performance of existing text-related information retrieval (IR) techniques.
ER  - 

TY  - JOUR
T1  - An improved mix framework for opinion leader identification in online learning communities
JO  - Knowledge-Based Systems
VL  - 43
IS  - 
SP  - 43
EP  - 51
PY  - 2013/5//
T2  - 
AU  - Li, Yanyan
AU  - Ma, Shaoqian
AU  - Zhang, Yonghe
AU  - Huang, Ronghuai
AU  - Kinshuk
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2013.01.005
UR  - http://www.sciencedirect.com/science/article/pii/S0950705113000099
KW  - Online learning communities
KW  - Opinion leader identification
KW  - User behaviour analysis
KW  - Topic modelling
KW  - Social network
AB  - With the widespread adoption of social media, online learning communities are perceived as a network of knowledge comprised of interconnected individuals with varying roles. Opinion leaders are important in social networks because of their ability to influence the attitudes and behaviours of others via their superior status, education, and social prestige. Many theories have been put forward to explain the formation, characteristics, and durability of social networks, but few address the issue of opinion leader identification. This paper proposes an improved mix framework for opinion leader identification in online learning communities. The framework is validated by an experimental study. By analysing textual content, user behaviour and time, this study ranked opinion leaders based on four distinguishing features: expertise, novelty, influence, and activity. Furthermore, the performances of opinion leaders were further investigated in terms of longevity and centrality. Experimental study on real datasets has shown that our framework effectively identifies opinion leaders in online learning communities.
ER  - 

TY  - JOUR
T1  - Analyzing future communities in growing citation networks
JO  - Knowledge-Based Systems
VL  - 69
IS  - 
SP  - 34
EP  - 44
PY  - 2014/10//
T2  - 
AU  - Jung, Sukhwan
AU  - Segev, Aviv
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2014.04.036
UR  - http://www.sciencedirect.com/science/article/pii/S095070511400166X
KW  - Community
KW  - Topic detection
KW  - Link prediction
KW  - Citation network
KW  - Community detection
AB  - Abstract
Citation networks contain temporal information about what researchers are interested in at a certain time. A community in such a network is built around either a renowned researcher or a common research field; either way, analyzing how the community will change in the future will give insight into the research trend in the future. The paper views the research community as a Social Web where the communication is through academic papers. The paper proposes methods to analyze how communities change over time in the citation network graph without additional external information and based on node and link prediction and community detection. Different combinations of the proposed methods are also analyzed. The identified communities are classified using key term labeling. Experiments show that the proposed methods can identify the changes in citation communities multiple years in the future with performance differing according to the analyzed time span. Furthermore, the method is shown to produce higher performance when analyzing communities to be disbanded and to be formed in the future.
ER  - 

TY  - JOUR
T1  - Robust predictive model for evaluating breast cancer survivability
JO  - Engineering Applications of Artificial Intelligence
VL  - 26
IS  - 9
SP  - 2194
EP  - 2205
PY  - 2013/10//
T2  - 
AU  - Park, Kanghee
AU  - Ali, Amna
AU  - Kim, Dokyoon
AU  - An, Yeolwoo
AU  - Kim, Minkoo
AU  - Shin, Hyunjung
SN  - 0952-1976
DO  - http://dx.doi.org/10.1016/j.engappai.2013.06.013
UR  - http://www.sciencedirect.com/science/article/pii/S0952197613001140
KW  - Machine learning
KW  - Semi-supervised learning
KW  - Breast cancer survivability
AB  - AbstractObjective
Many machine learning models have aided medical specialists in diagnosis and prognosis for breast cancer. Accuracy has been regarded as a primary measurement for the performance evaluation of the models, but stability which indicates the robustness of the performance to model parameter variation also becomes essential. A stable model is in practice of benefit to the medical specialists who may have little expertise in model tuning. The main purpose of this work is to address the importance of the stability of a model and to suggest one of such models.
Methods
A comparative study of three prominent machine learning models was carried out for the prognosis of breast-cancer survivability: support vector machines, artificial neural networks, and semi-supervised learning models.
Material
The surveillance, epidemiology, and end results database for breast cancer was used, which is known as the most comprehensive source of information on cancer incidence in the United States.
Results
The best performance was obtained from the semi-supervised learning model. It showed good overall accuracy and stability under model parameter variation. The sharpening procedure enhanced the stability of the model via the noise-reduction.
Conclusion
We suggest that semi-supervised learning model is a good candidate that medical professionals readily employ without consuming the time and effort for parameter searching for a specific model. The ease of use and faster time to results of the predictive model will eventually lead to the accurate and less-invasive prognosis for breast cancer patients.
ER  - 

TY  - JOUR
T1  - Evolving Fuzzy Min-max Neural Network for Outlier Detection
JO  - Procedia Computer Science
VL  - 45
IS  - 
SP  - 753
EP  - 761
PY  - 2015///
T2  - International Conference on Advanced Computing Technologies and Applications (ICACTA)
AU  - Upasani, Nilam
AU  - Om, Hari
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.03.148
UR  - http://www.sciencedirect.com/science/article/pii/S1877050915003841
KW  - Outlier detection
KW  - fuzzy logic
KW  - neural network
KW  - data mining
KW  - FNN ;FMN
KW  - Fuzzy Min-Max Neural Network ;
AB  - Abstract
Outlier detection is a complex task to perform because of the uncertainty involved in it. Fuzzy logic is more suitable for handling uncertainty. Many applications require real time outlier detection. Neural networks are good at real time operation, online adaption and efficient as they are massively parallel in nature. The hybridization of fuzzy and neural computing system is very promising, since they exactly tackle the situation associated with outliers. In this paper, a Fuzzy min-max neural network is used for outlier detection. In testing phase, a method is proposed for outlier detection which is based on majority voting. User has to define a threshold (t) and if the fuzzy membership value of test pattern in a hyper-box is below t then the pattern will be declared as an outlier with respect to the hyper-box. User should also define a parameter p which decides the percentage of hyper-boxes to be considered for voting a test pattern as an outlier. Experimentation is done on synthetic data and a standard database available on UCI Machine Learning Repository [19]. The proposed method has increased the recognition accuracy whereas the drawback is recall time increased as one more level of voting calculation with a serial time complexity of o(k) is added in the testing phase.
ER  - 

TY  - JOUR
T1  - SparseHC: A Memory-efficient Online Hierarchical Clustering Algorithm
JO  - Procedia Computer Science
VL  - 29
IS  - 
SP  - 8
EP  - 19
PY  - 2014///
T2  - 2014 International Conference on Computational Science
AU  - Nguyen, Thuy-Diem
AU  - Schmidt, Bertil
AU  - Kwoh, Chee-Keong
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2014.05.001
UR  - http://www.sciencedirect.com/science/article/pii/S1877050914001781
KW  - hierarchical clustering
KW  - memory-efficient clustering
KW  - sparse matrix
KW  - online algorithms
AB  - Abstract
Computing a hierarchical clustering of objects from a pairwise distance matrix is an important algorithmic kernel in computational science. Since the storage of this matrix requires quadratic space with respect to the number of objects, the design of memory-efficient approaches is of high importance to this research area. In this paper, we address this problem by presenting a memory-efficient online hierarchical clustering algorithm called SparseHC. SparseHC scans a sorted and possibly sparse distance matrix chunk-by-chunk. Meanwhile, a dendrogram is built by merging cluster pairs as and when the distance between them is determined to be the smallest among all remaining cluster pairs. The key insight used is that for finding the cluster pair with the smallest distance, it is unnecessary to complete the computation of all cluster pairwise distances. Partial information can be utilized to calculate a lower bound on cluster pairwise distances that are subsequently used for cluster distance comparison. Our experimental results show that SparseHC achieves a linear empirical memory complexity, which is a significant improvement compared to existing algorithms.
ER  - 

TY  - JOUR
T1  - Building trust from context similarity measures
JO  - Computer Standards & Interfaces
VL  - 36
IS  - 4
SP  - 792
EP  - 800
PY  - 2014/6//
T2  - Security in Information Systems: Advances and new Challenges.
AU  - Fernandez-Gago, Carmen
AU  - Agudo, Isaac
AU  - Lopez, Javier
SN  - 0920-5489
DO  - http://dx.doi.org/10.1016/j.csi.2013.12.012
UR  - http://www.sciencedirect.com/science/article/pii/S0920548913001864
KW  - Similarity networks
KW  - Trust model
AB  - Abstract
Trust is an essential feature of any system where entities have to collaborate. Trust can assist entities making decisions before establishing collaborations. It is desirable to simulate the behaviour of users as in social environments where they tend to trust users who have common interests or share some of their opinions, i.e., users similar to them. In this paper, we introduce the concept of context similarity among entities and derive a similarity network. Then, we define a trust model that allows us to establish trust along a path of entities. We validate our model in a proximity-based trust establishment scenario.
ER  - 

TY  - JOUR
T1  - Graph dual regularization non-negative matrix factorization for co-clustering
JO  - Pattern Recognition
VL  - 45
IS  - 6
SP  - 2237
EP  - 2250
PY  - 2012/6//
T2  - Brain Decoding
AU  - Shang, Fanhua
AU  - Jiao, L.C.
AU  - Wang, Fei
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2011.12.015
UR  - http://www.sciencedirect.com/science/article/pii/S0031320311005164
KW  - Low-rank matrix factorization
KW  - Non-negative matrix factorization (NMF)
KW  - Graph Laplacian
KW  - Graph dual regularization
KW  - Co-clustering
AB  - Low-rank matrix factorization is one of the most useful tools in scientific computing, data mining and computer vision. Among of its techniques, non-negative matrix factorization (NMF) has received considerable attention due to producing a parts-based representation of the data. Recent research has shown that not only the observed data are found to lie on a nonlinear low dimensional manifold, namely data manifold, but also the features lie on a manifold, namely feature manifold. In this paper, we propose a novel algorithm, called graph dual regularization non-negative matrix factorization (DNMF), which simultaneously considers the geometric structures of both the data manifold and the feature manifold. We also present a graph dual regularization non-negative matrix tri-factorization algorithm (DNMTF) as an extension of DNMF. Moreover, we develop two iterative updating optimization schemes for DNMF and DNMTF, respectively, and provide the convergence proofs of our two optimization schemes. Experimental results on UCI benchmark data sets, several image data sets and a radar HRRP data set demonstrate the effectiveness of both DNMF and DNMTF.
ER  - 

TY  - JOUR
T1  - LinkFCM: Relation integrated fuzzy c-means
JO  - Pattern Recognition
VL  - 46
IS  - 1
SP  - 272
EP  - 283
PY  - 2013/1//
T2  - 
AU  - Mei, Jian-Ping
AU  - Chen, Lihui
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2012.06.012
UR  - http://www.sciencedirect.com/science/article/pii/S0031320312002828
KW  - Clustering
KW  - Fuzzy c-means
KW  - Pairwise relation
KW  - Semi-supervised
KW  - Document categorization
AB  - Most existing fuzzy clustering approaches group objects in a dataset based on either a feature-vector representation of each object, or pairwise relationship representation between each pair of objects. However, when both forms of data representations from different descriptions are available for a given dataset, we believe that a dual and cooperative analysis of feature-vectors (vector data) and pair-wise relationships (relational data) is likely to gain a more comprehensive understanding on the characteristics of the dataset, based on which a better clustering result may be achieved. In this paper, we develop a new fuzzy clustering approach called LinkFCM, which integrates pair-wise relationships into fuzzy c-means vector data clustering. The objective function of LinkFCM consists of two different ways to measure the compactness of clusters with respect to vector data and relational data, respectively, so that clusters are formed by utilizing these two forms of data descriptions. Our experimental study shows that LinkFCM is able to produce good clustering results for real-world document datasets by effectively making use of both content of documents and links among documents. This demonstrates the great potential of the proposed approach for data clustering, where pair-wise relationships are available together with features that describe each object.
ER  - 

TY  - JOUR
T1  - A systematic approach for integrated trend analysis—The case of etching
JO  - Technological Forecasting and Social Change
VL  - 78
IS  - 3
SP  - 386
EP  - 407
PY  - 2011/3//
T2  - 
AU  - Wu, Feng-Shang
AU  - Hsu, Chun-Chi
AU  - Lee, Pei-Chun
AU  - Su, Hsin-Ning
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2010.08.006
UR  - http://www.sciencedirect.com/science/article/pii/S0040162510001885
KW  - Bibliometric analysis
KW  - Patent analysis
KW  - Text-mining
KW  - Trend analysis
KW  - Etching
AB  - Understanding technology development trends is of critical importance to countries, industries and enterprises to be sustainable in global competition. Attempts have been made to establish trend analysis by bibliometric and patent analyses. Also text-mining uncovers hidden and important information from structured or unstructured documents which serve as knowledge carriers. This study aims to provide a systematic approach for integrated trend analysis that takes into account bibliometric analysis, patent analysis and text-mining analysis. Etching is selected as the case study for integrating trend analysis method proposed in this study. Also, validity and applicability of the integrated analysis are evaluated.
ER  - 

TY  - JOUR
T1  - Literature-related discovery and innovation — update
JO  - Technological Forecasting and Social Change
VL  - 79
IS  - 4
SP  - 789
EP  - 800
PY  - 2012/5//
T2  - Contains Special Section: Innovation in India
AU  - Kostoff, Ronald N.
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2012.02.002
UR  - http://www.sciencedirect.com/science/article/pii/S004016251200039X
KW  - Literature-related discovery
KW  - Literature-Related Discovery and Innovation
KW  - Text mining
KW  - Multiple sclerosis
KW  - Discovery
KW  - Innovation
KW  - Disease prevention
KW  - Disease treatment
AB  - Literature-Related Discovery and Innovation (LRDI — formerly LRD — literature-related discovery) integrates 1) discovery generation from disparate literatures with 2) the wealth of knowledge contained in prior art to 3) potentially reverse chronic and infectious diseases and/or 4) potentially solve technical problems that appear intractable. This article describes the evolution of LRDI by the author and the insights gained/lessons learned over the past decade. To illustrate the potential power of LRDI, the article emphasizes the relationship between the results of our 2008 LRDI multiple sclerosis (MS) study and a recent demonstration of MS reversal.

Lessons learned from the six LRDI medical studies done so far include:⁎
The main operational problem in the author's LRDI approach is selecting the most important concepts from extremely large volumes of potential discovery retrieval. This is contrary to most published LRDI research, where the discovery focus is searching for rare events.
⁎
It is important to have topical specialist(s) working closely with information technologist(s); the topical specialist(s) applies judgment in selecting the most important concepts.
⁎
A functional form of the information retrieval query with proximity searching capability provides highly selective filtering for discovery retrieval and core prevention/treatment retrieval; the functional form of the query with proximity searching capability allows the use of full-text for discovery and core prevention/treatment.
⁎
Bibliographic coupling (identifying papers that share common references) combined with text-based relationships strengthens selection for potential discovery further.
⁎
Having ‘skin-in-the-game’ (being affected personally) relative to the medical outcome is a strong incentive to do whatever is necessary to solve the research problem.
⁎
Hormesis is critical to healing; relatively modest doses of stimuli tend to be beneficial, whereas relatively large doses may be harmful. The synergy of hormetic treatment doses produces effects larger than combinations of individual doses and requires smaller doses when combined; the synergy of hormetic doses allows conversion of megadoses of nutrients typically reported in lab/clinical studies to physiological (food-level) doses and associated increased safety.
⁎
Co-promoters (combinations of toxic stimuli required to produce disease symptoms) are extremely important for explaining seemingly conflicting results; if true co-promotion is present, elimination of one of the co-promoters may be adequate for removing symptoms, even though the overall problem persists.
⁎
Prior art (potential treatments already published in the literature but not pursued by mainline medicine) may have much to contribute to potentially solve many serious medical problems; much of prior art is overlooked, especially low-tech prior art (e.g., foods, food extracts, herbs, etc.).
⁎
Systemic and focused treatments are both necessary components of healing, but neither will be fully, or many times even partially, effective until the cause(s) is identified and removed. Any medical approach that involves administering treatments for chronic and infectious diseases without addressing the cause(s) results in a broad range of outcomes mainly involving substitution of one set of symptoms for another.
⁎
Past results of LRDI medical studies showed much overlap among preventatives/systemic treatments for different diseases. Differences will arise mainly in focused treatments, especially those involving high technology.
⁎
The central parameters to healing in much medical research are never identified nor reported. Many treatments require a combination of skilled practitioners, cause removal, and immune/neural/endocrine/circulatory systems to be healthy for full effectiveness, yet practitioner skill, degree of cause removal, and immune system et al. health are never reported. A lack of this information does not allow efficacy of different treatments to be compared. Reviews and meta-analyses that compare and draw conclusions about the effectiveness of these different treatments without the above critical information being reported are of extremely limited value and credibility.
⁎
Finally, the most important deficiency for fully reversing chronic and infectious diseases, as well as rapidly accelerating healing of injuries and wounds, is the credibility and integrity of the medical literature itself, especially in areas that concern commercial and government/political sensitivities. In the evaluation of many concepts that deviated from the norm, it was difficult to ascertain whether the difference was based on solid high-quality research, poor research, or deliberately skewed research.
ER  - 

TY  - JOUR
T1  - Hybridising harmony search with a Markov blanket for gene selection problems
JO  - Information Sciences
VL  - 258
IS  - 
SP  - 108
EP  - 121
PY  - 2014/2/10/
T2  - 
AU  - Shreem, Salam Salameh
AU  - Abdullah, Salwani
AU  - Nazri, Mohd Zakree Ahmad
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2013.10.012
UR  - http://www.sciencedirect.com/science/article/pii/S0020025513007378
KW  - Gene selection
KW  - Filter approach
KW  - Harmony search algorithm
KW  - Markov blanket
KW  - Wrapper approach
AB  - Abstract
Gene selection, which is a well-known NP-hard problem, is a challenging task that has been the subject of a large amount of research, especially in relation to classification tasks. This problem addresses the identification of the smallest possible set of genes that could achieve good predictive performance. Many gene selection algorithms have been proposed; however, because the search space increases exponentially with the number of genes, finding the best possible approach for a solution that would limit the search space is crucial. Metaheuristic approaches have the ability to discover a promising area without exploring the whole solution space. Hence, we propose a new method that hybridises the Harmony Search Algorithm (HSA) and the Markov Blanket (MB), called HSA-MB, for gene selection in classification problems. In this proposed approach, the HSA (as a wrapper approach) improvises a new harmony that is passed to the MB (treated as a filter approach) for further improvement. The addition and deletion of operators based on gene ranking information is used in the MB algorithm to further improve the harmony and to fine-tune the search space. The HSA-MB algorithm method works especially well on selected genes with higher correlation coefficients based on symmetrical uncertainty. Ten microarray datasets were experimented on, and the results demonstrate that the HSA-MB has a performance that is comparable to state-of-the-art approaches. HSA-MB yields very small sets of genes while preserving the classification accuracy. The results suggest that HSA-MB has a high potential for being an alternative method of gene selection when applied to microarray data and can be of benefit in clinical practice.
ER  - 

TY  - JOUR
T1  - Analysis of two-mode network data using nonnegative matrix factorization
JO  - Social Networks
VL  - 33
IS  - 3
SP  - 201
EP  - 210
PY  - 2011/7//
T2  - 
AU  - Brusco, Michael
SN  - 0378-8733
DO  - http://dx.doi.org/10.1016/j.socnet.2011.05.001
UR  - http://www.sciencedirect.com/science/article/pii/S0378873311000281
KW  - Two-mode networks
KW  - Nonnegative matrix factorization
KW  - Algorithm
AB  - Nonnegative matrix factorization has been offered as a fast and effective method for analyzing nonnegative two-mode proximity data. The goal is to structurally represent a nonnegative proximity matrix as the product of two lower-dimensional nonnegative matrices. Goodness of fit is typically measured as the sum of the squared deviations between the observed matrix elements and the estimated elements yielded by the product of the matrix factors. The preservation of nonnegativity of the factors has been touted as a major practical advantage over comparable decomposition methods (e.g., principal component analysis, singular-value decomposition, spectral analysis) because of its propensity for a more coherent additive interpretation. We provide descriptions of the nonnegative matrix factorization model and a rescaled gradient descent algorithm for estimating the factors. A small numerical example is provided along with application to three network matrices from the empirical literature.
ER  - 

TY  - JOUR
T1  - A novel combination of Particle Swarm Optimization and Genetic Algorithm for Pareto optimal design of a five-degree of freedom vehicle vibration model
JO  - Applied Soft Computing
VL  - 13
IS  - 5
SP  - 2577
EP  - 2591
PY  - 2013/5//
T2  - 
AU  - Mahmoodabadi, M.J.
AU  - Safaie, A. Adljooy
AU  - Bagheri, A.
AU  - Nariman-zadeh, N.
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2012.11.028
UR  - http://www.sciencedirect.com/science/article/pii/S1568494612005121
KW  - Hybrid algorithms
KW  - Particle Swarm Optimization
KW  - Genetic Algorithm
KW  - Single-objective problems
KW  - Multi-objective problems
KW  - Vehicle vibration model
AB  - In this paper, at first, a novel combination of Particle Swarm Optimization (PSO) and Genetic Algorithm (GA) is introduced. This hybrid algorithm uses the operators such as mutation, traditional or classical crossover, multiple-crossover, and PSO formula. The selection of these operators in each iteration for each particle or chromosome is based on a fuzzy probability. The performance of the proposed hybrid algorithm for solving both single and multi-objective optimization problems is challenged by using of some well-known benchmark problems. Obtained numerical results are compared with those of other optimization algorithms. At the end, the proposed multi-objective hybrid algorithm is used for the Pareto optimal design of a five-degree of freedom vehicle vibration model. The comparison of the obtained results with it in the literature demonstrates the superiority of this work.
ER  - 

TY  - JOUR
T1  - A novel incremental conceptual hierarchical text clustering method using CFu-tree
JO  - Applied Soft Computing
VL  - 27
IS  - 
SP  - 269
EP  - 278
PY  - 2015/2//
T2  - 
AU  - Peng, Tao
AU  - Liu, Lu
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2014.11.015
UR  - http://www.sciencedirect.com/science/article/pii/S1568494614005766
KW  - Text clustering
KW  - CFu-tree
KW  - Comparison Variation (CV)
KW  - Incremental hierarchical clustering
AB  - Abstract
As a data mining method, clustering, which is one of the most important tools in information retrieval, organizes data based on unsupervised learning which means that it does not require any training data. But, some text clustering algorithms cannot update existing clusters incrementally and, instead, have to recompute a new clustering from scratch. In view of above, this paper presents a novel down-top incremental conceptual hierarchical text clustering approach using CFu-tree (ICHTC-CF) representation, which starts with each item as a separate cluster. Term-based feature extraction is used for summarizing a cluster in the process. The Comparison Variation measure criterion is also adopted for judging whether the closest pair of clusters can be merged or a previous cluster can be split. And, our incremental clustering method is not sensitive to the input data order. Experimental results show that the performance of our method outperforms k-means, CLIQUE, single linkage clustering and complete linkage clustering, which indicate our new technique is efficient and feasible.
ER  - 

TY  - JOUR
T1  - Assessing the severity of phishing attacks: A hybrid data mining approach
JO  - Decision Support Systems
VL  - 50
IS  - 4
SP  - 662
EP  - 672
PY  - 2011/3//
T2  - Enterprise Risk and Security Management: Data, Text and Web Mining
AU  - Chen, Xi
AU  - Bose, Indranil
AU  - Leung, Alvin Chung Man
AU  - Guo, Chenhui
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2010.08.020
UR  - http://www.sciencedirect.com/science/article/pii/S0167923610001442
KW  - Financial loss
KW  - Phishing
KW  - Risk
KW  - Supervised classification
KW  - Text phrase extraction
KW  - Variable importance
AB  - Phishing is an online crime that increasingly plagues firms and their consumers. We assess the severity of phishing attacks in terms of their risk levels and the potential loss in market value suffered by the targeted firms. We analyze 1030 phishing alerts released on a public database as well as financial data related to the targeted firms using a hybrid method that predicts the severity of the attack with up to 89% accuracy using text phrase extraction and supervised classification. Our research identifies some important textual and financial variables that impact the severity of the attacks and potential financial loss.
ER  - 

TY  - JOUR
T1  - Semi-structured Documents Mining: A Review and Comparison
JO  - Procedia Computer Science
VL  - 22
IS  - 
SP  - 330
EP  - 339
PY  - 2013///
T2  - 17th International Conference in Knowledge Based and Intelligent Information and Engineering Systems - KES2013
AU  - Madani, Amina
AU  - Boussaid, Omar
AU  - Zegour, Djamel Eddine
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2013.09.110
UR  - http://www.sciencedirect.com/science/article/pii/S1877050913009034
KW  - Semi-structured documents
KW  - documents mining
KW  - clustering
KW  - association
KW  - classification
KW  - structure mining
KW  - content mining
AB  - Abstract
The number of semi-structured documents that is produced is steadily increasing. Thus, it will be essential for discovering new knowledge from them. In this survey paper, we review popular semi-structured documents mining approaches (structure alone and both structure and content). We provide a brief description of each technique as well as efficient algorithms for implementing the technique and comparing them using different comparison criteria.
ER  - 

TY  - JOUR
T1  - Estimation of Subjects that are Distributed at a High Density from Non-pixel Information Applying NMF
JO  - Procedia Computer Science
VL  - 24
IS  - 
SP  - 249
EP  - 260
PY  - 2013///
T2  - 17th Asia Pacific Symposium on Intelligent and Evolutionary Systems, IES2013
AU  - Kubo, Yusuke
AU  - Kubo, Masao
AU  - Sato, Hiroshi
AU  - Namatame, Akira
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2013.10.048
UR  - http://www.sciencedirect.com/science/article/pii/S1877050913011903
KW  - nonnegative matrix factorization
KW  - collective intelligence
KW  - social sensing
KW  - social mining
KW  - GIS
AB  - Abstract
We propose a method that estimates locations of subjects that has attracted crowd's attention with high accuracy from a large number of digital photographs. Recently, attempts that observe real world from a large number of data, assuming person as a sensor, have been very active. In the attempts, there are studies that try to estimate subjects attracting the crowd's attention in real time by quickly collecting a large number of photographs. The studies are focused on the tendency that a photograph is taken when a photographer comes upon an event that attracts its interest. Some of the proposed methods realize high availability by using only photographing, which includes information about location and azimuth of the camera and it is automatically embedded into photograph. Date size of photographing information is very small compared to that of pixel information, hence the proposed method reduce load on a communication infrastructure. However, there is a problem in accuracy when subjects are distributed at a high density. When there are many attractive subjects in a small region, the traditional works cannot find them because of their sequential search strategy. The proposed method applies non-negative matrix factorization (NMF) to subject's estimation, and the method is able to estimate subjects accurately even in a case that it is difficult with the conventional methods.
ER  - 

TY  - JOUR
T1  - Dual Exclusive Partition in Fuzzy CoDoK and SCAD-based Fuzzy Co-clustering
JO  - Procedia Computer Science
VL  - 22
IS  - 
SP  - 800
EP  - 809
PY  - 2013///
T2  - 17th International Conference in Knowledge Based and Intelligent Information and Engineering Systems - KES2013
AU  - Oh, Chi-Hyon
AU  - Honda, Katsuhiro
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2013.09.162
UR  - http://www.sciencedirect.com/science/article/pii/S1877050913009551
KW  - Co-clustering
KW  - Fuzzy clustering
KW  - Exclusive Partition
AB  - Abstract
Fuzzy co-clustering is a basic technique for revealing intrinsic co-cluster structures from cooccurrence information among objects and items. In most of fuzzy co-clustering algorithms, objects and items are partitioned based on different constraints. Objects are forced to be exclusively partitioned like as Fuzzy c-Means (FCM), while item memberships often represent just the relative significance of items in each cluster, i.e., items can be shared by multiple clusters. In a previous work, exclusive partition of items were achieved by introducing a penalty term in Fuzzy Clustering for Categorical Multivariate data (FCCM), which is an FCM-type co-clustering with entropy regularization mechanism. In this paper, the applicability of dual exclusive partition of objects and items are discussed in the frameworks of Fuzzy CoDoK and SCAD-based fuzzy co-clustering.
ER  - 

TY  - JOUR
T1  - Towards group behavioral reason mining
JO  - Expert Systems with Applications
VL  - 39
IS  - 16
SP  - 12671
EP  - 12682
PY  - 2012/11/15/
T2  - 
AU  - Zheng, Hai-Tao
AU  - Jiang, Yong
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2012.05.016
UR  - http://www.sciencedirect.com/science/article/pii/S0957417412007142
KW  - Behavior mining
KW  - Group behavior model
KW  - Group behavioral reason mining
KW  - BRMA algorithm
AB  - Many studies have been proposed to research behavior mining. However, in many cases, the aim of exploring behaviors is to exploit their motivations. Based on discovered behavioral reasons, we are able to conduct subsequent actions to impel or impede those behaviors. Although some logical approaches have been proposed to derive an explanation for a set of observations using abductive reasoning, there are few methods that take a statistical approach for group behavioral reason mining. Statistical methods enable us to discover behavioral reasons automatically in an uncertain situation. To address this issue, we propose a computational model and a family of algorithms called BRMA (Behavioral Reason Mining Algorithm), which exploits various distance functions to discover group behavioral reasons in three statistical ways. The BRMA algorithms have low time complexity and run extremely fast. Based on two datasets, we conducted comprehensive experiments to evaluate the effectiveness of the BRMA algorithms. The empirical experimental results indicate that the BRMA algorithms have a relatively high accuracy, and that among the BRMA family, BRMAMP outperforms BRMAAverage and BRMAWeight.
ER  - 

TY  - JOUR
T1  - Non-negative matrix factorization of multimodal MRI, fMRI and phenotypic data reveals differential changes in default mode subnetworks in ADHD
JO  - NeuroImage
VL  - 102, Part 1
IS  - 
SP  - 207
EP  - 219
PY  - 2014/11/15/
T2  - Multimodal Data Fusion
AU  - Anderson, Ariana
AU  - Douglas, Pamela K.
AU  - Kerr, Wesley T.
AU  - Haynes, Virginia S.
AU  - Yuille, Alan L.
AU  - Xie, Jianwen
AU  - Wu, Ying Nian
AU  - Brown, Jesse A.
AU  - Cohen, Mark S.
SN  - 1053-8119
DO  - http://dx.doi.org/10.1016/j.neuroimage.2013.12.015
UR  - http://www.sciencedirect.com/science/article/pii/S1053811913012196
KW  - fMRI
KW  - Multimodal data
KW  - NMF
KW  - ADHD
KW  - Phenotype
KW  - MRI
KW  - Latent variables
KW  - Biomarkers
KW  - Sparsity
KW  - Machine learning
KW  - Topic modeling
KW  - Attention deficit
KW  - Default mode
AB  - Abstract
In the multimodal neuroimaging framework, data on a single subject are collected from inherently different sources such as functional MRI, structural MRI, behavioral and/or phenotypic information. The information each source provides is not independent; a subset of features from each modality maps to one or more common latent dimensions, which can be interpreted using generative models. These latent dimensions, or “topics,” provide a sparse summary of the generative process behind the features for each individual. Topic modeling, an unsupervised generative model, has been used to map seemingly disparate features to a common domain. We use Non-Negative Matrix Factorization (NMF) to infer the latent structure of multimodal ADHD data containing fMRI, MRI, phenotypic and behavioral measurements. We compare four different NMF algorithms and find that the sparsest decomposition is also the most differentiating between ADHD and healthy patients. We identify dimensions that map to interpretable, recognizable dimensions such as motion, default mode network activity, and other such features of the input data. For example, structural and functional graph theory features related to default mode subnetworks clustered with the ADHD-Inattentive diagnosis. Structural measurements of the default mode network (DMN) regions such as the posterior cingulate, precuneus, and parahippocampal regions were all related to the ADHD-Inattentive diagnosis. Ventral DMN subnetworks may have more functional connections in ADHD-I, while dorsal DMN may have less. ADHD topics are dependent upon diagnostic site, suggesting diagnostic differences across geographic locations. We assess our findings in light of the ADHD-200 classification competition, and contrast our unsupervised, nominated topics with previously published supervised learning methods. Finally, we demonstrate the validity of these latent variables as biomarkers by using them for classification of ADHD in 730 patients. Cumulatively, this manuscript addresses how multimodal data in ADHD can be interpreted by latent dimensions.
ER  - 

TY  - JOUR
T1  - Business intelligence in banking: A literature analysis from 2002 to 2013 using text mining and latent Dirichlet allocation
JO  - Expert Systems with Applications
VL  - 42
IS  - 3
SP  - 1314
EP  - 1324
PY  - 2015/2/15/
T2  - 
AU  - Moro, Sérgio
AU  - Cortez, Paulo
AU  - Rita, Paulo
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2014.09.024
UR  - http://www.sciencedirect.com/science/article/pii/S0957417414005636
KW  - Banking
KW  - Business intelligence
KW  - Data mining
KW  - Text mining
KW  - Decision support systems
AB  - Abstract
This paper analyzes recent literature in the search for trends in business intelligence applications for the banking industry. Searches were performed in relevant journals resulting in 219 articles published between 2002 and 2013. To analyze such a large number of manuscripts, text mining techniques were used in pursuit for relevant terms on both business intelligence and banking domains. Moreover, the latent Dirichlet allocation modeling was used in order to group articles in several relevant topics. The analysis was conducted using a dictionary of terms belonging to both banking and business intelligence domains. Such procedure allowed for the identification of relationships between terms and topics grouping articles, enabling to emerge hypotheses regarding research directions. To confirm such hypotheses, relevant articles were collected and scrutinized, allowing to validate the text mining procedure. The results show that credit in banking is clearly the main application trend, particularly predicting risk and thus supporting credit approval or denial. There is also a relevant interest in bankruptcy and fraud prediction. Customer retention seems to be associated, although weakly, with targeting, justifying bank offers to reduce churn. In addition, a large number of articles focused more on business intelligence techniques and its applications, using the banking industry just for evaluation, thus, not clearly acclaiming for benefits in the banking business. By identifying these current research topics, this study also highlights opportunities for future research.
ER  - 

TY  - JOUR
T1  - An improved plagiarism detection scheme based on semantic role labeling
JO  - Applied Soft Computing
VL  - 12
IS  - 5
SP  - 1493
EP  - 1502
PY  - 2012/5//
T2  - 
AU  - Osman, Ahmed Hamza
AU  - Salim, Naomie
AU  - Binwahlan, Mohammed Salem
AU  - Alteeb, Rihab
AU  - Abuobieda, Albaraa
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2011.12.021
UR  - http://www.sciencedirect.com/science/article/pii/S1568494612000087
KW  - Plagiarism detection
KW  - Semantic similarity
KW  - Semantic role
KW  - Arguments weight
AB  - Plagiarism occurs when the content is copied without permission or citation. One of the contributing factors is that many text documents on the internet are easily copied and accessed. This paper introduces a plagiarism detection technique based on the Semantic Role Labeling (SRL). The technique analyses and compares text based on the semantic allocation for each term inside the sentence. SRL is superior in generating arguments for each sentence semantically. Weighting for each argument generated by SRL to study its behaviour is also introduced in this paper. It was found that not all arguments affect the plagiarism detection process. In addition, experimental results on PAN-PC-09 data sets showed that our method significantly outperforms the modern methods for plagiarism detection in terms of Recall, Precision and F-measure.
ER  - 

TY  - JOUR
T1  - CDDS: Constraint-driven document summarization models
JO  - Expert Systems with Applications
VL  - 40
IS  - 2
SP  - 458
EP  - 465
PY  - 2013/2/1/
T2  - 
AU  - Alguliev, Rasim M.
AU  - Aliguliyev, Ramiz M.
AU  - Isazade, Nijat R.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2012.07.049
UR  - http://www.sciencedirect.com/science/article/pii/S0957417412009049
KW  - Constraint-driven summarization
KW  - Coverage-driven summarization
KW  - Diversity-driven summarization
KW  - Quadratic integer programming
KW  - Particle swarm optimization
AB  - This paper proposes a constraint-driven document summarization approach emphasizing the following two requirements: (1) diversity in summarization, which seeks to reduce redundancy among sentences in the summary and (2) sufficient coverage, which focuses on avoiding the loss of the document’s main information when generating the summary. The constraint-driven document summarization models with tuning the constraint parameters can drive content coverage and diversity in a summary. The models are formulated as a quadratic integer programming (QIP) problem. To solve the QIP problem we used a discrete PSO algorithm. The models are implemented on multi-document summarization task. The comparative results showed that the proposed models outperform other methods on DUC2005 and DUC2007 datasets.
ER  - 

TY  - JOUR
T1  - A unique property of single-link distance and its application in data clustering
JO  - Data & Knowledge Engineering
VL  - 70
IS  - 11
SP  - 984
EP  - 1003
PY  - 2011/11//
T2  - 
AU  - Song, Yuqing
AU  - Jin, Shuyuan
AU  - Shen, Jie
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2011.07.003
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X11000942
KW  - Hierarchical clustering
KW  - Single-link cluster
KW  - Icluster
KW  - Isolation compactness
KW  - Monotonic sequence
AB  - We prove a unique property of single-link distance, based on which an algorithm is designed for data clustering. The property states that a single-link cluster is a subset with inter-subset distance greater than intra-subset distance, and vice versa. Among the major linkages (single, complete, average, centroid, median, and Ward's), only single-link distance has this property. Based on this property we introduce monotonic sequences of iclusters (i.e., single-link clusters) to model the phenomenon that a natural cluster has a dense kernel and the density decreases as we move from the kernel to the boundary. A monotonic sequence of iclusters is a sequence of nested iclusters such that an icluster in the sequence is a dominant child (in terms of size) of the icluster before it. Our data clustering algorithm is monotonic sequence based. We classify a dataset of one monotonic sequence into to two classes by splitting the sequence into two parts: the kernel part and the surrounding part. For a data set of multiple monotonic sequences, each leaf monotonic sequence represents the kernel of a class, which then “grows” by absorbing nearby non-kernel points. This algorithm, proved by experiments, compares favorable in effectiveness to other clustering algorithms.
ER  - 

TY  - JOUR
T1  - Non-negativity and dependence constrained sparse coding for image classification
JO  - Journal of Visual Communication and Image Representation
VL  - 26
IS  - 
SP  - 247
EP  - 254
PY  - 2015/1//
T2  - 
AU  - Han, Hong
AU  - Liu, Sanjun
AU  - Gan, Lu
SN  - 1047-3203
DO  - http://dx.doi.org/10.1016/j.jvcir.2014.12.002
UR  - http://www.sciencedirect.com/science/article/pii/S1047320314001990
KW  - Non-negative Matrix Factorization
KW  - Graph Laplacian
KW  - Dictionary learning
KW  - Sparse coding
KW  - Spatial pyramid
KW  - Image classification
KW  - Parameter selection
KW  - Sparseness
AB  - Abstract
Sparse coding method is a powerful tool in many computer vision applications. However, due to the combinatorial optimization of sparse coding involving both additive and subtractive interactions, the features can cancel each other out with subtraction. And also, in the process of independent coding, the locality and the similarity among the instances which be encoded may be lost. To solve these problems, an image classification framework by leveraging the Non-negative Matrix Factorization and graph Laplacian techniques is presented. Firstly, the Non-negative Matrix Factorization is used to constrain both of the codebook and the corresponding coding coefficients non-negativity. To preserve the dependence properties of the locality and the similarity among the instances, the graph Laplacian regularization is utilized. Then, along with max pooling and spatial pyramid matching, we extend our method to Bag-of-Words image representation. Finally, the linear SVM is leveraged for image classification. Experimental results show that the proposed method achieves or outperforms the state-of-the-art results on several benchmarks.
ER  - 

TY  - JOUR
T1  - Literature listing
JO  - World Patent Information
VL  - 32
IS  - 1
SP  - 81
EP  - 87
PY  - 2010/3//
T2  - 

SN  - 0172-2190
DO  - http://dx.doi.org/10.1016/j.wpi.2009.10.001
UR  - http://www.sciencedirect.com/science/article/pii/S0172219009001306
ER  - 

TY  - JOUR
T1  - Exploiting Universum data in AdaBoost using gradient descent
JO  - Image and Vision Computing
VL  - 32
IS  - 8
SP  - 550
EP  - 557
PY  - 2014/8//
T2  - 
AU  - Xu, Jingsong
AU  - Wu, Qiang
AU  - Zhang, Jian
AU  - Tang, Zhenmin
SN  - 0262-8856
DO  - http://dx.doi.org/10.1016/j.imavis.2014.04.009
UR  - http://www.sciencedirect.com/science/article/pii/S0262885614000778
KW  - AdaBoost
KW  - Gradient boost
KW  - U  AdaBoost
KW  - Universum
KW  - U  -SVM
AB  - Abstract
Recently, Universum data that does not belong to any class of the training data, has been applied for training better classifiers. In this paper, we address a novel boosting algorithm called U AdaBoost that can improve the classification performance of AdaBoost with Universum data. U AdaBoost chooses a function by minimizing the loss for labeled data and Universum data. The cost function is minimized by a greedy, stagewise, functional gradient procedure. Each training stage of U AdaBoost is fast and efficient. The standard AdaBoost weights labeled samples during training iterations while U AdaBoost gives an explicit weighting scheme for Universum samples as well. In addition, this paper describes the practical conditions for the effectiveness of Universum learning. These conditions are based on the analysis of the distribution of ensemble predictions over training samples. Experiments on handwritten digits classification and gender classification problems are presented. As exhibited by our experimental results, the proposed method can obtain superior performances over the standard AdaBoost by selecting proper Universum data.
ER  - 

TY  - JOUR
T1  - Unknown Chinese word extraction based on variety of overlapping strings
JO  - Information Processing & Management
VL  - 49
IS  - 2
SP  - 497
EP  - 512
PY  - 2013/3//
T2  - 
AU  - Ye, Yunming
AU  - Wu, Qingyao
AU  - Li, Yan
AU  - Chow, K.P.
AU  - Hui, Lucas C.K.
AU  - Yiu, S.M.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2012.09.004
UR  - http://www.sciencedirect.com/science/article/pii/S0306457312001173
KW  - Goodness measure
KW  - Chinese word extraction
KW  - Chinese information processing
AB  - Not all languages, e.g. Chinese, have delimiters for words. To extract words from a sentence in these languages, we usually rely on a dictionary for known words. For unknown words, some approaches rely on a domain specific dictionary or a tailor-made learning data set. However, this information may not be available. Another direction is to use unsupervised methods. These methods rely on a goodness measure to evaluate how likely the words are meaningful based on a statistical argument on the given text. The most challenging issue is to identify low-frequency meaningful words. In this paper, we first show by an empirical study on Chinese texts that all classical goodness measures cannot separate low-frequency meaningful and meaningless words effectively. To solve this problem, we propose a new goodness measure, the overlap variety method. The key idea behind the new measure is not to consider the absolute number of occurrences of the candidate (i.e., a string of Chinese characters) but to compare the goodness measures (we use the accessor variety) of the candidate and those of the strings overlapping the candidate. The candidate is likely to be meaningful if its accessor variety is larger than the accessor varieties of the overlapping strings. We implement an extraction system for unknown Chinese word, UNExtract, based on this overlap variety method. We evaluate our approach using the CIPS-SIGHAN-2010 bake off corpora and show that the proposed measure is more effective than the other five state-of-the-art goodness measures (accessor variety, branch entropy, description length gain, frequency substring reduction, pointwise mutual information), especially for low-frequency words and bi-gram words.
ER  - 

TY  - JOUR
T1  - Learning a subspace for clustering via pattern shrinking
JO  - Information Processing & Management
VL  - 49
IS  - 4
SP  - 871
EP  - 883
PY  - 2013/7//
T2  - 
AU  - Hou, Chenping
AU  - Nie, Feiping
AU  - Jiao, Yuanyuan
AU  - Zhang, Changshui
AU  - Wu, Yi
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2013.01.004
UR  - http://www.sciencedirect.com/science/article/pii/S0306457313000095
KW  - Clustering
KW  - Subspace learning
KW  - Pattern shrinking
AB  - Abstract
Clustering is a basic technique in information processing. Traditional clustering methods, however, are not suitable for high dimensional data. Thus, learning a subspace for clustering has emerged as an important research direction. Nevertheless, the meaningful data are often lying on a low dimensional manifold while existing subspace learning approaches cannot fully capture the nonlinear structures of hidden manifold. In this paper, we propose a novel subspace learning method that not only characterizes the linear and nonlinear structures of data, but also reflects the requirements of following clustering. Compared with other related approaches, the proposed method can derive a subspace that is more suitable for high dimensional data clustering. Promising experimental results on different kinds of data sets demonstrate the effectiveness of the proposed approach.
ER  - 

TY  - JOUR
T1  - A distributed aggregation and fast fractal clustering approach for SOAP traffic
JO  - Journal of Network and Computer Applications
VL  - 41
IS  - 
SP  - 1
EP  - 14
PY  - 2014/5//
T2  - 
AU  - Al-Shammary, Dhiah
AU  - Khalil, Ibrahim
AU  - Tari, Zahir
SN  - 1084-8045
DO  - http://dx.doi.org/10.1016/j.jnca.2013.10.001
UR  - http://www.sciencedirect.com/science/article/pii/S1084804513002026
KW  - SOAP
KW  - Aggregation
KW  - Fractal
KW  - Clustering
KW  - Web services
AB  - Abstract
The adoption of Web Services has increased tremendously by many network organizations. Although Web services as XML-based network applications provide significant advantages over other communication technologies in terms of interoperability and dynamic scalability, they suffer from congestion and bottlenecks as a result of the large demand and large XML messages. Aggregation of SOAP messages is one of the potential solutions to reduce network traffic by aggregating large numbers of messages (responses), minimizing their volume over the Internet. However, existing aggregation models only support this function at one node (Web server) and therefore they do not allow aggregation of SOAP messages at different servers as one collaborative technique. In this paper, a new distributed aggregation model is proposed to support aggregation of messages from several nodes that share the path of SOAP responses over the Internet. Furthermore, a fast fractal similarity-based clustering technique is proposed speeding up the computation of similar messages that can be aggregated together in order to achieve a higher reduction. The proposed models show significant results, with distributed aggregation outperforming regular aggregation, resulting in a 100% higher compression ratio. The fast fractal clustering has reduced the required processing time by 85% when compared to the classical fractal clustering technique.
ER  - 

TY  - JOUR
T1  - Hybrid dimension reduction by integrating feature selection with feature extraction method for text clustering
JO  - Expert Systems with Applications
VL  - 42
IS  - 6
SP  - 3105
EP  - 3114
PY  - 2015/4/15/
T2  - 
AU  - Bharti, Kusum Kumari
AU  - Singh, Pramod Kumar
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2014.11.038
UR  - http://www.sciencedirect.com/science/article/pii/S0957417414007301
KW  - Text clustering
KW  - Feature selection
KW  - Feature extraction
KW  - Term variance
KW  - Document frequency
KW  - Principal component analysis
AB  - Abstract
High dimensionality of the feature space is one of the major concerns owing to computational complexity and accuracy consideration in the text clustering. Therefore, various dimension reduction methods have been introduced in the literature to select an informative subset (or sublist) of features. As each dimension reduction method uses a different strategy (aspect) to select a subset of features, it results in different feature sublists for the same dataset. Hence, a hybrid approach, which encompasses different aspects of feature relevance altogether for feature subset selection, receives considerable attention. Traditionally, union or intersection is used to merge feature sublists selected with different methods. The union approach selects all features and the intersection approach selects only common features from considered features sublists, which leads to increase the total number of features and loses some important features, respectively. Therefore, to take the advantage of one method and lessen the drawbacks of other, a novel integration approach namely modified union is proposed. This approach applies union on selected top ranked features and applies intersection on remaining features sublists. Hence, it ensures selection of top ranked as well as common features without increasing dimensions in the feature space much. In this study, feature selection methods term variance (TV) and document frequency (DF) are used for features’ relevance score computation. Next, a feature extraction method principal component analysis (PCA) is applied to further reduce dimensions in the feature space without losing much information. The effectiveness of the proposed method is tested on three benchmark datasets namely Reuters-21,578, Classic4, and WebKB. The obtained results are compared with TV, DF, and variants of the proposed hybrid dimension reduction method. The experimental studies clearly demonstrate that our proposed method improves clustering accuracy compared to the competitive methods.
ER  - 

TY  - JOUR
T1  - A cloud supported model for efficient community health awareness
JO  - Pervasive and Mobile Computing
VL  - 28
IS  - 
SP  - 35
EP  - 50
PY  - 2016/6//
T2  - Special Issue on Big Data for Healthcare; Guest Editors: Sriram Chellappan, Nirmalya Roy, Sajal K. Das and Special Issue on Security and Privacy in Mobile Clouds Guest; Editors: Sherman S.M. Chow, Urs Hengartner, Joseph K. Liu, Kui Ren
AU  - Quwaider, Muhannad
AU  - Jararweh, Yaser
SN  - 1574-1192
DO  - http://dx.doi.org/10.1016/j.pmcj.2015.07.012
UR  - http://www.sciencedirect.com/science/article/pii/S1574119215001509
KW  - Health awareness
KW  - Cloud computing
KW  - Big data
KW  - Data analytics
KW  - MapReduce processing delay
AB  - Abstract
The needs for efficient and scalable community health awareness model become a crucial issue in today’s health care applications. Many health care service providers need to provide their services for long terms, in real time and interactively. Many of these applications are based on the emerging Wireless Body Area networks (WBANs) technology. WBANs have developed as an effective solution for a wide range of healthcare, military, sports, general health and social applications. On the other hand, handling data in a large scale (currently known as Big Data) requires an efficient collection and processing model with scalable computing and storage capacity. Therefore, a new computing paradigm is needed such as Cloud Computing and Internet of Things (IoT). In this paper we present a novel cloud supported model for efficient community health awareness in the presence of a large scale WBANs data generation. The objective is to process this big data in order to detect the abnormal data using MapReduce infrastructure and user defined functions with minimum processing delay. The goal is to have a large monitored data of WBANs to be available to the end user or to the decision maker in reliable manner. While reducing data packet processing energy, the proposed work is minimizing the data processing delay by choosing cloudlet or local cloud model and MapReduce infrastructure. So, the overall delay is minimized, thus leading to detect the abnormal data in the cloud in real time mode. In this paper we present a multi-layer computing model composed of Local Cloud (LC) layer and Enterprise Cloud (EP) layer that aim to process the collected data from Monitored Subjects (MSs) in a large scale to generate useful facts, observations or to find abnormal phenomena within the monitored data. Performance results show that integrating the MapReduce capabilities with cloud computing model will reduce the processing delay. The proposed MapReduce infrastructure has also been applied in lower layer, such as LC in order to reduce the amount of communications and processing delay. Performance results show that applying MapReduce infrastructure in lower tire will significantly decrease the overall processing delay.
ER  - 

TY  - JOUR
T1  - Computing semantic similarity between biomedical concepts using new information content approach
JO  - Journal of Biomedical Informatics
VL  - 59
IS  - 
SP  - 258
EP  - 275
PY  - 2016/2//
T2  - 
AU  - Ben Aouicha, Mohamed
AU  - Hadj Taieb, Mohamed Ali
SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2015.12.007
UR  - http://www.sciencedirect.com/science/article/pii/S1532046415002877
KW  - Semantic similarity
KW  - Information content
KW  - DAG topological parameters
KW  - MeSH
KW  - Biomedicine
AB  - Abstract
The exploitation of heterogeneous clinical sources and healthcare records is fundamental in clinical and translational research. The determination of semantic similarity between word pairs is an important component of text understanding that enables the processing and structuring of textual resources. Some of these measures have been adapted to the biomedical field by incorporating domain information extracted from clinical data or from medical ontologies such as MeSH. This study focuses on Information Content (IC) based measures that exploit the topological parameters of the taxonomy to express the semantics of a concept. A new intrinsic IC computing method based on the taxonomical parameters of the ancestors’ subgraph is then assigned to a biomedical concept into the “is a” hierarchy. Moreover, we present a study of the topological parameters through the MeSH taxonomy. This study treats the semantic interpretation and the different ways of expressing the parameters of depth and the descendants’ subgraph. Using MeSH as an input ontology, the accuracy of our proposal is evaluated and compared against other IC-based measures according to several widely-used benchmarks of biomedical terms. The correlation between the results obtained for the evaluated measure using the proposed approach and those from the ratings of human’ experts shows that our proposal outperforms the previous measures.
ER  - 

TY  - JOUR
T1  - Learning relational facts from the web: A tolerance rough set approach
JO  - Pattern Recognition Letters
VL  - 67, Part 2
IS  - 
SP  - 130
EP  - 137
PY  - 2015/12/1/
T2  - Granular Mining and Knowledge Discovery
AU  - Sengoz, Cenker
AU  - Ramanna, Sheela
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2014.12.005
UR  - http://www.sciencedirect.com/science/article/pii/S0167865514003729
KW  - Tolerance rough sets
KW  - Granular methodologies
KW  - Web mining
KW  - Semi-supervised learning,
AB  - Abstract
A key issue when mining web information is the labeling problem: data are abundant on the web but is unlabeled. In this paper, we address this problem by proposing (i) a granular model that structures categorical noun phrase instances as well as semantically related noun phrase pairs from a given corpus representing unstructured web pages with a tolerance form of rough sets, (ii) a semi-supervised Tolerant Pattern Learning (TPL) algorithm that labels categorical instances as well as relations. This work is an extension of the TPL algorithm presented in our earlier paper. Our model treats noun phrases, which are described as sets of their co-occurring contextual patterns. We use the ontological information from the Never Ending Language Learner (Nell) system. We compared the performance of our algorithm with Coupled Bayesian Sets (CBS) and Coupled Pattern Learner (CPL) algorithms for categorical and relational extractions, respectively. Experimental results suggest that TPL can achieve comparable performance with CBS and CPL in terms of precision.
ER  - 

TY  - JOUR
T1  - Meta-clustering of possibilistically segmented retail datasets
JO  - Fuzzy Sets and Systems
VL  - 286
IS  - 
SP  - 173
EP  - 196
PY  - 2016/3/1/
T2  - Theme: Images and Clustering
AU  - Ammar, Asma
AU  - Elouedi, Zied
AU  - Lingras, Pawan
SN  - 0165-0114
DO  - http://dx.doi.org/10.1016/j.fss.2015.07.019
UR  - http://www.sciencedirect.com/science/article/pii/S0165011415003619
KW  - Meta-clustering
KW  - Possibilistic segmentation
KW  - Possibilistic membership
KW  - k-Modes
KW  - Granular computing
AB  - Abstract
This paper proposes a possibilistic meta-clustering algorithm. The possibility theory is used for possibilistic segmentation of the input data as well as for determining the possibilistic membership of objects to multiple clusters. The meta-clustering uses connections between information granules to send clustering knowledge from one granule to another. The approach is demonstrated with the help of the k-modes clustering algorithm for a real-world retail store, where a customer is connected to the products bought, and products are connected to customers who buy them. The meta-clustering approach uses the results from clustering of customers as an input to cluster the products, and recursively uses clustering of products as input to the clustering customers. The customer granule is represented using static information from the database and dynamic information from the clustering of the products bought. Similarly, a product granule is represented by static information from the database and dynamic part from the clustering of the customers who buy the product. The static information from the database is represented using possibilistic segments.
ER  - 

TY  - JOUR
T1  - Extraction and clustering of arguing expressions in contentious text
JO  - Data & Knowledge Engineering
VL  - 100, Part B
IS  - 
SP  - 226
EP  - 239
PY  - 2015/11//
T2  - Special Issue of 19th International Conference on Applications of Natural Language Processing to Information Systems
AU  - Trabelsi, Amine
AU  - Zaïane, Osmar R.
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2015.05.004
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X15000324
KW  - Contention analysis
KW  - Topic models
KW  - Arguing expression detection
KW  - Opinion mining
KW  - Unsupervised clustering
KW  - Online debates
AB  - Abstract
This work proposes an unsupervised method intended to enhance the quality of opinion mining in contentious text. It presents a Joint Topic Viewpoint (JTV) probabilistic model to analyze the underlying divergent arguing expressions that may be present in a collection of contentious documents. The conceived JTV has the potential of automatically carrying the tasks of extracting associated terms denoting an arguing expression, according to the hidden topics it discusses and the embedded viewpoint it voices. Furthermore, JTV's structure enables the unsupervised grouping of obtained arguing expressions according to their viewpoints, using a proposed constrained clustering algorithm which is an adapted version of the constrained k-means clustering (COP-KMEANS). Experiments are conducted on three types of contentious documents (polls, online debates and editorials), through six different contentious data sets. Quantitative evaluations of the topic modeling output, as well as the constrained clustering results show the effectiveness of the proposed method to fit the data and generate distinctive patterns of arguing expressions. Moreover, it empirically demonstrates a better clustering of arguing expressions over state-of-the art and baseline methods. The qualitative analysis highlights the coherence of clustered arguing expressions of the same viewpoint and the divergence of opposing ones.
ER  - 

TY  - JOUR
T1  - Heterogeneous feature structure fusion for classification
JO  - Pattern Recognition
VL  - 53
IS  - 
SP  - 1
EP  - 11
PY  - 2016/5//
T2  - 
AU  - Lin, Guangfeng
AU  - Fan, Guoliang
AU  - Kang, Xiaobing
AU  - Zhang, Erhu
AU  - Yu, Liangjiang
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2015.10.013
UR  - http://www.sciencedirect.com/science/article/pii/S0031320315003921
KW  - Internal structure
KW  - External structure
KW  - Heterogeneous feature structure
KW  - Object classification
AB  - Abstract
The key to feature fusion for classification is to take advantage of the discriminative and complementary information from different feature sets, which can be represented as internal (within each feature set) or external structures (across different feature sets). Traditional approaches tend to preserve either internal or external structures via certain feature projection. Some early attempts consider both structures implicitly or indirectly without revealing their relative importance and relevance in feature fusion. We propose a new unsupervised heterogeneous structure fusion (HSF) algorithm that is able to jointly optimize two kinds of structures explicitly and directly via unified feature projection. Specifically, the internal structure is represented based on Locality Preserving Projection (LPP), and the external structure is captured by Canonical Correlation Analysis (CCA). The objective function of HSF combines two feature structures in a closed form which can be optimized alternately via linear programming and eigenvector methods. The HSF solution provides not only the optimal feature projection but also the weights that encode the relative importance between two kinds of feature structures. The experimental results on image classification, face recognition, shape analysis and infrared target recognition demonstrate the effectiveness and efficiency of HSF compared with state-of-the-art methods.
ER  - 

TY  - JOUR
T1  - Feature selection for clustering using instance-based learning by exploring the nearest and farthest neighbors
JO  - Information Sciences
VL  - 318
IS  - 
SP  - 14
EP  - 27
PY  - 2015/10/10/
T2  - Security, Privacy and trust in network-based Big Data
AU  - Chen, Chien-Hsing
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2015.05.019
UR  - http://www.sciencedirect.com/science/article/pii/S0020025515003783
KW  - Feature selection
KW  - Instance-based learning
KW  - Neighbor
KW  - Mutual information
KW  - Clustering
AB  - Abstract
Feature selection for clustering is an active research topic and is used to identify salient features that are helpful for data clustering. While partitioning a dataset into clusters, a data instance and its nearest neighbors will belong to the same cluster, and this instance and its farthest neighbors will belong to different clusters. We propose a new Feature Selection method to identify salient features that are useful for maintaining the instance’s Nearest neighbors and Farthest neighbors (referred to here as FSNF). In particular, FSNF uses the mutual information criterion to estimate feature salience by considering maintainability. Experiments on benchmark datasets demonstrate the effectiveness of FSNF within the context of cluster analysis.
ER  - 

TY  - JOUR
T1  - A modified two-stage Markov clustering algorithm for large and sparse networks
JO  - Computer Methods and Programs in Biomedicine
VL  - 135
IS  - 
SP  - 15
EP  - 26
PY  - 2016/10//
T2  - 
AU  - Szilágyi, László
AU  - Szilágyi, Sándor M.
SN  - 0169-2607
DO  - http://dx.doi.org/10.1016/j.cmpb.2016.07.007
UR  - http://www.sciencedirect.com/science/article/pii/S0169260716300967
KW  - Hierarchical clustering
KW  - Markov clustering
KW  - Efficient computing
KW  - Sparse matrix
KW  - Protein sequence networks
AB  - AbstractBackground
Graph-based hierarchical clustering algorithms become prohibitively costly in both execution time and storage space, as the number of nodes approaches the order of millions.
Objective
A fast and highly memory efficient Markov clustering algorithm is proposed to perform the classification of huge sparse networks using an ordinary personal computer.
Methods
Improvements compared to previous versions are achieved through adequately chosen data structures that facilitate the efficient handling of symmetric sparse matrices. Clustering is performed in two stages: the initial connected network is processed in a sparse matrix until it breaks into isolated, small, and relatively dense subgraphs, which are then processed separately until convergence is obtained. An intelligent stopping criterion is also proposed to quit further processing of a subgraph that tends toward completeness with equal edge weights. The main advantage of this algorithm is that the necessary number of iterations is separately decided for each graph node.
Results
The proposed algorithm was tested using the SCOP95 and large synthetic protein sequence data sets. The validation process revealed that the proposed method can reduce 3–6 times the processing time of huge sequence networks compared to previous Markov clustering solutions, without losing anything from the partition quality.
Conclusions
A one-million-node and one-billion-edge protein sequence network defined by a BLAST similarity matrix can be processed with an upper-class personal computer in 100 minutes. Further improvement in speed is possible via parallel data processing, while the extension toward several million nodes needs intermediary data storage, for example on solid state drives.
ER  - 

TY  - JOUR
T1  - K-Medoid Clustering for Heterogeneous DataSets
JO  - Procedia Computer Science
VL  - 70
IS  - 
SP  - 226
EP  - 237
PY  - 2015///
T2  - Proceedings of the 4th International Conference on Eco-friendly Computing and Communication Systems
AU  - Harikumar, Sandhya
AU  - PV, Surya
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.10.077
UR  - http://www.sciencedirect.com/science/article/pii/S187705091503241X
KW  - Clustering
KW  - Heterogeneous datasets
KW  - L1 norm
KW  - K-Medoid
KW  - Probabilistic Computation
AB  - Abstract
Recent years have explored various clustering strategies to partition datasets comprising of heterogeneous domains or types such as categorical, numerical and binary. Clustering algorithms seek to identify homogeneous groups of objects based on the values of their attributes. These algorithms either assume the attributes to be of homogeneous types or are converted into homogeneous types. However, datasets with heterogeneous data types are common in real life applications, which if converted, can lead to loss of information. This paper proposes a new similarity measure in the form of triplet to find the distance between two data objects with heterogeneous attribute types. A new k-medoid type of clustering algorithm is proposed by leveraging the similarity measure in the form of a vector. The proposed k-medoid type of clustering algorithm is compared with traditional clustering algorithms, based on cluster validation using Purity Index and Davies Bouldin index. Results show that the new clustering algorithm with new similarity measure outperforms the k-means clustering for mixed datasets.
ER  - 

TY  - JOUR
T1  - Single-pass and linear-time k-means clustering based on MapReduce
JO  - Information Systems
VL  - 60
IS  - 
SP  - 1
EP  - 12
PY  - 2016/8//
Y2  - 2016/9//
T2  - 
AU  - Shahrivari, Saeed
AU  - Jalili, Saeed
SN  - 0306-4379
DO  - http://dx.doi.org/10.1016/j.is.2016.02.007
UR  - http://www.sciencedirect.com/science/article/pii/S030643791630076X
KW  - Distributed k-means
KW  - Data clustering
KW  - MapReduce-based clustering
AB  - Abstract
In recent years, k-means has been fitted into the MapReduce framework and hence it has become a very effective solution for clustering very large datasets. However, k-means is not inherently suitable for execution in MapReduce. The iterative nature of k-means cannot be modeled in MapReduce and hence for each iteration of k-means an independent MapReduce job must be executed and this results in high I/O overhead because in each iteration the whole dataset must be read and written to slow disks. We have proposed a single-pass solution based on MapReduce called mrk-means which uses the reclustering technique. In contrast to available MapReduce-based k-means implementations, mrk-means just reads the dataset once and hence it is several times faster. The time complexity of mrk-means is linear which is lower than the iterative k-means. Due to usage of k-means++ seeding algorithm, mrk-means results in clusters with higher quality, too. Theoretically, the results of mrk-means are O ( log 2 k ) - competitive to optimal clustering in the worst case, considering k as the number of clusters. During our experiments which were done on a cluster of 40 machines running the Hadoop framework, mrk-means showed both faster execution times, and higher quality of clustering results compared to available MapReduce-based and stream-based k-means variants.
ER  - 

TY  - JOUR
T1  - A novel approach of cluster based optimal ranking of clicked URLs using genetic algorithm for effective personalized web search
JO  - Applied Soft Computing
VL  - 46
IS  - 
SP  - 90
EP  - 103
PY  - 2016/9//
T2  - 
AU  - Chawla, Suruchi
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2016.04.042
UR  - http://www.sciencedirect.com/science/article/pii/S1568494616302009
KW  - Information retrieval
KW  - Search engine
KW  - Information scent
KW  - Clustering
KW  - Genetic algorithm
KW  - Personalized web search
AB  - Abstract
In this paper a novel approach is proposed for generating the optimal ranked clicked URLs using genetic algorithm (GA) based on clustered web query sessions for effective personalized web search. Experimental study was conducted on the data set of web query sessions captured in the domains academics, entertainment and sports to test the effectiveness of clusterwise optimal ranked clicked URLs for personalized web search (PWS). The results, which are verified statistically shows an improvement in the average precision of the personalized web search based on optimal ranked clicked URLs over both Classic IR and personalized web search without optimal ranked clicked URLs. Thus the effectiveness of personalized web search using optimal ranked clicked URLs is confirmed for better customizing the web search according to the information need of the user.
ER  - 

TY  - JOUR
T1  - Modeling and visualization of media in Arabic
JO  - Journal of Informetrics
VL  - 10
IS  - 2
SP  - 439
EP  - 453
PY  - 2016/5//
T2  - 
AU  - Volkovich, Zeev
AU  - Granichin, Oleg
AU  - Redkin, Oleg
AU  - Bernikova, Olga
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2016.02.008
UR  - http://www.sciencedirect.com/science/article/pii/S1751157715302297
KW  - Media quantization
KW  - Visualization
KW  - Arabic text segmentation
AB  - Abstract
In this paper, a novel method for analyzing media in Arabic using new quantitative characteristics is proposed. A sequence of newspaper daily issues is represented as histograms of occurrences of informative terms. The histograms closeness is evaluated via a rank correlation coefficient by treating the terms as ordinal data consistent with their frequencies. A new characteristic is introduced to quantify the relationship of an issue with numerous earlier ones. A newspaper is imaged as a time series of this characteristic values affected by the current social situation. The change points of this process may indicate fluctuations in the social behavior of the corresponding society as is evident from changes in the linguistic content. Moreover, the similarity measure created by means of this characteristic makes it possible to accurately derive the groups of homogeneous issues without any additional information. The methodology is evaluated on sequential issues of an Egyptian newspaper, “Al-Ahraam”, and a Lebanese newspaper, “Al-Akhbaar”. The results exhibit the high ability of the proposed approach to expose changes in the linguistic content and to connect them with changes in the structure of society and the relationships in it. The method can be suitably extended to every alphabetic language media.
ER  - 

TY  - JOUR
T1  - Discovering top-k non-redundant clusterings in attributed graphs
JO  - Neurocomputing
VL  - 210
IS  - 
SP  - 45
EP  - 54
PY  - 2016/10/19/
T2  - SI:Behavior Analysis In SN
AU  - Guedes, Gustavo Paiva
AU  - Ogasawara, Eduardo
AU  - Bezerra, Eduardo
AU  - Xexeo, Geraldo
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2015.10.145
UR  - http://www.sciencedirect.com/science/article/pii/S0925231216306099
KW  - Multiple clusterings
KW  - Attributed graphs
KW  - Spectral clustering
KW  - Top-k clusterings
KW  - Non-redundant clusterings
KW  - Top-k non-redundant clusterings
AB  - Abstract
Many graph clustering algorithms focus on producing a single partition of the vertices in the input graph. Nevertheless, a single partition may not provide sufficient insight about the underlying data. In this context, it would be interesting to explore alternative clustering solutions. Many areas, such as social media marketing demand exploring multiple clustering solutions in social networks to allow for behavior analysis to find, for example, potential customers or influential members according to different perspectives. Additionally, it would be desirable to provide not only multiple clustering solutions, but also to present multiple non-redundant ones, in order to unleash the possible many facets from the underlying dataset. In this paper, we propose RM-CRAG, a novel algorithm to discover the top-k non-redundant clustering solutions in attributed graphs, i.e., a ranking of clusterings that share the least amount of information, in the information theoretic sense. We also propose MVNMI, an evaluation criterion to assess the quality of a set of clusterings. Experimental results using different datasets show the effectiveness of the proposed algorithm.
ER  - 

TY  - JOUR
T1  - The moderating effect of bilateral investment treaty stringency on the relationship between political instability and subsidiary ownership choice
JO  - International Business Review
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Williams, Christopher
AU  - Lukoianova (Vashchilko), Tatiana
AU  - Martinez, Candace A.
SN  - 0969-5931
DO  - http://dx.doi.org/10.1016/j.ibusrev.2016.05.002
UR  - http://www.sciencedirect.com/science/article/pii/S0969593116300634
KW  - Political instability
KW  - Bilateral investment treaties (BITs)
KW  - Subsidiary ownership choice
AB  - Abstract
We investigate whether the degree to which a bilateral investment treaty (BIT) protects against expropriation (i.e., its “stringency”) influences the international strategy of multinational enterprises (MNEs) as they invest in countries with varying levels of political instability. We draw on institutional logic and insights from political economics to hypothesize that BIT stringency will moderate the established positive relationship between host country political instability and minority ownership. Analysis of a sample of 289 foreign investments made by AEX-listed Dutch MNEs in 34 countries between 2004 and 2013 provides support: a more stringent BIT will encourage the MNE to choose a majority stake as political instability rises. Robustness tests provide further support for our argument. The results have both managerial and policy implications relating to the role that BIT stringency plays in determining MNE strategy.
ER  - 

TY  - JOUR
T1  - An improved density peaks-based clustering method for social circle discovery in social networks
JO  - Neurocomputing
VL  - 179
IS  - 
SP  - 219
EP  - 227
PY  - 2016/2/29/
T2  - 
AU  - Wang, Mengmeng
AU  - Zuo, Wanli
AU  - Wang, Ying
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2015.11.091
UR  - http://www.sciencedirect.com/science/article/pii/S0925231215019323
KW  - Discovering overlapping social circles
KW  - Improved density peaks-based clustering method
KW  - In-link Salton metric
KW  - Out-link Salton metric
KW  - Social networks
AB  - Abstract
With the development of Internet, social networks have become important platforms which allow users to follow streams of posts generated by their friends and acquaintances. Through mining a collection of nodes with similarities, community detection can make us understand the characteristics of complex network deeply. Therefore, community detection has attracted increasing attention in recent years. Since the problem of discovering social circles is posed as a community detecting problem, hence, in this paper, targeted at on-line social networks, we investigate how to exploit user׳s profile and topological structure information in social circle discovery. Firstly, according to directionality of linkages, we put forward in-link Salton metric and out-link Salton metric to measure user׳s topological structure. Then we propose an improved density peaks-based clustering method and deploy it to discover social circles with overlap on account of user׳s profile- and topological structure-based features. Experiments on real-world dataset demonstrate the effectiveness of the proposed framework. Further experiments are conducted to understand the importance of different parameters and different features in social circle discovery.
ER  - 

TY  - JOUR
T1  - Pairwise clustering based on the mutual-information criterion
JO  - Neurocomputing
VL  - 182
IS  - 
SP  - 284
EP  - 293
PY  - 2016/3/19/
T2  - 
AU  - Alush, Amir
AU  - Friedman, Avishay
AU  - Goldberger, Jacob
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2015.12.025
UR  - http://www.sciencedirect.com/science/article/pii/S0925231215019621
KW  - Graph clustering
KW  - Pairwise clustering
KW  - Mutual information
KW  - Spectral clustering
KW  - Normalized-cut
AB  - Abstract
Pairwise clustering methods partition a dataset using pairwise similarity between data-points. The pairwise similarity matrix can be used to define a Markov random walk on the data points. This view forms a probabilistic interpretation of spectral clustering methods. We utilize this probabilistic model to define a novel clustering cost function that is based on maximizing the mutual information between consecutively visited clusters of states of the Markov chain defined by the similarity matrix. This cost function can be viewed as an extension of the information-bottleneck principle to the case of pairwise clustering. We show that the complexity of a sequential clustering implementation of the suggested cost function is linear in the dataset size on sparse graphs. The improved performance and the reduced computational complexity of the proposed algorithm are demonstrated on several standard datasets and on image segmentation task.
ER  - 

TY  - JOUR
T1  - A kernel-based clustering method for gene selection with gene expression data
JO  - Journal of Biomedical Informatics
VL  - 62
IS  - 
SP  - 12
EP  - 20
PY  - 2016/8//
T2  - 
AU  - Chen, Huihui
AU  - Zhang, Yusen
AU  - Gutman, Ivan
SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2016.05.007
UR  - http://www.sciencedirect.com/science/article/pii/S1532046416300375
KW  - Gene expression data
KW  - Kernel-based clustering
KW  - Adaptive distance
KW  - Gene selection
KW  - Cancer classification
AB  - Abstract
Gene selection is important for cancer classification based on gene expression data, because of high dimensionality and small sample size. In this paper, we present a new gene selection method based on clustering, in which dissimilarity measures are obtained through kernel functions. It searches for best weights of genes iteratively at the same time to optimize the clustering objective function. Adaptive distance is used in the process, which is suitable to learn the weights of genes during the clustering process, improving the performance of the algorithm. The proposed algorithm is simple and does not require any modification or parameter optimization for each dataset. We tested it on eight publicly available datasets, using two classifiers (support vector machine, k-nearest neighbor), compared with other six competitive feature selectors. The results show that the proposed algorithm is capable of achieving better accuracies and may be an efficient tool for finding possible biomarkers from gene expression data.
ER  - 

TY  - JOUR
T1  - Multi-tier cloud infrastructure support for reliable global health awareness system
JO  - Simulation Modelling Practice and Theory
VL  - 67
IS  - 
SP  - 44
EP  - 58
PY  - 2016/9//
T2  - 
AU  - Quwaider, Muhannad
AU  - Jararweh, Yaser
SN  - 1569-190X
DO  - http://dx.doi.org/10.1016/j.simpat.2016.06.005
UR  - http://www.sciencedirect.com/science/article/pii/S1569190X1630123X
KW  - Global health awareness system
KW  - Cloud computing
KW  - Multi-tier cloud
KW  - MapReduce
KW  - Processing delay
AB  - Abstract
The exceptional outbreaks of a number of epidemic diseases such as Ebola, SARS, Zika and H1N1 and their wide distribution over multiple regions calls for a reliable global health awareness system. This system is needed to achieve early detection of such emergencies. Furthermore, such health awareness system should be capable of predicting the outbreaks patterns to facilitate future countermeasure planning. This health awareness system should cover large scale regions that can be extended to multiple countries, continents and ultimately the globe. Many advanced and industrial countries are still struggling in building such system effectively even with the availability of resources and domain experts. The realization of a reliable health awareness system is accompanied with multiple challenges such as the availability of resources and experts, the global agreements about the system from the legislative and control point of view and the availability of the infrastructure that will support the system functionality with a reasonable cost. This paper presents a novel global health awareness system that overcomes the aforementioned challenges. The system is exploiting the emerging cloud computing services availability over the globe. To handle the large scale requirements, we introduce a multi-tier based cloud system that spans over four tiers starting from the monitored subjects to a centralized global cloud system. Also, we present a mixed integer optimization formulation to tackle the issues related to the latency of detecting outbreaks. Our results show that processing the data in multi-tier health awareness system will reduce the overall delay significantly and enable efficient health data sharing.
ER  - 

TY  - JOUR
T1  - Robustness analysis of preconditioned successive projection algorithm for general form of separable NMF problem
JO  - Linear Algebra and its Applications
VL  - 497
IS  - 
SP  - 1
EP  - 22
PY  - 2016/5/15/
T2  - 
AU  - Mizutani, Tomohiko
SN  - 0024-3795
DO  - http://dx.doi.org/10.1016/j.laa.2016.02.016
UR  - http://www.sciencedirect.com/science/article/pii/S002437951600118X
KW  - Nonnegative matrix factorization
KW  - Separability
KW  - Successive projection algorithm
KW  - Robustness to noise
KW  - Preconditioning
AB  - Abstract
The successive projection algorithm (SPA) has been known to work well for separable nonnegative matrix factorization (NMF) problems arising in applications, such as topic extraction from documents and endmember detection in hyperspectral images. One of the reasons is in that the algorithm is robust to noise. Gillis and Vavasis showed in [8] that a preconditioner can further enhance its noise robustness. The proof rested on the condition that the dimension d and factorization rank r in the separable NMF problem coincide with each other. However, it may be unrealistic to expect that the condition holds in separable NMF problems appearing in actual applications; in such problems, d is usually greater than r. This paper shows, without the condition d = r , that the preconditioned SPA is robust to noise.
ER  - 

TY  - JOUR
T1  - Clustering and visualization of failure modes using an evolving tree
JO  - Expert Systems with Applications
VL  - 42
IS  - 20
SP  - 7235
EP  - 7244
PY  - 2015/11/15/
T2  - 
AU  - Chang, Wui Lee
AU  - Tay, Kai Meng
AU  - Lim, Chee Peng
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2015.04.036
UR  - http://www.sciencedirect.com/science/article/pii/S0957417415002729
KW  - Clustering
KW  - Visualization
KW  - Failure Mode and Effect Analysis
KW  - Evolving tree
KW  - Edible bird nest industry
KW  - Euclidean similarity
KW  - Neural network
AB  - Abstract
Despite the popularity of Failure Mode and Effect Analysis (FMEA) in a wide range of industries, two well-known shortcomings are the complexity of the FMEA worksheet and its intricacy of use. To the best of our knowledge, the use of computation techniques for solving the aforementioned shortcomings is limited. As such, the idea of clustering and visualization pertaining to the failure modes in FMEA is proposed in this paper. A neural network visualization model with an incremental learning feature, i.e., the evolving tree (ETree), is adopted to allow the failure modes in FMEA to be clustered and visualized as a tree structure. In addition, the ideas of risk interval and risk ordering for different groups of failure modes are proposed to allow the failure modes to be ordered, analyzed, and evaluated in groups. The main advantages of the proposed method lie in its ability to transform failure modes in a complex FMEA worksheet to a tree structure for better visualization, while maintaining the risk evaluation and ordering features. It can be applied to the conventional FMEA methodology without requiring additional information or data. A real world case study in the edible bird nest industry in Sarawak (Borneo Island) is used to evaluate the usefulness of the proposed method. The experiments show that the failure modes in FMEA can be effectively visualized through the tree structure. A discussion with FMEA users engaged in the case study indicates that such visualization is helpful in comprehending and analyzing the respective failure modes, as compared with those in an FMEA table. The resulting tree structure, together with risk interval and risk ordering, provides a quick and easily understandable framework to elucidate important information from complex FMEA forms; therefore facilitating the decision-making tasks by FMEA users. The significance of this study is twofold, viz., the use of a computational visualization approach to tackling two well-known shortcomings of FMEA; and the use of ETree as an effective neural network learning paradigm to facilitate FMEA implementations. These findings aim to spearhead the potential adoption of FMEA as a useful and usable risk evaluation and management tool by the wider community.
ER  - 

TY  - JOUR
T1  - A hybrid term–term relations analysis approach for topic detection
JO  - Knowledge-Based Systems
VL  - 93
IS  - 
SP  - 109
EP  - 120
PY  - 2016/2/1/
T2  - 
AU  - Zhang, Chen
AU  - Wang, Hao
AU  - Cao, Liangliang
AU  - Wang, Wei
AU  - Xu, Fanjiang
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2015.11.006
UR  - http://www.sciencedirect.com/science/article/pii/S0950705115004335
KW  - Topic detection
KW  - Topic modeling
KW  - Semantic relations
KW  - Co-occurrence relations
KW  - Graph analytical approach
AB  - Abstract
Topic detection as a tool to detect topics from online media attracts much attention. Generally, a topic is characterized by a set of informative keywords/terms. Traditional approaches are usually based on various topic models, such as Latent Dirichlet Allocation (LDA). They cluster terms into a topic by mining semantic relations between terms. However, co-occurrence relations across the document are commonly neglected, which leads to the detection of incomplete information. Furthermore, the inability to discover latent co-occurrence relations via the context or other bridge terms prevents the important but rare topics from being detected.

To tackle this issue, we propose a hybrid relations analysis approach to integrate semantic relations and co-occurrence relations for topic detection. Specifically, the approach fuses multiple relations into a term graph and detects topics from the graph using a graph analytical method. It can not only detect topics more effectively by combing mutually complementary relations, but also mine important rare topics by leveraging latent co-occurrence relations. Extensive experiments demonstrate the advantage of our approach over several benchmarks.
ER  - 

TY  - JOUR
T1  - A.1D-C: A novel fast automatic heuristic to handle large-scale one-dimensional clustering
JO  - Applied Soft Computing
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Ismkhan, Hassan
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2016.09.001
UR  - http://www.sciencedirect.com/science/article/pii/S1568494616304604
KW  - A.1D-C
KW  - One-dimensional
KW  - Number of clusters
KW  - Array of integers
KW  - New heuristic
AB  - Abstract
The one-dimensional clustering aims to group real-values of an input array into identified number of clusters. Some of the current algorithms, such as the k-means, need the number of clusters in advance, and use a goal function based on minimizing the sum of squared Euclidean distances to the mean of each group. This paper shows why this goal function is not efficient, even for one-dimensional case, then proposes an O (n × log n) efficient algorithm for the one-dimensional clustering purposes. The proposed algorithm can automatically detect the number of clusters. The performance of the proposed algorithm is approved across several experiments. In addition, results of experiments show why the goal function used in some current algorithms like the k-means is not suitable for the one-dimensional clustering.
ER  - 

TY  - JOUR
T1  - A computational model for mining consumer perceptions in social media
JO  - Decision Support Systems
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Pournarakis, Demitrios E.
AU  - Sotiropoulos, Dionisios N.
AU  - Giaglis, George M.
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2016.09.018
UR  - http://www.sciencedirect.com/science/article/pii/S0167923616301671
KW  - Social media
KW  - Big data
KW  - Consumer perceptions
AB  - Abstract
The proliferation of Big Data &amp; Analytics in recent years has compelled marketing practitioners to search for new methods when faced with assessing brand performance during brand equity appraisal. One of the challenges of current practices is that these methods rely heavily on traditional data collection and analysis methods such as questionnaires, and face to face or telephone interviews, which have a significant time lag. In this paper we introduce a computational model that combines topic and sentiment classification to elicit influential subjects from consumer perceptions in social media. Our model devises a novel genetic algorithm to improve clustering of tweets in semantically coherent groups, which act as an essential prerequisite when searching for prevailing topics and sentiment in big pools of data. To illustrate the validity of our model, we apply it to the Uber transportation network, from data collected through Twitter for the period between January and April 2015. The results obtained present consumer perceptions and produce insights for two fundamental brand equity dimensions: brand awareness and brand meaning. Simultaneously, they improve clustering results, in comparison to the k-means approach.
ER  - 

TY  - JOUR
T1  - A K-partitioning algorithm for clustering large-scale spatio-textual data
JO  - Information Systems
VL  - 64
IS  - 
SP  - 1
EP  - 11
PY  - 2017/3//
T2  - 
AU  - Choi, Dong-Wan
AU  - Chung, Chin-Wan
SN  - 0306-4379
DO  - http://dx.doi.org/10.1016/j.is.2016.08.003
UR  - http://www.sciencedirect.com/science/article/pii/S0306437915302039
KW  - Spatio-textual similarity
KW  - K-means clustering
KW  - K-medoids clustering
KW  - K-prototypes clustering
KW  - Expected distance
KW  - Grid partitioning
AB  - Abstract
The volume of spatio-textual data is drastically increasing in these days, and this makes more and more essential to process such a large-scale spatio-textual dataset. Even though numerous works have been studied for answering various kinds of spatio-textual queries, the analyzing method for spatio-textual data has rarely been considered so far. Motivated by this, this paper proposes a k-means based clustering algorithm specialized for a massive spatio-textual data. One of the strong points of the k-means algorithm lies in its efficiency and scalability, implying that it is appropriate for a large-scale data. However, it is challenging to apply the normal k-means algorithm to spatio-textual data, since each spatio-textual object has non-numeric attributes, that is, textual dimension, as well as numeric attributes, that is, spatial dimension. We address this problem by using the expected distance between a random pair of objects rather than constructing actual centroid of each cluster. Based on our experimental results, we show that the clustering quality of our algorithm is comparable to those of other k-partitioning algorithms that can process spatio-textual data, and its efficiency is superior to those competitors.
ER  - 

TY  - JOUR
T1  - Formal concept analysis in knowledge processing: A survey on applications
JO  - Expert Systems with Applications
VL  - 40
IS  - 16
SP  - 6538
EP  - 6560
PY  - 2013/11/15/
T2  - 
AU  - Poelmans, Jonas
AU  - Ignatov, Dmitry I.
AU  - Kuznetsov, Sergei O.
AU  - Dedene, Guido
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2013.05.009
UR  - http://www.sciencedirect.com/science/article/pii/S0957417413002959
KW  - Formal concept analysis (FCA)
KW  - Knowledge discovery in databases
KW  - Text mining
KW  - Applications
KW  - Systematic literature overview
AB  - Abstract
This is the second part of a large survey paper in which we analyze recent literature on Formal Concept Analysis (FCA) and some closely related disciplines using FCA. We collected 1072 papers published between 2003 and 2011 mentioning terms related to Formal Concept Analysis in the title, abstract and keywords. We developed a knowledge browsing environment to support our literature analysis process. We use the visualization capabilities of FCA to explore the literature, to discover and conceptually represent the main research topics in the FCA community. In this second part, we zoom in on and give an extensive overview of the papers published between 2003 and 2011 which applied FCA-based methods for knowledge discovery and ontology engineering in various application domains. These domains include software mining, web analytics, medicine, biology and chemistry data.
ER  - 

TY  - JOUR
T1  - DESAMC+DocSum: Differential evolution with self-adaptive mutation and crossover parameters for multi-document summarization
JO  - Knowledge-Based Systems
VL  - 36
IS  - 
SP  - 21
EP  - 38
PY  - 2012/12//
T2  - 
AU  - Alguliev, Rasim M.
AU  - Aliguliyev, Ramiz M.
AU  - Isazade, Nijat R.
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2012.05.017
UR  - http://www.sciencedirect.com/science/article/pii/S0950705112001670
KW  - Multi-document summarization
KW  - Optimization problem
KW  - p-Median problem
KW  - Differential evolution
KW  - Self-adaptive mutation and crossover strategies
AB  - Multi-document summarization is used to extract the main ideas of the documents and put them into a short summary. In multi-document summarization, it is important to reduce redundant information in the summaries and extract sentences, which are common to given documents. This paper presents a document summarization model which extracts salient sentences from given documents while reducing redundant information in the summaries and maximizing the summary relevancy. The model is represented as a modified p-median problem. The proposed approach not only expresses sentence-to-sentence relationship, but also expresses summary-to-document and summary-to-subtopics relationships. To solve the optimization problem a new differential evolution algorithm based on self-adaptive mutation and crossover parameters, called DESAMC, is proposed. Experimental studies on DUC benchmark data show the good performance of proposed model and its potential in summarization tasks.
ER  - 

TY  - JOUR
T1  - Shortest-linkage-based parallel hierarchical clustering on main-belt moving objects of the solar system
JO  - Future Generation Computer Systems
VL  - 34
IS  - 
SP  - 26
EP  - 46
PY  - 2014/5//
T2  - Special Section: Distributed Solutions for Ubiquitous Computing and Ambient Intelligence
AU  - Tang, Cheng-Hsien
AU  - Tsai, Meng-Feng
AU  - Chuang, Shan-Hao
AU  - Cheng, Jen-Jung
AU  - Wang, Wei-Jen
SN  - 0167-739X
DO  - http://dx.doi.org/10.1016/j.future.2013.12.029
UR  - http://www.sciencedirect.com/science/article/pii/S0167739X13002938
KW  - Hierarchical clustering
KW  - Incremental update
KW  - Parallel computing
AB  - Abstract
Data clustering is an important data preparation process in many scientific analysis researches. In astronomy, although the distributed environments and modern observation techniques enable users to collect and access huge amounts of data, the corresponding clustering process may become very costly. One of the challenges is that the sequential clustering algorithms, that can be applied to cluster hundreds of thousand main-belt asteroids to reason about the origins of the main-belt asteroids, may not be used in the distributed environment directly. Therefore, this study focuses on the problem of parallelizing the traditional hierarchical agglomerative clustering algorithm using shortest-linkage. We propose a new parallel hierarchical agglomerative clustering algorithm based on the master–worker model. The master process divides the whole computation into several small tasks, and distributes the tasks to the worker processes for parallel processing. Then, the master process merges the results from the worker processes to form a hierarchical data structure. The proposed algorithm uses a pruning threshold to reduce the execution time and the storage requirement during the computation. It also supports fast incremental update that merges new data items into a constructed hierarchical tree in seconds, given a tree of about 550,000 data items. To evaluate the performance of our algorithm, this study has conducted several experiments using the MPCORB dataset and a dataset from the DVO database. The results confirm the efficiency of our proposed methodology. Compared with prior similar studies, the proposed algorithm is more flexible and practical in the problem of distributed hierarchical agglomerative clustering.
ER  - 

TY  - JOUR
T1  - Qualitative and quantitative combinations of crisp and rough clustering schemes using dominance relations
JO  - International Journal of Approximate Reasoning
VL  - 55
IS  - 1, Part 2
SP  - 238
EP  - 258
PY  - 2014/1//
T2  - Special issue on Decision-Theoretic Rough Sets
AU  - Lingras, Pawan
AU  - Chen, Min
AU  - Miao, Duoqian
SN  - 0888-613X
DO  - http://dx.doi.org/10.1016/j.ijar.2013.05.007
UR  - http://www.sciencedirect.com/science/article/pii/S0888613X13001278
KW  - Crisp clustering
KW  - Rough clustering
KW  - Dominance relations
KW  - Preference relations
KW  - Qualitative reasoning
KW  - Combination of clustering schemes
AB  - Abstract
Due to their unsupervised learning nature, analyzing the semantics of clustering schemes can be difficult. Qualitative information such as preference relations may be useful in semantic analysis of clustering process. This paper describes a framework based on preference or dominance relations that helps us qualitatively analyze a clustering scheme. This qualitative interpretation is shown to be useful for combining clustering schemes that are based on different criteria. The qualitative combination can be used to analyze its quantitative counterpart and can also be used instead of the quantitative combination. The paper further extends the framework to accommodate rough set based clustering. The usefulness of the approach is illustrated using a synthetic retail database.
ER  - 

TY  - JOUR
T1  - Crime profiling for the Arabic language using computational linguistic techniques
JO  - Information Processing & Management
VL  - 50
IS  - 2
SP  - 315
EP  - 341
PY  - 2014/3//
T2  - 
AU  - Alruily, Meshrif
AU  - Ayesh, Aladdin
AU  - Zedan, Hussein
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2013.09.001
UR  - http://www.sciencedirect.com/science/article/pii/S0306457313000988
KW  - Arabic language
KW  - Crime domain
KW  - Pattern recognition
KW  - Clustering
KW  - Information extraction
KW  - Syntactic analysis
AB  - Abstract
Arabic is a widely spoken language but few mining tools have been developed to process Arabic text. This paper examines the crime domain in the Arabic language (unstructured text) using text mining techniques. The development and application of a Crime Profiling System (CPS) is presented. The system is able to extract meaningful information, in this case the type of crime, location and nationality, from Arabic language crime news reports. The system has two unique attributes; firstly, information extraction that depends on local grammar, and secondly, dictionaries that can be automatically generated. It is shown that the CPS improves the quality of the data through reduction where only meaningful information is retained. Moreover, the Self Organising Map (SOM) approach is adopted in order to perform the clustering of the crime reports, based on crime type. This clustering technique is improved because only refined data containing meaningful keywords extracted through the information extraction process are inputted into it, i.e. the data are cleansed by removing noise. The proposed system is validated through experiments using a corpus collated from different sources; it was not used during system development. Precision, recall and F-measure are used to evaluate the performance of the proposed information extraction approach. Also, comparisons are conducted with other systems. In order to evaluate the clustering performance, three parameters are used: data size, loading time and quantization error.
ER  - 

TY  - JOUR
T1  - Reprint of “Citation analysis as a measure of article quality, journal influence and individual researcher performance”
JO  - Nurse Education in Practice
VL  - 13
IS  - 5
SP  - 429
EP  - 436
PY  - 2013/9//
T2  - 
AU  - Nightingale, Julie M.
AU  - Marshall, Gill
SN  - 1471-5953
DO  - http://dx.doi.org/10.1016/j.nepr.2013.02.005
UR  - http://www.sciencedirect.com/science/article/pii/S1471595313000309
KW  - Journal metrics
KW  - Citation
KW  - Impact factor
KW  - Research quality
KW  - H-index
KW  - Research evaluation framework
AB  - The research-related performance of universities, as well as that of individual researchers, is increasingly evaluated through the use of objective measures, or metrics, which seek to support or in some cases even replace more traditional methods of peer review. In particular there is a growing awareness in research communities, government organisations and funding bodies around the concept of using evaluation metrics to analyse research citations. The tools available for ‘citation analysis’ are many and varied, enabling a quantification of scientific quality, academic impact and prestige. However there is increasing concern regarding the potential misuse of such tools, which have limitations in certain research disciplines.This article uses ‘real world’ examples from radiography research and scholarship to illustrate the range of currently available citation analysis tools. It explores the academic debate surrounding their strengths and limitations, and identifies the potential impact of citation analysis on the radiography research community.The article concludes that citation analysis is a valuable tool for researchers to use for personal reflection and research planning, yet there are inherent dangers if it is used inappropriately. Whilst citation analysis can give objective information regarding an individual, research group, journal or higher education institution, it should not be used as a total substitute for traditional qualitative review and peer assessment.
ER  - 

TY  - JOUR
T1  - Citation analysis as a measure of article quality, journal influence and individual researcher performance
JO  - Radiography
VL  - 18
IS  - 2
SP  - 60
EP  - 67
PY  - 2012/5//
T2  - 
AU  - Nightingale, Julie M.
AU  - Marshall, Gill
SN  - 1078-8174
DO  - http://dx.doi.org/10.1016/j.radi.2011.10.044
UR  - http://www.sciencedirect.com/science/article/pii/S1078817411001374
KW  - Journal metrics
KW  - Citation
KW  - Impact factor
KW  - Research quality
KW  - H-index
KW  - Research evaluation framework
AB  - The research-related performance of universities, as well as that of individual researchers, is increasingly evaluated through the use of objective measures, or metrics, which seek to support or in some cases even replace more traditional methods of peer review. In particular there is a growing awareness in research communities, government organisations and funding bodies around the concept of using evaluation metrics to analyse research citations. The tools available for ‘citation analysis’ are many and varied, enabling a quantification of scientific quality, academic impact and prestige. However there is increasing concern regarding the potential misuse of such tools, which have limitations in certain research disciplines.

This article uses ‘real world’ examples from radiography research and scholarship to illustrate the range of currently available citation analysis tools. It explores the academic debate surrounding their strengths and limitations, and identifies the potential impact of citation analysis on the radiography research community.

The article concludes that citation analysis is a valuable tool for researchers to use for personal reflection and research planning, yet there are inherent dangers if it is used inappropriately. Whilst citation analysis can give objective information regarding an individual, research group, journal or higher education institution, it should not be used as a total substitute for traditional qualitative review and peer assessment.
ER  - 

TY  - JOUR
T1  - HarVis: An integrated social media content analysis framework for youtube platform
JO  - Information Systems
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Ahmad, Uzair
AU  - Zahid, Anam
AU  - Shoaib, Muhammad
SN  - 0306-4379
DO  - http://dx.doi.org/10.1016/j.is.2016.10.004
UR  - http://www.sciencedirect.com/science/article/pii/S0306437916305014
KW  - User generated content
KW  - Data retrieval
KW  - Information visualization
KW  - Topic and discourse analysis
KW  - Social media analytics
AB  - Abstract
YouTube (owned by Google Inc.) is arguably among most popular social media platforms used by millions across the globe. It provides an ever-growing, unique and rich source of content which presents new opportunities and challenges for information discovery and analysis. It is pertinent to explore and understand a topic via YouTube content to discover interesting information about public opinions and sentiments. This paper presents an integrated framework to facilitate the acquisition, storage, management, processing, and visualization of relevant content with the objective to assist in such analysis. It not only collects a significant portion of content, relevant to a given topic, in short time but also offers tools for visual exploratory analysis such as; (i) temporal evolution, (ii) vocabulary network, (iii) authors relative popularity and influence (iv) categories and (v) user communities and influencers. The utility and effectiveness is demonstrated through content analysis of a famous YouTube entertainment topic, the “Gangnam Style”.
ER  - 

TY  - JOUR
T1  - Anti-logicist framework for design-knowledge representation
JO  - Annual Reviews in Control
VL  - 39
IS  - 
SP  - 144
EP  - 157
PY  - 2015///
T2  - 
AU  - Giovannini, A.
AU  - Aubry, A.
AU  - Panetto, H.
AU  - El Haouzi, H.
AU  - Pierrel, L.
AU  - Dassisti, M.
SN  - 1367-5788
DO  - http://dx.doi.org/10.1016/j.arcontrol.2015.03.013
UR  - http://www.sciencedirect.com/science/article/pii/S1367578815000140
AB  - Abstract
The knowledge reuse and mapping are among the most important concerns related to the design knowledge representation. In this paper, authors focus on the importance of one specific property of a design knowledge representation: the unambiguity. Authors show (1) how the ambiguity of the representation can increase the risk of a failure in the reuse and mapping processes, (2) how most of works in the literature use formal logic constructs and finally (3) how the use of these can increase the risk of ambiguity. On the basis of these remarks, an overview on the works on the anti-logicist architecture is provided: the systems based on this architecture show an intelligent behaviour without using logic constructs. An analysis and a transposition of the anti-logicist principles are then performed to build a framework allowing to represent design knowledge without logic constructs. To do so (1) main concepts are formalised in a conceptual model; (2) an algorithm has been designed to map pieces of knowledge based only on the representation syntax; (3) two instantiations of the framework are showed using a CAD instantiation. Finally, the limits of the current deployment of the framework and the research perspectives are discussed.
ER  - 

TY  - JOUR
T1  - A multi-faceted and automatic knowledge elicitation system (MAKES) for managing unstructured information
JO  - Expert Systems with Applications
VL  - 38
IS  - 5
SP  - 5245
EP  - 5258
PY  - 2011/5//
T2  - 
AU  - Cheung, C.F.
AU  - Lee, W.B.
AU  - Wang, W.M.
AU  - Wang, Y.
AU  - Yeung, W.M.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2010.10.033
UR  - http://www.sciencedirect.com/science/article/pii/S0957417410011772
KW  - Multi-facet
KW  - Taxonomy
KW  - Automatic
KW  - Unstructured information
KW  - Auditing
KW  - Knowledge management
KW  - Professional services
KW  - Self-associated concept mapping
KW  - Knowledge elicitation
KW  - Knowledge mining
AB  - Management of unstructured information, such as emails, is vital for supporting knowledge work in professional services. However, the conventional way for managing unstructured information is inadequate as the knowledge work and associated tasks are becoming more complex, are dynamically changing with time and involve multiple concepts. This paper attempts to address the inadequacy, deficiency and limitations of the methods presently used to elicit knowledge from masses of unstructured information. These methods rely heavily on manpower, are time consuming and costly. With the development of a multi-faceted and automatic knowledge elicitation system (MAKES) manpower, time and cost can be dramatically reduced. The MAKES integrates the processes of collecting data, classifying unstructured information, modelling knowledge flow and social network analysis, and makes all of these actions into a connected process to audit unstructured information automatically. This audit is based on specific search criteria, search keywords, and the user behaviours of the knowledge workers. The unstructured information is automatically organized, classified and presented in a multi-facet taxonomy map. New concepts and knowledge are uncovered, analyzed and updated continuously from the incoming unstructured information, using a purpose-built knowledge elicitation algorithm named self-associated concept mapping (SACM). The capability and advantages of the MAKES are demonstrated through a successful trial implementation and a verification test conducted in an electronics trading company. Encouraging results have been achieved and a number of potential advantages have been realized. The area of application in this first deployment is based on an email-intensive organization and the proposed study will contribute to the advancement of methods and tools for managing other kinds of unstructured information.
ER  - 

TY  - JOUR
T1  - How knowledge management impacts performance in projects: An empirical study
JO  - International Journal of Project Management
VL  - 32
IS  - 4
SP  - 590
EP  - 602
PY  - 2014/5//
T2  - 
AU  - Reich, Blaize Horner
AU  - Gemino, Andrew
AU  - Sauer, Chris
SN  - 0263-7863
DO  - http://dx.doi.org/10.1016/j.ijproman.2013.09.004
UR  - http://www.sciencedirect.com/science/article/pii/S0263786313001269
KW  - Knowledge management
KW  - IT-enabled business projects
KW  - Project Performance
KW  - Project Management Performance
KW  - Business value
AB  - Abstract
This paper develops theory and tests the relationships between knowledge management and various aspects of performance in IT-enabled business projects. The proposed theory posits that knowledge management is instrumental to Project Performance when mediated by a new concept, Knowledge Alignment. The research model is tested on survey data from 212 IT-enabled business projects. Findings show that project managers who achieve Knowledge Alignment among the people and the artefacts from three parts of the project – the IT team, the business change team, and the governance team – can have a significant positive impact on the achievement of business value from the project. Achieving higher levels of Knowledge Alignment is shown to have no significant negative impact on attainment of schedule and budget targets. This is the first statistical study to demonstrate the effect of knowledge management and Knowledge Alignment on the attainment of project management targets and of business value in IT-enabled projects.
ER  - 

TY  - JOUR
T1  - Plans versus people: Comparing knowledge management approaches in IT-enabled business projects
JO  - International Journal of Project Management
VL  - 33
IS  - 2
SP  - 299
EP  - 310
PY  - 2015/2//
T2  - 
AU  - Gemino, Andrew
AU  - Reich, Blaize Horner
AU  - Sauer, Chris
SN  - 0263-7863
DO  - http://dx.doi.org/10.1016/j.ijproman.2014.04.012
UR  - http://www.sciencedirect.com/science/article/pii/S0263786314000799
KW  - Knowledge management
KW  - Codification
KW  - Socialization
KW  - Knowledge alignment
KW  - Project performance
AB  - Abstract
This paper evaluates the impact of two approaches to knowledge management in projects — one focused on aligning project documents (“the Plan-based approach”) and another focused on developing shared understanding between different teams within a project (“the People-based approach”). A theoretical model and hypotheses are proposed and explored using data from a survey of 212 IT-enabled business projects. Results indicate that the people-based approach is more strongly influential on a project's success in securing business benefits. Although the plan-based approach is less influential, it does positively influence business benefit attainment and also supports the people-based approach. Thus, attaining shared understanding within the project team and aligning key documents are both important goals for a project's knowledge management strategy.
ER  - 

TY  - JOUR
T1  - Boundary work in sustainability partnerships: An exploration of the Round Table on Sustainable Palm Oil
JO  - Environmental Science & Policy
VL  - 50
IS  - 
SP  - 34
EP  - 45
PY  - 2015/6//
T2  - 
AU  - Offermans, Astrid
AU  - Glasbergen, Pieter
SN  - 1462-9011
DO  - http://dx.doi.org/10.1016/j.envsci.2015.01.016
UR  - http://www.sciencedirect.com/science/article/pii/S1462901115000180
KW  - Joint knowledge production
KW  - Sustainability partnerships
KW  - Boundary organizations
KW  - Boundary work
AB  - Abstract
Sustainability partnerships have the potential to function as boundary organizations that intertwine stakeholders from different domains of society to jointly produce knowledge linked to action. However, little is known about the practice of knowledge production in such arrangements. In this paper we develop an analytical framework, based on attributes of the nature of knowledge, the process of knowledge production, and the organization of that process, to analyze the extent to which knowledge processes in partnerships can be understood as joint knowledge production (JKP). The application of the framework to the exemplary case of the Round Table on Sustainable Palm Oil (RSPO) shows that science and scientific knowledge do not necessarily play a dominant role in such a boundary organization. The analysis also shows that an abstract concept like JKP can be operationalized and used to assess characteristic of knowledge production in partnerships. This may provide leverage points to the actors involved to improve their boundary work. The framework can also be used as a dialogue instrument to open-up discussions about, and to reflect upon JKP in boundary organizations.
ER  - 

TY  - JOUR
T1  - Information management and improvement of citation indices
JO  - International Journal of Information Management
VL  - 34
IS  - 2
SP  - 257
EP  - 271
PY  - 2014/4//
T2  - 
AU  - Gomez-Jauregui, Valentin
AU  - Gomez-Jauregui, Cecilia
AU  - Manchado, Cristina
AU  - Otero, Cesar
SN  - 0268-4012
DO  - http://dx.doi.org/10.1016/j.ijinfomgt.2014.01.002
UR  - http://www.sciencedirect.com/science/article/pii/S0268401214000036
KW  - Information management
KW  - Bibliometrics
KW  - Citation indices
KW  - Data cleaning
KW  - Software
AB  - Abstract
Bibliometrics and citation analysis have become important sets of methods for library and information science, as well as exceptional sources of information and knowledge for many other areas. Their main sources are citation indices, which are bibliographic databases like Web of Science, Scopus, Google Scholar, etc. However, bibliographical databases lack perfection and standardization. There are several software tools that perform useful information management and bibliometric analysis importing data from them. A comparison has been carried out to identify which of them perform certain pre-processing tasks. Usually, they are not strong enough to detect all the duplications, mistakes, misspellings and variant names, leaving to the user the tedious and time-consuming task of correcting the data. Furthermore, some of them do not import datasets from different citation indices, but mainly from Web of Science (WoS).

A new software tool, called STICCI.eu (Software Tool for Improving and Converting Citation Indices – enhancing uniformity), which is freely available online, has been created to solve these problems. STICCI.eu is able to do conversions between bibliographical citation formats (WoS, Scopus, CSV, BibTex, RIS), correct the usual mistakes appearing in those databases, detect duplications, misspellings, etc., identify and transform the full or abbreviated titles of the journals, homogenize toponymical names of countries and relevant cities or regions and list the processed data in terms of the most cited authors, journals, references, etc.
ER  - 

TY  - JOUR
T1  - Spontaneous Mind Map Use and Learning from Texts: The Role of Instruction and Student Characteristics
JO  - Procedia - Social and Behavioral Sciences
VL  - 69
IS  - 
SP  - 1387
EP  - 1394
PY  - 2012/12/24/
T2  - International Conference on Education &amp; Educational Psychology (ICEEPSY 2012)
AU  - Merchie, Emmelien
AU  - Van Keer, Hilde
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2012.12.077
UR  - http://www.sciencedirect.com/science/article/pii/S1877042812055371
KW  - Learning from texts
KW  - Mind Maps
KW  - instruction method
KW  - gender
KW  - appreciation
KW  - self-efficacy
AB  - Independently processing and learning informative study texts becomes increasingly important from the age of 11-13, when the focus shifts from ‘learning to read’ to ‘reading to learn’. The need arises to support students in dealing with study texts and stimulating generative study strategies promoting active knowledge transformation. This study shows that a Mind Map (MM) intervention can prompt fifth and sixth graders to use MM during text learning. Furthermore, the MM instruction method, students’ gender, MM appreciation, and self-efficacy seem to influence their spontaneous use. No significant differences were found on immediate free text recall.
ER  - 

TY  - JOUR
T1  - A hybrid cognitive assessment based on ontology knowledge map and skills
JO  - Knowledge-Based Systems
VL  - 73
IS  - 
SP  - 52
EP  - 60
PY  - 2015/1//
T2  - 
AU  - Zhong, Xiuqin
AU  - Fu, Hongguang
AU  - Xia, Huadong
AU  - Yang, Leina
AU  - Shang, Mingsheng
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2014.09.004
UR  - http://www.sciencedirect.com/science/article/pii/S0950705114003347
KW  - Ontology
KW  - Knowledge map
KW  - Skill
KW  - Cognitive model
KW  - Assessment
AB  - Abstract
An intelligent tutoring system plays vital role in education and its importance is constantly increasing, meanwhile the key challenge in the teaching learning process is assessing students’ learning efficiently. In this paper, a hybrid assessment based-on ACT-R cognitive learning theory, combining ontology knowledge map with skills is proposed. In order to assess how well students master knowledge structure, an ontology knowledge map is constructed to describe declarative knowledge; and in order to assess how well students master knowledge skills, a problem solving process is constructed to describe procedural knowledge based on ACT-R. Finally, a student’s mastery of knowledge is assessed through both the knowledge map and skills in the problem solving process, as well as auxiliary indicators like time usage, prior knowledge level, self-assessment, etc. This method is implemented in a geometric intelligent assessment system and is evaluated in a junior high school. Experiments show that the assessment results are consistent with students’ actual learning levels. The hybrid cognitive assessment method can not only obtain the score of students’ mastery of knowledge points and the structure through knowledge map, but also assess the learning skills in problem solving process through exercises quantitatively.
ER  - 

TY  - JOUR
T1  - MIND – Semantic Based Knowledge Visualization
JO  - Procedia CIRP
VL  - 36
IS  - 
SP  - 89
EP  - 94
PY  - 2015///
T2  - CIRP 25th Design Conference Innovative Product Creation
AU  - Molcho, Gila
AU  - Schneor, Ronit
SN  - 2212-8271
DO  - http://dx.doi.org/10.1016/j.procir.2015.03.011
UR  - http://www.sciencedirect.com/science/article/pii/S2212827115002085
KW  - Applied knowledge management
KW  - semantic analysis
KW  - knowledge visualization
AB  - Abstract
In what has come to be known as the ‘Knowledge Era’, economy relies more than ever on knowledge-based activities. The need to capture, integrate and capitalize on knowledge within organizations, in an efficient and effective way has become crucial to maintaining a competitive edge in the market. Knowledge, Information and Data have always been of importance in human history, however, as technology advances and knowledge becomes more readily available, the requirement of providing knowledge workers with relevant knowledge inline and online to their ongoing activities has become a significant modern industrial and academic challenge. Whilst in the past the challenge was to maximize benefit retrieved from data (i.e. ERP, CRP solutions) and later from information (Business Intelligence (BI) tools) the new task is to provide equivalent knowledge solutions. This paper will present MIND, a multipurpose and user friendly, semantic analysis and knowledge visualization tool. MIND is applicable to a wide spectrum of applications, three of which will be presented in this paper, knowledge community mapping, CAD part profiling and an advanced BI application.
ER  - 

TY  - JOUR
T1  - A comprehensive analysis of energy management strategies for hybrid electric vehicles based on bibliometrics
JO  - Renewable and Sustainable Energy Reviews
VL  - 48
IS  - 
SP  - 88
EP  - 104
PY  - 2015/8//
T2  - 
AU  - Zhang, Pei
AU  - Yan, Fuwu
AU  - Du, Changqing
SN  - 1364-0321
DO  - http://dx.doi.org/10.1016/j.rser.2015.03.093
UR  - http://www.sciencedirect.com/science/article/pii/S1364032115002464
KW  - Hybrid electric vehicles
KW  - Energy management strategy
KW  - Bibliometrics
KW  - Rule-based energy management strategy
KW  - Optimization-based energy management strategy
AB  - Abstract
Hybrid electric vehicles (HEVs) are one of the most viable technologies to achieve the goals of energy saving and environmental protection before a breakthrough in battery technology and fuel cell technology. Energy management strategy as a key technology of HEVs is studied extensively and deeply to improve the performance of HEVs and speed up the industrialization of HEVs. This paper quantitatively analyzes and evaluates current research status of energy management strategies for HEVs based on bibliometrics for the first time, through content analysis involving analysis of author keywords and abstracts. Then qualitative analysis is performed for all kinds of energy management strategies that are used in HEVs in detail, essential characteristics involving pros and cons, interconnections and improvement potential among various energy management strategies are revealed from the view of control theory. Finally, latest developing trends in energy management strategies of HEVs are presented to improve the performance of HEVs based on above quantitative analysis and qualitative analysis, covering driving cycle recognition/prediction algorithms, integrated multi-objective, coordinated optimization energy management strategies, good balance between computation complexity and optimization performance of energy management strategies, fair and credible evaluation system of energy management strategies. This paper not only first provides a comprehensive analysis of energy management strategies for HEVs, but also puts forward the emphasis and orientation of future study, which will broaden relevant researchers׳ vision and promote the development of a simple and practical energy management controller with low cost and high performance for HEVs.
ER  - 

TY  - JOUR
T1  - Probabilistic topic modeling in multilingual settings: An overview of its methodology and applications
JO  - Information Processing & Management
VL  - 51
IS  - 1
SP  - 111
EP  - 147
PY  - 2015/1//
T2  - 
AU  - Vulić, Ivan
AU  - De Smet, Wim
AU  - Tang, Jie
AU  - Moens, Marie-Francine
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2014.08.003
UR  - http://www.sciencedirect.com/science/article/pii/S0306457314000739
KW  - Multilingual probabilistic topic models
KW  - Cross-lingual text mining
KW  - Cross-lingual knowledge transfer
KW  - Cross-lingual information retrieval
KW  - Language-independent data representation
KW  - Non-parallel data
AB  - Abstract
Probabilistic topic models are unsupervised generative models which model document content as a two-step generation process, that is, documents are observed as mixtures of latent concepts or topics, while topics are probability distributions over vocabulary words. Recently, a significant research effort has been invested into transferring the probabilistic topic modeling concept from monolingual to multilingual settings. Novel topic models have been designed to work with parallel and comparable texts. We define multilingual probabilistic topic modeling (MuPTM) and present the first full overview of the current research, methodology, advantages and limitations in MuPTM. As a representative example, we choose a natural extension of the omnipresent LDA model to multilingual settings called bilingual LDA (BiLDA). We provide a thorough overview of this representative multilingual model from its high-level modeling assumptions down to its mathematical foundations. We demonstrate how to use the data representation by means of output sets of (i) per-topic word distributions and (ii) per-document topic distributions coming from a multilingual probabilistic topic model in various real-life cross-lingual tasks involving different languages, without any external language pair dependent translation resource: (1) cross-lingual event-centered news clustering, (2) cross-lingual document classification, (3) cross-lingual semantic similarity, and (4) cross-lingual information retrieval. We also briefly review several other applications present in the relevant literature, and introduce and illustrate two related modeling concepts: topic smoothing and topic pruning. In summary, this article encompasses the current research in multilingual probabilistic topic modeling. By presenting a series of potential applications, we reveal the importance of the language-independent and language pair independent data representations by means of MuPTM. We provide clear directions for future research in the field by providing a systematic overview of how to link and transfer aspect knowledge across corpora written in different languages via the shared space of latent cross-lingual topics, that is, how to effectively employ learned per-topic word distributions and per-document topic distributions of any multilingual probabilistic topic model in various cross-lingual applications.
ER  - 

TY  - JOUR
T1  - Identifying Citation Classics in Fuzzy Decision Making Field Using the Concept of H-Classics
JO  - Procedia Computer Science
VL  - 31
IS  - 
SP  - 567
EP  - 576
PY  - 2014///
T2  - 2nd International Conference on Information Technology and Quantitative Management, ITQM 2014
AU  - Cobo, M.J.
AU  - Martínez, M.A.
AU  - Gutiérrez-Salcedo, M.
AU  - Herrera, M.
AU  - Herrera-Viedma, E.
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2014.05.303
UR  - http://www.sciencedirect.com/science/article/pii/S1877050914004803
KW  - Citation classics
KW  - bibliometric measures
KW  - h-index
KW  - fuzzy decision making.
AB  - Abstract
Citation classics identify those highly cited papers which are an important reference point in a research field. Identifying citation classics in a research field is one of the main approaches used to conduct a systematic evaluation of research performance. Highly cited articles are interesting due to the potential association between high citation counts and high quality research.

The aim of this study is to identify and analyze the most frequently cited papers published into the Fuzzy Decision Making research field, using the H-Classics approach which is based in the well-known H-index. The Fuzzy Decision Making is represented by 70 highly citations classics which where published from 1981 to 2010. Furthermore, authors, affiliations, journals and the concept covered by those 70 highly cited documents are analyzed.

We identify three countries that have contributed substantially to development of the Fuzzy Decision Making research field: Spain, Peoples Republic of China and USA. Regarding the journals, Fuzzy Sets and Systems, European Journal of Operation Research, IEEE Transactions on Fuzzy Systems and International Journal of Intelligent Systems are the ones where the citations classics have been mainly published. Finally, the concepts covered by those citations classics are related with techniques and tools used in Fuzzy Sets theory and Fuzzy Decision Making research field, and terms related with Decision making theory and its developments.
ER  - 

TY  - JOUR
T1  - A comparative survey of Personalised Information Retrieval and Adaptive Hypermedia techniques
JO  - Information Processing & Management
VL  - 48
IS  - 4
SP  - 698
EP  - 724
PY  - 2012/7//
T2  - 
AU  - Steichen, Ben
AU  - Ashman, Helen
AU  - Wade, Vincent
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2011.12.004
UR  - http://www.sciencedirect.com/science/article/pii/S0306457311001178
KW  - Adaptive Hypermedia
KW  - Personalised Information Retrieval
KW  - Query adaptation
KW  - Adaptive composition
KW  - Adaptive presentation
KW  - Adaptive web
AB  - A key driver for next generation web information retrieval systems is becoming the degree to which a user’s search and presentation experience is adapted to individual user properties and contexts of use. Over the past decades, two parallel threads of personalisation research have emerged, one originating in the document space in the area of Personalised Information Retrieval (PIR) and the other arising from the hypertext space in the field of Adaptive Hypermedia (AH).

PIR typically aims to bias search results towards more personally relevant information by modifying traditional document ranking algorithms. Such techniques tend to represent users with simplified personas (often based on historic interests), enabling the efficient calculation of personalised ranked lists. On the other hand, the field of Adaptive Hypermedia (AH) has addressed the challenge of biasing content retrieval and presentation by adapting towards multiple characteristics. These characteristics, more typically called personalisation “dimensions”, include user goals or prior knowledge, enabling adaptive and personalised result compositions and navigations.

The question arises as to whether it is possible to provide a comparison of PIR and AH, where the respective strengths and limitations can be exposed, but also where potential complementary affordances can be identified. This survey investigates the key techniques and impacts in the use of PIR and AH technology in order to identify such affordances and limitations. In particular, the techniques are analysed by examining key activities in the retrieval process, namely (i) query adaptation, (ii) adaptive retrieval and (iii) adaptive result composition and presentation. In each of these areas, the survey identifies individual strengths and limitations. Following this comparison of techniques, the paper also illustrates an example of a potential synergy in a hybridised approach, where adaptation can be tailored in different aspects of PIR and AH systems. Moreover, the concerns resulting from interdependencies and the respective tradeoffs of techniques are discussed, along with potential future directions and remaining challenges.
ER  - 

TY  - JOUR
T1  - A survey on cloud computing security: Issues, threats, and solutions
JO  - Journal of Network and Computer Applications
VL  - 75
IS  - 
SP  - 200
EP  - 222
PY  - 2016/11//
T2  - 
AU  - Singh, Saurabh
AU  - Jeong, Young-Sik
AU  - Park, Jong Hyuk
SN  - 1084-8045
DO  - http://dx.doi.org/10.1016/j.jnca.2016.09.002
UR  - http://www.sciencedirect.com/science/article/pii/S1084804516301990
KW  - Cloud computing
KW  - Security
KW  - Embedded system
KW  - Resource pooling
AB  - Abstract
Over the internet, the cloud computing reveals a remarkable potential to provide on-demand services to consumers with greater flexibility in a cost effective manner. While moving towards the concept of on-demand service, resource pooling, shifting everything on the distributive environment, security is the major obstacle for this new dreamed vision of computing capability. This survey present a comprehensive overview of the security issues for different factors affecting cloud computing. Furthermore, a detailed discussion on several key topics regarding embedded system, application, storage system, clustering related issues and many more. This paper works on some public cloud and private cloud authorities as well as related security concerns. Additionally, it encompasses the requirements for better security management and suggests 3-tier security architecture. Open issues with discussion in which some new security concepts and recommendations are also provided.
ER  - 

TY  - JOUR
T1  - Approximation to the Study of Scientific Production of AEIPRO's International Congresses in Engineering and Project Management
JO  - Procedia - Social and Behavioral Sciences
VL  - 119
IS  - 
SP  - 796
EP  - 804
PY  - 2014/3/19/
T2  - Selected papers from the 27th IPMA (International Project Management Association), World Congress, Dubrovnik, Croatia, 2013
AU  - Guerrero, Dante
AU  - Martínez-Almela, Jesús
AU  - Yagüe, José L.
AU  - La Rosa, Gerson
AU  - Girón, Catherin
AU  - Zatán, Karen
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2014.03.089
UR  - http://www.sciencedirect.com/science/article/pii/S1877042814021806
KW  - Information visualization
KW  - scientific domain analysis
KW  - network analysis
AB  - Abstract
The paper shows the results from the analysis of scientific activity developed at Engineering International Congresses and Project Management organized by the Asociación Española de Dirección e Ingeniería de Proyectos (AEIPRO) (Spanish Association of Engineering and Management Project). Through the visualization of the scientific domain and by network analysis, we intend to provide a different perspective to the study of convergent relationships of literature developed at these international events.

The results allow to approximate the scientific knowledge foundation in Project Engineering developed at AEIPRO International congresses between 1998 and 2012, providing descriptive results of the degree of research integration, the distribution of international contribution, the scientific collaboration between universities, professional and scientific institutions, and also identifying scientific research fronts in order to promote scientific research in this field of science, which is relevant due to its scope and implication in different environments. Copyright © 2014 Elsevier Science Ltd. All rights reserved.
ER  - 

TY  - JOUR
T1  - Conceptual modeling for identification of worst case conditions in environmental risk assessment of nanomaterials using nZVI and C60 as case studies
JO  - Science of The Total Environment
VL  - 409
IS  - 19
SP  - 4109
EP  - 4124
PY  - 2011/9/1/
T2  - 
AU  - Grieger, Khara D.
AU  - Hansen, Steffen F.
AU  - Sørensen, Peter B.
AU  - Baun, Anders
SN  - 0048-9697
DO  - http://dx.doi.org/10.1016/j.scitotenv.2011.06.021
UR  - http://www.sciencedirect.com/science/article/pii/S0048969711006449
KW  - Environmental risk assessment
KW  - Nanomaterial
KW  - Nanoparticle
KW  - Worst-case conditions
KW  - nZVI
KW  - C60
AB  - Conducting environmental risk assessment of engineered nanomaterials has been an extremely challenging endeavor thus far. Moreover, recent findings from the nano-risk scientific community indicate that it is unlikely that many of these challenges will be easily resolved in the near future, especially given the vast variety and complexity of nanomaterials and their applications. As an approach to help optimize environmental risk assessments of nanomaterials, we apply the Worst-Case Definition (WCD) model to identify best estimates for worst-case conditions of environmental risks of two case studies which use engineered nanoparticles, namely nZVI in soil and groundwater remediation and C60 in an engine oil lubricant. Results generated from this analysis may ultimately help prioritize research areas for environmental risk assessments of nZVI and C60 in these applications as well as demonstrate the use of worst-case conditions to optimize future research efforts for other nanomaterials. Through the application of the WCD model, we find that the most probable worst-case conditions for both case studies include i) active uptake mechanisms, ii) accumulation in organisms, iii) ecotoxicological response mechanisms such as reactive oxygen species (ROS) production and cell membrane damage or disruption, iv) surface properties of nZVI and C60, and v) acute exposure tolerance of organisms. Additional estimates of worst-case conditions for C60 also include the physical location of C60 in the environment from surface run-off, cellular exposure routes for heterotrophic organisms, and the presence of light to amplify adverse effects. Based on results of this analysis, we recommend the prioritization of research for the selected applications within the following areas: organism active uptake ability of nZVI and C60 and ecotoxicological response end-points and response mechanisms including ROS production and cell membrane damage, full nanomaterial characterization taking into account detailed information on nanomaterial surface properties, and investigations of dose–response relationships for a variety of organisms.
ER  - 

TY  - JOUR
T1  - Herd Clustering: A synergistic data clustering approach using collective intelligence
JO  - Applied Soft Computing
VL  - 23
IS  - 
SP  - 61
EP  - 75
PY  - 2014/10//
T2  - 
AU  - Wong, Ka-Chun
AU  - Peng, Chengbin
AU  - Li, Yue
AU  - Chan, Tak-Ming
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2014.05.034
UR  - http://www.sciencedirect.com/science/article/pii/S1568494614002610
KW  - Heuristic
KW  - Natural computing
KW  - Herd behavior
KW  - Collective intelligence
AB  - Abstract
Traditional data mining methods emphasize on analytical abilities to decipher data, assuming that data are static during a mining process. We challenge this assumption, arguing that we can improve the analysis by vitalizing data. In this paper, this principle is used to develop a new clustering algorithm.

Inspired by herd behavior, the clustering method is a synergistic approach using collective intelligence called Herd Clustering (HC). The novel part is laid in its first stage where data instances are represented by moving particles. Particles attract each other locally and form clusters by themselves as shown in the case studies reported. To demonstrate its effectiveness, the performance of HC is compared to other state-of-the art clustering methods on more than thirty datasets using four performance metrics. An application for DNA motif discovery is also conducted. The results support the effectiveness of HC and thus the underlying philosophy.
ER  - 

TY  - JOUR
T1  - A conceptual representation of documents and queries for information retrieval systems by using light ontologies
JO  - Expert Systems with Applications
VL  - 39
IS  - 12
SP  - 10376
EP  - 10388
PY  - 2012/9/15/
T2  - 
AU  - Dragoni, Mauro
AU  - da Costa Pereira, Célia
AU  - Tettamanzi, Andrea G.B.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2012.01.188
UR  - http://www.sciencedirect.com/science/article/pii/S0957417412002163
KW  - Conceptual representation
KW  - Lexica
KW  - Ontologies
KW  - Intelligent information retrieval
AB  - This article presents a vector space model approach to representing documents and queries, based on concepts instead of terms and using WordNet as a light ontology. Such representation reduces information overlap with respect to classic semantic expansion techniques. Experiments carried out on the MuchMore benchmark and on the TREC-7 and TREC-8 Ad-Hoc collections demonstrate the effectiveness of the proposed approach.
ER  - 

TY  - JOUR
T1  - Communities of Web service registries: Construction and management
JO  - Journal of Systems and Software
VL  - 86
IS  - 3
SP  - 835
EP  - 853
PY  - 2013/3//
T2  - 
AU  - Sellami, Mohamed
AU  - Bouchaala, Olfa
AU  - Gaaloul, Walid
AU  - Tata, Samir
SN  - 0164-1212
DO  - http://dx.doi.org/10.1016/j.jss.2012.11.019
UR  - http://www.sciencedirect.com/science/article/pii/S0164121212003123
KW  - Service oriented computing
KW  - Organization of Web service registries
KW  - Communities of registries
KW  - Managing communities of registries
AB  - The last few years have seen a democratization in the use of Internet technologies, mainly Web services, for electronic B2B transactions. This has triggered an increase in the number of companies’ Web service registries. In this paper, we propose to use communities as a means to organize Web service registries in such a context. We provide an automatic and implicit approach to create communities of Web service registries using registries’ WSRD descriptions. We also define the needed management operations to ensure the communities consistency during a registry/community life-cycle. Experiments we have made show the feasibility and validity of our community creation approach as well as the specified managing operations.
ER  - 

TY  - JOUR
T1  - An open-source toolkit for mining Wikipedia
JO  - Artificial Intelligence
VL  - 194
IS  - 
SP  - 222
EP  - 239
PY  - 2013/1//
T2  - Artificial Intelligence, Wikipedia and Semi-Structured Resources
AU  - Milne, David
AU  - Witten, Ian H.
SN  - 0004-3702
DO  - http://dx.doi.org/10.1016/j.artint.2012.06.007
UR  - http://www.sciencedirect.com/science/article/pii/S000437021200077X
KW  - Wikipedia
KW  - Toolkit
KW  - Ontology extraction
KW  - Semantic relatedness
KW  - Disambiguation
KW  - Annotation
AB  - The online encyclopedia Wikipedia is a vast, constantly evolving tapestry of interlinked articles. For developers and researchers it represents a giant multilingual database of concepts and semantic relations, a potential resource for natural language processing and many other research areas. This paper introduces the Wikipedia Miner toolkit, an open-source software system that allows researchers and developers to integrate Wikipediaʼs rich semantics into their own applications. The toolkit creates databases that contain summarized versions of Wikipediaʼs content and structure, and includes a Java API to provide access to them. Wikipediaʼs articles, categories and redirects are represented as classes, and can be efficiently searched, browsed, and iterated over. Advanced features include parallelized processing of Wikipedia dumps, machine-learned semantic relatedness measures and annotation features, and XML-based web services. Wikipedia Miner is intended to be a platform for sharing data mining techniques.
ER  - 

TY  - JOUR
T1  - Extracting hot spots of topics from time-stamped documents
JO  - Data & Knowledge Engineering
VL  - 70
IS  - 7
SP  - 642
EP  - 660
PY  - 2011/7//
T2  - 
AU  - Chen, Wei
AU  - Chundi, Parvathi
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2011.03.009
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X11000449
KW  - Scan statistic
KW  - Text mining
KW  - Hot spots
KW  - Topics
AB  - Identifying time periods with a burst of activities related to a topic has been an important problem in analyzing time-stamped documents. In this paper, we propose an approach to extract a hot spot of a given topic in a time-stamped document set. Topics can be basic, containing a simple list of keywords, or complex. Logical relationships such as and, or, and not are used to build complex topics from basic topics. A concept of presence measure of a topic based on fuzzy set theory is introduced to compute the amount of information related to the topic in the document set. Each interval in the time period of the document set is associated with a numeric value which we call the discrepancy score. A high discrepancy score indicates that the documents in the time interval are more focused on the topic than those outside of the time interval. A hot spot of a given topic is defined as a time interval with the highest discrepancy score. We first describe a naive implementation for extracting hot spots. We then construct an algorithm called EHE (Efficient Hot Spot Extraction) using several efficient strategies to improve performance. We also introduce the notion of a topic DAG to facilitate an efficient computation of presence measures of complex topics. The proposed approach is illustrated by several experiments on a subset of the TDT-Pilot Corpus and DBLP conference data set. The experiments show that the proposed EHE algorithm significantly outperforms the naive one, and the extracted hot spots of given topics are meaningful.
ER  - 

TY  - JOUR
T1  - SBV-Cut: Vertex-cut based graph partitioning using structural balance vertices
JO  - Data & Knowledge Engineering
VL  - 72
IS  - 
SP  - 285
EP  - 303
PY  - 2012/2//
T2  - 
AU  - Kim, Mijung
AU  - Candan, K. Selçuk
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2011.11.004
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X11001480
KW  - Clustering
KW  - Mining methods and algorithms
KW  - Graph partitioning
KW  - Vertex-cut
AB  - Graphs are used for modeling a large spectrum of data from the web, to social connections between individuals, to concept maps and ontologies. As the number and complexities of graph based applications increase, rendering these graphs more compact, easier to understand, and navigate through are becoming crucial tasks. One approach to graph simplification is to partition the graph into smaller parts, so that instead of the whole graph, the partitions and their inter-connections need to be considered. Common approaches to graph partitioning involve identifying sets of edges (or edge-cuts) or vertices (or vertex-cuts) whose removal partitions the graph into the target number of disconnected components. While edge-cuts result in partitions that are vertex disjoint, in vertex-cuts the data vertices can serve as bridges between the resulting data partitions; consequently, vertex-cut based approaches are especially suitable when the vertices on the vertex-cut will be replicated on all relevant partitions. A significant challenge in vertex-cut based partitioning, however, is ensuring the balance of the resulting partitions while simultaneously minimizing the number of vertices that are cut (and thus replicated). In this paper, we propose a SBV-Cut algorithm which identifies a set of balance vertices that can be used to effectively and efficiently bisect a directed graph. The graph can then be further partitioned by a recursive application of structurally-balanced cuts to obtain a hierarchical partitioning of the graph. Experiments show that SBV-Cut provides better vertex-cut based expansion and modularity scores than its competitors and works several orders more efficiently than constraint-minimization based approaches.
ER  - 

TY  - JOUR
T1  - Literature listing
JO  - World Patent Information
VL  - 38
IS  - 
SP  - 95
EP  - 104
PY  - 2014/9//
T2  - 
AU  - Newton, David
SN  - 0172-2190
DO  - http://dx.doi.org/10.1016/j.wpi.2014.04.001
UR  - http://www.sciencedirect.com/science/article/pii/S0172219014000453
ER  - 

TY  - JOUR
T1  - SyMSS: A syntax-based measure for short-text semantic similarity
JO  - Data & Knowledge Engineering
VL  - 70
IS  - 4
SP  - 390
EP  - 405
PY  - 2011/4//
T2  - 
AU  - Oliva, Jesús
AU  - Serrano, José Ignacio
AU  - del Castillo, María Dolores
AU  - Iglesias, Ángel
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2011.01.002
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X11000036
KW  - Linguistic tools for IS modeling
KW  - Text DBs
KW  - Natural language processing (NLP)
KW  - Semantic similarity
KW  - Sentence similarity
AB  - Sentence and short-text semantic similarity measures are becoming an important part of many natural language processing tasks, such as text summarization and conversational agents. This paper presents SyMSS, a new method for computing short-text and sentence semantic similarity. The method is based on the notion that the meaning of a sentence is made up of not only the meanings of its individual words, but also the structural way the words are combined. Thus, SyMSS captures and combines syntactic and semantic information to compute the semantic similarity of two sentences. Semantic information is obtained from a lexical database. Syntactic information is obtained through a deep parsing process that finds the phrases in each sentence. With this information, the proposed method measures the semantic similarity between concepts that play the same syntactic role. Psychological plausibility is added to the method by using previous findings about how humans weight different syntactic roles when computing semantic similarity. The results show that SyMSS outperforms state-of-the-art methods in terms of rank correlation with human intuition, thus proving the importance of syntactic information in sentence semantic similarity computation.
ER  - 

TY  - JOUR
T1  - Collaborative clustering with background knowledge
JO  - Data & Knowledge Engineering
VL  - 69
IS  - 2
SP  - 211
EP  - 228
PY  - 2010/2//
T2  - 
AU  - Forestier, G.
AU  - Gançarski, P.
AU  - Wemmert, C.
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2009.10.004
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X09001463
KW  - Collaborative clustering
KW  - Unsupervised learning
KW  - Classification
KW  - Pattern recognition
KW  - Knowledge-guided clustering
AB  - The aim of collaborative clustering is to make different clustering methods collaborate, in order to reach at an agreement on the partitioning of a common dataset. As different clustering methods can produce different partitioning of the same dataset, finding a consensual clustering from these results is often a hard task. The collaboration aims to make the methods agree on the partitioning through a refinement of their results. This process tends to make the results more similar.

In this paper, after the introduction of the collaboration process, we present different ways to integrate background knowledge into it. Indeed, in recent years, the integration of background knowledge in clustering algorithms has been the subject of a lot of interest. This integration often leads to an improvement of the quality of the results. We discuss how such integration in the collaborative process is beneficial and we present experiments in which background knowledge is used to guide collaboration.
ER  - 

TY  - JOUR
T1  - Position-wise contextual advertising: Placing relevant ads at appropriate positions of a web page
JO  - Neurocomputing
VL  - 120
IS  - 
SP  - 524
EP  - 535
PY  - 2013/11/23/
T2  - Image Feature Detection and Description
AU  - Wu, Zongda
AU  - Xu, Guandong
AU  - Lu, Chenglang
AU  - Chen, Enhong
AU  - Zhang, Yanchun
AU  - Zhang, Hong
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2013.04.018
UR  - http://www.sciencedirect.com/science/article/pii/S0925231213005110
KW  - Wikipedia knowledge
KW  - Similarity
KW  - Contextual advertising
AB  - Abstract
Web advertising, a form of online advertising, which uses the Internet as a medium to post product or service information and attract customers, has become one of the most important marketing channels. As one prevalent type of web advertising, contextual advertising refers to the placement of the most relevant ads at appropriate positions of a web page, so as to provide a better user experience and increase the user's ad-click rate. However, most existing contextual advertising techniques only take into account how to select as relevant ads for a given page as possible, without considering the positional effect of the ad placement on the page, resulting in an unsatisfactory performance in ad local context relevance. In this paper, we address the novel problem of position-wise contextual advertising, i.e., how to select and place relevant ads properly for a target web page. In our proposed approach, the relevant ads are selected based on not only global context relevance but also local context relevance, so that the embedded ads yield contextual relevance to both the whole target page and the insertion positions where the ads are placed. In addition, to improve the accuracy of global and local context relevance measure, the rich wikipedia knowledge is used to enhance the semantic feature representation of pages and ad candidates. Last, we evaluate our approach using a set of ads and pages downloaded from the Internet, and demonstrate the effectiveness of our approach.
ER  - 

TY  - JOUR
T1  - Semantic search in the World News domain using automatically extracted metadata files
JO  - Knowledge-Based Systems
VL  - 27
IS  - 
SP  - 38
EP  - 50
PY  - 2012/3//
T2  - 
AU  - Kallipolitis, Leonidas
AU  - Karpis, Vassilis
AU  - Karali, Isambo
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2011.12.007
UR  - http://www.sciencedirect.com/science/article/pii/S0950705111002735
KW  - Semantic search
KW  - Automatic metadata extraction
KW  - World News
KW  - Text categorization
KW  - Natural language understanding
AB  - The Semantic Web can have great influence on various domains of information. One of them is the domain of World News. Semantic Web technologies aim at providing the means to organize the vast amount of knowledge that is scattered in the Web, in a machine understandable way. Then, searching and data retrieval would be much easier. This would be particularly helpful in the World News domain. There is a big variety of news sources and it would be useful to provide an efficient method to automatically organize them. In this paper, we describe World News Finder, a system which performs semantic search on the World News domain. The system is based on metadata files created for every single World News HTML webpage in an automatic way. According to a user query, the system performs the search on these metadata files rather than keyword search. To achieve the above, we developed the World News Ontology and a large set of domain-specific heuristic rules.
ER  - 

TY  - JOUR
T1  - Topic knowledge map and knowledge structure constructions with genetic algorithm, information retrieval, and multi-dimension scaling method
JO  - Knowledge-Based Systems
VL  - 67
IS  - 
SP  - 412
EP  - 428
PY  - 2014/9//
T2  - 
AU  - Chiu, Deng-Yiv
AU  - Pan, Ya-Chen
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2014.03.008
UR  - http://www.sciencedirect.com/science/article/pii/S0950705114000914
KW  - Knowledge structure
KW  - Topic knowledge map
KW  - Information retrieval
KW  - Genetic algorithm
KW  - Independent chi-square
KW  - Multi-dimension scaling
AB  - Abstract
This work presents a novel automated approach to construct topic knowledge maps with knowledge structures, followed by its application to an internationally renowned journal. Knowledge structures are diagrams showing the important components of knowledge in study. Knowledge maps identify the locations of objects and illustrate the relationship among objects. In our study, the important components derived from knowledge structures are used as objects to be spotted in a topic knowledge map. The purpose of our knowledge structures is to find out the major topics serving as subjects of article collections as well as related methods employed in the published papers. The purpose of topic knowledge maps is to transform high-dimensional objects (topic, paper, and cited frequency) into a 2-dimensional space to help understand complicated relatedness among high-dimensional objects, such as the related degree between an article and a topic.

First, we adopt independent chi-square test to examine the independence of topics and apply genetic algorithm to choose topics selection with best fitness value to construct knowledge structures.

Additionally, high-dimensional relationships among objects are transformed into a 2-dimensional space using the multi-dimension scaling method. The optimal transformation coordinate matrix is also determined by using a genetic algorithm to preserve the original relations among objects and construct appropriate topic knowledge maps.
ER  - 

TY  - JOUR
T1  - An ontology-based approach to Chinese semantic advertising
JO  - Information Sciences
VL  - 216
IS  - 
SP  - 138
EP  - 154
PY  - 2012/12/20/
T2  - 
AU  - Zheng, Hai-Tao
AU  - Chen, Jin-Yuan
AU  - Jiang, Yong
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2012.06.012
UR  - http://www.sciencedirect.com/science/article/pii/S0020025512004070
KW  - Contextual advertising
KW  - Sponsored search
KW  - Chinese semantic advertising
KW  - Taobao Ontology
KW  - Distance function
AB  - In the web advertising domain, contextual advertising and sponsored search are two of the main advertising channels used to display related advertisements on web pages. A major challenge for contextual advertising is to match advertisements and web pages based on their semantics. When a web page and its semantically related advertisements contain many different words, the performance of the traditional methods can be very poor. In particular, there are few studies presented for Chinese contextual advertising that are based on semantics. To address these issues, we propose an ontology-based approach to Chinese semantic advertising. We utilize an ontology called the Taobao Ontology and populate it by automatically adding related phrases as instances. The ontology is used to match web pages and advertisements on a conceptual level. Based on the Taobao Ontology, the proposed method exploits seven distance functions to measure the similarities between concepts and web pages or advertisements. Then, the similarities between web pages and advertisements are calculated by considering the ontology-based similarities as well as term-based similarities. The empirical experiments indicate that our method is able to match Chinese web pages and advertisements with a relatively high accuracy. Among the seven distance functions, Cosine distance and Tanimoto distance show the best performance in terms of precision, recall, and F-measure. In addition, our method outperforms two contextual advertising methods, i.e., the impedance coupling method and the SVM-based method.
ER  - 

TY  - JOUR
T1  - Multiple documents summarization based on evolutionary optimization algorithm
JO  - Expert Systems with Applications
VL  - 40
IS  - 5
SP  - 1675
EP  - 1689
PY  - 2013/4//
T2  - 
AU  - Alguliev, Rasim M.
AU  - Aliguliyev, Ramiz M.
AU  - Isazade, Nijat R.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2012.09.014
UR  - http://www.sciencedirect.com/science/article/pii/S0957417412010688
KW  - Multi-document summarization
KW  - Diversity
KW  - Content coverage
KW  - Optimization model
KW  - Differential evolution algorithm
KW  - Self-adaptive crossover
AB  - This paper proposes an optimization-based model for generic document summarization. The model generates a summary by extracting salient sentences from documents. This approach uses the sentence-to-document collection, the summary-to-document collection and the sentence-to-sentence relations to select salient sentences from given document collection and reduce redundancy in the summary. To solve the optimization problem has been created an improved differential evolution algorithm. The algorithm can adjust crossover rate adaptively according to the fitness of individuals. We implemented the proposed model on multi-document summarization task. Experiments have been performed on DUC2002 and DUC2004 data sets. The experimental results provide strong evidence that the proposed optimization-based approach is a viable method for document summarization.
ER  - 

TY  - JOUR
T1  - Analyzing multilingual knowledge innovation in patents
JO  - Expert Systems with Applications
VL  - 40
IS  - 17
SP  - 7010
EP  - 7023
PY  - 2013/12/1/
T2  - 
AU  - Segev, Aviv
AU  - Kantola, Jussi
AU  - Jung, Chihoon
AU  - Lee, Jaehwa
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2013.06.013
UR  - http://www.sciencedirect.com/science/article/pii/S095741741300393X
KW  - Conceptual modeling
KW  - Ontologies
KW  - Knowledge management applications
KW  - Database semantics
AB  - Abstract
In the process of analyzing knowledge innovation, it is necessary to identify the existing boundaries of knowledge so as to determine whether knowledge is new – outside these boundaries. For a patent to be granted, all aspects of the patent request must be studied to determine the patent innovation. Knowledge innovation for patent requests depends on analyzing current state of the art in multiple languages. Currently the process is usually limited to the languages and search terms the patent seeker knows. The paper describes a model for representing the patent request by a set of concepts related to a multilingual knowledge ontology. The search for patent knowledge is based on Fuzzy Logic Decision Support and allows a multilingual search. The model was analyzed using a twofold approach: a total of 104,296 patents from the United States Patent and Trademark Office were used to analyze the patent extraction process, and patents from the Korean, US, and Chinese patent offices were used in the analysis of the multilingual decision process. The results display high recall and precision and suggest that increasing the number of languages used only has minor effects on the model results.
ER  - 

TY  - JOUR
T1  - Soft computing applications in customer segmentation: State-of-art review and critique
JO  - Expert Systems with Applications
VL  - 40
IS  - 16
SP  - 6491
EP  - 6507
PY  - 2013/11/15/
T2  - 
AU  - Hiziroglu, Abdulkadir
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2013.05.052
UR  - http://www.sciencedirect.com/science/article/pii/S0957417413003503
KW  - Customer segmentation
KW  - Segmentation review
KW  - Soft computing in segmentation
KW  - Data mining
AB  - Abstract
Segmentation has been taken immense attention and has extensively been used in strategic marketing. Vast majority of the research in this area focuses on the usage or development of different techniques. By means of the internet and database technologies, huge amount of data about markets and customers has now become available to be exploited and this enables researchers and practitioners to make use of sophisticated data analysis techniques apart from the traditional multivariate statistical tools. These sophisticated techniques are a family of either data mining or machine learning research. Recent research shows a tendency towards the usage of them into different business and marketing problems, particularly in segmentation. Soft computing, as a family of data mining techniques, has been recently started to be exploited in the area of segmentation and it stands out as a potential area that may be able to shape the future of segmentation research. In this article, the current applications of soft computing techniques in segmentation problem are reviewed based on certain critical factors including the ones related to the segmentation effectiveness that every segmentation study should take into account. The critical analysis of 42 empirical studies reveals that the usage of soft computing in segmentation problem is still in its early stages and the ability of these studies to generate knowledge may not be sufficient. Given these findings, it can be suggested that there is more to dig for in order to obtain more managerially interpretable and acceptable results in further studies. Also, recommendations are made for other potentials of soft computing in segmentation research.
ER  - 

TY  - JOUR
T1  - From spoken narratives to domain knowledge: Mining linguistic data for medical image understanding
JO  - Artificial Intelligence in Medicine
VL  - 62
IS  - 2
SP  - 79
EP  - 90
PY  - 2014/10//
T2  - 
AU  - Guo, Xuan
AU  - Yu, Qi
AU  - Alm, Cecilia Ovesdotter
AU  - Calvelli, Cara
AU  - Pelz, Jeff B.
AU  - Shi, Pengcheng
AU  - Haake, Anne R.
SN  - 0933-3657
DO  - http://dx.doi.org/10.1016/j.artmed.2014.08.001
UR  - http://www.sciencedirect.com/science/article/pii/S0933365714000852
KW  - Unified Medical Language System
KW  - Lexical consensus
KW  - Semantic relatedness
KW  - Clustering algorithm
KW  - Image-based diagnostic reasoning
KW  - Medical data analysis
AB  - AbstractObjectives
Extracting useful visual clues from medical images allowing accurate diagnoses requires physicians’ domain knowledge acquired through years of systematic study and clinical training. This is especially true in the dermatology domain, a medical specialty that requires physicians to have image inspection experience. Automating or at least aiding such efforts requires understanding physicians’ reasoning processes and their use of domain knowledge. Mining physicians’ references to medical concepts in narratives during image-based diagnosis of a disease is an interesting research topic that can help reveal experts’ reasoning processes. It can also be a useful resource to assist with design of information technologies for image use and for image case-based medical education systems.
Methods and materials
We collected data for analyzing physicians’ diagnostic reasoning processes by conducting an experiment that recorded their spoken descriptions during inspection of dermatology images. In this paper we focus on the benefit of physicians’ spoken descriptions and provide a general workflow for mining medical domain knowledge based on linguistic data from these narratives. The challenge of a medical image case can influence the accuracy of the diagnosis as well as how physicians pursue the diagnostic process. Accordingly, we define two lexical metrics for physicians’ narratives—lexical consensus score and top N relatedness score—and evaluate their usefulness by assessing the diagnostic challenge levels of corresponding medical images. We also report on clustering medical images based on anchor concepts obtained from physicians’ medical term usage. These analyses are based on physicians’ spoken narratives that have been preprocessed by incorporating the Unified Medical Language System for detecting medical concepts.
Results
The image rankings based on lexical consensus score and on top 1 relatedness score are well correlated with those based on challenge levels (Spearman correlation &gt;0.5 and Kendall correlation &gt;0.4). Clustering results are largely improved based on our anchor concept method (accuracy &gt;70% and mutual information &gt;80%).
Conclusions
Physicians’ spoken narratives are valuable for the purpose of mining the domain knowledge that physicians use in medical image inspections. We also show that the semantic metrics introduced in the paper can be successfully applied to medical image understanding and allow discussion of additional uses of these metrics.
ER  - 

TY  - JOUR
T1  - Towards a framework for developing semantic relatedness reference standards
JO  - Journal of Biomedical Informatics
VL  - 44
IS  - 2
SP  - 251
EP  - 265
PY  - 2011/4//
T2  - 
AU  - Pakhomov, Serguei V.S.
AU  - Pedersen, Ted
AU  - McInnes, Bridget
AU  - Melton, Genevieve B.
AU  - Ruggieri, Alexander
AU  - Chute, Christopher G.
SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2010.10.004
UR  - http://www.sciencedirect.com/science/article/pii/S1532046410001565
KW  - Semantic relatedness
KW  - Reference standards
KW  - Reliability
KW  - Inter-annotator agreement
AB  - Our objective is to develop a framework for creating reference standards for functional testing of computerized measures of semantic relatedness. Currently, research on computerized approaches to semantic relatedness between biomedical concepts relies on reference standards created for specific purposes using a variety of methods for their analysis. In most cases, these reference standards are not publicly available and the published information provided in manuscripts that evaluate computerized semantic relatedness measurement approaches is not sufficient to reproduce the results. Our proposed framework is based on the experiences of medical informatics and computational linguistics communities and addresses practical and theoretical issues with creating reference standards for semantic relatedness. We demonstrate the use of the framework on a pilot set of 101 medical term pairs rated for semantic relatedness by 13 medical coding experts. While the reliability of this particular reference standard is in the “moderate” range; we show that using clustering and factor analyses offers a data-driven approach to finding systematic differences among raters and identifying groups of potential outliers. We test two ontology-based measures of relatedness and provide both the reference standard containing individual ratings and the R program used to analyze the ratings as open-source. Currently, these resources are intended to be used to reproduce and compare results of studies involving computerized measures of semantic relatedness. Our framework may be extended to the development of reference standards in other research areas in medical informatics including automatic classification, information retrieval from medical records and vocabulary/ontology development.
ER  - 

TY  - JOUR
T1  - Structure preserving non-negative matrix factorization for dimensionality reduction
JO  - Computer Vision and Image Understanding
VL  - 117
IS  - 9
SP  - 1175
EP  - 1189
PY  - 2013/9//
T2  - 
AU  - Li, Zechao
AU  - Liu, Jing
AU  - Lu, Hanqing
SN  - 1077-3142
DO  - http://dx.doi.org/10.1016/j.cviu.2013.04.003
UR  - http://www.sciencedirect.com/science/article/pii/S1077314213000891
KW  - Dimensionality reduction
KW  - Non-negative matrix factorization
KW  - Structure preserving
KW  - Basis compactness
KW  - Multiplicative update algorithm
AB  - Abstract
The problem of dimensionality reduction is to map data from high dimensional spaces to low dimensional spaces. In the process of dimensionality reduction, the data structure, which is helpful to discover the latent semantics and simultaneously respect the intrinsic geometric structure, should be preserved. In this paper, to discover a low-dimensional embedding space with the nature of structure preservation and basis compactness, we propose a novel dimensionality reduction algorithm, called Structure Preserving Non-negative Matrix Factorization (SPNMF). In SPNMF, three kinds of constraints, namely local affinity, distant repulsion, and embedding basis redundancy elimination, are incorporated into the NMF framework. SPNMF is formulated as an optimization problem and solved by an effective iterative multiplicative update algorithm. The convergence of the proposed update solutions is proved. Extensive experiments on both synthetic data and six real world data sets demonstrate the encouraging performance of the proposed algorithm in comparison to the state-of-the-art algorithms, especially some related works based on NMF. Moreover, the convergence of the proposed updating rules is experimentally validated.
ER  - 

TY  - JOUR
T1  - A new paradigm for serious games: Transmedia learning for more effective training and education
JO  - Journal of Computational Science
VL  - 5
IS  - 3
SP  - 471
EP  - 481
PY  - 2014/5//
T2  - 
AU  - Raybourn, Elaine M.
SN  - 1877-7503
DO  - http://dx.doi.org/10.1016/j.jocs.2013.08.005
UR  - http://www.sciencedirect.com/science/article/pii/S1877750313001014
KW  - Transmedia learning
KW  - Serious games
KW  - Transmedia campaigns
KW  - Storytelling
KW  - Social media
KW  - Data mining
KW  - xAPI
KW  - MOOC
AB  - Abstract
Serious games present a relatively new approach to training and education for international organizations such as NATO (North Atlantic Treaty Organization), non-governmental organizations (NGOs), the U.S. Department of Defense (DoD) and the U.S. Department of Homeland Security (DHS). Although serious games are often deployed as stand-alone solutions, they can also serve as entry points into a comprehensive training pipeline in which content is delivered via different media to rapidly scale immersive training and education for mass audiences. The present paper introduces a new paradigm for more effective and scalable training and education called transmedia learning. Transmedia learning leverages several new media trends including the peer communications of social media, the scalability of massively openonline course (MOOCs), and the design of transmedia storytelling used by entertainment, advertising, and commercial game industries to sustain audience engagement. Transmedia learning is defined as the scalable system of messages representing a narrative or core experience that unfolds from the use of multiple media, emotionally engaging learners by involving them personally in the story. In the present paper, we introduce the transmedia learning paradigm as offering more effective use of serious games for training and education. This approach is consistent with the goals of international organizations implementing approaches similar to those described by the Army Learning Model (ALM) to deliver training and education to Soldiers across multiple media. We discuss why the human brain is wired for transmedia learning and demonstrate how the Simulation Experience Design Method can be used to create transmedia learning story worlds for serious games. We describe how social media interactions and MOOCs may be used in transmedia learning, and how data mining social media and experience tracking can inform the development of computational learner models for transmedia learning campaigns. Examples of how the U.S. Army has utilized transmedia campaigns for strategic communication and game-based training are provided. Finally, we provide strategies the reader can use today to incorporate transmedia storytelling elements such as Internet, serious games, video, social media, graphic novels, machinima, blogs, and alternate reality gaming into a new paradigm for training and education: transmedia learning.
ER  - 

TY  - JOUR
T1  - Achieving Accountable MapReduce in cloud computing
JO  - Future Generation Computer Systems
VL  - 30
IS  - 
SP  - 1
EP  - 13
PY  - 2014/1//
T2  - Special Issue on Extreme Scale Parallel Architectures and Systems, Cryptography in Cloud Computing and Recent Advances in Parallel and Distributed Systems, ICPADS 2012 Selected Papers
AU  - Xiao, Zhifeng
AU  - Xiao, Yang
SN  - 0167-739X
DO  - http://dx.doi.org/10.1016/j.future.2013.07.001
UR  - http://www.sciencedirect.com/science/article/pii/S0167739X13001465
KW  - Accountable
KW  - MapReduce
KW  - Cloud computing
AB  - Abstract
MapReduce is a programming model that is capable of processing large data sets in distributed computing environments. The original MapReduce model was designed to be fault-tolerant in case of various network abnormalities. However, fault-tolerance does not guarantee that each working machine will be completely accountable; when nodes are malicious, they may intentionally misrepresent the processing result during mapping or reducing, and they may thus make the final results inaccurate and untrustworthy. In this paper, we propose Accountable MapReduce, which forces each machine to be held responsible for its behaviors. In our approach, we set up a group of auditors to perform an Accountability Test ( A -test) that checks all of the working machines and detects malicious nodes in real time. The A -test can be implemented with different options depending upon how the auditors are assigned. To optimize the utilization resource, we also formalize the Optimal Worker and Auditor Assignment (OWAA) problem, which is aimed at finding the optimal number of workers and auditors in order to minimize the total processing time. Our evaluation results show that the A -test can be practically and effectively applied to existing cloud platforms employing MapReduce.
ER  - 

TY  - JOUR
T1  - Automatic clustering of construction project documents based on textual similarity
JO  - Automation in Construction
VL  - 42
IS  - 
SP  - 36
EP  - 49
PY  - 2014/6//
T2  - 
AU  - Al Qady, Mohammed
AU  - Kandil, Amr
SN  - 0926-5805
DO  - http://dx.doi.org/10.1016/j.autcon.2014.02.006
UR  - http://www.sciencedirect.com/science/article/pii/S0926580514000314
KW  - Document management
KW  - Single pass clustering
KW  - Supervised/unsupervised learning methods
AB  - Abstract
Text classifiers, as supervised learning methods, require a comprehensive training set that covers all classes in order to classify new instances. This limits the use of text classifiers for organizing construction project documents since it is not guaranteed that sufficient samples are available for all possible document categories. To overcome the restriction imposed by the all-inclusive requirement, an unsupervised learning method was used to automatically cluster documents together based on textual similarities. Repeated evaluations using different randomizations of the dataset revealed a region of threshold/dimensionality values of consistently high precision values and average recall values. Accordingly, a hybrid approach was proposed which initially uses an unsupervised method to develop core clusters and then trains a text classifier on the core clusters to classify outlier documents in a consequent refinement step. Evaluation of the hybrid approach demonstrated a significant improvement in recall values, resulting in an overall increase in F-measure scores.
ER  - 

TY  - JOUR
T1  - Using semantic techniques to access web data
JO  - Information Systems
VL  - 36
IS  - 2
SP  - 117
EP  - 133
PY  - 2011/4//
T2  - Special Issue: Semantic Integration of Data, Multimedia, and Services
AU  - Trillo, Raquel
AU  - Po, Laura
AU  - Ilarri, Sergio
AU  - Bergamaschi, Sonia
AU  - Mena, Eduardo
SN  - 0306-4379
DO  - http://dx.doi.org/10.1016/j.is.2010.06.008
UR  - http://www.sciencedirect.com/science/article/pii/S0306437910000621
KW  - Semantic search
KW  - Ontologies
KW  - Categorization
KW  - Disambiguation
KW  - Semantic annotation
AB  - Nowadays, people frequently use different keyword-based web search engines to find the information they need on the web. However, many words are polysemous and, when these words are used to query a search engine, its output usually includes links to web pages referring to their different meanings. Besides, results with different meanings are mixed up, which makes the task of finding the relevant information difficult for the users, especially if the user-intended meanings behind the input keywords are not among the most popular on the web.

In this paper, we propose a set of semantics techniques to group the results provided by a traditional search engine into categories defined by the different meanings of the input keywords. Differently from other proposals, our method considers the knowledge provided by ontologies available on the web in order to dynamically define the possible categories. Thus, it is independent of the sources providing the results that must be grouped. Our experimental results show the interest of the proposal.
ER  - 

TY  - JOUR
T1  - A hybrid approach for estimating document frequencies in unstructured P2P networks
JO  - Information Systems
VL  - 36
IS  - 3
SP  - 579
EP  - 595
PY  - 2011/5//
T2  - Special Issue on WISE 2009 - Web Information Systems Engineering
AU  - Neumayer, Robert
AU  - Doulkeridis, Christos
AU  - Nørvåg, Kjetil
SN  - 0306-4379
DO  - http://dx.doi.org/10.1016/j.is.2010.08.006
UR  - http://www.sciencedirect.com/science/article/pii/S0306437910000839
KW  - Peer-to-peer
KW  - Distributed information retrieval
KW  - Distributed aggregation
AB  - Scalable search and retrieval over numerous web document collections distributed across different sites can be achieved by adopting a peer-to-peer (P2P) communication model. Terms and their document frequencies are the main components of text information retrieval and as such need to be computed, aggregated, and distributed throughout the system. This is a challenging problem in the context of unstructured P2P networks, since the local document collections may not reflect the global collection in an accurate way. This might happen due to skews in the distribution of documents to peers. Moreover, central assembly of the total information is not a scalable solution due to the excessive cost of storage and maintenance, and because of issues related to digital rights management. In this paper, we present an efficient hybrid approach for aggregation of document frequencies using a hierarchical overlay network for a carefully selected set of the most important terms, together with gossip-based aggregation for the remaining terms in the collections. Furthermore, we present a cost analysis to compute the communication cost of hybrid aggregation. We conduct experiments on three document collections, in order to evaluate the quality of the proposed hybrid aggregation.
ER  - 

TY  - JOUR
T1  - Discovery of clinical pathway patterns from event logs using probabilistic topic models
JO  - Journal of Biomedical Informatics
VL  - 47
IS  - 
SP  - 39
EP  - 57
PY  - 2014/2//
T2  - 
AU  - Huang, Zhengxing
AU  - Dong, Wei
AU  - Ji, Lei
AU  - Gan, Chenxi
AU  - Lu, Xudong
AU  - Duan, Huilong
SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2013.09.003
UR  - http://www.sciencedirect.com/science/article/pii/S1532046413001445
KW  - Clinical pathway analysis
KW  - Topic models
KW  - Latent Dirichlet Allocation
KW  - Pattern discovery
KW  - Clinical event log
AB  - Abstract
Discovery of clinical pathway (CP) patterns has experienced increased attention over the years due to its importance for revealing the structure, semantics and dynamics of CPs, and to its usefulness for providing clinicians with explicit knowledge which can be directly used to guide treatment activities of individual patients. Generally, discovery of CP patterns is a challenging task as treatment behaviors in CPs often have a large variability depending on factors such as time, location and patient individual. Based on the assumption that CP patterns can be derived from clinical event logs which usually record various treatment activities in CP executions, this study proposes a novel approach to CP pattern discovery by modeling CPs using mixtures of an extension to the Latent Dirichlet Allocation family that jointly models various treatment activities and their occurring time stamps in CPs. Clinical case studies are performed to evaluate the proposed approach via real-world data sets recording typical treatment behaviors in patient careflow. The obtained results demonstrate the suitability of the proposed approach for CP pattern discovery, and indicate the promise in research efforts related to CP analysis and optimization.
ER  - 

TY  - JOUR
T1  - Fuzzy relational clustering around medoids: A unified view
JO  - Fuzzy Sets and Systems
VL  - 183
IS  - 1
SP  - 44
EP  - 56
PY  - 2011/11/16/
T2  - Theme : Information processing
AU  - Mei, Jian-Ping
AU  - Chen, Lihui
SN  - 0165-0114
DO  - http://dx.doi.org/10.1016/j.fss.2011.06.009
UR  - http://www.sciencedirect.com/science/article/pii/S0165011411002958
KW  - Fuzzy clustering
KW  - Relational data
KW  - Weighted medoids
AB  - Medoid-based fuzzy clustering generates clusters of objects based on relational data, which records pairwise similarities or dissimilarities among objects. Compared with single-medoid based approaches, our recently proposed fuzzy clustering with multiple-weighted medoids has shown superior performance in clustering via experimental study. In this paper, we present a new version of fuzzy relational clustering in this family called fuzzy clustering with multi-medoids (FMMdd). Based on the new objective function of FMMdd, update equations can be derived more conveniently. Moreover, a unified view of FMMdd and two existing fuzzy relational approaches fuzzy c-medoids (FCMdd) and assignment-prototype (A-P) can be established, which allows us to conduct further analytical study to investigate the effectiveness and feasibility of the proposed approach as well as the limitations of existing ones. The robustness of FMMdd is also investigated. Our theoretical and numerical studies show that the proposed approach produces good quality of clusters with rich cluster-based information and it is less sensitive to noise.
ER  - 

TY  - JOUR
T1  - Large high resolution displays for co-located collaborative sensemaking: Display usage and territoriality
JO  - International Journal of Human-Computer Studies
VL  - 71
IS  - 11
SP  - 1078
EP  - 1088
PY  - 2013/11//
T2  - 
AU  - Bradel, Lauren
AU  - Endert, Alex
AU  - Koch, Kristen
AU  - Andrews, Christopher
AU  - North, Chris
SN  - 1071-5819
DO  - http://dx.doi.org/10.1016/j.ijhcs.2013.07.004
UR  - http://www.sciencedirect.com/science/article/pii/S1071581913000992
KW  - Large high-resolution displays
KW  - Co-located collaborative sensemaking
KW  - Visual analytics
KW  - Territoriality
AB  - Abstract
From an exploratory user study using a fictional textual intelligence analysis task on a large, high-resolution vertical display, we investigated how pairs of users interact with the display to construct spatial schemas and externalize information, as well as how they establish shared and private territories. We investigated users' space management strategies depending on the design philosophy of the user interface (visualization- or document-centric). We classified the types of territorial behavior exhibited in terms of how the users interacted with information on the display (integrated or independent workspaces). Next, we examined how territorial behavior impacted the common ground between the pairs of users. Finally, we offer design suggestions for building future co-located collaborative visual analytics tools for use on large, high-resolution vertical displays.
ER  - 

TY  - JOUR
T1  - Improving MeSH classification of biomedical articles using citation contexts
JO  - Journal of Biomedical Informatics
VL  - 44
IS  - 5
SP  - 881
EP  - 896
PY  - 2011/10//
T2  - 
AU  - Aljaber, Bader
AU  - Martinez, David
AU  - Stokes, Nicola
AU  - Bailey, James
SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2011.05.007
UR  - http://www.sciencedirect.com/science/article/pii/S1532046411000980
KW  - Citation contexts
KW  - Document expansion
KW  - Biomedical text classification
KW  - MeSH terms
AB  - Medical Subject Headings (MeSH) are used to index the majority of databases generated by the National Library of Medicine. Essentially, MeSH terms are designed to make information, such as scientific articles, more retrievable and assessable to users of systems such as PubMed. This paper proposes a novel method for automating the assignment of biomedical publications with MeSH terms that takes advantage of citation references to these publications. Our findings show that analysing the citation references that point to a document can provide a useful source of terms that are not present in the document. The use of these citation contexts, as they are known, can thus help to provide a richer document feature representation, which in turn can help improve text mining and information retrieval applications, in our case MeSH term classification. In this paper, we also explore new methods of selecting and utilising citation contexts. In particular, we assess the effect of weighting the importance of citation terms (found in the citation contexts) according to two aspects: (i) the section of the paper they appear in and (ii) their distance to the citation marker.

We conduct intrinsic and extrinsic evaluations of citation term quality. For the intrinsic evaluation, we rely on the UMLS Metathesaurus conceptual database to explore the semantic characteristics of the mined citation terms. We also analyse the “informativeness” of these terms using a class-entropy measure. For the extrinsic evaluation, we run a series of automatic document classification experiments over MeSH terms. Our experimental evaluation shows that citation contexts contain terms that are related to the original document, and that the integration of this knowledge results in better classification performance compared to two state-of-the-art MeSH classification systems: MeSHUP and MTI. Our experiments also demonstrate that the consideration of Section and Distance factors can lead to statistically significant improvements in citation feature quality, thus opening the way for better document feature representation in other biomedical text processing applications.
ER  - 

TY  - JOUR
T1  - A visual analysis approach to validate the selection review of primary studies in systematic reviews
JO  - Information and Software Technology
VL  - 54
IS  - 10
SP  - 1079
EP  - 1091
PY  - 2012/10//
T2  - 
AU  - Felizardo, Katia R.
AU  - Andery, Gabriel F.
AU  - Paulovich, Fernando V.
AU  - Minghim, Rosane
AU  - Maldonado, José C.
SN  - 0950-5849
DO  - http://dx.doi.org/10.1016/j.infsof.2012.04.003
UR  - http://www.sciencedirect.com/science/article/pii/S0950584912000742
KW  - Systematic Literature Review (SLR)
KW  - Visual Text Mining (VTM)
KW  - Information visualization
KW  - Content document map
KW  - Citation document map
AB  - Context
Systematic Literature Reviews (SLRs) are an important component to identify and aggregate research evidence from different empirical studies. Despite its relevance, most of the process is conducted manually, implying additional effort when the Selection Review task is performed and leading to reading all studies under analysis more than once.
Objective
We propose an approach based on Visual Text Mining (VTM) techniques to assist the Selection Review task in SLR. It is implemented into a VTM tool (Revis), which is freely available for use.
Method
We have selected and implemented appropriate visualization techniques into our approach and validated and demonstrated its usefulness in performing real SLRs.
Results
The results have shown that employment of VTM techniques can successfully assist in the Selection Review task, speeding up the entire SLR process in comparison to the conventional approach.
Conclusion
VTM techniques are valuable tools to be used in the context of selecting studies in the SLR process, prone to speed up some stages of SLRs.
ER  - 

TY  - JOUR
T1  - Applying agglomerative hierarchical clustering algorithms to component identification for legacy systems
JO  - Information and Software Technology
VL  - 53
IS  - 6
SP  - 601
EP  - 614
PY  - 2011/6//
T2  - Special Section: Best papers from the APSECBest papers from the APSEC
AU  - Cui, Jian Feng
AU  - Chae, Heung Seok
SN  - 0950-5849
DO  - http://dx.doi.org/10.1016/j.infsof.2011.01.006
UR  - http://www.sciencedirect.com/science/article/pii/S0950584911000176
KW  - Component identification
KW  - Agglomerative hierarchical clustering algorithm
KW  - Weighting scheme
KW  - Similarity measure
KW  - Legacy systems
KW  - Software reengineering
AB  - Context
Component identification, the process of evolving legacy system into finely organized component-based software systems, is a critical part of software reengineering. Currently, many component identification approaches have been developed based on agglomerative hierarchical clustering algorithms. However, there is a lack of thorough investigation on which algorithm is appropriate for component identification.
Objective
This paper focuses on analyzing agglomerative hierarchical clustering algorithms in software reengineering, and then identifying their respective strengths and weaknesses in order to apply them effectively for future practical applications.
Method
A series of experiments were conducted for 18 clustering strategies combined according to various similarity measures, weighting schemes and linkage methods. Eleven subject systems with different application domains and source code sizes were used in the experiments. The component identification results are evaluated by the proposed size, coupling and cohesion criteria.
Results
The experimental results suggested that the employed similarity measures, weighting schemes and linkage methods can have various effects on component identification results with respect to the proposed size, coupling and cohesion criteria, so the hierarchical clustering algorithms produced quite different clustering results.
Conclusions
According to the experimental results, it can be concluded that it is difficult to produce perfectly satisfactory results for a given clustering algorithm. Nevertheless, these algorithms demonstrated varied capabilities to identify components with respect to the proposed size, coupling and cohesion criteria.
ER  - 

TY  - JOUR
T1  - Mining methodologies from NLP publications: A case study in automatic terminology recognition
JO  - Computer Speech & Language
VL  - 26
IS  - 2
SP  - 105
EP  - 126
PY  - 2012/4//
T2  - 
AU  - Kovačević, Aleksandar
AU  - Konjović, Zora
AU  - Milosavljević, Branko
AU  - Nenadic, Goran
SN  - 0885-2308
DO  - http://dx.doi.org/10.1016/j.csl.2011.09.001
UR  - http://www.sciencedirect.com/science/article/pii/S0885230811000465
KW  - Information extraction
KW  - Methodology mining
KW  - Conditional Random Fields
KW  - Automatic terminology mining
AB  - The task of reviewing scientific publications and keeping up with the literature in a particular domain is extremely time-consuming. Extraction and exploration of methodological information, in particular, requires systematic understanding of the literature, but in many cases is performed within a limited context of publications that can be manually reviewed by an individual or group. Automated methodology identification could provide an opportunity for systematic retrieval of relevant documents and for exploring developments within a given discipline. In this paper we present a system for the identification of methodology mentions in scientific publications in the area of natural language processing, and in particular in automatic terminology recognition. The system comprises two major layers: the first layer is an automatic identification of methodological sentences; the second layer highlights methodological phrases (segments). Each mention is categorised in four semantic categories: Task, Method, Resource/Feature and Implementation. Extraction and classification of the segments is formalised as a sequence tagging problem and four separate phrase-based Conditional Random Fields are used to accomplish the task. The system has been evaluated on a manually annotated corpus comprising 45 full text articles. The results for the segment level annotation show an F-measure of 53% for identification of Task and Method mentions (with 70% precision), whereas the F-measures for Resource/Feature and Implementation identification were 61% (with 67% precision) and 75% (with 86% precision) respectively. At the document-level, an F-measure of 72% (with 81% precision) for Task mentions, 60% (with 81% precision) for Method mentions, 74% (with 78% precision) for the Resource/Feature and 79% (with 81% precision) for the Implementation categories have been achieved. We provide a detailed analysis of errors and explore the impact that the particular groups of features have on the extraction of methodological segments.
ER  - 

TY  - JOUR
T1  - Bipartite spectral graph partitioning for clustering dialect varieties and detecting their linguistic features
JO  - Computer Speech & Language
VL  - 25
IS  - 3
SP  - 700
EP  - 715
PY  - 2011/7//
T2  - 
AU  - Wieling, Martijn
AU  - Nerbonne, John
SN  - 0885-2308
DO  - http://dx.doi.org/10.1016/j.csl.2010.05.004
UR  - http://www.sciencedirect.com/science/article/pii/S0885230810000410
KW  - Bipartite spectral graph partitioning
KW  - Clustering
KW  - Sound correspondences
KW  - Dialectometry
KW  - Dialectology
KW  - Language variation
AB  - In this study we use bipartite spectral graph partitioning to simultaneously cluster varieties and identify their most distinctive linguistic features in Dutch dialect data. While clustering geographical varieties with respect to their features, e.g. pronunciation, is not new, the simultaneous identification of the features which give rise to the geographical clustering presents novel opportunities in dialectometry. Earlier methods aggregated sound differences and clustered on the basis of aggregate differences. The determination of the significant features which co-vary with cluster membership was carried out on a post hoc basis. Bipartite spectral graph clustering simultaneously seeks groups of individual features which are strongly associated, even while seeking groups of sites which share subsets of these same features. We show that the application of this method results in clear and sensible geographical groupings and discuss and analyze the importance of the concomitant features.
ER  - 

TY  - CHAP
AU  - Lam, Dao
AU  - Wunsch, Donald C.
T1  - Chapter 20 - Clustering
A2  - Paulo S.R. Diniz, Johan A.K. Suykens, Rama Chellappa and Sergios Theodoridis
BT  - Academic Press Library in Signal Processing
PB  - Elsevier
PY  - 2014///
VL  - Volume 1
SP  - 1115
EP  - 1149
T2  - Academic Press Library in Signal Processing: Volume 1Signal Processing Theory and Machine Learning
SN  - 2351-9819
DO  - http://dx.doi.org/10.1016/B978-0-12-396502-8.00020-6
UR  - http://www.sciencedirect.com/science/article/pii/B9780123965028000206
KW  - Hierarchical clustering
KW  - EM
KW  - k-means
KW  - Spectral clustering
KW  - Biclustering
KW  - Co-clustering
KW  - Subspace clustering
KW  - Clustering validation
AB  - Abstract
Clustering has been applied in many areas, including signal and image processing. This chapter reviews the motivation for clustering and several different types of clustering. See [35,5] for more detailed information, from which some of this material has been taken.
ER  - 

TY  - JOUR
T1  - Semantically-grounded construction of centroids for datasets with textual attributes
JO  - Knowledge-Based Systems
VL  - 35
IS  - 
SP  - 160
EP  - 172
PY  - 2012/11//
T2  - 
AU  - Martı´nez, Sergio
AU  - Valls, Aida
AU  - Sánchez, David
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2012.04.030
UR  - http://www.sciencedirect.com/science/article/pii/S0950705112001268
KW  - Data analysis
KW  - Centroid
KW  - Clustering
KW  - Semantic similarity
KW  - Ontologies
AB  - Centroids are key components in many data analysis algorithms such as clustering or microaggregation. They are considered as the central value that minimises the distance to all the objects in a dataset or cluster. Methods for centroid construction are mainly devoted to datasets with numerical and categorical attributes, focusing on the numerical and distributional properties of data. Textual attributes, on the contrary, consist of term lists referring to concepts with a specific semantic content (i.e., meaning), which cannot be evaluated by means of classical numerical operators. Hence, the centroid of a dataset with textual attributes should be the term that minimises the semantic distance against the members of the set. Semantically-grounded methods aiming to construct centroids for datasets with textual attributes are scarce and, as it will be discussed in this paper, they are hampered by their limited semantic analysis of data. In this paper, we propose a method that, exploiting the knowledge provided by background ontologies (like WordNet), is able to construct the centroid of multivariate datasets described by means of textual attributes. Special efforts have been put in the minimisation of the semantic distance between the centroid and the input data. As a result, our method is able to provide optimal centroids (i.e., those that minimise the distance to all the objects in the dataset) according to the exploited background ontology and a semantic similarity measure. Our proposal has been evaluated by means of a real dataset consisting on short textual answers provided by visitors of a natural park. Results show that our centroids retain the semantic content of the input data better than related works.
ER  - 

TY  - JOUR
T1  - Multi-view learning with Universum
JO  - Knowledge-Based Systems
VL  - 70
IS  - 
SP  - 376
EP  - 391
PY  - 2014/11//
T2  - 
AU  - Wang, Zhe
AU  - Zhu, Yujin
AU  - Liu, Wenwen
AU  - Chen, Zhihua
AU  - Gao, Daqi
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2014.07.019
UR  - http://www.sciencedirect.com/science/article/pii/S0950705114002767
KW  - Multi-view learning
KW  - Universum learning
KW  - Regularization learning
KW  - Rademacher complexity
KW  - Pattern classification
AB  - Abstract
The traditional Multi-view Learning (MVL) studies how to process patterns with multiple information sources. In practice, the MVL is proven to have a significant advantage over the Single-view Learning (SVL). But in most real-world cases, there are only single-source patterns to be dealt with and the existing MVL is unable to be directly applied. In order to solve this problem, an alternative MVL technique was developed for the single-source patterns through reshaping the original vector representation of the single-source patterns into multiple matrix representations in our previous work. Doing so can effectively bring an improved classification performance. This paper aims to generalize the previous MVL through taking advantage of the Universum examples which do not belong to either class of the classification problem. The newly-proposed generalization can not only inherit the advantage of the previous MVL, but also get a prior domain knowledge of the whole data distribution. To our knowledge, it introduces the Universum technique into the MVL for the first time. In the implementation, our previous MVL named MultiV-MHKS is selected as the learning paradigm and incorporate MultiV-MHKS with the Universum technique, which forms a more flexible MVL with the Universum called UMultiV-MHKS for short. The subsequent experiments validate that the proposed UMultiV-MHKS can effectively improve the classification performance over both the original MultiV-MHKS and some other state-of-the-art algorithms. Finally, it is demonstrated that the UMultiV-MHKS can get a tighter generalization risk bound in terms of the Rademacher complexity.
ER  - 

TY  - JOUR
T1  - A SNOMED supported ontological vector model for subclinical disorder detection using EHR similarity
JO  - Engineering Applications of Artificial Intelligence
VL  - 24
IS  - 8
SP  - 1398
EP  - 1409
PY  - 2011/12//
T2  - Semantic-based Information and Engineering Systems
AU  - Chan, L.W.C.
AU  - Liu, Y.
AU  - Shyu, C.R.
AU  - Benzie, I.F.F.
SN  - 0952-1976
DO  - http://dx.doi.org/10.1016/j.engappai.2011.05.013
UR  - http://www.sciencedirect.com/science/article/pii/S0952197611000959
KW  - Electronic Health Record
KW  - Vector model
KW  - SNOMED
KW  - Similarity
KW  - Clinical decision support
KW  - Atherosclerosis
AB  - Electronic Health Records (EHR) form a valuable resource in the healthcare enterprise because clinical evidence can be provided to identify potential complications and support decisions on early intervention. Simple string matching, the common search algorithm, is not able to map a query to the similar health records in the database with respect to the medical concepts. A novel ontological vector model supported by the Systematized Nomenclature of Medicine Clinical Terms (SNOMED-CT) is proposed in this paper to project the disease terms of a health record to a feature space so that each health record can be characterized using a feature vector, giving a fingerprint of the record. The similarity between the query and database health records was measured by similarity measures of their feature vectors and string matching score respectively. Three types of similarity measures were considered in this study, namely, Euclidean distance (ED), direction cosine (DC) and modified direction cosine (mDC). Medical history and carotid ultrasonic imaging findings were collected from 47 subjects in Hong Kong. The dataset formed 1081 pairs of health records and ROC analysis was used to evaluate and compare the accuracy of the ontological vector model and simple string matching against the agreement of the presence or absence of carotid plaques identified by carotid ultrasound between two subjects. It was found that the score generated by simple string matching was a random rater but the ontological vector model was not. In other words, the degree of health record similarity based on the ontological vector model is associated with the agreement of atherosclerosis between two patients. The vector model using feature terms at the SNOMED-CT level 4 gave the best performance. The performance of mDC was very close to that of ED and DC but the properties of mDC make it more suitable for the retrieval of similar health records. It was also shown that the ontological vector model was enhanced by the support vector classifier approach.
ER  - 

TY  - JOUR
T1  - A convex semi-nonnegative matrix factorisation approach to fuzzy c-means clustering
JO  - Fuzzy Sets and Systems
VL  - 270
IS  - 
SP  - 90
EP  - 110
PY  - 2015/7/1/
T2  - Theme: Information Processing, Classification and Clustering
AU  - Suleman, Abdul
SN  - 0165-0114
DO  - http://dx.doi.org/10.1016/j.fss.2014.07.021
UR  - http://www.sciencedirect.com/science/article/pii/S016501141400342X
KW  - Fuzzy clustering
KW  - Fuzzy c-means
KW  - Semi-nonnegative matrix factorisation
KW  - Principal component analysis
AB  - Abstract
We propose an alternative approach to fuzzy c-means clustering which eliminates the weighting exponent parameter of conventional algorithms. It is based on a particular convex factorisation of data matrix. The proposed method is invariant under certain linear transformations of the data including principal component analysis. We tested its accuracy using both synthetic data and real datasets, and compared it to that provided by the usual fuzzy c-means algorithm. We were able to ascertain that our proposal can be a credible yet easier alternative to this approach to fuzzy clustering. Moreover, it showed no noticeable sensitivity to the initial guess of the partition matrix.
ER  - 

TY  - JOUR
T1  - Fuzzy partition based soft subspace clustering and its applications in high dimensional data
JO  - Information Sciences
VL  - 246
IS  - 
SP  - 133
EP  - 154
PY  - 2013/10/10/
T2  - 
AU  - Wang, Jun
AU  - Wang, Shitong
AU  - Chung, Fulai
AU  - Deng, Zhaohong
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2013.05.029
UR  - http://www.sciencedirect.com/science/article/pii/S0020025513004040
KW  - Fuzzy clustering
KW  - Soft subspace clustering
KW  - Convergence
KW  - High dimensional data
AB  - Abstract
As one of the most popular clustering techniques for high dimensional data, soft subspace clustering (SSC) algorithms have been receiving a great deal of attention in recent years. Unfortunately, most existing works do not cluster high dimensional sparse data and noisy data in an effective manner. In this study, a novel soft subspace clustering algorithm called PI-SSC is proposed. By introducing a partition index (PI) into the objective function, a novel soft subspace clustering algorithm that combines the concepts of hard and fuzzy clustering is proposed. Furthermore, the robust property of PI-SSC is analyzed from the viewpoint of ε-insensitive distance. A convergence theorem for PI-SSC is also established by applying Zangwill’s convergence theorem. The results of the experiment demonstrate the effectiveness of the proposed algorithm in high dimensional sparse text data and noisy texture data.
ER  - 

TY  - JOUR
T1  - Mixed integer programming formulations for clustering problems related to structural balance
JO  - Social Networks
VL  - 35
IS  - 4
SP  - 639
EP  - 651
PY  - 2013/10//
T2  - 
AU  - Figueiredo, Rosa
AU  - Moura, Gisele
SN  - 0378-8733
DO  - http://dx.doi.org/10.1016/j.socnet.2013.09.002
UR  - http://www.sciencedirect.com/science/article/pii/S0378873313000774
KW  - Structural balance
KW  - Signed graph
KW  - Graph partition
KW  - Integer programming
KW  - Social network
AB  - Abstract
In this work, we study graph clustering problems associated with structural balance. One of these problems is known in computer science literature as the correlation-clustering (CC) problem and another (RCC) can be viewed as its relaxed version. The solution of CC and RCC problems has been previously used in the literature as tools for the evaluation of structural balance in a social network. Our aim is to solve these problems to optimality. We describe integer linear programming formulations for these problems which includes the first mathematical formulation for the RCC problem. We also discuss alternative models for the relaxed structural balance and the solution of clustering problems associated with these new models. Numerical experiments are carried out with each formulation on a set of benchmark instances available in the literature.
ER  - 

TY  - JOUR
T1  - A novel ant-based clustering algorithm using Renyi entropy
JO  - Applied Soft Computing
VL  - 13
IS  - 5
SP  - 2643
EP  - 2657
PY  - 2013/5//
T2  - 
AU  - Zhang, Lei
AU  - Cao, Qixin
AU  - Lee, Jay
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2012.11.022
UR  - http://www.sciencedirect.com/science/article/pii/S1568494612005066
KW  - Swarm intelligence
KW  - Ant-based clustering
KW  - Renyi entropy
KW  - Kernel
KW  - The Friedman test
AB  - Ant-based clustering is a type of clustering algorithm that imitates the behavior of ants. To improve the efficiency, increase the adaptability to non-Gaussian datasets and simplify the parameters of the algorithm, a novel ant-based clustering algorithm using Renyi Entropy (NAC-RE) is proposed. There are two aspects to application of Renyi entropy. Firstly, Kernel Entropy Component Analysis (KECA) is applied to modify the random projection of objects when the algorithm is run initially. This projection can create rough clusters and improve the algorithm's efficiency. Secondly, a novel ant movement model governed by Renyi entropy is proposed. The model takes each object as an ant. When the object (ant) moves to a new region, the Renyi entropy in its local neighborhood will be changed. The differential value of entropy governs whether the object should move or be moveless. The new model avoids complex parameters that have influence on the clustering results. The theoretical analysis has been conducted by kernel method to show that Renyi entropy metric is feasible and superior to distance metric. The novel algorithm was compared with other classic ones by several well-known benchmark datasets. The Friedman test with the corresponding Nemenyi test are applied to compare and conclude the algorithms’ performance The results indicate that NAC-RE can get better results for non-linearly separable datasets while its parameters are simple.
ER  - 

TY  - JOUR
T1  - Multi-objective design of hierarchical consensus functions for clustering ensembles via genetic programming
JO  - Decision Support Systems
VL  - 51
IS  - 4
SP  - 794
EP  - 809
PY  - 2011/11//
T2  - Recent Advances in Data, Text, and Media Mining &amp; Information Issues in Supply Chain and in Service System Design
AU  - Coelho, André L.V.
AU  - Fernandes, Everlândio
AU  - Faceli, Katti
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2011.01.014
UR  - http://www.sciencedirect.com/science/article/pii/S0167923611000431
KW  - Cluster analysis
KW  - Clustering ensembles
KW  - Multi-objective clustering
KW  - Hierarchical fusion
KW  - Partition selection
KW  - Genetic programming
AB  - This paper investigates a genetic programming (GP) approach aimed at the multi-objective design of hierarchical consensus functions for clustering ensembles. By this means, data partitions obtained via different clustering techniques can be continuously refined (via selection and merging) by a population of fusion hierarchies having complementary validation indices as objective functions. To assess the potential of the novel framework in terms of efficiency and effectiveness, a series of systematic experiments, involving eleven variants of the proposed GP-based algorithm and a comparison with basic as well as advanced clustering methods (of which some are clustering ensembles and/or multi-objective in nature), have been conducted on a number of artificial, benchmark and bioinformatics datasets. Overall, the results corroborate the perspective that having fusion hierarchies operating on well-chosen subsets of data partitions is a fine strategy that may yield significant gains in terms of clustering robustness.
ER  - 

TY  - JOUR
T1  - Particle swarm optimization: Hybridization perspectives and experimental illustrations
JO  - Applied Mathematics and Computation
VL  - 217
IS  - 12
SP  - 5208
EP  - 5226
PY  - 2011/2/15/
T2  - 
AU  - Thangaraj, Radha
AU  - Pant, Millie
AU  - Abraham, Ajith
AU  - Bouvry, Pascal
SN  - 0096-3003
DO  - http://dx.doi.org/10.1016/j.amc.2010.12.053
UR  - http://www.sciencedirect.com/science/article/pii/S0096300310012555
KW  - Particle swarm optimization
KW  - Hybridization
KW  - Differential evolution
KW  - Genetic algorithms
AB  - Metaheuristic optimization algorithms have become popular choice for solving complex and intricate problems which are otherwise difficult to solve by traditional methods. In the present study an attempt is made to review the hybrid optimization techniques in which one main algorithm is a well known metaheuristic; particle swarm optimization or PSO. Hybridization is a method of combining two (or more) techniques in a judicious manner such that the resulting algorithm contains the positive features of both (or all) the algorithms. Depending on the algorithm/s used we made three classifications as (i) Hybridization of PSO and genetic algorithms (ii) Hybridization of PSO with differential evolution and (iii) Hybridization of PSO with other techniques. Where, other techniques include various local and global search methods. Besides giving the review we also show a comparison of three hybrid PSO algorithms; hybrid differential evolution particle swarm optimization (DE-PSO), adaptive mutation particle swarm optimization (AMPSO) and hybrid genetic algorithm particle swarm optimization (GA-PSO) on a test suite of nine conventional benchmark problems.
ER  - 

TY  - JOUR
T1  - An unsupervised anomaly-based detection approach for integrity attacks on SCADA systems
JO  - Computers & Security
VL  - 46
IS  - 
SP  - 94
EP  - 110
PY  - 2014/10//
T2  - 
AU  - Almalawi, Abdulmohsen
AU  - Yu, Xinghuo
AU  - Tari, Zahir
AU  - Fahad, Adil
AU  - Khalil, Ibrahim
SN  - 0167-4048
DO  - http://dx.doi.org/10.1016/j.cose.2014.07.005
UR  - http://www.sciencedirect.com/science/article/pii/S0167404814001072
KW  - Unsupervised detection
KW  - Cyber-warfare
KW  - SCADA systems
KW  - Intrusion Detection System
KW  - Consistent/Inconsistent SCADA Patterns
AB  - Abstract
Supervisory Control and Data Acquisition (SCADA) systems are a core part of industrial systems, such as smart grid power and water distribution systems. In recent years, such systems become highly vulnerable to cyber attacks. The design of efficient and accurate data-driven anomaly detection models become an important topic of interest relating to the development of SCADA-specific Intrusion Detection Systems (IDSs) to counter cyber attacks. This paper proposes two novel techniques: (i) an automatic identification of consistent and inconsistent states of SCADA data for any given system, and (ii) an automatic extraction of proximity detection rules from identified states. During the identification phase, the density factor for the k-nearest neighbours of an observation is adapted to compute its inconsistency score. Then, an optimal inconsistency threshold is calculated to separate inconsistent from consistent observations. During the extraction phase, the well-known fixed-width clustering technique is extended to extract proximity-detection rules, which forms a small and most-representative data set for both inconsistent and consistent behaviours in the training data set. Extensive experiments were carried out both on real as well as simulated data sets, and we show that the proposed techniques provide significant accuracy and efficiency in detecting cyber attacks, compared to three well-known anomaly detection approaches.
ER  - 

TY  - JOUR
T1  - Mining language variation using word using and collocation characteristics
JO  - Expert Systems with Applications
VL  - 41
IS  - 17
SP  - 7805
EP  - 7819
PY  - 2014/12/1/
T2  - 
AU  - Tang, Peng
AU  - Chow, Tommy W.S.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2014.05.018
UR  - http://www.sciencedirect.com/science/article/pii/S095741741400298X
KW  - Language variation
KW  - Text mining
KW  - Frequency Rank Ratio
KW  - Overall Intimacy
AB  - Abstract
Two textual metrics “Frequency Rank” (FR) and “Intimacy” are proposed in this paper to measure the word using and collocation characteristics which are two important aspects of text style. The FR, derived from the local index numbers of terms in a sentences ordered by the global frequency of terms, provides single-term-level information. The Intimacy models relationship between a word and others, i.e. the closeness a term is to other terms in the same sentence. Two textual features “Frequency Rank Ratio (FRR)” and “Overall Intimacy (OI)” for capturing language variation are derived by employing the two proposed textual metrics. Using the derived features, language variation among documents can be visualized in a text space. Three corpora consisting of documents of diverse topics, genres, regions, and dates of writing are designed and collected to evaluate the proposed algorithms. Extensive simulations are conducted to verify the feasibility and performance of our implementation. Both theoretical analyses based on entropy and the simulations demonstrate the feasibility of our method. We also show the proposed algorithm can be used for visualizing the closeness of several western languages. Variation of modern English over time is also recognizable when using our analysis method. Finally, our method is compared to conventional text classification implementations. The comparative results indicate our method outperforms the others.
ER  - 

TY  - JOUR
T1  - Multilingual document mining and navigation using self-organizing maps
JO  - Information Processing & Management
VL  - 47
IS  - 5
SP  - 647
EP  - 666
PY  - 2011/9//
T2  - Managing and Mining Multilingual Documents
AU  - Yang, Hsin-Chang
AU  - Hsiao, Han-Wei
AU  - Lee, Chung-Hong
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2009.12.003
UR  - http://www.sciencedirect.com/science/article/pii/S0306457309001423
KW  - Multilingual Web page navigation
KW  - Multilingual text mining
KW  - Self-organizing map
KW  - Hierarchy alignment
AB  - One major approach for information finding in the WWW is to navigate through some Web directories and browse them until the goal pages were found. However, such directories are generally constructed manually and may have disadvantages of narrow coverage and inconsistency. Besides, most of existing directories provide only monolingual hierarchies that organized Web pages in terms that a user may not be familiar with. In this work, we will propose an approach that could automatically arrange multilingual Web pages into a multilingual Web directory to break the language barriers in Web navigation. In this approach, a self-organizing map is constructed to train each set of monolingual Web pages and obtain two feature maps, which reveal the relationships among Web pages and thematic keywords, respectively, for such language. We then apply a hierarchy generation process on these maps to obtain the monolingual hierarchy for these Web pages. A hierarchy alignment method is then applied on these monolingual hierarchies to discover the associations between nodes in different hierarchies. Finally, a multilingual Web directory is constructed according to such associations. We applied the proposed approach on a set of Web pages and obtained interesting result that demonstrates the feasibility of our method in multilingual Web navigation.
ER  - 

TY  - JOUR
T1  - A scalable privacy-preserving recommendation scheme via bisecting k-means clustering
JO  - Information Processing & Management
VL  - 49
IS  - 4
SP  - 912
EP  - 927
PY  - 2013/7//
T2  - 
AU  - Bilge, Alper
AU  - Polat, Huseyin
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2013.02.004
UR  - http://www.sciencedirect.com/science/article/pii/S0306457313000320
KW  - Accuracy
KW  - Binary decision diagrams
KW  - Clustering methods
KW  - Data preprocessing
KW  - Data privacy
KW  - Recommender systems
AB  - Abstract
Privacy-preserving collaborative filtering is an emerging web-adaptation tool to cope with information overload problem without jeopardizing individuals’ privacy. However, collaborative filtering with privacy schemes commonly suffer from scalability and sparseness as the content in the domain proliferates. Moreover, applying privacy measures causes a distortion in collected data, which in turn defects accuracy of such systems. In this work, we propose a novel privacy-preserving collaborative filtering scheme based on bisecting k-means clustering in which we apply two preprocessing methods. The first preprocessing scheme deals with scalability problem by constructing a binary decision tree through a bisecting k-means clustering approach while the second produces clones of users by inserting pseudo-self-predictions into original user profiles to boost accuracy of scalability-enhanced structure. Sparse nature of collections are handled by transforming ratings into item features-based profiles. After analyzing our scheme with respect to privacy and supplementary costs, we perform experiments on benchmark data sets to evaluate it in terms of accuracy and online performance. Our empirical outcomes verify that combined effects of the proposed preprocessing schemes relieve scalability and augment accuracy significantly.
ER  - 

TY  - JOUR
T1  - Clustering dense graphs: A web site graph paradigm
JO  - Information Processing & Management
VL  - 46
IS  - 3
SP  - 247
EP  - 267
PY  - 2010/5//
T2  - 
AU  - Moussiades, L.
AU  - Vakali, A.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2009.11.003
UR  - http://www.sciencedirect.com/science/article/pii/S0306457309001368
KW  - Graph-clustering
KW  - Graph partitioning
KW  - Benchmark graphs
KW  - Community structure
KW  - Web graph
AB  - Typically graph-clustering approaches assume that a cluster is a vertex subset such that for all of its vertices, the number of links connecting a vertex to its cluster is higher than the number of links connecting the vertex to the remaining graph. We consider a cluster such that for all of its vertices, the number of links connecting a vertex to its cluster is higher than the number of links connecting the vertex to any other cluster. Based on this fundamental view, we propose a graph-clustering algorithm that identifies clusters even if they contain vertices more strongly connected outside than inside their cluster; hence, the proposed algorithm is proved exceptionally efficient in clustering densely interconnected graphs. Extensive experimentation with artificial and real datasets shows that our approach outperforms earlier alternate clustering techniques.
ER  - 

TY  - JOUR
T1  - Probabilistic co-relevance for query-sensitive similarity measurement in information retrieval
JO  - Information Processing & Management
VL  - 49
IS  - 2
SP  - 558
EP  - 575
PY  - 2013/3//
T2  - 
AU  - Na, Seung-Hoon
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2012.10.002
UR  - http://www.sciencedirect.com/science/article/pii/S0306457312001215
KW  - Probabilistic co-relevance
KW  - Query-sensitive similarity
KW  - Inter-document similarity
KW  - Cluster hypothesis
KW  - Cluster-based retrieval
AB  - Interdocument similarities are the fundamental information source required in cluster-based retrieval, which is an advanced retrieval approach that significantly improves performance during information retrieval (IR). An effective similarity metric is query-sensitive similarity, which was introduced by Tombros and Rijsbergen as method to more directly satisfy the cluster hypothesis that forms the basis of cluster-based retrieval. Although this method is reported to be effective, existing applications of query-specific similarity are still limited to vector space models wherein there is no connection to probabilistic approaches. We suggest a probabilistic framework that defines query-sensitive similarity based on probabilistic co-relevance, where the similarity between two documents is proportional to the probability that they are both co-relevant to a specific given query. We further simplify the proposed co-relevance-based similarity by decomposing it into two separate relevance models. We then formulate all the requisite components for the proposed similarity metric in terms of scoring functions used by language modeling methods. Experimental results obtained using standard TREC test collections consistently showed that the proposed query-sensitive similarity measure performs better than term-based similarity and existing query-sensitive similarity in the context of Voorhees’ nearest neighbor test (NNT).
ER  - 

TY  - JOUR
T1  - Live and learn from mistakes: A lightweight system for document classification
JO  - Information Processing & Management
VL  - 49
IS  - 1
SP  - 83
EP  - 98
PY  - 2013/1//
T2  - 
AU  - Borodin, Yevgen
AU  - Polishchuk, Valentin
AU  - Mahmud, Jalal
AU  - Ramakrishnan, I.V.
AU  - Stent, Amanda
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2012.02.001
UR  - http://www.sciencedirect.com/science/article/pii/S0306457312000179
KW  - 3LM
KW  - Centroid
KW  - Clusterhead
KW  - Classifier
KW  - Lifelong
KW  - Online
AB  - We present a Life-Long Learning from Mistakes (3LM) algorithm for document classification, which could be used in various scenarios such as spam filtering, blog classification, and web resource categorization. We extend the ideas of online clustering and batch-mode centroid-based classification to online learning with negative feedback. The 3LM is a competitive learning algorithm, which avoids over-smoothing, characteristic of the centroid-based classifiers, by using a different class representative, which we call clusterhead. The clusterheads competing for vector-space dominance are drawn toward misclassified documents, eventually bringing the model to a “balanced state” for a fixed distribution of documents. Subsequently, the clusterheads oscillate between the misclassified documents, heuristically minimizing the rate of misclassifications, an NP-complete problem. Further, the 3LM algorithm prevents over-fitting by “leashing” the clusterheads to their respective centroids. A clusterhead provably converges if its class can be separated by a hyper-plane from all other classes. Lifelong learning with fixed learning rate allows 3LM to adapt to possibly changing distribution of the data and continually learn and unlearn document classes. We report on our experiments, which demonstrate high accuracy of document classification on Reuters21578, OHSUMED, and TREC07p-spam datasets. The 3LM algorithm did not show over-fitting, while consistently outperforming centroid-based, Naïve Bayes, C4.5, AdaBoost, kNN, and SVM whose accuracy had been reported on the same three corpora.
ER  - 

TY  - JOUR
T1  - Evaluating subtopic retrieval methods: Clustering versus diversification of search results
JO  - Information Processing & Management
VL  - 48
IS  - 2
SP  - 358
EP  - 373
PY  - 2012/3//
T2  - 
AU  - Carpineto, Claudio
AU  - D’Amico, Massimiliano
AU  - Romano, Giovanni
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2011.08.004
UR  - http://www.sciencedirect.com/science/article/pii/S0306457311000835
KW  - Subtopic retrieval
KW  - Clustering
KW  - Search results re-ranking
KW  - Diversification
KW  - Search results clustering
KW  - Search results diversification
KW  - Subtopic retrieval evaluation
AB  - To address the inability of current ranking systems to support subtopic retrieval, two main post-processing techniques of search results have been investigated: clustering and diversification. In this paper we present a comparative study of their performance, using a set of complementary evaluation measures that can be applied to both partitions and ranked lists, and two specialized test collections focusing on broad and ambiguous queries, respectively. The main finding of our experiments is that diversification of top hits is more useful for quick coverage of distinct subtopics whereas clustering is better for full retrieval of single subtopics, with a better balance in performance achieved through generating multiple subsets of diverse search results. We also found that there is little scope for improvement over the search engine baseline unless we are interested in strict full-subtopic retrieval, and that search results clustering methods do not perform well on queries with low divergence subtopics, mainly due to the difficulty of generating discriminative cluster labels.
ER  - 

TY  - JOUR
T1  - An unsupervised approach to generating generic summaries of documents
JO  - Applied Soft Computing
VL  - 34
IS  - 
SP  - 236
EP  - 250
PY  - 2015/9//
T2  - 
AU  - Alguliyev, Rasim M.
AU  - Aliguliyev, Ramiz M.
AU  - Isazade, Nijat R.
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2015.04.050
UR  - http://www.sciencedirect.com/science/article/pii/S156849461500277X
KW  - Maximum relevance
KW  - Minimum redundancy
KW  - Optimization model
KW  - Differential evolution algorithm
KW  - Combined similarity measure
AB  - Abstract
We present an optimization-based unsupervised approach to automatic document summarization. In the proposed approach, text summarization is modeled as a Boolean programming problem. This model generally attempts to optimize three properties, namely, (1) relevance: summary should contain informative textual units that are relevant to the user; (2) redundancy: summaries should not contain multiple textual units that convey the same information; and (3) length: summary is bounded in length. The approach proposed in this paper is applicable to both tasks: single- and multi-document summarization. In both tasks, documents are split into sentences in preprocessing. We select some salient sentences from document(s) to generate a summary. Finally, the summary is generated by threading all the selected sentences in the order that they appear in the original document(s). We implemented our model on multi-document summarization task. When comparing our methods to several existing summarization methods on an open DUC2005 and DUC2007 data sets, we found that our method improves the summarization results significantly. This is because, first, when extracting summary sentences, this method not only focuses on the relevance scores of sentences to the whole sentence collection, but also the topic representative of sentences. Second, when generating a summary, this method also deals with the problem of repetition of information. The methods were evaluated using ROUGE-1, ROUGE-2 and ROUGE-SU4 metrics. In this paper, we also demonstrate that the summarization result depends on the similarity measure. Results of the experiment showed that combination of symmetric and asymmetric similarity measures yields better result than their use separately.
ER  - 

TY  - JOUR
T1  - Product concept evaluation and selection using data mining and domain ontology in a crowdsourcing environment
JO  - Advanced Engineering Informatics
VL  - 29
IS  - 4
SP  - 759
EP  - 774
PY  - 2015/10//
T2  - Collective Intelligence Modeling, Analysis, and Synthesis for Innovative Engineering Decision MakingSpecial Issue of the 1st International Conference on Civil and Building Engineering Informatics
AU  - Chang, Danni
AU  - Chen, Chun-Hsien
SN  - 1474-0346
DO  - http://dx.doi.org/10.1016/j.aei.2015.06.003
UR  - http://www.sciencedirect.com/science/article/pii/S1474034615000646
KW  - Product concept evaluation and selection
KW  - Data mining
KW  - Domain ontology
KW  - Crowdsourcing
AB  - Abstract
For product design and development, crowdsourcing shows huge potential for fostering creativity and has been regarded as one important approach to acquiring innovative concepts. Nevertheless, prior to the approach could be effectively implemented, the following challenges concerning crowdsourcing should be properly addressed: (1) burdensome concept review process to deal with a large amount of crowd-sourced design concepts; (2) insufficient consideration in integrating design knowledge and principles into existing data processing methods/algorithms for crowdsourcing; and (3) lack of a quantitative decision support process to identify better concepts. To tackle these problems, a product concept evaluation and selection approach, which comprises three modules, is proposed. These modules are respectively: (1) a data mining module to extract meaningful information from online crowd-sourced concepts; (2) a concept re-construction module to organize word tokens into a unified frame using domain ontology and extended design knowledge; and (3) a decision support module to select better concepts in a simplified manner. A pilot study on future PC (personal computer) design was conducted to demonstrate the proposed approach. The results show that the proposed approach is promising and may help to improve the concept review and evaluation efficiency; facilitate data processing using design knowledge; and enhance the reliability of concept selection decisions.
ER  - 

TY  - JOUR
T1  - Semantic relation based personalized ranking approach for engineering document retrieval
JO  - Advanced Engineering Informatics
VL  - 29
IS  - 3
SP  - 366
EP  - 379
PY  - 2015/8//
T2  - 
AU  - Hahm, Gyeong June
AU  - Lee, Jae Hyun
AU  - Suh, Hyo Won
SN  - 1474-0346
DO  - http://dx.doi.org/10.1016/j.aei.2015.01.003
UR  - http://www.sciencedirect.com/science/article/pii/S1474034615000154
KW  - Ranking
KW  - Personalized search
KW  - Semantic search
KW  - Domain ontology
KW  - Engineering document
AB  - Abstract
Since engineering design is heavily informational, engineers want to retrieve existing engineering documents accurately during the product development process. However, engineers have difficulties searching for documents because of low retrieval accuracy. One of the reasons for this is the limitation of existing document ranking approaches, in which relationships between terms in documents are not considered to assess the relevance of the retrieved documents. Therefore, we propose a new ranking approach that provides more correct evaluation of document relevance to a given query. Our approach exploits domain ontology to consider relationships among terms in the relevance scoring process. Based on domain ontology, the semantics of a document are represented by a graph (called Document Semantic Network) and, then, proposed relation-based weighting schemes are used to evaluate the graph to calculate the document relevance score. In our ranking approach, user interests and searching intent are also considered in order to provide personalized services. The experimental results show that the proposed approach outperforms existing ranking approaches. A precisely represented semantics of a document as a graph and multiple relation-based weighting schemes are important factors underlying the notable improvement.
ER  - 

TY  - JOUR
T1  - A distributional approach to open questions in market research
JO  - Computers in Industry
VL  - 78
IS  - 
SP  - 16
EP  - 28
PY  - 2016/5//
T2  - Natural Language Processing and Text Analytics in Industry
AU  - Evert, Stefan
AU  - Greiner, Paul
AU  - Baigger, João Filipe
AU  - Lang, Bastian
SN  - 0166-3615
DO  - http://dx.doi.org/10.1016/j.compind.2015.10.008
UR  - http://www.sciencedirect.com/science/article/pii/S016636151530049X
KW  - Topic clustering
KW  - Distributional semantics
KW  - Sentiment analysis
KW  - Market research
AB  - Abstract
Free-text responses to open questions are a rich and valuable resource in modern-day market research, but often pose problems for a traditional analysis, which requires prohibitively expensive manual coding of topic categories. The Klugator Engine (TKE) is a system for semi-automatic identification, exploration and visualization of topics and sentiment in large collections of such free-text responses or other short text fragments. The system utilizes state-of-the-art techniques of natural language processing and machine learning to transform textual input into a structured corpus, complemented by automatically determined polarity scores for individual responses. Statistical and distributional methods are then applied in order to identify semantic clusters of responses, label each topic cluster with a set of salient keywords, and evaluate the sentiment associated with the topic. This process can run in fully automated fashion, but it also offers the opportunity of interactive parameter tuning and refinement guided by the end user. Results are presented in a concise graphical visualization supported by detailed tables with numerical information. Embedded in RogTCS, the Rogator Text Clustering Solution, TKE enables customers to obtain a good overview of the main topics in a text collection comprising thousands of responses within 20 min of interactive exploration. An evaluation study based on a data set of more than 60,000 word tokens has shown good agreement with the topics identified by manual coding, rendering TKE a powerful tool for the analysis of unstructured textual data.
ER  - 

TY  - JOUR
T1  - Finding imaging patterns of structural covariance via Non-Negative Matrix Factorization
JO  - NeuroImage
VL  - 108
IS  - 
SP  - 1
EP  - 16
PY  - 2015/3//
T2  - 
AU  - Sotiras, Aristeidis
AU  - Resnick, Susan M.
AU  - Davatzikos, Christos
SN  - 1053-8119
DO  - http://dx.doi.org/10.1016/j.neuroimage.2014.11.045
UR  - http://www.sciencedirect.com/science/article/pii/S1053811914009756
KW  - Data analysis
KW  - Structural covariance
KW  - Non-Negative Matrix Factorization
KW  - Principal Component Analysis
KW  - Independent Component Analysis
KW  - Diffusion Tensor Imaging
KW  - Fractional anisotropy
KW  - Structural Magnetic Resonance Imaging
KW  - Gray matter
KW  - RAVENS
AB  - Abstract
In this paper, we investigate the use of Non-Negative Matrix Factorization (NNMF) for the analysis of structural neuroimaging data. The goal is to identify the brain regions that co-vary across individuals in a consistent way, hence potentially being part of underlying brain networks or otherwise influenced by underlying common mechanisms such as genetics and pathologies. NNMF offers a directly data-driven way of extracting relatively localized co-varying structural regions, thereby transcending limitations of Principal Component Analysis (PCA), Independent Component Analysis (ICA) and other related methods that tend to produce dispersed components of positive and negative loadings. In particular, leveraging upon the well known ability of NNMF to produce parts-based representations of image data, we derive decompositions that partition the brain into regions that vary in consistent ways across individuals. Importantly, these decompositions achieve dimensionality reduction via highly interpretable ways and generalize well to new data as shown via split-sample experiments. We empirically validate NNMF in two data sets: i) a Diffusion Tensor (DT) mouse brain development study, and ii) a structural Magnetic Resonance (sMR) study of human brain aging. We demonstrate the ability of NNMF to produce sparse parts-based representations of the data at various resolutions. These representations seem to follow what we know about the underlying functional organization of the brain and also capture some pathological processes. Moreover, we show that these low dimensional representations favorably compare to descriptions obtained with more commonly used matrix factorization methods like PCA and ICA.
ER  - 

TY  - JOUR
T1  - A semantics and image retrieval system for hierarchical image databases
JO  - Information Processing & Management
VL  - 52
IS  - 4
SP  - 571
EP  - 591
PY  - 2016/7//
T2  - 
AU  - Pandey, Shreelekha
AU  - Khanna, Pritee
AU  - Yokota, Haruo
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2015.12.005
UR  - http://www.sciencedirect.com/science/article/pii/S0306457315001429
KW  - Content based image retrieval
KW  - Semantic assignment
KW  - Clustering
KW  - Visual search space
KW  - Indexing of visual features
AB  - Abstract
This work presents a content based semantics and image retrieval system for semantically categorized hierarchical image databases. Each module is designed with an aim to develop a system that works closer to human perception. Images are mapped to a multidimensional feature space, where images belonging a semantic are clustered and indexed to acquire its efficient representation. This helps in handling the existing variability or heterogeneity within this semantic. Adaptive combinations of the obtained depictions are utilized by the branch selection and pruning algorithms to identify some closer semantics and select only a part of the large hierarchical search space for actual search. So obtained search space is finally used to retrieve desired semantics and similar images corresponding to them. The system is evaluated in terms of accuracy of the retrieved semantics and precision-recall curves. Experiments show promising semantics and image retrieval results on hierarchical image databases. The results reported with non-hierarchical but categorized image databases further prove the efficacy of the proposed system.
ER  - 

TY  - JOUR
T1  - On characterizing population commonalities and subject variations in brain networks
JO  - Medical Image Analysis
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Ghanbari, Yasser
AU  - Bloy, Luke
AU  - Tunc, Birkan
AU  - Shankar, Varsha
AU  - Roberts, Timothy P.L.
AU  - Edgar, J. Christopher
AU  - Schultz, Robert T.
AU  - Verma, Ragini
SN  - 1361-8415
DO  - http://dx.doi.org/10.1016/j.media.2015.10.009
UR  - http://www.sciencedirect.com/science/article/pii/S1361841515001516
KW  - Connectivity analysis
KW  - Non-negative matrix factorization
KW  - Multi-layer graph clustering
KW  - Population difference
KW  - Autism spectrum disorder
AB  - Abstract
Brain networks based on resting state connectivity as well as inter-regional anatomical pathways obtained using diffusion imaging have provided insight into pathology and development. Such work has underscored the need for methods that can extract sub-networks that can accurately capture the connectivity patterns of the underlying population while simultaneously describing the variation of sub-networks at the subject level. We have designed a multi-layer graph clustering method that extracts clusters of nodes, called ‘network hubs’, which display higher levels of connectivity within the cluster than to the rest of the brain. The method determines an atlas of network hubs that describes the population, as well as weights that characterize subject-wise variation in terms of within- and between-hub connectivity. This lowers the dimensionality of brain networks, thereby providing a representation amenable to statistical analyses. The applicability of the proposed technique is demonstrated by extracting an atlas of network hubs for a population of typically developing controls (TDCs) as well as children with autism spectrum disorder (ASD), and using the structural and functional networks of a population to determine the subject-level variation of these hubs and their inter-connectivity. These hubs are then used to compare ASD and TDCs. Our method is generalizable to any population whose connectivity (structural or functional) can be captured via non-negative network graphs.
ER  - 

TY  - JOUR
T1  - Opposition chaotic fitness mutation based adaptive inertia weight BPSO for feature selection in text clustering
JO  - Applied Soft Computing
VL  - 43
IS  - 
SP  - 20
EP  - 34
PY  - 2016/6//
T2  - 
AU  - Bharti, Kusum Kumari
AU  - Singh, Pramod Kumar
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2016.01.019
UR  - http://www.sciencedirect.com/science/article/pii/S1568494616300060
KW  - Text clustering
KW  - Binary particle swarm optimization
KW  - Mutation
KW  - Chaotic map
KW  - Opposition-based learning
AB  - Abstract
Due to the ever increasing number of documents in the digital form, automated text clustering has become a promising method for the text analysis in last few decades. A major issue in the text clustering is high dimensionality of the feature space. Most of these features are irrelevant, redundant, and noisy that mislead the underlying algorithm. Therefore, feature selection is an essential step in the text clustering to reduce dimensionality of the feature space and to improve accuracy of the underlying clustering algorithm. In this paper, a hybrid intelligent algorithm, which combines the binary particle swarm optimization (BPSO) with opposition-based learning, chaotic map, fitness based dynamic inertia weight, and mutation, is proposed to solve feature selection problem in the text clustering. Here, fitness based dynamic inertia weight is integrated with the BPSO to control movement of the particles based on their current status, and the mutation and the chaotic strategy are applied to enhance the global search capability of the algorithm. Moreover, an opposition-based initialization is used to start with a set of promising and well-diversified solutions to achieve a better final solution. In addition, the opposition-based learning method is also used to generate opposite position of the gbest particle to get rid of the stagnation in the swarm. To prove effectiveness of the proposed method, experimental analysis is conducted on three different benchmark text datasets Reuters-21578, Classic4, and WebKB. The experimental results demonstrate that the proposed method selects more informative features set compared to the competitive methods as it attains higher clustering accuracy. Moreover, it also improves convergence speed of the BPSO.
ER  - 

TY  - JOUR
T1  - Social big data: Recent achievements and new challenges
JO  - Information Fusion
VL  - 28
IS  - 
SP  - 45
EP  - 59
PY  - 2016/3//
T2  - 
AU  - Bello-Orgaz, Gema
AU  - Jung, Jason J.
AU  - Camacho, David
SN  - 1566-2535
DO  - http://dx.doi.org/10.1016/j.inffus.2015.08.005
UR  - http://www.sciencedirect.com/science/article/pii/S1566253515000780
KW  - Big data
KW  - Data mining
KW  - Social media
KW  - Social networks
KW  - Social-based frameworks and applications
AB  - Abstract
Big data has become an important issue for a large number of research areas such as data mining, machine learning, computational intelligence, information fusion, the semantic Web, and social networks. The rise of different big data frameworks such as Apache Hadoop and, more recently, Spark, for massive data processing based on the MapReduce paradigm has allowed for the efficient utilisation of data mining methods and machine learning algorithms in different domains. A number of libraries such as Mahout and SparkMLib have been designed to develop new efficient applications based on machine learning algorithms. The combination of big data technologies and traditional machine learning algorithms has generated new and interesting challenges in other areas as social media and social networks. These new challenges are focused mainly on problems such as data processing, data storage, data representation, and how data can be used for pattern mining, analysing user behaviours, and visualizing and tracking data, among others. In this paper, we present a revision of the new methodologies that is designed to allow for efficient data mining and information fusion from social media and of the new applications and frameworks that are currently appearing under the “umbrella” of the social networks, social media and big data paradigms.
ER  - 

TY  - JOUR
T1  - Multi-Label Regularized Generative Model for Semi-Supervised Collective Classification in Large-Scale Networks
JO  - Big Data Research
VL  - 2
IS  - 4
SP  - 187
EP  - 201
PY  - 2015/12//
T2  - 
AU  - Wu, Qingyao
AU  - Chen, Jian
AU  - Ho, Shen-Shyang
AU  - Li, Xutao
AU  - Min, Huaqing
AU  - Han, Chao
SN  - 2214-5796
DO  - http://dx.doi.org/10.1016/j.bdr.2015.04.002
UR  - http://www.sciencedirect.com/science/article/pii/S2214579615000301
KW  - Collective classification
KW  - Generative model
KW  - Semi-supervised learning
KW  - Multi-label learning
KW  - Large-scale sparsely labeled networks
AB  - Abstract
The problem of collective classification (CC) for large-scale network data has received considerable attention in the last decade. Enabling CC usually increases accuracy when given a fully-labeled network with a large amount of labeled data. However, such labels can be difficult to obtain and learning a CC model with only a few such labels in large-scale sparsely labeled networks can lead to poor performance. In this paper, we show that leveraging the unlabeled portion of the data through semi-supervised collective classification (SSCC) is essential to achieving high performance. First, we describe a novel data-generating algorithm, called generative model with network regularization (GMNR), to exploit both labeled and unlabeled data in large-scale sparsely labeled networks. In GMNR, a network regularizer is constructed to encode the network structure information, and we apply the network regularizer to smooth the probability density functions of the generative model. Second, we extend our proposed GMNR algorithm to handle network data consisting of multi-label instances. This approach, called the multi-label regularized generative model (MRGM), includes an additional label regularizer to encode the label correlation, and we show how these smoothing regularizers can be incorporated into the objective function of the model to improve the performance of CC in multi-label setting. We then develop an optimization scheme to solve the objective function based on EM algorithm. Empirical results on several real-world network data classification tasks show that our proposed methods are better than the compared collective classification algorithms especially when labeled data is scarce.
ER  - 

TY  - JOUR
T1  - Terms-based discriminative information space for robust text classification
JO  - Information Sciences
VL  - 372
IS  - 
SP  - 518
EP  - 538
PY  - 2016/12/1/
T2  - 
AU  - Junejo, Khurum Nazir
AU  - Karim, Asim
AU  - Hassan, Malik Tahir
AU  - Jeon, Moongu
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2016.08.073
UR  - http://www.sciencedirect.com/science/article/pii/S002002551630651X
KW  - Text classification
KW  - Discriminative term weights
KW  - Linear opinion pooling
KW  - Feature construction
AB  - Abstract
With the popularity of Web 2.0, there has been a phenomenal increase in the utility of text classification in applications like document filtering and sentiment categorization. Many of these applications demand that the classification method be efficient and robust, yet produce accurate categorizations by using the terms in the documents only. In this paper, we propose a novel and efficient method using terms-based discriminative information space for robust text classification. Terms in the documents are assigned weights according to the discrimination information they provide for one category over the others. These weights also serve to partition the terms into category sets. A linear opinion pool is adopted for combining the discrimination information provided by each set of terms to yield a feature space (discriminative information space) having dimensions equal to the number of classes. Subsequently, a discriminant function is learned to categorize the documents in the feature space. This classification methodology relies upon corpus information only, and is robust to distribution shifts and noise. We develop theoretical parallels of our methodology with generative, discriminative, and hybrid classifiers. We evaluate our methodology extensively with five different discriminative term weighting schemes on six data sets from different application areas. We give a side-by-side comparison with four well-known text classification techniques. The results show that our methodology consistently outperforms the rest, especially when there is a distribution shift from training to test sets. Moreover, our methodology is simple and effective for different application domains and training set sizes. It is also fast with a small and tunable memory footprint.
ER  - 

TY  - JOUR
T1  - A convergent algorithm for orthogonal nonnegative matrix factorization
JO  - Journal of Computational and Applied Mathematics
VL  - 260
IS  - 
SP  - 149
EP  - 166
PY  - 2014/4//
T2  - 
AU  - Mirzal, Andri
SN  - 0377-0427
DO  - http://dx.doi.org/10.1016/j.cam.2013.09.022
UR  - http://www.sciencedirect.com/science/article/pii/S0377042713004779
KW  - Nonnegative matrix factorization
KW  - Orthogonality constraint
KW  - Convergent algorithm
KW  - Clustering methods
AB  - Abstract
This paper proposes a convergent algorithm for nonnegative matrix factorization (NMF) with orthogonality constraint on the factors. We design the algorithm based on the additive update rule algorithm for the standard NMF proposed by Lee and Seung, and derive the convergent version by generalizing the convergence proof of the algorithm developed by Lin. Further we use the proposed algorithms to improve clustering capability of the standard NMF using the Reuter document corpus, a standard dataset in clustering research.
ER  - 

TY  - JOUR
T1  - Interval-valued fuzzy set approach to fuzzy co-clustering for data classification
JO  - Knowledge-Based Systems
VL  - 107
IS  - 
SP  - 1
EP  - 13
PY  - 2016/9/1/
T2  - 
AU  - Pham, Van Nha
AU  - Ngo, Long Thanh
AU  - Pedrycz, Witold
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2016.05.049
UR  - http://www.sciencedirect.com/science/article/pii/S0950705116301460
KW  - Fuzzy clustering
KW  - Fuzzy co-clustering
KW  - Interval type-2 fuzzy sets
KW  - Interval-valued fuzzy sets
KW  - Data classification
AB  - Abstract
Data clustering is aimed at discovering a structure in data. The revealed structure is usually represented in terms of prototypes and partition matrices. In some cases, the prototypes are simultaneously formed using data and features by running a co-clustering (bi-clustering) algorithm. Interval valued fuzzy clustering exhibits advantages when handling uncertainty. This study introduces a novel clustering technique by combining fuzzy co-clustering approach and interval-valued fuzzy sets in which two values of the fuzzifier of the fuzzy clustering algorithm are used to form the footprint of uncertainty (FOU). The study demonstrates the performance of the proposed method through a series of experiments completed for various datasets (including color segmentation, multi-spectral image classification, and document categorization). The experiments quantify the quality of results with the aid of validity indices and visual inspection. Some comparative analysis is also covered.
ER  - 

TY  - JOUR
T1  - Hierarchical Bayesian nonparametric models for knowledge discovery from electronic medical records
JO  - Knowledge-Based Systems
VL  - 99
IS  - 
SP  - 168
EP  - 182
PY  - 2016/5/1/
T2  - 
AU  - Li, Cheng
AU  - Rana, Santu
AU  - Phung, Dinh
AU  - Venkatesh, Svetha
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2016.02.005
UR  - http://www.sciencedirect.com/science/article/pii/S0950705116000836
KW  - Bayesian nonparametric models
KW  - Correspondence models
KW  - Word distances
KW  - Disease topics
KW  - Readmission prediction
KW  - Procedure codes prediction
AB  - Abstract
Electronic Medical Record (EMR) has established itself as a valuable resource for large scale analysis of health data. A hospital EMR dataset typically consists of medical records of hospitalized patients. A medical record contains diagnostic information (diagnosis codes), procedures performed (procedure codes) and admission details. Traditional topic models, such as latent Dirichlet allocation (LDA) and hierarchical Dirichlet process (HDP), can be employed to discover disease topics from EMR data by treating patients as documents and diagnosis codes as words. This topic modeling helps to understand the constitution of patient diseases and offers a tool for better planning of treatment. In this paper, we propose a novel and flexible hierarchical Bayesian nonparametric model, the word distance dependent Chinese restaurant franchise (wddCRF), which incorporates word-to-word distances to discover semantically-coherent disease topics. We are motivated by the fact that diagnosis codes are connected in the form of ICD-10 tree structure which presents semantic relationships between codes. We exploit a decay function to incorporate distances between words at the bottom level of wddCRF. Efficient inference is derived for the wddCRF by using MCMC technique. Furthermore, since procedure codes are often correlated with diagnosis codes, we develop the correspondence wddCRF (Corr-wddCRF) to explore conditional relationships of procedure codes for a given disease pattern. Efficient collapsed Gibbs sampling is derived for the Corr-wddCRF. We evaluate the proposed models on two real-world medical datasets – PolyVascular disease and Acute Myocardial Infarction disease. We demonstrate that the Corr-wddCRF model discovers more coherent topics than the Corr-HDP. We also use disease topic proportions as new features and show that using features from the Corr-wddCRF outperforms the baselines on 14-days readmission prediction. Beside these, the prediction for procedure codes based on the Corr-wddCRF also shows considerable accuracy.
ER  - 

TY  - JOUR
T1  - Extracting features from online software reviews to aid requirements reuse
JO  - Applied Soft Computing
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Bakar, Noor Hasrina
AU  - Kasirun, Zarinah M.
AU  - Salleh, Norsaremah
AU  - Jalab, Hamid A.
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2016.07.048
UR  - http://www.sciencedirect.com/science/article/pii/S1568494616303830
KW  - Requirements reuse
KW  - Software engineering
KW  - Natural language processing
KW  - Unsupervised learning
KW  - Latent semantic analysis
AB  - Abstract
Sets of common features are essential assets to be reused in fulfilling specific needs in software product line methodology. In Requirements Reuse (RR), the extraction of software features from Software Requirement Specifications (SRS) is viable only to practitioners who have access to these software artefacts. Due to organisational privacy, SRS are always kept confidential and not easily available to the public. As alternatives, researchers opted to use the publicly available software descriptions such as product brochures and online software descriptions to identify potential software features to initiate the RR process. The aim of this paper is to propose a semi-automated approach, known as Feature Extraction for Reuse of Natural Language requirements (FENL), to extract phrases that can represent software features from software reviews in the absence of SRS as a way to initiate the RR process. FENL is composed of four stages, which depend on keyword occurrences from several combinations of nouns, verbs, and/or adjectives. In the experiment conducted, phrases that could reflect software features, which reside within online software reviews were extracted by utilising the techniques from information retrieval (IR) area. As a way to demonstrate the feature groupings phase, a semi-automated approach to group the extracted features were then conducted with the assistance of a modified word overlap algorithm. As for the evaluation, the proposed extraction approach is evaluated through experiments against the truth data set created manually. The performance results obtained from the feature extraction phase indicates that the proposed approach performed comparably with related works in terms of recall, precision, and F-Measure.
ER  - 

TY  - JOUR
T1  - Clustering of heterogeneous networks with directional flows based on “Snake” similarities
JO  - Transportation Research Part B: Methodological
VL  - 91
IS  - 
SP  - 250
EP  - 269
PY  - 2016/9//
T2  - 
AU  - Saeedmanesh, Mohammadreza
AU  - Geroliminis, Nikolas
SN  - 0191-2615
DO  - http://dx.doi.org/10.1016/j.trb.2016.05.008
UR  - http://www.sciencedirect.com/science/article/pii/S0191261515302605
KW  - Graph partitioning
KW  - Spatiotemporal correlation
KW  - Macroscopic fundamental diagram
KW  - Non-negative matrix factorization
KW  - Missing data
AB  - Abstract
Aggregated network level modeling and control of traffic in urban networks have recently gained a lot of interest due to unpredictability of travel behaviors and high complexity of physical modeling in microscopic level. Recent research has shown the existence of well-defined Macroscopic Fundamental Diagrams (MFDs) relating average flow and density in homogeneous networks. The concept of MFD allows to design real-time traffic control schemes specifically hierarchical perimeter control approaches to alleviate or postpone congestion. Considering the fact that congestion is spatially correlated in adjacent roads and it propagates spatiotemporaly with finite speed, describing the main pockets of congestion in a heterogeneous city with small number of clusters is conceivable. In this paper, we propose a three-step clustering algorithm to partition heterogeneous networks into connected homogeneous regions, which makes the application of perimeter control feasible. The advantages of the proposed method compared to the existing ones are the ability of finding directional congestion within a cluster, robustness with respect to parameters calibration, and its good performance for networks with low connectivity and missing data. Firstly, we start to find a connected homogeneous area around each road of the network in an iterative way (i.e. it forms a sequence of roads). Each sequence of roads, defined as ‘snake’, is built by starting from a single road and iteratively adding one adjacent road based on its similarity to join previously added roads in that sequence. Secondly, based on the obtained sequences from the first step, a similarity measure is defined between each pair of the roads in the network. The similarities are computed in a way that put more weight on neighboring roads and facilitate connectivity of the clusters. Finally, Symmetric Non-negative Matrix Factorization (SNMF) framework is utilized to assign roads to proper clusters with high intra-similarity and low inter-similarity. SNMF partitions the data by providing a lower rank approximation of the similarity matrix. The proposed clustering framework is applied in medium and large-size networks based on micro-simulation and empirical data from probe vehicles. In addition, the extension of the algorithm is proposed to deal with the networks with sparse measurements where information of some links is missing. The results show the effectiveness and robustness of the extended algorithm applied to simulated network under different penetration rates (percentage of links with data).
ER  - 

TY  - JOUR
T1  - Iterative ensemble normalized cuts
JO  - Pattern Recognition
VL  - 52
IS  - 
SP  - 274
EP  - 286
PY  - 2016/4//
T2  - 
AU  - He, Li
AU  - Zhang, Hong
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2015.10.019
UR  - http://www.sciencedirect.com/science/article/pii/S0031320315003982
KW  - Iterative ensemble NCut
KW  - Gap-normalized distance
KW  - Spectral clustering
KW  - Image segmentation
AB  - Abstract
A fast spectral clustering method is proposed. Eigenvectors used in NCut are studied as the gap-normalized distances defined in this paper. The out-of-sample extensions of NCut are derived by extending the gap-normalized distances to new data, which is interestingly found to be perfectly matched with the Nyström-based eigenfunction approximation. From the view of gap-normalized distance, the ensemble NCut method is built by assembling distances of small groups to learn the partitions of the entire dataset. By iteratively calling such assembly, the iterative ensemble NCut method is proposed. Experiments on real world datasets and the image segmentation tasks show that, compared with the state-of-the-art, the proposed IENCut method produces improved clustering quality although this improvement may sometimes come at the expense of increased processing time.
ER  - 

TY  - JOUR
T1  - Wordification: Propositionalization by unfolding relational data into bags of words
JO  - Expert Systems with Applications
VL  - 42
IS  - 17–18
SP  - 6442
EP  - 6456
PY  - 2015/10//
T2  - 
AU  - Perovšek, Matic
AU  - Vavpetič, Anže
AU  - Kranjc, Janez
AU  - Cestnik, Bojan
AU  - Lavrač, Nada
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2015.04.017
UR  - http://www.sciencedirect.com/science/article/pii/S095741741500247X
KW  - Wordification
KW  - Inductive Logic Programming
KW  - Relational Data Mining
KW  - Propositionalization
KW  - Text mining
KW  - Classification
AB  - Abstract
Inductive Logic Programming (ILP) and Relational Data Mining (RDM) address the task of inducing models or patterns from multi-relational data. One of the established approaches to RDM is propositionalization, characterized by transforming a relational database into a single-table representation. This paper presents a propositionalization technique called wordification which can be seen as a transformation of a relational database into a corpus of text documents. Wordification constructs simple, easy to understand features, acting as words in the transformed Bag-Of-Words representation. This paper presents the wordification methodology, together with an experimental comparison of several propositionalization approaches on seven relational datasets. The main advantages of the approach are: simple implementation, accuracy comparable to competitive methods, and greater scalability, as it performs several times faster on all experimental databases. Furthermore, the wordification methodology and the evaluation procedure are implemented as executable workflows in the web-based data mining platform ClowdFlows. The implemented workflows include also several other ILP and RDM algorithms, as well as the utility components that were added to the platform to enable access to these techniques to a wider research audience.
ER  - 

TY  - JOUR
T1  - NMFE-SSCC: Non-negative matrix factorization ensemble for semi-supervised collective classification
JO  - Knowledge-Based Systems
VL  - 89
IS  - 
SP  - 160
EP  - 172
PY  - 2015/11//
T2  - 
AU  - Wu, Qingyao
AU  - Tan, Mingkui
AU  - Li, Xutao
AU  - Min, Huaqing
AU  - Sun, Ning
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2015.06.026
UR  - http://www.sciencedirect.com/science/article/pii/S0950705115002440
KW  - Collective classification
KW  - Non-negative matrix factorization
KW  - Semi-supervised collective classification
KW  - Ensemble classification
AB  - Abstract
Collective classification (CC) is a task to jointly classifying related instances of network data. Enabling CC usually improves the performance of predictive models on fully-labeled training networks with large amount of labeled data. However, acquiring such labels can be difficult and costly, and learning a CC classifier with only a few labeled data can lead to poor performance. On the other hand, there are usually large amount of unlabeled data available in practical. This naturally motivates semi-supervised collective classification (SSCC) approaches for leveraging the unlabeled data to improve CC from a sparsely-labeled network. In this paper, we propose a novel non-negative matrix factorization (NMF) based SSCC algorithm, called NMF-SSCC, to effectively learn a data representation by exploiting both labeled and unlabeled data on the network. Our idea is to use matrix factorization to obtain a compact representation of network data which uncovers the class discrimination of the data inferred from the labeled instances and simultaneously respects the intrinsic network structure. To achieve this, we design a new matrix factorization objective function and incorporate a label matrix factorization term as well as a network regularization term into it. An efficient optimization algorithm using the multiplicative updating rules is then developed to solve the new objective function. To further boost the predicting performance, we extend the proposed NMF-SSCC method into an ensemble scheme, called NMFE-SSCC, in terms of building a classification ensemble with a set of NMF-SSCC collective classifiers using different constructed latent graphs. Each NMF-SSCC classifier is learnt from one latent graph generated with various latent linkages for effectively label propagation. Experimental results on real-world data sets have demonstrated the effectiveness of the new methods.
ER  - 

TY  - JOUR
T1  - Rare-PEARs: A new multi objective evolutionary algorithm to mine rare and non-redundant quantitative association rules
JO  - Knowledge-Based Systems
VL  - 89
IS  - 
SP  - 366
EP  - 384
PY  - 2015/11//
T2  - 
AU  - Almasi, Mehrdad
AU  - Abadeh, Mohammad Saniee
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2015.07.016
UR  - http://www.sciencedirect.com/science/article/pii/S0950705115002701
KW  - Random permutation
KW  - Multi objective evolutionary algorithms
KW  - Quantitative association rules
AB  - Abstract
Since finding quantitative association rules (QARs) is an NP-hard problem, evolutionary methods are suitable solutions for discovery QARs. Nevertheless, most of the previous evolutionary methods to discover association rules only consider frequent dependency among items in datasets. They do not pay specific attention to interestingness and non-redundancy as two critical objectives. In this paper, the proposed algorithm (Rare-PEARs) gives a chance to each rule with different length and appearance (antecedent and consequent parts of rules) to be created. Therefore, various interesting, rare or interesting and rare rules can be found. Some of these rules might be uninteresting (those that contain frequent item sets). However, we try to avoid them by Rare-PEARs. To accomplish this goal, our method decomposes the process of association rule mining into N − 1 sub-problems (N is the number of attributes, and each sub-problem is handled by an independent sub-process during Rare-PEARs execution). Each sub-process starts individually with a different initial population. It then explores the search space of its corresponding sub-problem to find rules with semi-optimal intervals for each of the attributes. This process is done by a new definition of Non-Dominated concept. Rare-PEARs uses this definition to find semi-optimal intervals for attributes during the execution of each sub-process. Finally, Rare-PEARs collects QARs from sub-processes and determines the ultimate Non-Dominated rules based on the interestingness and reliability measures. Rare-PEARs tries to maximize three objectives: interestingness, accuracy and reliability while providing vast coverage on the input dataset. We compared Rare-PEARs with ten algorithms (multi-objective, mono-objective and classical algorithms of association rule mining) over several real-world datasets. The results demonstrate high efficiency of Rare-PEARs.
ER  - 

TY  - JOUR
T1  - Insights from hashtag #supplychain and Twitter Analytics: Considering Twitter and Twitter data for supply chain practice and research
JO  - International Journal of Production Economics
VL  - 165
IS  - 
SP  - 247
EP  - 259
PY  - 2015/7//
T2  - 
AU  - Chae, Bongsug (Kevin)
SN  - 0925-5273
DO  - http://dx.doi.org/10.1016/j.ijpe.2014.12.037
UR  - http://www.sciencedirect.com/science/article/pii/S0925527314004319
KW  - Supply chain management
KW  - Twitter
KW  - Data analytics
KW  - Network analytics
KW  - Content analytics
KW  - Big data
KW  - Social media analytics
KW  - Application Programming Interface (API)
AB  - Abstract
Recently, businesses and research communities have paid a lot of attention to social media and big data. However, the field of supply chain management (SCM) has been relatively slow in studying social media and big data for research and practice. In these contexts, this research contributes to the SCM community by proposing a novel, analytical framework (Twitter Analytics) for analyzing supply chain tweets, highlighting the current use of Twitter in supply chain contexts, and further developing insights into the potential role of Twitter for supply chain practice and research. The proposed framework combines three methodologies – descriptive analytics (DA), content analytics (CA) integrating text mining and sentiment analysis, and network analytics (NA) relying on network visualization and metrics – for extracting intelligence from 22,399 #supplychain tweets. Some of the findings are: supply chain tweets are used by different groups of supply chain professionals and organizations (e.g., news services, IT companies, logistic providers, manufacturers) for information sharing, hiring professionals, and communicating with stakeholders, among others; diverse topics are being discussed, ranging from logistics and corporate social responsibility, to risk, manufacturing, SCM IT and even human rights; some tweets carry strong sentiments about companies׳ delivery services, sales performance, and environmental standards, and risk and disruption in supply chains. Based on these findings, this research presents insights into the use and potential role of Twitter for supply chain practices (e.g., professional networking, stakeholder engagement, demand shaping, new product/service development, supply chain risk management) and the implications for research. Finally, the limitations of the current study and suggestions for future research are presented.
ER  - 

TY  - JOUR
T1  - A Simultaneous Extraction of Context and Community from pervasive signals using nested Dirichlet process
JO  - Pervasive and Mobile Computing
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Nguyen, Thuong
AU  - Nguyen, Vu
AU  - Salim, Flora D.
AU  - Le, Duc V.
AU  - Phung, Dinh
SN  - 1574-1192
DO  - http://dx.doi.org/10.1016/j.pmcj.2016.08.019
UR  - http://www.sciencedirect.com/science/article/pii/S1574119216302097
KW  - Context discovery
KW  - Community detection
KW  - Pervasive signals
KW  - Nested Dirichlet process
KW  - Bayesian nonparametric
AB  - Abstract
Understanding user contexts and group structures plays a central role in pervasive computing. These contexts and community structures are complex to mine from data collected in the wild due to the unprecedented growth of data, noise, uncertainties and complexities. Typical existing approaches would first extract the latent patterns to explain human dynamics or behaviors and then use them as a way to consistently formulate numerical representations for community detection, often via a clustering method. While being able to capture high-order and complex representations, these two steps are performed separately. More importantly, they face a fundamental difficulty in determining the correct number of latent patterns and communities. This paper presents an approach that seamlessly addresses these challenges to simultaneously discover latent patterns and communities in a unified Bayesian nonparametric framework. Our Simultaneous Extraction of Context and Community (SECC) model roots in the nested Dirichlet process theory which allows a nested structure to be built to summarize data at multiple levels. We demonstrate our framework on five datasets where the advantages of the proposed approach are validated.
ER  - 

TY  - JOUR
T1  - A new selection strategy for selective cluster ensemble based on Diversity and Independency
JO  - Engineering Applications of Artificial Intelligence
VL  - 56
IS  - 
SP  - 260
EP  - 272
PY  - 2016/11//
T2  - 
AU  - Yousefnezhad, Muhammad
AU  - Reihanian, Ali
AU  - Zhang, Daoqiang
AU  - Minaei-Bidgoli, Behrouz
SN  - 0952-1976
DO  - http://dx.doi.org/10.1016/j.engappai.2016.10.005
UR  - http://www.sciencedirect.com/science/article/pii/S0952197616301804
KW  - Independency of algorithms
KW  - Diversity of primary results
KW  - Selective cluster ensemble
KW  - Algorithm’s graph
AB  - Abstract
This research introduces a new strategy in cluster ensemble selection by using Independency and Diversity metrics. In recent years, Diversity and Quality, which are two metrics in evaluation procedure, have been used for selecting basic clustering results in the cluster ensemble selection. Although quality can improve the final results in cluster ensemble, it cannot control the procedures of generating basic results, which causes a gap in prediction of the generated basic results’ accuracy. Instead of quality, this paper introduces Independency as a supplementary method to be used in conjunction with Diversity. Therefore, this paper uses a heuristic metric, which is based on the procedure of converting code to graph in Software Testing, in order to calculate the Independency of two basic clustering algorithms. Moreover, a new modeling language, which we called as “Clustering Algorithms Independency Language” (CAIL), is introduced in order to generate graphs which depict Independency of algorithms. Also, Uniformity, which is a new similarity metric, has been introduced for evaluating the diversity of basic results. As a credential, our experimental results on varied different standard data sets show that the proposed framework improves the accuracy of final results dramatically in comparison with other cluster ensemble methods.
ER  - 

TY  - JOUR
T1  - A semantic-grained perspective of Latent Knowledge Modeling
JO  - Information Fusion
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Rocca, Paola Della
AU  - Senatore, Sabrina
AU  - Loia, Vincenzo
SN  - 1566-2535
DO  - http://dx.doi.org/10.1016/j.inffus.2016.11.003
UR  - http://www.sciencedirect.com/science/article/pii/S1566253516301257
KW  - Knowledge Structuring
KW  - Latent Dirichlet Allocation (LDA)
KW  - Latent Semantic Analysis (LSA)
KW  - Concept Extraction
KW  - Ontology
KW  - SKOS
AB  - Abstract
In the era of Web 2.0, the knowledge is the de-facto social currency in the global network environment. Knowledge is not an accumulation of data, but a relation-based representation of the information content, which needs to be distilled and arranged in a semantic infrastructure to guarantee interoperability and sharable understanding.

In the light of this scenario, the paper introduces a semantically enhanced document retrieval system that describes each retrieved document with an ontological multi-grained network of the extracted conceptualization. The system is based on two well-known latent models: Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA): LSA provides a spatial distribution of the input documents, facilitating their retrieval, thanks to an ontological representation of their relationship network. LDA works instead at deeper level: it drives the ontological structuring of the knowledge inside the individual retrieved documents in terms of words, concepts and topics. The novelty of this approach is a multi-level granulation of the knowledge: from a document matching the query (coarse granularity), to the topics that join documents, until to the words describing a concept into a topic (fine granularity). The final result is a SKOS-based ontology, ad-hoc created for a document corpus; graphically supported for the navigation, it enables the exploration of the concepts at different granularity levels.
ER  - 

TY  - JOUR
T1  - Experts community memory for entity similarity functions recommendation
JO  - Information Sciences
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Ryu, Seung Hwan
AU  - Benatallah, Boualem
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2016.10.045
UR  - http://www.sciencedirect.com/science/article/pii/S0020025516313962
KW  - Entity matching
KW  - Similarity function
KW  - Incremental knowledge acquisition
KW  - Similarity search
KW  - Similarity measure
KW  - Recommendation
AB  - Abstract
Similarity search (or similar entity search) is the process of finding all entities similar to a given entity (e.g., a person, a document, or an image). Although many techniques for similarity analysis have been proposed in the past, little work has been done on the question of which of the presented techniques are most suitable for a given similarity search task. Knowing the right similarity function is important as the task is highly domain- and data-dependent. In this article, we provide an approach for recommending which similarity functions (e.g., edit distance or jaccard similarity) should be used for measuring the similarity between two entities. The approach employs an incremental knowledge acquisition technique for capturing domain experts’ knowledge about similarity functions and their usage contexts (e.g., entity class, attribute name and some keywords). In addition, for situations where domain experts have little or no knowledge about datasets, we analyze the features of the datasets and then suggest similarity functions based on the identified features. We also demonstrate the feasibility and effectiveness of our proposed approach on several real-world datasets from different domains.
ER  - 

TY  - JOUR
T1  - Comparison of unsupervised classification methods for brain tumor segmentation using multi-parametric MRI
JO  - NeuroImage: Clinical
VL  - 12
IS  - 
SP  - 753
EP  - 764
PY  - 2016///
T2  - 
AU  - Sauwen, N.
AU  - Acou, M.
AU  - Van Cauter, S.
AU  - Sima, D.M.
AU  - Veraart, J.
AU  - Maes, F.
AU  - Himmelreich, U.
AU  - Achten, E.
AU  - Van Huffel, S.
SN  - 2213-1582
DO  - http://dx.doi.org/10.1016/j.nicl.2016.09.021
UR  - http://www.sciencedirect.com/science/article/pii/S2213158216301796
KW  - Segmentation
KW  - Glioma
KW  - Multi-parametric MRI
KW  - Unsupervised classification
KW  - Non-negative matrix factorization
KW  - Clustering
AB  - Abstract
Tumor segmentation is a particularly challenging task in high-grade gliomas (HGGs), as they are among the most heterogeneous tumors in oncology. An accurate delineation of the lesion and its main subcomponents contributes to optimal treatment planning, prognosis and follow-up. Conventional MRI (cMRI) is the imaging modality of choice for manual segmentation, and is also considered in the vast majority of automated segmentation studies. Advanced MRI modalities such as perfusion-weighted imaging (PWI), diffusion-weighted imaging (DWI) and magnetic resonance spectroscopic imaging (MRSI) have already shown their added value in tumor tissue characterization, hence there have been recent suggestions of combining different MRI modalities into a multi-parametric MRI (MP-MRI) approach for brain tumor segmentation. In this paper, we compare the performance of several unsupervised classification methods for HGG segmentation based on MP-MRI data including cMRI, DWI, MRSI and PWI. Two independent MP-MRI datasets with a different acquisition protocol were available from different hospitals. We demonstrate that a hierarchical non-negative matrix factorization variant which was previously introduced for MP-MRI tumor segmentation gives the best performance in terms of mean Dice-scores for the pathologic tissue classes on both datasets.
ER  - 

TY  - JOUR
T1  - Social network analysis of Iranian researchers in the field of violence
JO  - Chinese Journal of Traumatology
VL  - 19
IS  - 5
SP  - 264
EP  - 270
PY  - 2016/10/13/
T2  - 
AU  - Salamati, Payman
AU  - Soheili, Faramarz
SN  - 1008-1275
DO  - http://dx.doi.org/10.1016/j.cjtee.2016.06.008
UR  - http://www.sciencedirect.com/science/article/pii/S1008127516302206
KW  - Social network analysis
KW  - Violence
KW  - Iran
AB  - AbstractPurpose
The social network analysis (SNA) is a paradigm for analyzing structural patterns in social relations, testing knowledge sharing process and identifying bottlenecks of information flow. The purpose of this study was to determine the status of research in the field of violence in Iran using SNA.
Methods
Research population included all the papers with at least one Iranian affiliation published in violence field indexed in SCIE, PubMed and Scopus databases. The co-word maps, co-authorship network and structural holes were drawn using related software. In the next step, the active authors and some measures of our network including degree centrality (DC), closeness, eigenvector, betweeness, density, diameter, compactness and size of the main component were assessed. Likewise, the trend of the published articles was evaluated based on the number of documents and their citations from 1972 to 2014.
Results
Five hundred and seventy one records were obtained. The five main clusters and hot spots were mental health, violence, war, psychiatric disorders and suicide. The co-authorship network was complex, tangled and scale free. The top nine authors with cut point role and top ten active authors were identified. The mean (standard deviation) of normalized DC, closeness, eigenvector and betweeness were 0.449 (0.805), 0.609 (0.214), 2.373 (7.353) and 0.338 (1.122), respectively. The density, diameter and mean compactness of our co-authorship network were 0.0494, 3.955 and 0.125, respectively. The main component consisted of 216 nodes that formed 17% of total size of the network. Both the number of the documents and their citations has increased in the field of violence in the recent years.
Conclusion
Although the number of the documents has recently increased in the field of violence, the information flow is slow and there are not many relations among the authors in the network. However, the active authors have ability to influence the flow of knowledge within the network.
ER  - 

TY  - JOUR
T1  - Similarities and contrasts of complexity, uncertainty, risks, and resilience in supply chains and temporary multi-organization projects
JO  - International Journal of Project Management
VL  - 34
IS  - 7
SP  - 1328
EP  - 1346
PY  - 2016/10//
T2  - 
AU  - Thomé, Antônio Márcio Tavares
AU  - Scavarda, Luiz Felipe
AU  - Scavarda, Annibal
AU  - Thomé, Felipe Eduardo Sydio de Souza
SN  - 0263-7863
DO  - http://dx.doi.org/10.1016/j.ijproman.2015.10.012
UR  - http://www.sciencedirect.com/science/article/pii/S0263786315001763
KW  - Research synthesis
KW  - Project management
KW  - Operations management
KW  - Supply chain collaboration
KW  - Literature review
AB  - Abstract
Although complexity, uncertainty, risk, and resilience are concepts of growing interest, there is a lack of structured synthesis of these concepts and their relationships in supply chain management (SCM) and project management (PM) literatures. This paper addresses this gap through novel tertiary and bibliometric analyses. The tertiary research embraces 22 literature reviews and guides the development of the synthesis framework. The bibliometric analysis includes 1,275 papers and complements the tertiary research with study descriptors, a co-citation, and a static and dynamic/longitudinal co-word network analysis. Authors cite each other within the confines of their research area with no cross-fertilization of studies in PM and SCM, despite several commonalities among the areas. Both areas use similar conceptual definitions and there are close resemblances in risk management in SCM and temporary multi-organization (TMOs) projects. Resilience appears as a new topic in SCM but is absent in TMO. A research agenda closes the paper.
ER  - 

TY  - JOUR
T1  - Visualizing of the structure of subject trends in Persian articles published during 2008–2012 in information organization domain
JO  - The International Information & Library Review
VL  - 45
IS  - 3–4
SP  - 157
EP  - 167
PY  - 2013/12//
T2  - 
AU  - Mousavizadeh, Maryam
AU  - Bagheri, Masume
AU  - Bagheri, Mansure
AU  - Karbala aghaie Kamran, Masume
SN  - 1057-2317
DO  - http://dx.doi.org/10.1016/j.iilr.2013.10.005
UR  - http://www.sciencedirect.com/science/article/pii/S1057231713000258
KW  - Information organization
KW  - Semantic map
KW  - Term weighting
KW  - Co-term analysis
KW  - Term relationships
KW  - Subject trends
KW  - Information visualization
KW  - Cataloging
KW  - Ontologies
KW  - Information retrieval
AB  - Abstract
This research investigates structure of the subject trends in the Persian articles published during the period of 2008–2012 about “information organization” in Iranian journals and creates a semantic map for this domain. This structure has been considered in two sections: First, the weight of each subject term used in articles was indicated, and then the relationships amounts of terms were measured. Content analysis and weighting were used in the first section. The Vector Space Model formula was used in order to weight terms. In the second section, Co-term analysis was used, that is, the number of co-occurrence of any two terms in the same article. Then the term/document occurrence matrix of these terms was created and at last the relations significant between terms were measured by Pearson Correlation Coefficient. To illustrate the structure of information organization domain, Ucinet software was used. Findings show that high-weight categories in Persian articles are: “cataloging”, “information retrieval”, “information systems” and “authority files”. Furthermore through weighting, determined that in trends rate aspect, the terms “ontologies”, “cataloging”, “evaluation”, “Dewey Decimal Classification”, “fields”, “libraries and information centers” and “descriptors”, “Functional Requirements for Bibliographic Records”, “metadata elements” and “National library and archives of I.R. of Iran” are 10 highest-weight terms. Research findings about the relationships of terms show attention to “cataloging” by “IFLA” and “National library and archives of Iran” and critical approach to this subject. Some other findings about this show: “indexing” are considered by cataloging and thesauri, “metadata” are considered in web-based and information retrieval points of view, “ontologies” term is considered in approach of basic concepts, tools and relevance, and attention to some organizations such as “IFLA” and “National library and archives organization of Iran” besides “users” and their information needs. In terms of weighting and relationships between the subject terms in Persian articles, “cataloging” is in the center of information organization domain. The semantic map of information organization in Persian articles illustrates three region of subject area including: 1. Cataloging, 2. Ontologies, thesauri and information retrieval, and 3. Metadata and information retrieval.
ER  - 

TY  - JOUR
T1  - Building a Knowledge Brokering System using social network analysis: A case study of the Korean financial industry
JO  - Expert Systems with Applications
VL  - 38
IS  - 12
SP  - 14633
EP  - 14649
PY  - 2011/11//
Y2  - 2011/12//
T2  - 
AU  - Kim, Sungjin
AU  - Suh, Euiho
AU  - Jun, Youngjoon
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2011.05.019
UR  - http://www.sciencedirect.com/science/article/pii/S0957417411008025
KW  - Knowledge management
KW  - Knowledge transfer
KW  - Knowledge Brokering System
KW  - Social network analysis
AB  - The importance of knowledge is increasing in our global and knowledge-based society. As a part of knowledge management, successful knowledge transfer can improve an organization’s competitive advantages and increase an organization’s valuable knowledge assets. However, knowledge transfer is complex and a lot of factors exist that affect successful knowledge transfer such as context, social networks, and IT/IS. This paper aims at the role of the knowledge broker which is to be a link between knowledge seekers and knowledge experts. In this context, this research implemented a Knowledge Brokering System – called K-broker system – as a prototype system to improve knowledge transfer in an organization based on an analysis of users’ social network. The K-broker system can provide a ‘single view’ screen for identifying knowledge experts and has no bottlenecks in contrast with a human knowledge broker and can provide a permanent communication channel between knowledge seekers and knowledge experts.
ER  - 

TY  - JOUR
T1  - Construction of concept granule based on rough set and representation of knowledge-based complex system
JO  - Knowledge-Based Systems
VL  - 24
IS  - 6
SP  - 809
EP  - 815
PY  - 2011/8//
T2  - 
AU  - Zhao, Jian
AU  - Liu, Lei
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2011.03.002
UR  - http://www.sciencedirect.com/science/article/pii/S0950705111000529
KW  - Formal concept analysis
KW  - Rough set
KW  - Concept element
KW  - Concept granule
KW  - Granular computing
AB  - The isomorphic relationship between indiscernibility relation in rough set theory and nominal scale in formal concept analysis was studied in this paper, upon which the conceptual elements were constructed as the basic units of internal elements in a knowledge-based complex system. The nature of the association between conceptual elements was studied in this paper, where the definition and properties of association intensity were provided. Furthermore, concept granules were constructed by studying the mapping between conceptual elements. The general forms of expansion and aggregation of concept granules were also given. The theories in the study laid the foundation for evolutionary analysis of knowledge-based complex system, and offered a referential model to the studies on knowledge evolution of ontology engineering.
ER  - 

TY  - JOUR
T1  - Integrated knowledge management model and system for construction projects
JO  - Engineering Applications of Artificial Intelligence
VL  - 23
IS  - 7
SP  - 1200
EP  - 1215
PY  - 2010/10//
T2  - 
AU  - Kanapeckiene, L.
AU  - Kaklauskas, A.
AU  - Zavadskas, E.K.
AU  - Seniut, M.
SN  - 0952-1976
DO  - http://dx.doi.org/10.1016/j.engappai.2010.01.030
UR  - http://www.sciencedirect.com/science/article/pii/S0952197610000710
KW  - Knowledge management
KW  - Tacit and explicit knowledge
KW  - Construction projects management
KW  - Multiple criteria and multivariant analysis
KW  - COPRAS method
AB  - In the past there has been no structured approach to learning from construction projects once they are completed. Now, however, the construction industry is adapting concepts of tacit and explicit knowledge management to improve the situation. Top managers generally assume that professionals in enterprises already possess tacit knowledge and experience for specific types of projects. Such knowledge is extremely important to organisations because, once a project is completed, professionals tend to forget it and start something new. Therefore, knowledge multifold utilisation is a key factor in productively executing a construction project. This paper discusses the benefits of knowledge management to construction industry organisations and projects and emphasises the significance of tacit knowledge. The main purpose of this paper is to present the integrated knowledge management model for the construction industry as well as system architecture and system of the Knowledge Based Decision Support System for Construction Projects Management (KDSS-CPM) which the authors of this paper have developed. Different knowledge management models that are presented in scientific literature are discussed and compared, and the proposed new, KDSS-CPM model, as developed by this paper’s authors, is introduced.
ER  - 

TY  - JOUR
T1  - Risk Management in Construction Projects: A Knowledge-based Approach
JO  - Procedia - Social and Behavioral Sciences
VL  - 119
IS  - 
SP  - 653
EP  - 662
PY  - 2014/3/19/
T2  - Selected papers from the 27th IPMA (International Project Management Association), World Congress, Dubrovnik, Croatia, 2013
AU  - Serpella, Alfredo Federico
AU  - Ferrada, Ximena
AU  - Howard, Rodolfo
AU  - Rubio, Larissa
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2014.03.073
UR  - http://www.sciencedirect.com/science/article/pii/S1877042814021648
KW  - Risk
KW  - management
KW  - knowledge
KW  - best practices
KW  - evaluation
AB  - Abstract
One of the major roles undertaken by a project manager is the management of the risk of a project. However, this duty is particularly complex and inefficient if good risk management has not been done from the beginning of the project. An effective and efficient risk management approach requires a proper and systematic methodology and, more importantly, knowledge and experience. Previous research results in Chile have shown that both, owners and contractors do not systematically apply risk management practices, resulting in negative consequences for projects’ performance. This paper addresses the problems of risk management in construction projects using a knowledge-based approach, and proposes a methodology based on a three-fold arrangement that includes the modeling of the risk management function, its evaluation, and the availability of a best practices model. This approach is part of a* research effort that is underway. A major preliminary conclusion of this research is the fact that risk management in construction projects is still very ineffective and that the main cause of this situation is the lack of knowledge. It is expected that the application of the proposed approach will allow clients and contractors to develop a project's risk management function based on best practices, and also to improve the performance of this function.
ER  - 

TY  - JOUR
T1  - Building a Better Model: A Novel Approach for Mapping Organisational and Functional Structure
JO  - Procedia Computer Science
VL  - 44
IS  - 
SP  - 194
EP  - 203
PY  - 2015///
T2  - 2015 Conference on Systems Engineering Research
AU  - Flynn, D.N.
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.03.003
UR  - http://www.sciencedirect.com/science/article/pii/S1877050915002392
KW  - Organisational structure
KW  - organisational modelling
KW  - systems approach
KW  - social network analysis
KW  - group modelling
AB  - Abstract
The true structure of an organisation is as much related to inter-social group networks as it is the departmental structure that defines the organisation's hierarchical tree. This paper proposes a novel methodology for building a model to represent the true functional and organisational structure within an organisation by using holistically, a combination of social network analysis and group model building techniques. It is described how the methodology may be used as useful way to capture the current organisational state and its value is displayed and discussed through a case study of applying the methodology to private engineering firm Parker.
ER  - 

TY  - JOUR
T1  - Formalising the Informal? – Finding a Balance between Formal Teams and Communities of Practice in a Project-based Organisation
JO  - Procedia - Social and Behavioral Sciences
VL  - 194
IS  - 
SP  - 105
EP  - 114
PY  - 2015/7/2/
T2  - Proceedings of the 2014 IPMA World Congress (Sept 29-Oct 1 – Rotterdam, Netherlands)
AU  - Keikotlhaile, Ronald Tebogo
AU  - Ekambaram, Anandasivakumar
AU  - Halvorsen, Siri Bøe
AU  - Klakegg, Ole Jonny
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2015.06.127
UR  - http://www.sciencedirect.com/science/article/pii/S187704281503606X
KW  - Project-based organisation
KW  - Communities of practice (CoP)
KW  - Learning
KW  - Knowledge sharing
KW  - Team
AB  - Abstract
There are several issues and challenges related to forming and implementing knowledge management initiatives in project-based organisations in such a way to promote knowledge sharing, learning, innovation, organisation development. One such issue is to identify proper organisational structure(s) that can support and facilitate learning and development. There are 2 commonly used organisational structures. They are formal work-teams and (informal) communities of practice (CoP). Organisations, in general, have and/or need both the formal and informal structures. The challenge that several organizations have is how to combine formal work-teams and CoP – How to find a balance between them?

This paper will look at a Scandinavian project-based organisation, and describe what this organisation has done in order to accomplish the balance. In this regard, the paper will focus on how the organisation deals with its organisational structure in such a way to facilitate learning and knowledge sharing; how it utilizes both formal teams and CoP in this process, and the challenges and opportunities that are associated with this process.

This paper is based on the study whose objective was to see how a Scandinavian project-based organisation transformed itself into a double-knit organisation – effectively using both formal and informal structures to improve its work-performance. The study used a qualitative research method; a case study that incorporated interviews (semi-structures interviews), observations and document analysis. At the start of the study, the organisation was transforming its ‘below the radar’ CoP into recognised structures within the organisation. Hence, the situation offered an opportunity to study the actual transition process.

Findings of the study discuss among other things, the organisation's formalization of (previously informal) team leadership positions, incorporating members of CoP in the advisory board and leadership roles, and formalising CoP, while at the same time strengthening formal structures such as formal teams. The organisation used social settings to encourage interaction among employees. The major findings were that for double-knit organisation to effectively work, there is a need to balance organic, informal settings (CoP) and formal teams. The study confirmed previous findings that tacit knowledge plays a very significant role in knowledge transfer in project-based organisations. The study also showed that while formal teams were easier to create and define scope for them, the same could not be said about CoP. CoP were unpredictable and seemed to work better independent of the organisational leaders’ interference. However, they were promoted by employee interactions.

As practical implications, the findings presented in this paper can be considered as suggestions – or, at least as focal points for reflection – for other project-based organisations to strengthen their knowledge management practices in order to obtain better results.
ER  - 

TY  - JOUR
T1  - Construction and analysis of educational assessments using knowledge maps with weight appraisal of concepts
JO  - Computers & Education
VL  - 55
IS  - 3
SP  - 1300
EP  - 1311
PY  - 2010/11//
T2  - 
AU  - Su, C.Y.
AU  - Wang, T.I.
SN  - 0360-1315
DO  - http://dx.doi.org/10.1016/j.compedu.2010.05.027
UR  - http://www.sciencedirect.com/science/article/pii/S0360131510001594
KW  - Applications in subject areas
KW  - Architectures for educational technology system
KW  - Elementary education
KW  - Human–computer interface
KW  - Improving classroom teaching
AB  - The rapid advance of information and communication technologies (ICT) has important impacts on teaching and learning, as well as on the educational assessment. Teachers may create assessments utilizing some developed assessment software or test authoring tools. However, problems could occur, such as neglecting key concepts in the curriculum or having disproportionate course topics distribution, when teachers create assessments or test items. This study proposes a novel approach, which uses knowledge map with appraisal of concept weights and other ICTs, and implements an assessment system KMAAS to help primary school teachers in Taiwan, or elsewhere, create educational assessments properly. When compiling an assessment, KMAAS ensures that teachers can include all important course concepts intended for assessing and maintain correct balance between course concepts among test items. It does so first by analyzing course material of the assessment range and displaying a concept-weight-annotated knowledge map which concretize and visualize the importance of and the relationships among concepts in the range. It then analyzes the test sheet which is being complied and displays another similar real-time updated knowledge map containing balance between course concepts among the test items. Teachers may cross-refer to these maps to help them adjust concept balances and even select appropriate test items from test banks. The system has being evaluated in both the accuracy of learning concepts extraction and the degree of user satisfaction, as measured by questionnaires given to the teachers who tested the system. The promising results confirm the feasibility of this system in helping teachers compile their educational assessments easily and precisely. Other results of the formative evaluations on techniques have being used to improve the system in order to make it more effective and efficient. The methodology and technologies KMAAS employed are all well developed and are domain independent, which makes it highly flexible to transfer to other course subject domain too.
ER  - 

TY  - JOUR
T1  - Bibliometric Mapping of “International Symposium on Safety Science and Technology (1998-2012)”
JO  - Procedia Engineering
VL  - 84
IS  - 
SP  - 70
EP  - 79
PY  - 2014///
T2  - 2014 International Symposium on Safety Science and Technology
AU  - Jie, Li
AU  - Xiaohong, Guo
AU  - Shifei, Shen
AU  - Jovanovic, Aleksandar
SN  - 1877-7058
DO  - http://dx.doi.org/10.1016/j.proeng.2014.10.411
UR  - http://www.sciencedirect.com/science/article/pii/S1877705814017329
KW  - Knowledge map
KW  - Bibliometrics
KW  - Scientometrics
KW  - Safety Science
KW  - Safemetrics ;VOSviewer
AB  - Abstract
This paper aim to analyze the papers published in International Symposium on Safety Science and Technology (ISSST) in the period 1998-2012. Totally, 2781 ISSST papers were got from Web of Science, Bibliometrics indicators including annual publications, categories, geospatial distributions and topic analysis were used in this study. Results revealed that annual publications of ISSST could be divided in two stages, 1998-2004 as a period of increase in the number of publications and 2004-2012 as the period of decrease in the number of publications. The main categories of ISSST papers are in Engineering fields, that including Multidisciplinary Engineering, Industrial Engineering and Civil Engineering. Papers published in ISSST were originate from more than 30 countries/territories, while papers are mainly from China. In addition, these results also reflect in the institutional level. The analysis of the terms has revealed that all the topics of ISSST could be clustered into three groups, “safety and accident management”, “fire safety” and “coal mine safety”. The time slice of the topic analysis also shown the similar results to the integer terms analysis.
ER  - 

TY  - JOUR
T1  - A hybrid knowledge-sharing model for corporate foreign investment in China’s construction market
JO  - Expert Systems with Applications
VL  - 39
IS  - 9
SP  - 7585
EP  - 7590
PY  - 2012/7//
T2  - 
AU  - Chen, Jieh-Haur
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2011.11.076
UR  - http://www.sciencedirect.com/science/article/pii/S0957417411016228
KW  - Knowledge management
KW  - Knowledge sharing
KW  - SOM
KW  - Fuzzy
KW  - Artificial neural networks (ANN)
KW  - Foreign investment
KW  - Construction company
AB  - The research proposes a hybrid knowledge-sharing model, which integrates the concepts of the self-organizing feature map optimization, fuzzy logic control, and hyper-rectangular composite neural networks, to provide 32 rules that suggest performing or not performing foreign construction investment. The database is derived from 520 quarterly financial reports of all listed construction companies in Taiwan that have now or in the past five years made foreign investment in China’s construction industry. The input variables are set to all 25 financial ratios assessable in public, reducing to 11 ratios after feature deduction using t-test. The model yields a high successful classification rate of 90.6% and generates 14 and 18 rules for Taiwan construction companies performing or not performing foreign investment in China, respectively. The valuable rules give user a closer look at what is the appropriate corporate financial status, what knowledge can be shared from the interpretations of the rules, and the impact by investment on corporate finance.
ER  - 

TY  - JOUR
T1  - Integrating buildings into a rural landscape using a multi-criteria spatial decision analysis in GIS-enabled web environment
JO  - Biosystems Engineering
VL  - 112
IS  - 2
SP  - 82
EP  - 92
PY  - 2012/6//
T2  - 
AU  - Jeong, Jin Su
AU  - García-Moruno, Lorenzo
AU  - Hernández-Blanco, Julio
SN  - 1537-5110
DO  - http://dx.doi.org/10.1016/j.biosystemseng.2012.03.002
UR  - http://www.sciencedirect.com/science/article/pii/S1537511012000402
AB  - There is often a difficult relationship between rural buildings and the landscape. This may be overcome by methodologies that support a decision-making processes for establishing harmonious relationships and sustainable environment integrity within a unique framework. Preliminary results are presented from a continuing broad research project developing a spatial methodology for integrating new rural buildings associated with tourist functions into landscapes and coupling multi-criteria evaluations (MCE) into a web environment that uses a geographic information system (GIS) technique. Use of the internet allows users easy access to diverse GIS data sources and also allows support collaboration amongst planners, stakeholders and the public. The aim of this methodology, which applies an overlay and index method involving several parameters, is to evaluate its suitability in the study region, Hervás, Spain, in order to optimally plan for rural building integration within its landscape. The methodology used intermediate suitability maps classified by five evaluation criteria, namely physical, visual, economic, social, and environmental criteria. A combination of the five intermediate maps resulted in a final composite suitability map for buildings in a rural landscape. The possibility of designing and implementing a GIS-enabled web application with the methodology, consisting of a general overview, a multi-criteria spatial decision support system, an interoperable knowledge map and a post-task questionnaire to identify spatial models for the different perceptions of building integration within the rural landscape and to certify the possible economic impact on tourism, is presented.
ER  - 

TY  - JOUR
T1  - The Search Engine IQ Test based on the Internet IQ Evaluation Algorithm
JO  - Procedia Computer Science
VL  - 31
IS  - 
SP  - 1066
EP  - 1073
PY  - 2014///
T2  - 2nd International Conference on Information Technology and Quantitative Management, ITQM 2014
AU  - Liu, Feng
AU  - Shi, Yong
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2014.05.361
UR  - http://www.sciencedirect.com/science/article/pii/S1877050914005389
KW  - Search Engine
KW  - Absolute IQ
KW  - Deviation IQ
AB  - Abstract
This paper initiates an innovative concept and basic measurements on testing the IQ (Intelligence Quotient) on Internet search engines. It first proposes the stipulation of 2014 Internet intelligence scale and designs an IQ test question bank to aim at the search engine. To show its applicability, the paper then carries out the IQ test on seven classic search engines, such as Google, Baidu, Sogou, Bing, Zhongsou, panguso, so, etc., compared with the results of the same IQ test on three groups of Children whose ages are 6, 12, 18. Based on the absolute IQ and relative IQ of ten testing objects, this paper finds that the IQ search engine of Internet is behind far away that of human being in the field of creative testing.
ER  - 

TY  - JOUR
T1  - System Dynamics Modeling of a Knowledge Management Process: A Case Study in Turkish Airlines
JO  - Procedia - Social and Behavioral Sciences
VL  - 99
IS  - 
SP  - 545
EP  - 552
PY  - 2013/11/6/
T2  - The Proceedings of 9th International Strategic Management Conference
AU  - Zaim, Selim
AU  - Bayyurt, Nizamettin
AU  - Tarim, Mehves
AU  - Zaim, Halil
AU  - Guc, Yunus
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2013.10.524
UR  - http://www.sciencedirect.com/science/article/pii/S1877042813039694
KW  - Knowledge management
KW  - Firm performance
KW  - System dynamics
KW  - Aviation industry
AB  - Abstract
Tangible assets like land, machinery and equipment are crucial for an organization, while knowledge and intellectual capital are considered to be the primary source to complete an Organization. Knowledge management is defined as ‘any practice of creating, acquiring, capturing, sharing and using knowledge to increase organizations’ performance.’ Knowledge management aims at managing positive and negative critical knowledge functions in different kinds of operations, identifying new strategies and new products, augmenting human resource management, and accomplishing number of targeted objectives or goals.

Knowledge management process consists of four sets. These are creation or generation, storage or retrieval, transfer or sharing, and utilization. The main purpose of this study is to examine how the activities of knowledge management process and the variables excluded from knowledge management process interact with each other and how they affect organization performance by using system dynamics model specific case of Turkish airline. This study indicates that the activities of knowledge management process have a positive relationship with each other. There is also a positive relationship between these activities and organization performance.
ER  - 

TY  - JOUR
T1  - Stimulating creativity and innovation through Intelligent Fast Failure
JO  - Thinking Skills and Creativity
VL  - 7
IS  - 3
SP  - 265
EP  - 270
PY  - 2012/12//
T2  - 
AU  - Tahirsylaj, Armend S.
SN  - 1871-1871
DO  - http://dx.doi.org/10.1016/j.tsc.2012.05.005
UR  - http://www.sciencedirect.com/science/article/pii/S1871187112000442
KW  - Intelligent Fast Failure
KW  - Creativity
KW  - Innovation
KW  - Teaching and learning
AB  - Literature on creativity and innovation has discussed the issue of failure in the light of its benefits and limitations for enhancing human potential in all domains of life, but in business, science, engineering, and industry more specifically. In this paper, the Intelligent Fast Failure (IFF) as a useful tool of creativity and innovation for maximizing personal and institutional productivity, relevance and value is reviewed. In particular, IFF is a useful teaching and learning tool for public and private educational contexts. IFF, a term coined by Jack V. Matson in late 1980s and early 1990s, demystifies the aversion from failure, encourages calculated and well-informed risk-taking and initiative, and whenever applied, either yields results that could benefit individuals, organizations and society at large or teaches lessons for future endeavors. IFF and some of its derivatives used by various authors and institutions are explored along with some examples of its applications, and its potential and limitations in the 21st century.
ER  - 

TY  - JOUR
T1  - Identifying Knowledge Indicators in Higher Education Organization
JO  - Procedia Computer Science
VL  - 46
IS  - 
SP  - 449
EP  - 456
PY  - 2015///
T2  - Proceedings of the International Conference on Information and Communication Technologies, ICICT 2014, 3-5 December 2014 at Bolgatty Palace &amp; Island Resort, Kochi, India
AU  - Gupta, Preeti
AU  - Mehrotra, Deepti
AU  - Sharma, T.K.
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2015.02.043
UR  - http://www.sciencedirect.com/science/article/pii/S1877050915001076
KW  - Knowledge Management
KW  - Data Mining
KW  - Knowledge Indicators
AB  - Abstract
With the advent of K-economy, all leading business organizations are incorporating knowledge management as an integral part of their functioning. Education sector, though a non-profit domain has also witnessed increase in the implementation of business intelligence and knowledge centric processes over the years. The paper exemplifies the importance of knowledge evaluation in higher education organizations, through measures developed using data mining techniques. Applying these knowledge measures or indicator in the education domain eventually help the higher education organizations to establish themselves as knowledge centric higher education organizations (KCHEO).
ER  - 

TY  - JOUR
T1  - Facilitating the Transition of Nurse Clinician to Nurse Scientist: Significance of Entry PhD Courses
JO  - Journal of Professional Nursing
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Armstrong, Deborah K.
AU  - McCurry, Mary
AU  - Dluhy, Nancy M.
SN  - 8755-7223
DO  - http://dx.doi.org/10.1016/j.profnurs.2016.06.005
UR  - http://www.sciencedirect.com/science/article/pii/S8755722316300394
KW  - PhD nursing education
KW  - Scientist identity
KW  - Clinician perspective
KW  - Nursing science
AB  - Transitioning into the role of nurse scientist requires the acquisition of new knowledge but also involves the development of new scholarly skills and the appropriation of the unique values and goals of the new role. Students engaged in doctor of philosophy education in all practice disciplines are confronted with a necessary shift in perspective and identity from that of the practice expert to the research scientist and experience a tension referred to as the research–practice dualism. The purpose of this article is to examine the ramifications of this identity shift in nursing doctor of philosophy education and to detail one program's strategy to address the inherent tension. This transition into the role of nurse scientist includes learning to value scholarly literature, expanding one's philosophical and disciplinary vocabulary, cultivating disciplinary inquisitiveness, learning scholarly communication and dissemination skills, and developing new collegial relationships. It is essential that this process of transitioning from clinician to scholar be purposively supported from the outset of the program. Faculty must critically examine current educational strategies and design new approaches to more effectively integrate the practice and science worlds, thereby enhancing program completion and graduating nurse scientists who are equipped to contribute to the knowledge of the discipline.
ER  - 

TY  - JOUR
T1  - Approximate XML structure validation based on document–grammar tree similarity
JO  - Information Sciences
VL  - 295
IS  - 
SP  - 258
EP  - 302
PY  - 2015/2/20/
T2  - 
AU  - Tekli, Joe
AU  - Chbeir, Richard
AU  - Traina, Agma J.M.
AU  - Traina Jr., Caetano
AU  - Fileto, Renato
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2014.09.044
UR  - http://www.sciencedirect.com/science/article/pii/S0020025514009566
KW  - XML
KW  - Semi-structured data
KW  - XML grammar
KW  - Structural similarity
KW  - Tree edit distance
KW  - Document classification
AB  - Abstract
Comparing XML documents with XML grammars, also known as XML document and grammar validation, is useful in various applications such as: XML document classification, document transformation, grammar evolution, XML retrieval, and the selective dissemination of information. While exact (Boolean) XML validation has been extensively investigated in the literature, the more general problem of approximate (similarity-based) XML validation, i.e., document–grammar similarity evaluation, has not yet received strong attention. In this paper, we propose an original method for measuring the structural similarity between an XML document and an XML grammar (DTD or XSD), considering their most common operators that designate constraints on the existence, repeatability and alternativeness of XML elements/attributes (e.g., ?, ∗, MinOccurs, MaxOccurs, etc.). Our approach exploits the concept of tree edit distance, introducing a novel edit distance recurrence and dedicated algorithms to effectively compare XML documents and grammar structures, modeled as ordered labeled trees. Our method also inherently performs exact validation by imposing a maximum similarity threshold (minimum edit distance) on the returned results. We implemented a prototype and conducted several experiments on large sets of real and synthetic XML documents and grammars. Results underline our approach’s effectiveness in classifying similar documents with respect to predefined grammars, accurately detecting document and/or grammar modifications, and performing document and grammar relevance ranking. Time and space analysis were also conducted.
ER  - 

TY  - JOUR
T1  - Detecting research fronts using different types of weighted citation networks
JO  - Journal of Engineering and Technology Management
VL  - 32
IS  - 
SP  - 129
EP  - 146
PY  - 2014/4//
Y2  - 2014/6//
T2  - Special Issue on Emergence of Technologies: Methods and Tools for Management
AU  - Fujita, Katsuhide
AU  - Kajikawa, Yuya
AU  - Mori, Junichiro
AU  - Sakata, Ichiro
SN  - 0923-4748
DO  - http://dx.doi.org/10.1016/j.jengtecman.2013.07.002
UR  - http://www.sciencedirect.com/science/article/pii/S0923474813000398
KW  - Research front
KW  - Citation network analysis
KW  - Bibliometrics
KW  - Decision support
AB  - Abstract
In this paper, we investigate the performance of different types of weighted citation networks for detecting emerging research fronts by a comparative study. Three citation patterns including direct citation, co-citation and bibliographic coupling, have been tested in three research domains including gallium nitride, complex networks, and nano-carbon. These three patterns of citation networks are constructed for each research domain, and the papers in those domains are divided into clusters to detect the research front. Additionally, we apply some measures to weighted citations like difference in publication years between citing and cited papers and similarities of keywords between them, which are expected to be able to effectively to detect emerging research fronts. To investigate the performance of different types of weighted citation networks for detecting emerging research fields, we evaluate the performance of each approach by using the following measures of extracted research fronts: visibility, speed, and topological and textual relevance.
ER  - 

TY  - JOUR
T1  - Minimally-supervised learning of domain-specific causal relations using an open-domain corpus as knowledge base
JO  - Data & Knowledge Engineering
VL  - 88
IS  - 
SP  - 142
EP  - 163
PY  - 2013/11//
T2  - 
AU  - Ittoo, Ashwin
AU  - Bouma, Gosse
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2013.08.004
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X13000803
KW  - Text mining
KW  - Knowledge management applications
KW  - Causal relations-causality
KW  - Natural language processing
KW  - Information extraction
AB  - Abstract
We propose a novel framework for overcoming the challenges in extracting causal relations from domain-specific texts. Our technique is minimally-supervised, alleviating the need for manually-annotated, expensive training data. As our main contribution, we show that open-domain corpora can be exploited as knowledge bases to overcome data sparsity issues posed by domain-specific relation extraction, and that they enable substantial performance gains. We also address longstanding challenges of extant minimally-supervised approaches. To suppress the negative impact of semantic drift, we propose a technique based on the Latent Relational Hypothesis. In addition, our approach discovers both explicit (e.g. “to cause”) and implicit (e.g. “to destroy”) causal patterns/relations. Unlike existing minimally-supervised techniques, we adopt a principled seed selection strategy, which enables us to discover a more diverse set of causal patterns/relations. Our experiments reveal that our approach outperforms a state-of-the-art baseline in discovering causal relations from a real-life, domain-specific corpus.
ER  - 

TY  - JOUR
T1  - Contents
JO  - Procedia Engineering
VL  - 30
IS  - 
SP  - iii
EP  - viii
PY  - 2012///
T2  - International Conference on Communication Technology and System Design 2011

SN  - 1877-7058
DO  - http://dx.doi.org/10.1016/S1877-7058(12)01403-8
UR  - http://www.sciencedirect.com/science/article/pii/S1877705812014038
ER  - 

TY  - JOUR
T1  - Transfer learning in heterogeneous collaborative filtering domains
JO  - Artificial Intelligence
VL  - 197
IS  - 
SP  - 39
EP  - 55
PY  - 2013/4//
T2  - 
AU  - Pan, Weike
AU  - Yang, Qiang
SN  - 0004-3702
DO  - http://dx.doi.org/10.1016/j.artint.2013.01.003
UR  - http://www.sciencedirect.com/science/article/pii/S0004370213000143
KW  - Transfer learning
KW  - Collaborative filtering
KW  - Missing ratings
AB  - A major challenge for collaborative filtering (CF) techniques in recommender systems is the data sparsity that is caused by missing and noisy ratings. This problem is even more serious for CF domains where the ratings are expressed numerically, e.g. as 5-star grades. We assume the 5-star ratings are unordered bins instead of ordinal relative preferences. We observe that, while we may lack the information in numerical ratings, we sometimes have additional auxiliary data in the form of binary ratings. This is especially true given that users can easily express themselves with their preferences expressed as likes or dislikes for items. In this paper, we explore how to use these binary auxiliary preference data to help reduce the impact of data sparsity for CF domains expressed in numerical ratings. We solve this problem by transferring the rating knowledge from some auxiliary data source in binary form (that is, likes or dislikes), to a target numerical rating matrix.

In particular, our solution is to model both the numerical ratings and ratings expressed as like or dislike in a principled way. We present a novel framework of Transfer by Collective Factorization (TCF), in which we construct a shared latent space collectively and learn the data-dependent effect separately. A major advantage of the TCF approach over the previous bilinear method of collective matrix factorization is that we are able to capture the data-dependent effect when sharing the data-independent knowledge. This allows us to increase the overall quality of knowledge transfer. We present extensive experimental results to demonstrate the effectiveness of TCF at various sparsity levels, and show improvements of our approach as compared to several state-of-the-art methods.
ER  - 

TY  - JOUR
T1  - Dimensionality reduction: An interpretation from manifold regularization perspective
JO  - Information Sciences
VL  - 277
IS  - 
SP  - 694
EP  - 714
PY  - 2014/9/1/
T2  - 
AU  - Fan, Mingyu
AU  - Gu, Nannan
AU  - Qiao, Hong
AU  - Zhang, Bo
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2014.03.011
UR  - http://www.sciencedirect.com/science/article/pii/S0020025514002916
KW  - Dimensionality reduction
KW  - Manifold regularization
KW  - Feature mapping
KW  - Manifold learning
KW  - Out-of-sample extrapolation
AB  - Abstract
In this paper, we propose to unify various dimensionality reduction algorithms by interpreting the Manifold Regularization (MR) framework in a new way. Although the MR framework was originally proposed for learning, we utilize it to give a unified treatment for many dimensionality reduction algorithms from linear to nonlinear, supervised to unsupervised, and single class to multi-class approaches. In addition, the framework can provide a general platform to design new dimensionality reduction algorithms. The framework is expressed in the form of a regularized fitting problem in a Reproducing Kernel Hilbert Space. It consists of one error part and two regularization terms: the complexity term and the smoothness term. The error part measures the difference between the estimated (low-dimensional) data distribution and the true (high-dimensional) data distribution or the difference between the estimated and targeted low-dimensional representations of data, the complexity term is a measurement of the complexity of the feature mapping for dimensionality reduction, and the smoothness term reflects the intrinsic structure of data. Based on the framework, we propose a Manifold Regularized Kernel Least Squares (MR-KLS) method which can efficiently learn an explicit feature mapping (in the semi-supervised sense). Experiments show that our approach is effective for out-of-sample extrapolation.
ER  - 

TY  - JOUR
T1  - PCIR: Combining DHTs and peer clusters for efficient full-text P2P indexing
JO  - Computer Networks
VL  - 54
IS  - 12
SP  - 2019
EP  - 2040
PY  - 2010/8/26/
T2  - P2P Technologies for Emerging Wide-Area Collaborative Services and Applications
AU  - Papapetrou, Odysseas
AU  - Siberski, Wolf
AU  - Nejdl, Wolfgang
SN  - 1389-1286
DO  - http://dx.doi.org/10.1016/j.comnet.2010.03.025
UR  - http://www.sciencedirect.com/science/article/pii/S1389128610001842
KW  - P2P information retrieval
KW  - DHT
KW  - Hybrid topologies
AB  - Distributed hash tables (DHTs) are very efficient for querying based on key lookups. However, building huge term indexes, as required for IR-style keyword search, poses a scalability challenge for plain DHTs. Due to the large sizes of document term vocabularies, peers joining the network cause huge amounts of key inserts and, consequently, a large number of index maintenance messages. Thus, the key to exploiting DHTs for distributed information retrieval is to reduce index maintenance costs. Various approaches in this direction have been pursued, including the use of hybrid infrastructures, or changing the granularity of the inverted index to peer level. We show that indexing costs can be significantly reduced further by letting peers form groups in a self-organized fashion. Instead of each individual peer submitting index information separately, all peers of a group cooperate to publish the index updates to the DHT in batches. Our evaluation shows that this approach reduces index maintenance cost by an order of magnitude, while still keeping a complete and correct term index for query processing.
ER  - 

TY  - JOUR
T1  - Contents
JO  - Procedia Computer Science
VL  - 17
IS  - 
SP  - iii
EP  - viii
PY  - 2013///
T2  - First International Conference on Information Technology and Quantitative Management

SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/S1877-0509(13)00300-1
UR  - http://www.sciencedirect.com/science/article/pii/S1877050913003001
ER  - 

TY  - JOUR
T1  - Tight bounds for parameterized complexity of Cluster Editing with a small number of clusters
JO  - Journal of Computer and System Sciences
VL  - 80
IS  - 7
SP  - 1430
EP  - 1447
PY  - 2014/11//
T2  - 
AU  - Fomin, Fedor V.
AU  - Kratsch, Stefan
AU  - Pilipczuk, Marcin
AU  - Pilipczuk, Michał
AU  - Villanger, Yngve
SN  - 0022-0000
DO  - http://dx.doi.org/10.1016/j.jcss.2014.04.015
UR  - http://www.sciencedirect.com/science/article/pii/S0022000014000592
KW  - Cluster editing
KW  - Correlation clustering
KW  - Parameterized complexity
KW  - Subexponential-time algorithms
KW  - Exponential-time hypothesis
AB  - Abstract
In the Cluster Editing problem, also known as Correlation Clustering, we are given an undirected n-vertex graph G and a positive integer k. The task is to decide if G can be transformed into a cluster graph, i.e., a disjoint union of cliques, by changing at most k adjacencies, i.e. by adding/deleting at most k edges. We give a subexponential-time parameterized algorithm that in time 2 O ( p k ) + n O ( 1 ) decides whether G can be transformed into a cluster graph with exactly p cliques by changing at most k adjacencies. Our algorithmic findings are complemented by the following tight lower bound on the asymptotic behavior of our algorithm. We show that unless ETH fails, for any constant 0 &lt; σ ≤ 1 , there is p = Θ ( k σ ) such that there is no algorithm deciding in time 2 o ( p k ) ⋅ n O ( 1 ) whether G can be transformed into a cluster graph with at most p cliques by changing at most k adjacencies.
ER  - 

TY  - CHAP
AU  - Stanković, StašaVujičić
AU  - Kojić, Nemanja
AU  - Rakočević, Goran
AU  - Vitas, Duško
AU  - Milutinović, Veljko
T1  - Chapter 4 - A Classification of Data Mining Algorithms for Wireless Sensor Networks, and Classification Extension to Concept Modeling in System of Wireless Sensor Networks Based on Natural Language Processing
A2  - Ali Hurson
BT  - Advances in Computers
PB  - Elsevier
PY  - 2013///
VL  - Volume 90
SP  - 223
EP  - 283
T2  - Connected Computing Environment
SN  - 0065-2458
DO  - http://dx.doi.org/10.1016/B978-0-12-408091-1.00004-X
UR  - http://www.sciencedirect.com/science/article/pii/B978012408091100004X
KW  - Data mining
KW  - Wireless sensor networks
KW  - Concept modeling
KW  - Natural language processing
KW  - Information extraction
KW  - Named entity recognition
AB  - Abstract
In this article, we propose one original classification and one extension thereof, which takes into consideration the relevant issues in Natural Language Processing. The newly introduced classification of Data Mining algorithms is on the level of a single Wireless Sensor Network and its extension to Concept Modeling on the level of a System of Wireless Sensor Networks. Most of the scientists in this field put emphasis on issues related to applications of Wireless Sensor Networks in different areas, while we here put emphasis on categorization of the selected approaches from the open literature, to help application designers/developers get a better understanding of their options in different areas. Our main goal is to provide a good starting point for a more effective analysis leading to possible new solutions, possible improvements of existing solutions, and possible combination of two or more of the existing solutions into new ones, using the hybridization principle. Another contribution of this article is a synergistic interdisciplinary review of problems in two areas: Data Mining and Natural Language Processing. This enables interoperability improvements on the interface between Wireless Sensor Networks that often share data in native natural languages.
ER  - 

TY  - JOUR
T1  - Diverse reduct subspaces based co-training for partially labeled data
JO  - International Journal of Approximate Reasoning
VL  - 52
IS  - 8
SP  - 1103
EP  - 1117
PY  - 2011/11//
T2  - 
AU  - Miao, Duoqian
AU  - Gao, Can
AU  - Zhang, Nan
AU  - Zhang, Zhifei
SN  - 0888-613X
DO  - http://dx.doi.org/10.1016/j.ijar.2011.05.006
UR  - http://www.sciencedirect.com/science/article/pii/S0888613X11000880
KW  - Rough set theory
KW  - Markov blanket
KW  - Attribute reduction
KW  - Rough co-training
KW  - Partially labeled data
AB  - Rough set theory is an effective supervised learning model for labeled data. However, it is often the case that practical problems involve both labeled and unlabeled data, which is outside the realm of traditional rough set theory. In this paper, the problem of attribute reduction for partially labeled data is first studied. With a new definition of discernibility matrix, a Markov blanket based heuristic algorithm is put forward to compute the optimal reduct of partially labeled data. A novel rough co-training model is then proposed, which could capitalize on the unlabeled data to improve the performance of rough classifier learned only from few labeled data. The model employs two diverse reducts of partially labeled data to train its base classifiers on the labeled data, and then makes the base classifiers learn from each other on the unlabeled data iteratively. The classifiers constructed in different reduct subspaces could benefit from their diversity on the unlabeled data and significantly improve the performance of the rough co-training model. Finally, the rough co-training model is theoretically analyzed, and the upper bound on its performance improvement is given. The experimental results show that the proposed model outperforms other representative models in terms of accuracy and even compares favorably with rough classifier trained on all training data labeled.
ER  - 

TY  - JOUR
T1  - CohEEL: Coherent and efficient named entity linking through random walks
JO  - Web Semantics: Science, Services and Agents on the World Wide Web
VL  - 37–38
IS  - 
SP  - 75
EP  - 89
PY  - 2016/3//
T2  - 
AU  - Gruetze, Toni
AU  - Kasneci, Gjergji
AU  - Zuo, Zhe
AU  - Naumann, Felix
SN  - 1570-8268
DO  - http://dx.doi.org/10.1016/j.websem.2016.03.001
UR  - http://www.sciencedirect.com/science/article/pii/S1570826816000172
KW  - Entity linking
KW  - Named entity disambiguation
KW  - Random walk
KW  - Machine learning
AB  - Abstract
In recent years, the ever-growing amount of documents on the Web as well as in digital libraries led to a considerable increase of valuable textual information about entities. Harvesting entity knowledge from these large text collections is a major challenge. It requires the linkage of textual mentions within the documents with their real-world entities. This process is called entity linking.

Solutions to this entity linking problem have typically aimed at balancing the rate of linking correctness (precision) and the linking coverage rate (recall). While entity links in texts could be used to improve various Information Retrieval tasks, such as text summarization, document classification, or topic-based clustering, the linking precision is the decisive factor. For example, for topic-based clustering a method that produces mostly correct links would be more desirable than a high-coverage method that leads to more but also more uncertain clusters.

We propose an efficient linking method that uses a random walk strategy to combine a precision-oriented and a recall-oriented classifier in such a way that a high precision is maintained, while recall is elevated to the maximum possible level without affecting precision. An evaluation on three datasets with distinct characteristics demonstrates that our approach outperforms seminal work in the area and shows higher precision and time performance than the most closely related state-of-the-art methods.
ER  - 

TY  - JOUR
T1  - A comprehensive survey of traditional, merge-split and evolutionary approaches proposed for determination of cluster number
JO  - Swarm and Evolutionary Computation
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Hancer, Emrah
AU  - Karaboga, Dervis
SN  - 2210-6502
DO  - http://dx.doi.org/10.1016/j.swevo.2016.06.004
UR  - http://www.sciencedirect.com/science/article/pii/S2210650216300475
KW  - Clustering
KW  - Validity indexes
KW  - Automatic cluster evolution
KW  - Knee point
KW  - Evolutionary algorithms
AB  - Abstract
Today's data mostly does not include the knowledge of cluster number. Therefore, it is not possible to use conventional clustering approaches to partition today's data, i.e., it is necessary to use the approaches that automatically determine the cluster number or cluster structure. Although there has been a considerable attempt to analyze and categorize clustering algorithms, it is difficult to find a survey paper in the literature that has thoroughly focused on the determination of cluster number. This significant issue motivates us to introduce concepts and review methods related to automatic cluster evolution from a theoretical perspective in this study.
ER  - 

TY  - JOUR
T1  - A survey of the applications of text mining in financial domain
JO  - Knowledge-Based Systems
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Kumar, B. Shravan
AU  - Ravi, Vadlamani
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2016.10.003
UR  - http://www.sciencedirect.com/science/article/pii/S0950705116303872
KW  - Text mining
KW  - Financial applications
KW  - FOREX rate prediction
KW  - Stock market prediction
KW  - Customer relationship management
KW  - Cyber security
AB  - Abstract
Text mining has found a variety of applications in diverse domains. Of late, prolific work is reported in using text mining techniques to solve problems in financial domain. The objective of this paper is to provide a state-of-the-art survey of various applications of Text mining to finance. These applications are categorized broadly into FOREX rate prediction, stock market prediction, customer relationship management (CRM) and cyber security. Since finance is a service industry, these problems are paramount in operational and customer growth aspects. We reviewed 89 research papers that appeared during the period 2000–2016, highlighted some of the issues, gaps, key challenges in this area and proposed some future research directions. Finally, this review can be extremely useful to budding researchers in this area, as many open problems are highlighted.
ER  - 

TY  - JOUR
T1  - Assessing the Value of Team Science: A Study Comparing Center- and Investigator-Initiated Grants
JO  - American Journal of Preventive Medicine
VL  - 42
IS  - 2
SP  - 157
EP  - 163
PY  - 2012/2//
T2  - 
AU  - Hall, Kara L.
AU  - Stokols, Daniel
AU  - Stipelman, Brooke A.
AU  - Vogel, Amanda L.
AU  - Feng, Annie
AU  - Masimore, Beth
AU  - Morgan, Glen
AU  - Moser, Richard P.
AU  - Marcus, Stephen E.
AU  - Berrigan, David
SN  - 0749-3797
DO  - http://dx.doi.org/10.1016/j.amepre.2011.10.011
UR  - http://www.sciencedirect.com/science/article/pii/S0749379711008488
AB  - Background
Large cross-disciplinary scientific teams are becoming increasingly prominent in the conduct of research.
Purpose
This paper reports on a quasi-experimental longitudinal study conducted to compare bibliometric indicators of scientific collaboration, productivity, and impact of center-based transdisciplinary team science initiatives and traditional investigator-initiated grants in the same field.
Methods
All grants began between 1994 and 2004 and up to 10 years of publication data were collected for each grant. Publication information was compiled and analyzed during the spring and summer of 2010.
Results
Following an initial lag period, the transdisciplinary research center grants had higher overall publication rates than the investigator-initiated R01 (NIH Research Project Grant Program) grants. There were relatively uniform publication rates across the research center grants compared to dramatically dispersed publication rates among the R01 grants. On average, publications produced by the research center grants had greater numbers of coauthors but similar journal impact factors compared with publications produced by the R01 grants.
Conclusions
The lag in productivity among the transdisciplinary center grants was offset by their overall higher publication rates and average number of coauthors per publication, relative to investigator-initiated grants, over the 10-year comparison period. The findings suggest that transdisciplinary center grants create benefits for both scientific productivity and collaboration.
ER  - 

TY  - JOUR
T1  - A relational database for bibliometric analysis
JO  - Journal of Informetrics
VL  - 4
IS  - 4
SP  - 564
EP  - 580
PY  - 2010/10//
T2  - 
AU  - Mallig, Nicolai
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2010.06.007
UR  - http://www.sciencedirect.com/science/article/pii/S1751157710000611
KW  - Bibliometrics
KW  - Relational database
KW  - SQL
AB  - In this article a relational database schema for a bibliometric database is developed. After the introduction explaining the motivation to use relational databases in bibliometrics, an overview of the related literature is given. A review of typical bibliometric questions serves as an informal requirement analysis. The database schema is developed as an entity-relationship diagram using the structural information typically found in scientific articles. Several SQL queries for the tasks presented in the requirement analysis show the usefulness of the developed database schema.
ER  - 

TY  - JOUR
T1  - Viticulture and oenology scientific research: The Old World versus the New World wine-producing countries
JO  - International Journal of Information Management
VL  - 36
IS  - 3
SP  - 389
EP  - 396
PY  - 2016/6//
T2  - 
AU  - Aleixandre, José Luis
AU  - Aleixandre-Tudó, José Luis
AU  - Bolaños-Pizarro, Máxima
AU  - Aleixandre-Benavent, Rafael
SN  - 0268-4012
DO  - http://dx.doi.org/10.1016/j.ijinfomgt.2016.01.003
UR  - http://www.sciencedirect.com/science/article/pii/S0268401216000049
KW  - Scientific productivity
KW  - Viticulture and oenology
KW  - Wine-producing countries
KW  - Old World
KW  - New World
AB  - Abstract
The main aim of this study was to analyze the scientific productivity and collaboration between Old World wine-producing countries (Austria, Bulgaria, France, Germany, Greece, Hungary, Italy, Portugal, Romania, Spain, Switzerland) and New World wine-producing countries (Argentina, Australia, Brazil, Canada, Chile, Mexico, New Zealand, Peru, South Africa, United Sates, Uruguay) in viticulture and oenology through bibliometric analyses of articles included in the Science Citation Index Expanded database for the period 1994–2013. A number of 1527 research articles were published in 563 journals. The results highlight an important growth in the collaboration between countries during the second decade (2004–2013). Papers have been published in numerous journals belonging to several subject areas. Food Science and Technology, Horticulture and Biotechnology and Applied Microbiology appeared as the most productive research areas. A social network analysis of collaboration between these countries was also performed in order to analyze the most powerful scientific cooperation.
ER  - 

TY  - JOUR
T1  - Could removal of project-level knowledge flow obstacles contribute to software process improvement? A study of software engineer perceptions
JO  - Information and Software Technology
VL  - 72
IS  - 
SP  - 151
EP  - 170
PY  - 2016/4//
T2  - 
AU  - Mitchell, Susan M.
AU  - Seaman, Carolyn B.
SN  - 0950-5849
DO  - http://dx.doi.org/10.1016/j.infsof.2015.12.007
UR  - http://www.sciencedirect.com/science/article/pii/S0950584915002165
KW  - Software process
KW  - Software process improvement
KW  - SPI
KW  - Knowledge management
KW  - Knowledge flow (K-flow)
KW  - Software engineering
AB  - AbstractContext
Software process improvement (SPI) is one type of innovation often formulated to address problems such as uncontrollable costs, schedule overruns, and poor end product quality. This study investigates SPI through the application of knowledge management (KM) at the software project level, viewing KM, when applied in software development, as complementary to SPI.
Objective
This study advances the use of KM in SPI by investigating impediments to the use and flow of knowledge within an individual software development project. Our proposition is that the removal of obstacles to project-level knowledge flow (K-flow) will enhance SPI. We investigate this proposition by exploring the problems associated with project K-flows as seen by software project team members.
Method
We conducted a descriptive case study of an industrial software development project, in which we collected data concerning project knowledge sources and K-flows using semi-structured interviews. Using this data, we constructed a diagnostic project knowledge map (K-map). The K-map was analyzed to identify K-flow obstacles and potential solutions. Questionnaires based on these obstacles and solutions were formulated to probe software engineers’ perceptions of the effect of the solutions on SPI.
Results
Findings from participant questionnaires reveal that software engineers perceive that the removal or mitigation of project-level K-flow obstacles generally reduces the time to perform their work, helps them to meet their deadlines, and improves their work quality, thus resulting in SPI.
Conclusions
This study provides support for the usefulness of project-level K-flow obstacle removal for SPI. It provides a unique project-level perspective, using input from the project's software engineers. It also explains and supports the use of K-mapping for the identification of project-level K-flow obstacles. With this approach, practitioners gain insight into SPI in “real time” as a project is executed. These insights may help to enhance their current and future SPI efforts.
ER  - 

TY  - JOUR
T1  - A multilayered analysis of energy security research and the energy supply process
JO  - Applied Energy
VL  - 123
IS  - 
SP  - 415
EP  - 423
PY  - 2014/6/15/
T2  - 
AU  - Kiriyama, Eriko
AU  - Kajikawa, Yuya
SN  - 0306-2619
DO  - http://dx.doi.org/10.1016/j.apenergy.2014.01.026
UR  - http://www.sciencedirect.com/science/article/pii/S0306261914000452
KW  - Energy security
KW  - Energy policy
KW  - Energy supply chain
KW  - Network analysis
AB  - Abstract
After the Fukushima nuclear disaster, a reassessment of the energy system is needed in order to include such aspects as human security and resilience. More open and careful discussions are needed concerning the various risks and uncertainties of future energy options, both in Japan and globally. In this paper, we aim to offer a fundamental basis for discourse on energy security by analyzing the status and trends in academic publications on that issue. Our bibliometrics analysis indicates that research has shifted from promoting strategies for ensuring the self-sufficiency of the primary energy to diversification of the secondary energy supply chain by introducing energy networks consisting of an infrastructure established through international coordination. In the literature, the concept of energy security is ambiguous and allows for multiple interpretations. Our results illustrate the existence of highly multidisciplinary topics within energy security, which can be categorized into four perspectives: geopolitical, economic, policy related, and technological.
ER  - 

TY  - JOUR
T1  - Putting the value into biosimilar decision making: The judgment value criteria
JO  - Autoimmunity Reviews
VL  - 13
IS  - 6
SP  - 678
EP  - 684
PY  - 2014/6//
T2  - 
AU  - Mendes de Abreu, Mirhelen
AU  - Strand, Vibeke
AU  - Levy, Roger Abramino
AU  - Araujo, Denizar Vianna
SN  - 1568-9972
DO  - http://dx.doi.org/10.1016/j.autrev.2014.01.051
UR  - http://www.sciencedirect.com/science/article/pii/S1568997214000639
KW  - Biosimilars
KW  - Value in health
KW  - Immunogenicity
KW  - Decision process
KW  - Value chain
AB  - Abstract
Uncertainties remain the key issue surrounding biosimilars, although decisions regarding their use must be made. The challenges for policymakers, doctors, patients and others seeking to navigate in the uncharted waters of biosimilars must be clarified. At the most basic level, scientific understanding of the issue remains limited and when making decisions, policymakers must consider all those affected by health policy decisions, particularly the ultimate recipients of these medicines: the patients.

The biosimilar-value chain relies on measurement of comparabilities. The goal is to demonstrate how, from a molecular perspective, closely similar they are or are not and how potential small differences may be relevant to clinical outcomes. To critically understand these points, this conceptual paper will present a knowledge-value chain and discuss each dimension assigning value in the decision making process re-utilization of biosimilars.
ER  - 

TY  - JOUR
T1  - Does one-to-one access to laptops improve learning: Lessons from New Brunswick's individual laptop school initiative
JO  - Procedia - Social and Behavioral Sciences
VL  - 2
IS  - 2
SP  - 5686
EP  - 5692
PY  - 2010///
T2  - Innovation and Creativity in Education
AU  - Freiman, Viktor
AU  - Beauchamp, Jacinthe
AU  - Blain, Sylvie
AU  - Lirette-Pitre, Nicole
AU  - Fournier, Hélène
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2010.03.929
UR  - http://www.sciencedirect.com/science/article/pii/S1877042810009699
KW  - Individual laptops
KW  - science
KW  - mathematics
KW  - language arts
KW  - problem-based learning
AB  - A two-year study on the use of laptop computers by New Brunswick (Canada) grade 7–8 francophone students aimed to better understand the impact of laptops on learning. Two problem-based learning (PBL) interdisciplinary scenarios (math, science, language arts) were implemented in eight experimental classes to measure students’ learning process, particularly in terms of their ability to scientifically investigate complex problems, to reason mathematically, and to communicate. Based on our findings, we argue that laptops in themselves may not automatically lead to better results on standardized tests, but rather create opportunities for more open-ended, constructive, collaborative, reflective, and cognitively rich learning tasks.
ER  - 

TY  - JOUR
T1  - Enhancing Reading Comprehension through Cognitive and Graphic Strategies: A Constructivism Approach
JO  - Procedia - Social and Behavioral Sciences
VL  - 64
IS  - 
SP  - 151
EP  - 160
PY  - 2012/11/9/
T2  - 12 th International Educational Technology Conference - IETC 2012
AU  - Mohd Yussof, Yusfarina
AU  - Rasid Jamian, Abdul
AU  - Roslan, Samsilah
AU  - Hamzah, Zaitul Azma Zainon
AU  - Kamarul Kabilan, Muhammad
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2012.11.018
UR  - http://www.sciencedirect.com/science/article/pii/S1877042812049956
KW  - Reading Comprehension
KW  - Cognitive Strategies
KW  - Graphic Strategy
KW  - Constructivism Approach.
AB  - Graphic Strategy and several Cognitive Strategies (Story Structure, Questioning, Synthesizing, Visualizing and Inferencing) are used on narrative texts, following constructivism principle, to discern the increase in students’ reading comprehension.A quasi-experimental study involved 45 students(experimental group) receiving treatment via graphic and cognitive strategies and another 45 students (control group) using classroom's common practice (conventional method).Paired T-test Analysis shows significant difference for both groups. However, mean score and effect size (eta square value) are larger in the experimental group (M=59.63, 0.78) than the control group's (M=55.34, 0.31). This indicates that the implemented strategies increased students’ reading comprehension effectively compared to conventional method.
ER  - 

TY  - JOUR
T1  - Intelligent Utilisation of Digital Databases for Assembly Time Determination in Early Phases of Product Emergence
JO  - Procedia CIRP
VL  - 3
IS  - 
SP  - 424
EP  - 429
PY  - 2012///
T2  - 45th CIRP Conference on Manufacturing Systems 2012
AU  - Erohin, O.
AU  - Kuhlang, P.
AU  - Schallow, J.
AU  - Deuse, J.
SN  - 2212-8271
DO  - http://dx.doi.org/10.1016/j.procir.2012.07.073
UR  - http://www.sciencedirect.com/science/article/pii/S2212827112002454
KW  - Product Emergence Process
KW  - Knowledge Discovery
KW  - Digital Manufacturing
KW  - Assembly Time
KW  - Time Determination
AB  - Manufacturing industry has been progressively using digital tools for product development and manufacturing control to handle product and process complexity as well as to react to ever-increasing cost and time pressure. This paper presents aims and potentials of the application of knowledge discovery processes in industrial databases for the identification and extraction of new knowledge in order to support planning and decision making processes in product emergence. Therefore, it describes basic approaches for the intelligent utilisation of discovered knowledge on the example of prospective assembly time determination in early phases of product emergence
ER  - 

TY  - JOUR
T1  - Towards Knowledge Ecosystems: Modelling Knowledge Dynamics in Environmental Systems
JO  - Procedia Computer Science
VL  - 35
IS  - 
SP  - 1360
EP  - 1369
PY  - 2014///
T2  - Knowledge-Based and Intelligent Information &amp; Engineering Systems 18th Annual Conference, KES-2014 Gdynia, Poland, September 2014 Proceedings
AU  - Noennig, Jörg Rainer
AU  - Scheler, Anna-Maria
AU  - Piskorek, Katarzyna
AU  - Barski, Jan
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2014.08.179
UR  - http://www.sciencedirect.com/science/article/pii/S1877050914011442
KW  - Knowledge ecosystems
KW  - Cellular Automaton
KW  - Agent Modelling
KW  - Knowledge dynamics
AB  - Abstract
In order to understand basic mechanisms of so-called Knowledge Ecosystems, the paper presents a study for modelling the emergence and diffusion of knowledge in regards to environmental conditions. The text gives an outline for the description of Knowledge Ecosystems by integrating 1) models for environmental dynamics based on resources and attractiveness, and 2) models for knowledge dynamics based on the behaviors and processes of knowledge agents (innovators) and agencies. As key methods, the work employs Cellular Automata for the modelling of knowledge environments, as well as agent models for the simulation of knowledge agents (innovators). The paper presents preliminary results of the ongoing study, including a first version of both scopes integrated into one descriptive system.
ER  - 

TY  - JOUR
T1  - Analysis of Knowledge Management and E-Learning Integration Models
JO  - Procedia Computer Science
VL  - 43
IS  - 
SP  - 154
EP  - 162
PY  - 2015///
T2  - ICTE in Regional Development, December 2014, Valmiera, Latvia
AU  - Judrups, Janis
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2014.12.021
UR  - http://www.sciencedirect.com/science/article/pii/S1877050914015890
KW  - Knowledge Management
KW  - E-learning
KW  - Integration models.
AB  - Abstract
The development of knowledge management (KM) and e-learning (EL) naturally brings both disciplines closer and encourages integration. There are several models that offer possible ways of such integration. With the goal to develop practically applicable integration solution for specific organization, existing integration models are analysed in this paper. The main criterion for analysis is application of integration model in the enterprise. Model analysis shows several different theoretical approaches for integration that are tied to specific goals and needs of organization. The more general approach is to base integration on common ground, which is identified as learning.
ER  - 

TY  - JOUR
T1  - Ontology-based system for supporting manufacturing sustainability
JO  - Annual Reviews in Control
VL  - 36
IS  - 2
SP  - 309
EP  - 317
PY  - 2012/12//
T2  - 
AU  - Giovannini, Antonio
AU  - Aubry, Alexis
AU  - Panetto, Hervé
AU  - Dassisti, Michele
AU  - El Haouzi, Hind
SN  - 1367-5788
DO  - http://dx.doi.org/10.1016/j.arcontrol.2012.09.012
UR  - http://www.sciencedirect.com/science/article/pii/S1367578812000478
KW  - Sustainability
KW  - Manufacturing processes
KW  - Knowledge-based systems
KW  - Expert systems
KW  - Ontology
AB  - Sustainability is one of the biggest challenges of this century either for the environment or economical growth. The required cultural shift needs challenging action that will involve deeply software and hardware aspect of manufacturing processes. In this paper, the software part of the matter is addressed by proposing a product centric ontology, in which concepts of product, processes and resources are associated to functions and sustainable manufacturing knowledge. The aim is to design a knowledge-based system that, simulating a sustainable manufacturing expert, is able to automatically identify change opportunities and to propose alternatives on the basis of the existing production scenario.
ER  - 

TY  - JOUR
T1  - Improving similarity measures of relatedness proximity: Toward augmented concept maps
JO  - Journal of Informetrics
VL  - 9
IS  - 3
SP  - 618
EP  - 628
PY  - 2015/7//
T2  - 
AU  - Sasson, Elan
AU  - Ravid, Gilad
AU  - Pliskin, Nava
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2015.06.003
UR  - http://www.sciencedirect.com/science/article/pii/S1751157715000541
KW  - Augmented concept map
KW  - Relatedness proximity
KW  - Co-word analysis
KW  - Webometrics
KW  - Technology assessment
AB  - Abstract
Decision makers relying on web search engines in concept mapping for decision support are confronted with limitations inherent in similarity measures of relatedness proximity between concept pairs. To cope with this challenge, this paper presents research model for augmenting concept maps on the basis of a novel method of co-word analysis that utilizes webometrics web counts for improving similarity measures. Technology assessment serves as a use case to demonstrate and validate our approach for a spectrum of information technologies. Results show that the yielded technology assessments are highly correlated with subjective expert assessments (n = 136; r &gt; 0.879), suggesting that it is safe to generalize the research model to other applications. The contribution of this work is emphasized by the current growing attention to big data.
ER  - 

TY  - JOUR
T1  - Vernacular and Technology. InBetween
JO  - Procedia Environmental Sciences
VL  - 32
IS  - 
SP  - 412
EP  - 419
PY  - 2016///
T2  - ECOSMART - Environment at Crossroads: Smart Approaches for a Sustainable Development
AU  - Hărmănescu, Mihaela
AU  - Enache, Cristina
SN  - 1878-0296
DO  - http://dx.doi.org/10.1016/j.proenv.2016.03.047
UR  - http://www.sciencedirect.com/science/article/pii/S1878029616001961
KW  - Tradition
KW  - culture
KW  - smart landscape
KW  - knowledge
KW  - sustainability
AB  - Abstract
The challenges of 21st century are related to the community's ability to succeed a sustainable management of the landscape's resources, in a world where tradition's nostalgia and the patrimonialization are interpreted and re-used in relation with globalization and consuming. In a time of dramatic changes on the social scale and technology, sustainability means more than preserving traditions in places where the vernacular knowledge are important resources to recovery the local identity. It requires a reformulation of their use, a suitable dynamic adaptation of the contemporary world, merging with the technology integration into the landscape. This paper proposes introspection on the integration of indigenous values identified in the current technology development through the transfer of information on landscape. A smart landscape is an adaptable landscape. Adaptability is derived from the proposed uses of technologies in a sustainable vision, in a balanced use of local resources and evolutionary protection of the heritage. The resource, local heritage and technology need to be reconsidered in a relationship with a return to the primary motivation - their coexistence in the landscape, which can be seen as information's primary database that spawned the first technological elements - clay, metal tools and first building blocks. In a cyclical evolution, the technology returns in the 21st century landscape in the form of information and its impact and consequences oscillates between transformation and conservation nostalgia. In this context the dialogue between vernacular and technology gains materiality, redefining old taboo-dispute between tradition and contemporaneousness. The paper aims towards to highlighting the concept of “vernacular” and “technology” and to underline how can their relation be reinterpreting in a sustainable and resilient vision, in a way that respond to the landscape continuous changes.
ER  - 

TY  - JOUR
T1  - Knowledge-Based System for Manufacturing Sustainability
JO  - IFAC Proceedings Volumes
VL  - 45
IS  - 6
SP  - 1333
EP  - 1338
PY  - 23///
Y2  - 2012/5/25/
T2  - 14th IFAC Symposium on Information Control Problems in Manufacturing
AU  - Giovannini, Antonio
AU  - Aubry, Alexis
AU  - Panetto, Hervé
AU  - Dassisti, Michele
AU  - Haouzi, Hind El
SN  - 1474-6670
DO  - http://dx.doi.org/10.3182/20120523-3-RO-2023.00383
UR  - http://www.sciencedirect.com/science/article/pii/S1474667016333365
KW  - Sustainability
KW  - Manufacturing Processes
KW  - Knowledge-Based Systems
KW  - Ontology
KW  - Design
KW  - Process Planning
AB  - Abstract
Today, sustainability becomes one of the biggest challenges. It represents a key issue in every production activity. To face this issue, a possible solution is to enhance knowledge usage in manufacturing and sustainability domains. In this paper, we extend the ONTO-PDM ontology for formalizing sustainable manufacturing knowledge. An industrial case is presented for instantiating the extension. Moreover we design a knowledge-based system, which exploits sustainable manufacturing knowledge for supporting design and process planning with sustainability proposals, generating machine code starting from product specifications.
ER  - 

TY  - JOUR
T1  - A meta-model for knowledge representation in engineering design
JO  - IFAC Proceedings Volumes
VL  - 45
IS  - 6
SP  - 1641
EP  - 1646
PY  - 23///
Y2  - 2012/5/25/
T2  - 14th IFAC Symposium on Information Control Problems in Manufacturing
AU  - Belkadi, F.
AU  - Notin, A.
AU  - Drémont, N.
AU  - Troussier, N.
SN  - 1474-6670
DO  - http://dx.doi.org/10.3182/20120523-3-RO-2023.00283
UR  - http://www.sciencedirect.com/science/article/pii/S1474667016333869
KW  - knowledge meta-modeling
KW  - Meta-Model of Data
KW  - Meta-Model of Collaboration
AB  - Abstract
Computer Aided Design (CAD) and Computer Aided Engineering (CAE) models are often used during product design. Various interactions between the different models must be managed for the designed system to be robust and to fit initially defined specifications. A lot of data are exchanged in collaborative design and different problems must be managed in terms of data consistency. A literature survey about existing knowledge models is done before presenting the proposed meta-model of knowledge. This meta-model is decomposed in a meta-model of expert knowledge and one of collaboration knowledge in order to represent interaction and link among knowledge between the different expertise of collaborative design.
ER  - 

TY  - JOUR
T1  - Evaluation of Intangible Assets and Best Practices in a Medium-sized Port Community
JO  - Procedia Computer Science
VL  - 91
IS  - 
SP  - 75
EP  - 84
PY  - 2016///
T2  - Promoting Business Analytics and Quantitative Management of Technology: 4th International Conference on Information Technology and Quantitative Management (ITQM 2016)
AU  - Córdova, Felisa M.
AU  - Durán, Claudia A.
AU  - Galindo, Raquel
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2016.07.043
UR  - http://www.sciencedirect.com/science/article/pii/S1877050916312248
KW  - Knowledge Management
KW  - Medium-sized Ports
KW  - KM Model
KW  - KM Measurement
KW  - Indicators
AB  - Abstract
This paper analyses the main factors involved in the knowledge management of different actors participating in a Chilean port community. The intangible assets participating in the creation of value of the port community, which are expressed in ideas, attitudes, perceptions, experiences, information and knowledge management, are evaluated and classified according to community members’ core competencies. Then, the current situation of public institutions and companies participating in the port community is diagnosed utilizing interviews to experts and relevant actors. The role of the intellectual, structural, and social capital is examined in relation to strategic statements present in the missions of public and private port system companies. The results of the assessment enable to identify the main critical factors in knowledge management, transference, dissemination, collaboration and team work, storage, and best practices. In particular, the Conversation System stage of the Primary Model is analyzed and evaluated, as well as its causes, by actors of the port community and experts. Initiatives fostering collective work and encouraging conversations are proposed. Some of the best practices developed by the port community to create and disseminate stakeholders’ knowledge are presented. Also, a set of knowledge management indicators and indexes is developed and presented.
ER  - 

TY  - CHAP

T1  - Subject Index
A2  - Bruno Robert
BT  - Advances in Botanical Research
PB  - Academic Press
PY  - 2016///
VL  - Volume 79
SP  - 223
EP  - 233
T2  - Artificial Photosynthesis
SN  - 0065-2296
DO  - http://dx.doi.org/10.1016/S0065-2296(16)30072-6
UR  - http://www.sciencedirect.com/science/article/pii/S0065229616300726
ER  - 

TY  - JOUR
T1  - Computing with the Collective Intelligence of Honey Bees – A Survey
JO  - Swarm and Evolutionary Computation
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Rajasekhar, Anguluri
AU  - Lynn, Nandar
AU  - Das, Swagatam
AU  - Suganthan, P.N.
SN  - 2210-6502
DO  - http://dx.doi.org/10.1016/j.swevo.2016.06.001
UR  - http://www.sciencedirect.com/science/article/pii/S221065021630027X
KW  - Nature inspired computing
KW  - Swarm intelligence
KW  - Honey bees foraging
KW  - Particle swarm optimization
KW  - Bee colony optimisation
AB  - Abstract
Over past few decades, families of algorithms based on the intelligent group behaviors of social creatures like ants, birds, fishes, and bacteria have been extensively studied and applied for computer-aided optimization. Recently there has been a surge of interest in developing algorithms for search, optimization, and communication by simulating different aspects of the social life of a very well-known creature: the honey bee. Several articles reporting the success of the heuristics based on swarming, mating, and foraging behaviors of the honey bees are being published on a regular basis. In this paper we provide a brief but comprehensive survey of the entire horizon of research so far undertaken on the algorithms inspired by the honey bees. Starting with the biological perspectives and motivations, we outline the major bees-inspired algorithms, their prospects in the respective problem domains and their similarities and dissimilarities with the other swarm intelligence algorithms. We also provide an account of the engineering applications of these algorithms. Finally we identify some open research issues and promising application areas for the bees-inspired computing techniques.
ER  - 

TY  - JOUR
T1  - Improved multi-kernel classification machine with Nyström approximation technique and Universum data
JO  - Neurocomputing
VL  - 175, Part A
IS  - 
SP  - 610
EP  - 634
PY  - 2016/1/29/
T2  - 
AU  - Zhu, Changming
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2015.10.102
UR  - http://www.sciencedirect.com/science/article/pii/S0925231215015787
KW  - Multiple kernel learning
KW  - Nyström approximation
KW  - Reduced computation complexity
KW  - Generalization risk analysis
KW  - Pattern classification
KW  - Universum learning
AB  - Abstract
Universum learning can reflect priori knowledge about application domain and improve classification performances. The kernelized modification of Ho–Kashyap algorithm with squared approximation of the misclassification errors (KMHKS) is an effective learning machine for nonlinearly separable classification problems. While KMHKS only adopts one kernel function, so a multi-kernel classification machine with reduced complexity named Nyström approximation matrix with multiple KMHKSs (NMKMHKS) has been developed. But NMKMHKS has to initialize many parameters and it has not an ability to process noises well. To this end, some scholars propose an improved multi-kernel classification machine with Nyström approximation technique (INMKMHKS). INMKMHKS is based on a new way of generating kernel functions and a new Nyström approximation technique. Related experiments have validated that INMKMHKS possesses five advantages: (1) avoiding the problem of setting too many parameters; (2) keeping comparable space and computational complexities after comparing with NMKMHKS; (3) having a tighter generalization risk bound in terms of Rademacher complexity analysis; (4) possessing an ability to process noises and practical images; (5) a superior recognition can be gotten in a strong correlation between multiple used kernels, which can give a guide advice for choosing kernels. But for traditional multiple kernel learning (MKL), many classification machines including INMKMHKS focus on MKL optimizations, for example, the optimization of model for a MKL. It is difficult for us to find or create a new optimization way now. Indeed, if one pays more attention to data themselves, performance of MKL will also have an improvement. This paper adopts INMKMHKS as a basic learning machine and focuses on data themselves, then it introduces Universum learning into the procedure of INMKMHKS and proposes Universum-based INMKMHKS (Uni-INMKMHKS). The motivation of Uni-INMKMHKS is that it can design a learning machine from data perspective and avoid paying too much attention to MKL optimization which is difficult for scholars to some extent. The contribution of Uni-INMKMHKS is that it has a better recognition than INMKMHKS in average with Universum learning used and inherits the advantages of INMKMHKS simultaneously.
ER  - 

TY  - JOUR
T1  - Quantifying surface gradients with a 2-band Enhanced Vegetation Index (EVI2)
JO  - Ecological Indicators
VL  - 11
IS  - 3
SP  - 918
EP  - 924
PY  - 2011/5//
T2  - 
AU  - Mondal, Pinki
SN  - 1470-160X
DO  - http://dx.doi.org/10.1016/j.ecolind.2010.10.006
UR  - http://www.sciencedirect.com/science/article/pii/S1470160X10001779
KW  - Surface gradient model
KW  - Landscape metrics
KW  - EVI2
KW  - Landscape pattern
KW  - Protected area
KW  - India
AB  - Quantification of spatial and temporal heterogeneity has been given much attention in order to link ecological patterns to processes. The patch mosaic model, as an operational paradigm, has led to major advances in the field of quantitative landscape ecology. However, it is more realistic to conceptualize landscapes based on continuous rather than discrete spatial heterogeneity. While a conceptual shift has been proposed to supplement the patch mosaic model, few studies use the surface gradient model as a context. This paper explores some comparatively less-utilized metrics to quantify surface gradients in a protected landscape in Central India. Since surface metrics would require continuous variables capable of representing landscape characteristics, this study also explores the utility of a 2-band Enhanced Vegetation Index (EVI2) as a gradient surface. Findings suggest EVI2 relates strongly with discrete land cover classes and thus has potential to describe landscape characteristics without incorporating error through subjectivity. Surface metrics used in this study show potential to be effectively used in landscape level studies. However, these metrics were not developed for landscape level studies and should be used with caution, especially when dealing with multi-scale patterns and processes. Nevertheless, with the rapidly emerging field of surface metrology more studies need to apply these tools to quantify surface gradients and test the robustness of such metrics.
ER  - 

TY  - JOUR
T1  - Dawn′s exploration of Vesta
JO  - Acta Astronautica
VL  - 94
IS  - 1
SP  - 159
EP  - 167
PY  - 2014/1//
Y2  - 2014/2//
T2  - 
AU  - Rayman, Marc D.
AU  - Mase, Robert A.
SN  - 0094-5765
DO  - http://dx.doi.org/10.1016/j.actaastro.2013.08.003
UR  - http://www.sciencedirect.com/science/article/pii/S0094576513003123
KW  - Dawn
KW  - Ion propulsion
KW  - Solar electric propulsion
KW  - Asteroid
KW  - Vesta
KW  - Operations
AB  - Abstract
On 16 July 2011, after completing nearly four years of interplanetary flight, Dawn entered orbit around (4) Vesta, the second most massive body in the main asteroid belt. Dawn used solar electric propulsion to spiral to six different orbits to accomplish its science campaign. Although the transfers to progressively lower orbits presented significant challenges, all were executed smoothly. During its nearly 14 months in orbit, Dawn spiraled down to 210 km above the surface and back up before initiating the gradual departure to travel to dwarf planet (1) Ceres for a 2015 rendezvous. Dawn′s exploration of Vesta has shown it to be geologically complex and fascinating, resembling terrestrial planets more than typical asteroids. Among the principal features is a 500-km-diameter impact basin within which is the second tallest mountain known in the solar system. This paper presents Dawn′s operations at Vesta and summarizes the principal findings.
ER  - 

TY  - JOUR
T1  - Domain Analysis of the Research In Professional Competences, Technology and Engineering Cluster
JO  - Procedia - Social and Behavioral Sciences
VL  - 182
IS  - 
SP  - 163
EP  - 172
PY  - 2015/5/13/
T2  - 4th WORLD CONFERENCE on EDUCATIONAL TECHNOLOGY RESEARCHES (WCETR-2014)
AU  - Guerrero, Dante
AU  - Gerson, La Rosa
AU  - Patricia, Lopez
AU  - Lucia, Bayona Ana
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2015.04.752
UR  - http://www.sciencedirect.com/science/article/pii/S187704281503027X
KW  - Domain analysis
KW  - Professional competence
KW  - Engineering
KW  - Technology
AB  - AbstractObjective
The paper aims to apply scientific domain analysis and network analysis to research in professional competences and its relationship to technology and engineering.
Methodology
Network analysis is a tool of scientific domain analysis. Nowadays it is supported by technology and computer sciences, which allow the generation of network maps in order to process the information.
Results
The models of competences proposed for professionals in information technologies have been analyzed together with the importance of developing competency management systems and the support of computer technologies to this field.
Conclusions
Domain analysis facilitates the structuring and organization of information, which is very useful to the analysis of competences and its relation with technology and engineering, being a new subject of study.
ER  - 

TY  - JOUR
T1  - Referenced Publication Years Spectroscopy applied to iMetrics: Scientometrics, Journal of Informetrics, and a relevant subset of JASIST
JO  - Journal of Informetrics
VL  - 8
IS  - 1
SP  - 162
EP  - 174
PY  - 2014/1//
T2  - 
AU  - Leydesdorff, Loet
AU  - Bornmann, Lutz
AU  - Marx, Werner
AU  - Milojević, Staša
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2013.11.006
UR  - http://www.sciencedirect.com/science/article/pii/S1751157713001077
KW  - Cited references
KW  - Historiography
KW  - Citation classics
KW  - iMetrics
AB  - Abstract
We have developed a (freeware) routine for “Referenced Publication Years Spectroscopy” (RPYS) and apply this method to the historiography of “iMetrics,” that is, the junction of the journals Scientometrics, Informetrics, and the relevant subset of JASIST (approx. 20%) that shapes the intellectual space for the development of information metrics (bibliometrics, scientometrics, informetrics, and webometrics). The application to information metrics (our own field of research) provides us with the opportunity to validate this methodology, and to add a reflection about using citations for the historical reconstruction. The results show that the field is rooted in individual contributions of the 1920s to 1950s (e.g., Alfred J. Lotka), and was then shaped intellectually in the early 1960s by a confluence of the history of science (Derek de Solla Price), documentation (e.g., Michael M. Kessler's “bibliographic coupling”), and “citation indexing” (Eugene Garfield). Institutional development at the interfaces between science studies and information science has been reinforced by the new journal Informetrics since 2007. In a concluding reflection, we return to the question of how the historiography of science using algorithmic means—in terms of citation practices—can be different from an intellectual history of the field based, for example, on reading source materials.
ER  - 

TY  - JOUR
T1  - Author bibliographic coupling analysis: A test based on a Chinese academic database
JO  - Journal of Informetrics
VL  - 6
IS  - 4
SP  - 532
EP  - 542
PY  - 2012/10//
T2  - 
AU  - Ma, Ruimin
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2012.04.006
UR  - http://www.sciencedirect.com/science/article/pii/S1751157712000405
KW  - Author bibliographic coupling analysis
KW  - Author co-citation analysis
KW  - Domain mapping
KW  - Intellectual structure
AB  - The paper first introduces the basic problems of author bibliographic coupling including the relationship between author bibliographic coupling and document bibliographic coupling as well as the three calculation methods of author coupling strength, namely, simple method, minimum method and combined method. Next I choose a small sample of authors in Chinese library and information science (LIS) as the research objects to have a comparative analysis of three types of author coupling strength algorithms (the data source is from the Chinese Social Sciences Citation Index (CSSCI)). The result shows that the minimum method is the most appropriate one to calculate the author coupling strength. Then a large sample of authors is chosen to analyze the intellectual structure of Chinese LIS. The result shows that author bibliographic coupling analysis (ABCA) can discover the intellectual structure of a discipline better. It is also found that compared with author cocitation analysis (ACA), ABCA has the advantage that it not only can discover the intellectual structure of a discipline more comprehensively and concretely but also can reflect the research frontier of the discipline. Finally, some practical problems that arise during this research are discussed.
ER  - 

TY  - JOUR
T1  - Hydrogen distribution in the lunar polar regions
JO  - Icarus
VL  - 
IS  - 
SP  - 
EP  - 
PY  - 
T2  - 
AU  - Sanin, A.B.
AU  - Mitrofanov, I.G.
AU  - Litvak, M.L.
AU  - Bakhtin, B.N.
AU  - Bodnarik, J.G.
AU  - Boynton, W.V.
AU  - G. Chin
AU  - Evans, L.G.
AU  - Harshman, K.
AU  - Fedosov, F.
AU  - Golovin, D.V.
AU  - Kozyrev, A.S.
AU  - Livengood, T.A.
AU  - Malakhov, A.V.
AU  - McClanahan, T.P.
AU  - Mokrousov, M.I.
AU  - Starr, R.D.
AU  - Sagdeev, R.Z.
AU  - Tret'yakov, V.I.
AU  - Vostrukhin, A.A.
SN  - 0019-1035
DO  - http://dx.doi.org/10.1016/j.icarus.2016.06.002
UR  - http://www.sciencedirect.com/science/article/pii/S0019103516302639
KW  - Moon
KW  - surface
KW  - Regoliths
KW  - Ices
AB  - Abstract
We present a method of conversion of the lunar neutron counting rate measured by the Lunar Reconnaissance Orbiter (LRO) Lunar Exploration Neutron Detector (LEND) instrument collimated neutron detectors, to water equivalent hydrogen (WEH) in the top ∼1 m layer of lunar regolith. Polar maps of the Moon's inferred hydrogen abundance are presented and discussed.
ER  - 

TY  - JOUR
T1  - Climate Change, Wine and Sustainability: A Quantitative Discourse Analysis of the International Scientific Literature
JO  - Agriculture and Agricultural Science Procedia
VL  - 8
IS  - 
SP  - 167
EP  - 175
PY  - 2016///
T2  - Florence “Sustainability of Well-Being International Forum”. 2015: Food for Sustainability and not just food, FlorenceSWIF2015
AU  - Sacchelli, Sandro
AU  - Fabbrizzi, Sara
AU  - Menghini, Silvio
SN  - 2210-7843
DO  - http://dx.doi.org/10.1016/j.aaspro.2016.02.090
UR  - http://www.sciencedirect.com/science/article/pii/S2210784316300900
KW  - climatic change impact
KW  - intervention strategies
KW  - wine making
KW  - sustainable development
KW  - text mining
KW  - multidimensional scaling
KW  - research trend.
AB  - Abstract
The paper analyses the evolution and potential future trend of research debate related to climate change impacts on the wine chain. A particular emphasis was given to the evaluation of sustainability in the examined literature. From a methodological point of view, sets of text analysis techniques were combined for the investigation of those selected scientific papers. Results highlight that the detailed and in-depth examination of the subject is quite recent. Furthermore, the analysis of climate change on wine production sustainability is primarily focused on the environmental aspects and not to the socio-economic ones. Lastly, future potential research issues and aims for the examined topic were suggested.
ER  - 

TY  - JOUR
T1  - Strategies and symbolism in the adoption of organizational social networking systems
JO  - The Journal of Strategic Information Systems
VL  - 24
IS  - 1
SP  - 15
EP  - 32
PY  - 2015/3//
T2  - 
AU  - Karoui, Myriam
AU  - Dudezert, Aurélie
AU  - Leidner, Dorothy E.
SN  - 0963-8687
DO  - http://dx.doi.org/10.1016/j.jsis.2014.11.003
UR  - http://www.sciencedirect.com/science/article/pii/S0963868714000468
KW  - Social network analysis systems
KW  - Social capital
KW  - Symbolic capital
KW  - Adoption strategies
KW  - Case study
AB  - Abstract
Because of the important role being played by social networks, many organizations are turning to the use of social network systems to help manage these social networks and the accompanying social capital. When a social networking system is implemented in an organization, it may serve as a signal to organizational actors that social capital, heretofore largely ignored and invisible, will hereafter represent an important resource for the organization. As a result, individuals may consciously manipulate the system to either increase their own social capital or decrease the value of others’ social capital. In a case study of two organizations in the process of adopting an SAP-based social networking system, our research examines how groups of actors develop strategies to control the social networking system as well as the symbolic capital that emerges during the adoption of the system.
ER  - 

TY  - JOUR
T1  - Co-Insights framework for collaborative decision support and tacit knowledge transfer
JO  - Expert Systems with Applications
VL  - 45
IS  - 
SP  - 85
EP  - 96
PY  - 2016/3/1/
T2  - 
AU  - Zhong, Hao
AU  - Ozsoy, Engin
AU  - Nof, Shimon Y.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2015.09.036
UR  - http://www.sciencedirect.com/science/article/pii/S095741741500665X
KW  - Best matching
KW  - Collaborative control theory
KW  - Collaborative visual analytics
KW  - Decision support
KW  - Knowledge transfer
AB  - Abstract
Abundant software tools use visual analytics (VA) techniques to support various decisions with the aim of boosting better insights. Large organizations, however, lose efficiency in selecting the right tools to support the persons who apply the tools to various decision tasks. Consequently, the creation and sharing of insights are far from optimal, leading consistently to sub-optimal decisions. In this work, the Co-Insights framework is introduced with automated collaboration support features to enable effective creation and sharing of distributed insights. A collaboration network (Co-Net) is established to model the collaborative decision making process in an organization. Two important features of the Co-Insights framework are developed: collaborative agent allocation analysis (CA3) for task–participant matching; and a robust mechanism for the recommendation of selected VA tools, by participant–tool matching. Thus, by better matching of tasks and tools with participants, the creation and sharing of insights are improved in any collaborative team for better decision making, accompanied with the tacit knowledge transfer to sustain the entire organization. To validate the effectiveness of these two main features, two experiments built on the Co-Net model are performed to test the newly developed algorithms. It has been found that CA3 significantly improves the matching scores by up to 35%, compared with conventional task–participant matching methods. The neural network based participant–tool matching mechanism yields robust results with 4% mismatches for 10% noise levels, and with 16% mismatches for 30% noise levels. Real case applications and implications are described, and further plans to extend this new framework are also outlined based on the reported experiments and evaluations.
ER  - 

TY  - JOUR
T1  - A scientific approach with bibliometric analysis related to brick and tile drying: A review
JO  - Renewable and Sustainable Energy Reviews
VL  - 59
IS  - 
SP  - 206
EP  - 224
PY  - 2016/6//
T2  - 
AU  - Yataganbaba, Alptug
AU  - Kurtbaş, İrfan
SN  - 1364-0321
DO  - http://dx.doi.org/10.1016/j.rser.2015.12.357
UR  - http://www.sciencedirect.com/science/article/pii/S136403211600023X
KW  - Drying
KW  - Porous media
KW  - Brick/tile drying
KW  - Bibliometric analysis
AB  - Abstract
Extensive analyses of technological developments and technology foresight studies have been vital to help prepare possible scientific scenarios for the future. The primary purpose of this type of foresight study is to utilise methods and attempt to assess development trends in science and technology. This paper presents an approach to find out the various trends in scientific studies in the field of drying brick/tile that are occurring in the world. All documents used in this study were obtained from the Scopus database. To shed light on drying trends, both bibliometric and network analyses were conducted in this research. For the bibliometric analysis, the Scopus database was systematically searched to obtain a dataset in relation to the drying of brick/tile. The year range covered from 1980 to 2015. On the other hand, the patent data used in the study were taken from the Espacenet international patent database. The same keywords coupled with bibliometric analysis were used to find the relevant patent data. Some parameters were considered, such as the number of documents, authorship and ownership, patterns of international collaborations, address, and number of times cited. The collaboration networks with co-citation analysis for authors were also analysed in this study. Significant growth is observed in scientific production particularly in the period from 2000–2015. The countries that became evident as most productive on a scientific basis are the United States, Germany and China.
ER  - 

TY  - JOUR
T1  - Approaches to validating a mutual participatory web-planning interface in rural Extremadura (Spain)
JO  - Land Use Policy
VL  - 39
IS  - 
SP  - 211
EP  - 223
PY  - 2014/7//
T2  - 
AU  - Jeong, Jin Su
AU  - Hernández-Blanco, Julio
AU  - García-Moruno, Lorenzo
SN  - 0264-8377
DO  - http://dx.doi.org/10.1016/j.landusepol.2014.02.014
UR  - http://www.sciencedirect.com/science/article/pii/S0264837714000349
KW  - Participatory web
KW  - Collaborative planning
KW  - Rural building integration
KW  - Tourism
KW  - User perceptions
KW  - Knowledge sharing
AB  - Abstract
In this work, a mutual participatory web-planning interface was developed to support rural tourism building integrations into a landscape that combines multi-criteria decision analysis (MCDA); an application of the proposed interface for the Hervás region (northern Extremadura region) in Spain is further presented. Through the web interface with the given methods, stakeholders can reflect upon their individual experiences to achieve desirable planning outcomes through asynchronous, distributed collaboration with the public. Based on the qualitative and quantitative content and survey data set, this study examined the identification of spatial models that could implement different perceptions and promote the sharing of knowledge about integrating buildings into a rural landscape, the certification of the possible impact on tourism and the refining of the interface's usability. To strengthen data interpretation, these hypotheses were analysed by four different clusters of people with the aid of the analysis of variance (ANOVA) and principal component analysis (PCA) tests: weak ties, socially linked, roots and resources, and dedicated to the place, based on social and emotional terms. In general, most participants gave a positive response to the questions and an interesting fact amongst the findings was the difference between roots and resources (positive to building integrations) and dedicated to the place (negative to building integrations). Thus, the analysed results demonstrated that the web interface could achieve a consensus on recommendations for the spatial planning with the implementation of decision alternatives and understanding of the other interest groups’ preferences.
ER  - 

TY  - JOUR
T1  - Conscious worst case definition for risk assessment, part II: A methodological case study for pesticide risk assessment
JO  - Science of The Total Environment
VL  - 408
IS  - 18
SP  - 3860
EP  - 3870
PY  - 2010/8/15/
T2  - Cumulative Stressors - Risk assessment of mixtures of chemicals and combinations of chemicals and natural stressors
AU  - Sørensen, Peter B.
AU  - Giralt, Francesc
AU  - Rallo, Robert
AU  - Espinosa, Gabriela
AU  - Münier, Bernd
AU  - Gyldenkærne, Steen
AU  - Thomsen, Marianne
SN  - 0048-9697
DO  - http://dx.doi.org/10.1016/j.scitotenv.2009.11.030
UR  - http://www.sciencedirect.com/science/article/pii/S0048969709011450
KW  - Ecological risk assessment
KW  - Hasse diagram technique
KW  - Linear extension
KW  - Neural networks
KW  - Partial order
KW  - Pesticides
KW  - Ranking
KW  - WCD model
AB  - This paper illustrates, by a case study, how to apply the conceptual Worst-Case Definition (WCD) model, developed in the methodological paper in the current journal, by Sørensen et al. (2010-this issue). The case is about eco-toxicological risk assessment of pesticides under Danish conditions. Cumulative aspects are included on a conceptual basis as elements of the worst-case conditions. This defines factors that govern the risk assessment, including location in time and space of risk “hotspots”. Two pillars of concern drive the conceptual modelling: (1) What to protect (denoted Protected Units (PUs)) and (2) the reason for increased risk level (denoted Causes of Risks (CRs)). Both PUs and CRs are analysed using hierarchical procedures that facilitate a complete listing of concrete factors governing increased risk for adverse effect due to agricultural usage of pesticide. The factors governing pesticide risk are combined in a context that combines the protection of relevant groupings of organisms with the factors for increased risk level for each of these. Identification of the most important relations between defined types of PUs and CRs is illustrated using expert knowledge. Existing databases are used to form spatial distributed risk indicators as estimators for a selection of important relations between PUs and CRs. This paper illustrates how the WCD model can break down the complex issue of uncertainty into fractions that are more open for evaluations. Finally, it shows application of risk indicators in a multi-criterion analysis using respectively self organizing mapping and partial order technique in a comparative analysis that highlights critical aspects of uncertainty, due to the ambiguity between single risk indicator rankings.
ER  - 

TY  - JOUR
T1  - On contradiction clouds
JO  - Procedia Engineering
VL  - 9
IS  - 
SP  - 368
EP  - 378
PY  - 2011///
T2  - Proceeding of the ETRIA World TRIZ Future Conference
AU  - Cavallucci, Denis
AU  - Rousselot, François
AU  - Zanni, Cecilia
SN  - 1877-7058
DO  - http://dx.doi.org/10.1016/j.proeng.2011.03.126
UR  - http://www.sciencedirect.com/science/article/pii/S1877705811001433
KW  - Contradiction
KW  - Clouds
KW  - TRIZ
KW  - Problem framing
AB  - Our proposal, through this article, addresses the issue of obtaining, representing and selecting the appropriate subset of contradictions among a complete set of contradictions resulting from an initial situation framing within a specific domain. This contribution has to be understood within the Inventive Design context since most of its grounding relies on the fact that any problem can be formulated as a contradiction (in the sense of TRIZ). By proposing the concept of “contradiction cloud” as three value graphical representation of a set of elementary contradictions, we claim that designers considerably reduce the fuzziness of a contradiction choice prior entering in a solving phase in Inventive Design processes. The modes of interpretation of this cloud will be also presented. The impact of this new element in the teaching of TRIZ was tested both in educational situations within the framework of our engineering curriculum and in several industrial partnerships. A discussion section will then highlight the assets, the limits and the perspectives of our contribution.
ER  - 

TY  - JOUR
T1  - Building ontology based knowledge maps to assist business process re-engineering
JO  - Decision Support Systems
VL  - 52
IS  - 3
SP  - 577
EP  - 589
PY  - 2012/2//
T2  - 
AU  - Rao, Lila
AU  - Mansingh, Gunjan
AU  - Osei-Bryson, Kweku-Muata
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2011.10.014
UR  - http://www.sciencedirect.com/science/article/pii/S0167923611001862
KW  - Business process reengineering
KW  - Ontology
KW  - Knowledge maps
KW  - Knowledge management
AB  - Business Process Re-engineering (BPR) is being used to improve the efficiency of the organizational processes, however, a number of obstacles have prevented its full potential from being realised. One of these obstacles is caused by an emphasis on the business process itself at the exclusion of considering other important knowledge of the organization. Another is due to the lack of tools for identifying the cause of the inefficiencies and inconsistencies in BPR. In this paper we propose a methodology for BPR that overcomes these two obstacles through the use of a formal organizational ontology and knowledge structure and source maps. These knowledge maps are represented formally to facilitate an inferencing mechanism which helps to automatically identify the causes of the inefficiencies and inconsistencies. We demonstrate the applicability of this methodology through the use of a case study of a university domain.
ER  - 

TY  - JOUR
T1  - Knowledge management: An information science perspective
JO  - International Journal of Information Management
VL  - 30
IS  - 5
SP  - 416
EP  - 424
PY  - 2010/10//
T2  - 
AU  - Kebede, Gashaw
SN  - 0268-4012
DO  - http://dx.doi.org/10.1016/j.ijinfomgt.2010.02.004
UR  - http://www.sciencedirect.com/science/article/pii/S0268401210000290
KW  - Information science
KW  - Knowledge management
KW  - Information management
KW  - Knowledge hierarchy
KW  - Scope of knowledge management
AB  - Knowledge management (KM) is an emerging field of specialization in a number of professions, including Information Science (IS). The different professions are contributing to and influencing the developments in KM in their own ways. However, it is argued here that IS is not contributing to the advancement of KM as much as it should for a number of apparent reasons. The main purpose of the paper is to call on the members of the IS profession to take a more proactive and visible role in advancing KM by showing that KM is a natural and long-awaited development in IS and that a number of circumstances have made KM to be an area of emphasis in IS whose time has come. The paper also aims at contributing towards achieving a consensus among IS professionals on conceptualization, goals, and scope of KM in IS. The recommendations of the paper focus on how the profession could proactively be involved in advancing KM.
ER  - 

TY  - JOUR
T1  - Combining analytic and experiential communication in participatory scenario development
JO  - Landscape and Urban Planning
VL  - 107
IS  - 3
SP  - 203
EP  - 213
PY  - 2012/9/15/
T2  - 
AU  - Vervoort, J.M.
AU  - Kok, K.
AU  - Beers, P.-J.
AU  - Van Lammeren, R.
AU  - Janssen, R.
SN  - 0169-2046
DO  - http://dx.doi.org/10.1016/j.landurbplan.2012.06.011
UR  - http://www.sciencedirect.com/science/article/pii/S0169204612001971
KW  - Communication
KW  - Public participation
KW  - Social–ecological systems change
KW  - Scenarios
KW  - Visualization
AB  - This paper explores the need to combine analytic understanding and experiential engagement in communication on social–ecological systems futures. Humans use two distinct mental modes to deal with salient information: analytic processing and experiential processing. Tools combining both modes of processing can help societal actors seeking to stimulate active and informed environmental governance to facilitate both understanding of and engagement with social–ecological systems. In this paper, we combine two tools, each geared to one mode of communication. The System Perspectives Scope is a tool aimed at eliciting and sharing analytic perspectives on social–ecological systems change. ScenarioCommunities facilitates the communication of perspectives on the future in an engaging experiential mode. We applied these two tools in two scenario workshops in Oxfordshire. Each workshop featured the tools in a different order to compare the effects across tools. The System Perspectives Scope was able to elicit participants’ analytic perspectives and let them reflect on the systems they described. ScenarioCommunities communicated animated scenario storyline segments in a vivid and engaging experiential mode. This stimulated participants to create individual, experiential perspectives on the scenarios. The workshop that started with experiential engagement yielded reinforcing effects of the first tool on the second. This study shows that analytic and experiential communication can be used to generate both understanding of and engagement with social–ecological systems change. The study also indicates that the social–ecological systems frame used to develop these tools entails that they offer complementary advantages when compared to tools used in participatory landscape ecology and participatory modeling.
ER  - 

TY  - JOUR
T1  - Knowledge Management in Open Innovation Paradigm Context: High Tech Sector Perspective
JO  - Procedia - Social and Behavioral Sciences
VL  - 110
IS  - 
SP  - 164
EP  - 173
PY  - 2014/1/24/
T2  - The 2-dn International Scientific conference „Contemporary Issues in Business, Management and Education 2013“
AU  - Žemaitis, Eigirdas
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2013.12.859
UR  - http://www.sciencedirect.com/science/article/pii/S1877042813054992
KW  - open innovation
KW  - high tech
KW  - knowledge management
KW  - knowledge transfer
KW  - serious play
KW  - tacit knowledge
AB  - Abstract
Open innovation paradigm is new contemporary innovation phenomena. Innovation activities in high tech sector require broad level of collaborative, creative efforts and effective knowledge management models for the companies. Theories of knowledge creation inside organisation are based on systematic ways to create procedures and tools for collecting knowledge. Although new communication paradigms and collaborative working environments are not enough reflected as possible tools for creation of knowledge for innovation processes. Fast and successful development of high technology companies requires non-linear thinking and disruptive creative solutions for the market. Main aim of this article is to propose practical framework for knowledge exchange inside companies, using new interdisciplinary communicative learning tools.
ER  - 

TY  - JOUR
T1  - Using Web 2.0 Technology to Enhance Knowledge Sharing in an Academic Department
JO  - Procedia - Social and Behavioral Sciences
VL  - 102
IS  - 
SP  - 406
EP  - 420
PY  - 2013/11/22/
T2  - 6th International Forum on Engineering Education (IFEE 2012)
AU  - Balubaid, Mohammed A
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2013.10.756
UR  - http://www.sciencedirect.com/science/article/pii/S1877042813042924
KW  - Web 2.0
KW  - Kowledge Sharing
KW  - Academic
KW  - Engineering Education.
AB  - Abstract
Academic departments at colleges and universities perform various functions that involve teaching, scheduling, registration and course management. As new technologies emerge and digital culture evolves, academic departments need to decide which technologies to adopt and when to implement them in order to continue functioning effectively. Nowadays, knowledge is regarded as a strategic resource in organizations; therefore the leverage of knowledge is a key decision-making issue. Research has shown that Web 2.0 technologies such as social networks are easy to use and familiar, allowing learners to share and generate knowledge within the small group environment. This study examines the use of Web 2.0 technologies as platforms for sharing knowledge between the Industrial Engineering department of King Abdulaziz University and its students. This was done by carrying out a survey of the students, from which 77 valid responses were collected. The survey found that a significant percentage of students reported that the current knowledge-sharing process in the department, using notice boards, is acceptable and good but that it needs to improve to reach more students. Knowledge of scheduling and registration was said by the largest number of participants to be the type that they most strongly preferred to be shared. Finally, 70% of the students chose Facebook as the best platform for sharing knowledge and information between students and the department, 16% chose Twitter, 13% Google+ and 1% others.

This study is original, not only for being one of the first in Saudi Arabia, but for being one of the few to explore the use of Web 2.0 technology for sharing knowledge between an academic department and its students.
ER  - 

TY  - JOUR
T1  - Knowledge cultivating for intelligent decision making in small &amp; middle businesses
JO  - Procedia Computer Science
VL  - 1
IS  - 1
SP  - 2479
EP  - 2488
PY  - 2010/5//
T2  - ICCS 2010
AU  - Li, Xingsen
AU  - Zhu, Zhengxiang
AU  - Pan, Xuwei
SN  - 1877-0509
DO  - http://dx.doi.org/10.1016/j.procs.2010.04.280
UR  - http://www.sciencedirect.com/science/article/pii/S1877050910002814
KW  - Intelligent knowledge mangament
KW  - Knowledge cultivating
KW  - Decision making
KW  - Small and a middle businesses
KW  - Extenics
AB  - Small and middle businesses (SMBs) are playing an increasingly important role, but their decision making process mostly relies on skilled employees which are usually inadequate. Based on information systems, data mining and Extension Theory (Extenics), we present a knowledge cultivating method and design a knowledge management platform for improve decision making quality. Through divergence analysis, correlation analysis, and implication analysis, a flow chart of knowledge cultivating algorithm has been designed, and an intelligent knowledge management platform has been developed. By collecting knowledge or information from conditions and the goal, we choose several knowledge as seed, then distribute it to all the department leaders, let them input relative knowledge including data mining knowledge to the platform. The platform then connects them into a knowledge tree with Human-Computer Interaction and enterprise ontology techniques intelligently. From the knowledge tree, we can find the problem solving map and guide the managers in SBMs to take actions by scanning all possible paths. The application in a food company proved its practicality value.
ER  - 

TY  - JOUR
T1  - The Status of Project Management within a City Hall of a European Capital
JO  - Procedia - Social and Behavioral Sciences
VL  - 74
IS  - 
SP  - 305
EP  - 315
PY  - 2013/3/29/
T2  - Selected papers from the 26th IPMA (International Project Management Association), World Congress, Crete, Greece, 2012
AU  - Hlodversdottir, Kolbrun Hlin
AU  - Ingason, Helgi Thor
AU  - Jonasson, Haukur Ingi
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2013.03.028
UR  - http://www.sciencedirect.com/science/article/pii/S1877042813004576
KW  - Project management maturity
KW  - municipality
KW  - knowledge management
AB  - We live in times of changes. The credit-crunch has affected businesses and organisations all over the world, its consequences being layoffs, cutbacks in projects due to lack of funding amongst other things. The municipality of Reykjavik is no exception; it is one of the largest workplaces in Iceland with operations that are diverse and complex. Employees are well educated specialists and many have studied management. No PMO is in place, and therefore there is no standardized set of practices and procedures regarding the preparation and execution of projects, nor a centralized documentation of projects completed (or failed). The Human Resource System does not list the abilities and education of its employees and no formal knowledge management is practiced. The level of project management maturity is uncertain and this paper attempts to give an overview of the maturity level of the municipality. Finally a suggestion is made on how project- and knowledge management might be strengthened in order to increase support and cooperation between offices and departments, enhance project management consciousness and -skills and improve the efficiency of municipal organisations.
ER  - 

TY  - JOUR
T1  - Title Paper: Natural computing: A problem solving paradigm with granular information processing
JO  - Applied Soft Computing
VL  - 13
IS  - 9
SP  - 3944
EP  - 3955
PY  - 2013/9//
T2  - 
AU  - Pal, Sankar K.
AU  - Meher, Saroj K.
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2013.06.026
UR  - http://www.sciencedirect.com/science/article/pii/S1568494613002159
KW  - Natural computing
KW  - Granular computing
KW  - Soft computing
KW  - Hybrid model
KW  - Decision systems
AB  - Abstract
Natural computing, inspired by biological course of action, is an interdisciplinary field that formalizes processes observed in living organisms to design computational methods for solving complex problems, or designing artificial systems with more natural behaviour. Based on the tasks abstracted from natural phenomena, such as brain modelling, self-organization, self-repetition, self evaluation, Darwinian survival, granulation and perception, nature serves as a source of inspiration for the development of computational tools or systems that are used for solving complex problems. Nature inspired main computing paradigms used for such development include artificial neural networks, fuzzy logic, rough sets, evolutionary algorithms, fractal geometry, DNA computing, artificial life and granular or perception-based computing. Information granulation in granular computing is an inherent characteristic of human thinking and reasoning process performed in everyday life. The present article provides an overview of the significance of natural computing with respect to the granulation-based information processing models, such as neural networks, fuzzy sets and rough sets, and their hybridization. We emphasize on the biological motivation, design principles, application areas, open research problems and challenging issues of these models.
ER  - 

TY  - JOUR
T1  - Cognitive, metacognitive and motivational perspectives on preflection in self-regulated online learning
JO  - Computers in Human Behavior
VL  - 32
IS  - 
SP  - 313
EP  - 323
PY  - 2014/3//
T2  - 
AU  - Lehmann, Thomas
AU  - Hähnlein, Inka
AU  - Ifenthaler, Dirk
SN  - 0747-5632
DO  - http://dx.doi.org/10.1016/j.chb.2013.07.051
UR  - http://www.sciencedirect.com/science/article/pii/S0747563213002902
KW  - Self-regulated learning
KW  - Online education
KW  - Preflection
KW  - Reflection
KW  - Prompting
AB  - Abstract
Self-regulated learning is regarded as a critical component of successful online education. Hence, the development of effective online education requires an orchestration of external control and freedom for self-regulation. Prompts are regarded as effective means for promoting such personalised and adaptive learning processes in online education. Within two experimental studies, the effectiveness of preflective and reflective prompts is tested. Additionally, personal characteristics such as motivation and learning preferences are controlled. Results indicate that directed preflective prompts work best for novice learners. Such prompts also activate positive motivation within online learning environments. Still, more research is needed for investigating personalised and adaptive realisation of preflective prompts as well as automated feedback for SRL.
ER  - 

TY  - JOUR
T1  - Contextually relevant pedagogical agents: Visual appearance, stereotypes, and first impressions and their impact on learning
JO  - Computers & Education
VL  - 55
IS  - 2
SP  - 576
EP  - 585
PY  - 2010/9//
T2  - 
AU  - Veletsianos, George
SN  - 0360-1315
DO  - http://dx.doi.org/10.1016/j.compedu.2010.02.019
UR  - http://www.sciencedirect.com/science/article/pii/S0360131510000539
KW  - Pedagogical agents
KW  - Virtual characters
KW  - Stereotypes
KW  - Visual appearance
KW  - Contextual relevance
AB  - Humans draw on their stereotypic beliefs to make assumptions about others. Even though prior research has shown that individuals respond socially to media, there is little evidence with regards to learners stereotyping and categorizing pedagogical agents. This study investigated whether learners stereotype a pedagogical agent as being knowledgeable or not knowledgeable and how this acuity influenced learning. Participants were assigned to four experimental conditions differing by agent (scientist or artist) and tutorial type (nanotechnology or punk rock). Quantitative analyses indicated that agents were stereotyped depending on their image and the academic domain under which they functioned. Regardless of tutorial, participants assigned to the artist agent recalled more information than participants assigned to the scientist agent. Learning differences between the groups varied according to whether agent appearance fit the content area under investigation. Qualitative results indicated learner's stereotypic expectations as well as their unwillingness to draw conclusions based on visual appearance.
ER  - 

TY  - JOUR
T1  - Modelling in evaluating a working life project in higher education
JO  - Studies in Educational Evaluation
VL  - 38
IS  - 2
SP  - 55
EP  - 64
PY  - 2012/6//
T2  - 
AU  - Sarja, Anneli
AU  - Janhonen, Sirpa
AU  - Havukainen, Pirjo
AU  - Vesterinen, Anne
SN  - 0191-491X
DO  - http://dx.doi.org/10.1016/j.stueduc.2012.06.001
UR  - http://www.sciencedirect.com/science/article/pii/S0191491X12000296
KW  - Program evaluation
KW  - Evaluation methods
KW  - Evaluation utilisation
KW  - Systems approach
KW  - Work-related learning
AB  - This article describes an evaluation method based on collaboration between the higher education, a care home and university, in a R&amp;D project. The aim of the project was to elaborate modelling as a tool of developmental evaluation for innovation and competence in project cooperation. The approach was based on activity theory. Modelling enabled a development of the curriculum and encouraged stakeholders to participate in the evaluation process. The results verified the features of the method: (1) the contradictions of the joint practice are a central source of evaluation; (2) comprehensive data collection methods are needed; (3) shared tools can be developed in interactive forums in ongoing evaluation, and (4) modelling makes professional expertise visible and brakes boundaries between different professions.
ER  - 

TY  - JOUR
T1  - A meta-modelling framework for knowledge consistency in collaborative design
JO  - Annual Reviews in Control
VL  - 36
IS  - 2
SP  - 346
EP  - 358
PY  - 2012/12//
T2  - 
AU  - Belkadi, Farouk
AU  - Dremont, Nicolas
AU  - Notin, Alban
AU  - Troussier, Nadege
AU  - Messadia, Mourad
SN  - 1367-5788
DO  - http://dx.doi.org/10.1016/j.arcontrol.2012.09.016
UR  - http://www.sciencedirect.com/science/article/pii/S136757881200051X
AB  - The design of complex system requires a lot of interactions between experts and then between numerous Computer Aided X software (CAX) (where X can be Design (CAD), Engineering (CAE), Manufacturing (CAM), etc.). In order to improve the consistency of the whole system design and the related data and information, knowledge crossing the expertises must be tracked and formalized regarding a shared reference. That means that instead of defining a large reference models to which each expert refers to, a light collaborative model is defined enabling to connect data from each expert model to adhoc data from other expert models, following the least commitment principle. In this topic, a new meta-model is proposed in a Model-Driven Engineering approach to manage the integration of heterogeneous experts’ knowledge models in a collaborative process. The structure of the proposed knowledge meta-model is defined taking into account the complexity of knowledge definition and the properties of its components. This meta-model is split in a meta-model of data on one hand and a Collaboration Meta-Model in the other hand, to represent the distinction between the core concepts of knowledge and additional elements serving to represent the relation between these concepts, and between concepts of heterogeneous experts’ models. The proposed meta-model is illustrated on an industrial case study to highlight the way to put it in use, and its interests to enable collaboration between experts throughout the design process.
ER  - 

TY  - JOUR
T1  - A novel intelligent protection system for power transformers considering possible electrical faults, inrush current, CT saturation and over-excitation
JO  - International Journal of Electrical Power & Energy Systems
VL  - 64
IS  - 
SP  - 1129
EP  - 1140
PY  - 2015/1//
T2  - 
AU  - Yazdani-Asrami, Mohammad
AU  - Taghipour-Gorjikolaie, Mehran
AU  - Mohammad Razavi, S.
AU  - Asghar Gholamian, S.
SN  - 0142-0615
DO  - http://dx.doi.org/10.1016/j.ijepes.2014.08.008
UR  - http://www.sciencedirect.com/science/article/pii/S0142061514005341
KW  - Magnetizing inrush current
KW  - Internal fault
KW  - CT saturation
KW  - Over-excitation
KW  - Bayesian classifier
KW  - Improved gravitational search algorithm
AB  - Abstract
Many electrical events can be easily damage electrical equipments in power systems. Such events or faults can be easily stopped at incipient steps but because of weakness of protecting systems they grow and extend, and consequently impose so many problems and cost to utilities. Power transformers are one of the vital equipments in electrical networks and industries, although many protecting systems have been implemented to prevent dangerous electrical faults, but most of them suffer many problems, such as; time wasting, computational burden, and low speed in response. In addition, whenever patterns of fault signals are similar, their discrimination from each other is so hard. Magnetizing inrush current, internal fault, CT saturation and over excitation are common electrical faults in power transformers so that most of the time are difficult to be separated. In this paper all considerations for designing perfect protecting system for power transformers are considered. Using intelligent approach, Artificial Neural Network (ANN) based method is designed. Indeed, proposed protecting system includes two major sections. In the first section, using Bayesian Classifier (BC) which works based on Bayesian rules and uses knowledge of training data directly; internal fault is detected and is discriminated from three other mentioned faults and normal condition. If the event is not internal fault, second condition of this intelligent system makes a decision. In this section, ANN trained by swarm based algorithms, namely; Improved Gravitational Search Algorithm (IGSA) or Particle Swarm Optimization (PSO) is used to discriminate magnetizing inrush current, current transformer (CT) saturation and over excitation. Obtained results show that proposed system can easily and precisely follow the electrical faults in power transformer and detect them at incipient steps. Such quick and accurate response helps to save so much energy, financial cost and time.
ER  - 

TY  - JOUR
T1  - Ontology design and individual cognitive peculiarities: A pilot study
JO  - Expert Systems with Applications
VL  - 42
IS  - 8
SP  - 3883
EP  - 3892
PY  - 2015/5/15/
T2  - 
AU  - Gavrilova, Tatiana A.
AU  - Leshcheva, Irina A.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2015.01.008
UR  - http://www.sciencedirect.com/science/article/pii/S0957417415000238
KW  - Ontologies
KW  - Knowledge engineering
KW  - Cognitive style
KW  - Conceptual structuring
KW  - Collaborative design
KW  - Cognitive ergonomics
AB  - Abstract
The paper presents the main results of the KOMET (Knowledge and cOntent structuring via METhods of collaborative ontology design) project, which aims to develop a novel paradigm for knowledge structuring based on the interplay between cognitive psychology and ontology engineering. By the knowledge structure (a conceptual model) we define the main domain concepts and relations between them in the form of a graph, map or diagram. This approach considers individual cognitive styles and uses recent advances in knowledge engineering and conceptual structuring; it aims to create new, consistent and structurally holistic knowledge bases for various areas of science and technology. Two stages of research have been completed: research into correlations between the expert’s individual cognitive style and the peculiarities of the expert’s subject domain ontology development; and research into correlations between the expert’s individual cognitive style and the group ontology design (including design accomplished by groups of experts with either similar or different cognitive styles). The results of these research stages can be applied to organizing collaborative ontology design (especially for research and learning purposes), data structuring and other group analytical work. Implications for practice are briefly delineated.
ER  - 

TY  - JOUR
T1  - The study of building integration into the surrounding rural landscape: Focus on implementation of a Web-based MC-SDSS and its validation by two-way participation
JO  - Land Use Policy
VL  - 57
IS  - 
SP  - 719
EP  - 729
PY  - 2016/11/30/
T2  - 
AU  - Jeong, Jin Su
AU  - García-Moruno, Lorenzo
SN  - 0264-8377
DO  - http://dx.doi.org/10.1016/j.landusepol.2016.07.005
UR  - http://www.sciencedirect.com/science/article/pii/S0264837716301740
KW  - Participatory DMs
KW  - Web MC-SDSS
KW  - Two-way participation
KW  - Building suitability
KW  - MCDA order
KW  - Perception analysis
AB  - Abstract
Everyday people are tackling various decisions. Decision problems in the spatial planning sense often are involved with many alternatives because of their complicated characters and are evaluated on multiple-perspectives based. This paper deals with the implementation of a Web-based Multi-Criteria Spatial Decision Support System (MC-SDSS) and its validation by two-way participation aimed at assessing the suitability of new rural tourism buildings integration occurred in Spanish landscapes. The proposed system focuses on the methodology combined with Multi-Criteria Decision Analysis (MCDA) that borrows Geographic Information System (GIS) capabilities. Several parameters with an overlay and index method are used to evaluate the suitability of a case study area in Spain. Based on the results of a previous work where the authors defined the first phases of a conceptual framework implementation and prototype application with the methodology, this paper presents the final web implementation and its validation. The implementation was consisted of four consecutive sections with improvements from the previous one. Then, it showed the validated results with radar diagrams, reflecting the different perception of spatial models based on the qualitative two-way content and survey data, public and academic participation, according to the sense of place and field concept. The results contribute consensus on recommendation and new knowledge within the broader field of the analysis and interpretation of the building integration with the Web-based MC-SDSS, which is fundamental to support proper land-uses and decision alternatives through accurate and efficient tool, and to able to apply other destinations.
ER  - 

TY  - JOUR
T1  - Knowledge Strategy: Key Player or Relict of the Past?
JO  - Procedia - Social and Behavioral Sciences
VL  - 150
IS  - 
SP  - 628
EP  - 636
PY  - 2014/9/15/
T2  - 10th International Strategic Management Conference 2014
AU  - Mládková, Ludmila
SN  - 1877-0428
DO  - http://dx.doi.org/10.1016/j.sbspro.2014.09.082
UR  - http://www.sciencedirect.com/science/article/pii/S1877042814051313
KW  - knowledge
KW  - knowledge strategy
KW  - codification strategy
KW  - personalisation strategy
KW  - system of organisational management
AB  - Abstract
The article discusses the role of knowledge strategy in organisation. Knowledge and the way how organisations work with it directly influences their readiness for action and success, especially in knowledge society. Knowledge consists of two dimensions, explicit and tacit. Although all organisations work with both dimensions, one of them is usually more important for concrete organisation. Based on their leading knowledge dimension, organisations can choose between two basic knowledge strategies, a codification or a personalisation strategy. Codification strategy is more convenient for organisations for which explicit knowledge is the leading one; personalisation strategy supports the work with tacit knowledge. Historically organisations were recommended to choose one of the strategies and to stick to it. When we look at latest case studies and empiric researches we see that many organisations do not choose one knowledge strategy and try to address both dimensions of knowledge equally. Is it good decision or no? Is it still true that every organisation has one leading dimension of knowledge and should choose correct knowledge strategy to become successful? The article tries to find some answers to this question on the example of top knowledge institution, University of Economics, Prague.
ER  - 

TY  - CHAP
AU  - Artero, V.
AU  - Chandezon, F.
AU  - Co, D.T.
AU  - Dietzek, B.
T1  - Chapter Seven - European and International Initiatives in the Field of Artificial Photosynthesis
A2  - Bruno Robert
BT  - Advances in Botanical Research
PB  - Academic Press
PY  - 2016///
VL  - Volume 79
SP  - 193
EP  - 221
T2  - Artificial Photosynthesis
SN  - 0065-2296
DO  - http://dx.doi.org/10.1016/bs.abr.2016.03.002
UR  - http://www.sciencedirect.com/science/article/pii/S006522961630043X
KW  - Artificial photosynthesis
KW  - European Energy Research Alliance
KW  - International Energy Agency
KW  - Photoelectrochemical water splitting
KW  - Solar fuels
KW  - Solar Fuels Institute
AB  - Abstract
In a context of the rising awareness of the need for alternative renewable energy sources to achieve a low-carbon society, artificial photosynthesis, that is, the possibility to directly convert solar energy to chemical energy, is an appealing emerging energy technology. Mimicking the photosynthetic process, the endeavour is to produce a fuel, called solar fuel. We present here a bibliometric analysis showing the evolution of the field in recent years and mapping the emerging academic key actors. This young multidisciplinary research area is swiftly developing, and several European and international initiatives have emerged in recent years to foster its development towards the market. Although artificial photosynthesis is still at the laboratory level, it is also attracting the interest of industries. Many national initiatives in Europe, United States and Asia focussing on artificial photosynthesis have been launched. On the European side, the field begins to be addressed in the agendas of the EU framework programmes as well as in dedicated COST actions (Perspect-H2O) or in the Joint Programme ‘Advanced Materials and Processes for Energy Applications’ from the European Energy Research Alliance. Other international initiatives focussing on artificial photosynthesis are the International Energy Agency, the Solar Fuels Institute and the Energy Innovation Hub and several Energy Frontier Research Centers in United States. There are also dedicated conferences such as the Gordon Research Conference series on Solar Fuels and the recently launched International Solar Fuels conference. It is expected that as the field develops, new initiatives and new actors will emerge in different parts of the world.
ER  - 

TY  - JOUR
T1  - The impact of conservation agriculture on smallholder agricultural yields: A scoping review of the evidence
JO  - Agriculture, Ecosystems & Environment
VL  - 187
IS  - 
SP  - 11
EP  - 32
PY  - 2014/4/1/
T2  - Evaluating conservation agriculture for small-scale farmers in Sub-Saharan Africa and South Asia
AU  - Brouder, Sylvie M.
AU  - Gomez-Macpherson, Helena
SN  - 0167-8809
DO  - http://dx.doi.org/10.1016/j.agee.2013.08.010
UR  - http://www.sciencedirect.com/science/article/pii/S0167880913002703
KW  - Conservation agriculture
KW  - Systematic reviews
KW  - Meta-analysis
KW  - Zero-tillage
KW  - Crop yield
KW  - Crop residues
KW  - Mulching
KW  - Sub-Saharan Africa
KW  - South Asia
AB  - Abstract
Widespread implementation of conservation agriculture (CA) in North and South America and Australia suggests significant farmer profitability achieved through some combination of sustained or increased agronomic productivity and reduced input costs. Many believe similar agronomic benefits can accrue to smallholder farmers in sub-Saharan Africa (SSA) and South Asia (SA) for a broad array of crops and farming systems despite marked differences in biophysical and socio-economic environments across these regions. Our objectives were to characterize (1) the quality of existing research including an assessment of the relevance of previously published reviews and surveys to SSA and SA, and (2) the empirical evidence from SSA and SA for agronomic benefits derived from implementing zero tillage (ZT) including the identification of knowledge gaps. Mulching and rotation were considered as associated practices within systems. Among surveys and reviews, most syntheses of multiple, independent studies were either entirely qualitative or used overly simplistic approaches to data aggregation. Few reviews used meta-analysis or other rigorous statistics that permit assessment of outcome sensitivity to influential observations; in general, review protocol descriptions were not sufficient to ensure transparency and appropriate handling of common biases. A search and screening of peer-reviewed literature identified empirical studies on conservation tillage in SSA and SA for maize (22), rice (16), cowpea (10) and sorghum (8). In attempting to extract data for an unbiased, systematic review of CA and maize, we found few studies fully reported critical data or meta-data; most common omissions were the univariate statistics required for study use in meta-analyses and critical supporting or explanatory data on soil type, prevailing weather, and management practices including handling of crop residues. In the short-term, ZT generally resulted in lower yields than with conventional tillage (CT). Occasionally these reductions could be linked to direct effects (e.g. increased soil compaction in rice), but failure to adapt other managements (e.g. weed control) to the CA system was a common and confounding indirect effect. Sufficient maize data existed to demonstrate that negative impacts on yield ameliorated with time in some cases accompanied by higher soil water infiltration and soil organic matter, particularly when mulch was added. However, the low number of studies, the missing supporting data and the large variation in treatments made it difficult to infer general direct effects due to mulching or rotation.

Well-designed long-term experiments on CA featuring sound agronomic practice and comprehensive documentation are largely missing from the literature. Future systematic reviews addressing agronomic impacts of CA interventions will require appropriate handling of within and between study variance as well as sensitivity analyses and quantitative assessments of publication bias; on-going and future empirical studies must report a minimum dataset encompassing valid statistical measures and comprehensive intervention descriptions that enable standardization and systematic approaches in syntheses. We propose a minimum dataset that is generic to competent agronomy with measurements that are increasingly low-cost and easy to achieve and should therefore be routine in field experiments quantifying and explaining crop and cropping system performance. Until a larger number of field studies provide such quantifying and explanatory data from key crops and representative cropping systems, it is not possible to make strong general conclusions about benefits of CA and ZT on yields and resource use efficiency of smallholder farmers.
ER  - 

TY  - JOUR
T1  - Choreographies in the wild
JO  - Science of Computer Programming
VL  - 109
IS  - 
SP  - 36
EP  - 60
PY  - 2015/10/1/
T2  - Selected Papers of the 6th Interaction and Concurrency Experience (ICE 2013)
AU  - Bartoletti, Massimo
AU  - Lange, Julien
AU  - Scalas, Alceste
AU  - Zunino, Roberto
SN  - 0167-6423
DO  - http://dx.doi.org/10.1016/j.scico.2014.11.015
UR  - http://www.sciencedirect.com/science/article/pii/S0167642314005565
KW  - Contracts
KW  - Choreographies
KW  - Session types
AB  - Abstract
We investigate the use of choreographies in distributed scenarios where, as in the real world, mutually distrusting (and possibly dishonest) participants may be unfaithful to their expected behaviour. In our model, each participant advertises its promised behaviour as a contract. Participants may interact through multiparty sessions, created when their contracts allow to synthesise a choreography. We show that systems of honest participants (which always adhere to their contracts) enjoy progress and session fidelity.
ER  - 

TY  - JOUR
T1  - A review of novelty detection
JO  - Signal Processing
VL  - 99
IS  - 
SP  - 215
EP  - 249
PY  - 2014/6//
T2  - 
AU  - Pimentel, Marco A.F.
AU  - Clifton, David A.
AU  - Clifton, Lei
AU  - Tarassenko, Lionel
SN  - 0165-1684
DO  - http://dx.doi.org/10.1016/j.sigpro.2013.12.026
UR  - http://www.sciencedirect.com/science/article/pii/S016516841300515X
KW  - Novelty detection
KW  - One-class classification
KW  - Machine learning
AB  - Abstract
Novelty detection is the task of classifying test data that differ in some respect from the data that are available during training. This may be seen as “one-class classification”, in which a model is constructed to describe “normal” training data. The novelty detection approach is typically used when the quantity of available “abnormal” data is insufficient to construct explicit models for non-normal classes. Application includes inference in datasets from critical systems, where the quantity of available normal data is very large, such that “normality” may be accurately modelled. In this review we aim to provide an updated and structured investigation of novelty detection research papers that have appeared in the machine learning literature during the last decade.
ER  - 

TY  - JOUR
T1  - Framing flexibility: Theorising and data mining to develop a useful definition of flexibility and related concepts
JO  - Futures
VL  - 43
IS  - 9
SP  - 923
EP  - 933
PY  - 2011/11//
T2  - Special Issue: Flexible infrastructures
AU  - de Haan, J.
AU  - Kwakkel, J.H.
AU  - Walker, W.E.
AU  - Spirco, J.
AU  - Thissen, W.A.H.
SN  - 0016-3287
DO  - http://dx.doi.org/10.1016/j.futures.2011.06.002
UR  - http://www.sciencedirect.com/science/article/pii/S0016328711001364
AB  - Flexibility is a term used in various fields with widely differing interpretations. Moreover, several related concepts, such as adaptability, exist that have an overlap in meaning or are simply used synonymously. This article presents a framing of flexibility, and three concepts with which it bears a close family resemblance, for the use in the context of infrastructure constellations. The definitions proposed in this frame draw inspiration from existing literature, though they are not based upon a classical literature review. Rather, a usable set of definitions is proposed for the intended context. The definitions all have the same structure to better appreciate how the concepts are related and how they differ. To verify whether the definitions correspond to their practical use, a data-mining exercise is performed on over 11,000 scientific articles that use the concepts of flexibility. After the corpus of articles is identified that is close to the intended field of application (infrastructure constellations), a co-occurrence analysis is carried out in order to clarify the differences between the concepts and to give nuance to the meaning conveyed in the definitions.
ER  - 

TY  - JOUR
T1  - Optimizing SCImago Journal &amp; Country Rank classification by community detection
JO  - Journal of Informetrics
VL  - 8
IS  - 2
SP  - 369
EP  - 383
PY  - 2014/4//
T2  - 
AU  - Gómez-Núñez, Antonio J.
AU  - Batagelj, Vladimir
AU  - Vargas-Quesada, Benjamín
AU  - Moya-Anegón, Félix
AU  - Chinchilla-Rodríguez, Zaida
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2014.01.011
UR  - http://www.sciencedirect.com/science/article/pii/S1751157714000182
KW  - Community detection
KW  - Clustering
KW  - SCImago Journal &amp; Country Rank
KW  - Journal classification
KW  - Citation-based network
AB  - Abstract
Subject classification arises as an important topic for bibliometrics and scientometrics, searching to develop reliable and consistent tools and outputs. Such objectives also call for a well delimited underlying subject classification scheme that adequately reflects scientific fields. Within the broad ensemble of classification techniques, clustering analysis is one of the most successful.

Two clustering algorithms based on modularity – the VOS and Louvain methods – are presented here for the purpose of updating and optimizing the journal classification of the SCImago Journal &amp; Country Rank (SJR) platform. We used network analysis and Pajek visualization software to run both algorithms on a network of more than 18,000 SJR journals combining three citation-based measures of direct citation, co-citation and bibliographic coupling. The set of clusters obtained was termed through category labels assigned to SJR journals and significant words from journal titles.

Despite the fact that both algorithms exhibited slight differences in performance, the results show a similar behaviour in grouping journals. Consequently, they are deemed to be appropriate solutions for classification purposes. The two newly generated algorithm-based classifications were compared to other bibliometric classification systems, including the original SJR and WoS Subject Categories, in order to validate their consistency, adequacy and accuracy. In addition to some noteworthy differences, we found a certain coherence and homogeneity among the four classification systems analysed.
ER  - 

TY  - JOUR
T1  - Citing-side normalization of journal impact: A robust variant of the Audience Factor
JO  - Journal of Informetrics
VL  - 4
IS  - 3
SP  - 392
EP  - 406
PY  - 2010/7//
T2  - 
AU  - Zitt, Michel
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2010.03.004
UR  - http://www.sciencedirect.com/science/article/pii/S175115771000026X
KW  - Audience factor
KW  - Impact factor
KW  - Normalized impact
KW  - Citing-side normalization
KW  - Source normalization
KW  - Journal impact
AB  - The principle of a new type of impact measure was introduced recently, called the “Audience Factor” (AF). It is a variant of the journal impact factor where emitted citations are weighted inversely to the propensity to cite of the source. In the initial design, propensity was calculated using the average length of bibliography at the source level with two options: a journal-level average or a field-level average. This citing-side normalization controls for propensity to cite, the main determinant of impact factor variability across fields. The AF maintains the variability due to exports–imports of citations across field and to growth differences. It does not account for influence chains, powerful approaches taken in the wake of Pinski–Narin's influence weights. Here we introduce a robust variant of the audience factor, trying to combine the respective advantages of the two options for calculating bibliography lengths: the classification-free scheme when the bibliography length is calculated at the individual journal level, and the robustness and avoidance of ad hoc settings when the bibliography length is averaged at the field level. The variant proposed relies on the relative neighborhood of a citing journal, regarded as its micro-field and assumed to reflect the citation behavior in this area of science. The methodology adopted allows a large range of variation of the neighborhood, reflecting the local citation network, and partly alleviates the “cross-scale” normalization issue. Citing-side normalization is a general principle which may be extended to other citation counts.
ER  - 

TY  - JOUR
T1  - A Comparative Study on the Performance of Evolutionary Fuzzy and Crisp Rule Based Classification Methods in Congestion Prediction
JO  - Transportation Research Procedia
VL  - 14
IS  - 
SP  - 4458
EP  - 4467
PY  - 2016///
T2  - Transport Research Arena TRA2016
AU  - Onieva, E.
AU  - Lopez-Garcia, P.
AU  - Masegosa, A.D.
AU  - Osaba, E.
AU  - Perallos, A.
SN  - 2352-1465
DO  - http://dx.doi.org/10.1016/j.trpro.2016.05.368
UR  - http://www.sciencedirect.com/science/article/pii/S235214651630374X
KW  - Intelligent Transportation Systems
KW  - traffic congestion prediction
KW  - traffic forecast
KW  - genetic algorithms
KW  - fuzzy logic
KW  - evolutionary fuzzy rule learning
KW  - evolutionary crisp rule learning
AB  - Abstract
Accurate estimation of the future state of the traffic is an attracting area for researchers in the field of Intelligent Transportation Systems (ITS). This kind of predictions can lead to traffic managers and drivers to act in consequence, reducing the economic and social impact of a possible congestion. Due to the inter-urban traffic information nature, the task of predicting the future state of the traffic requires, in most cases, a non-linear patterns search in the input data. In recent years, a wide variety of models has been used to solve this problem in the most accurate way. Due to that, models generated to provide information about the future state of the road are, usually, incomprehensible to a human operator, making impossible to give him/her an explanation about the causes of the prediction. Given the capacity of rule based systems to explain the reasoning followed to classify a new pattern, the advantages and disadvantages of such approaches are explored in this work.

To conduct such task, datasets recorded from the California Department of Transportation are created. A 9-kilometer section of the I5 highway of Sacramento is used for this research. Two different types of datasets are built for the experimentation. One of them contains the entire information recorded. The other one contains with a simplified version of the information, considering only the first, middle and last monitored points of the road. Twelve prediction horizons, from 5 to 60 minutes, were considered for prediction. An experimental comparative study involving 16 state of the art techniques is performed. Techniques tested include those that fall within the categories of Evolutionary Crisp Rule Learning (ECRL) and Evolutionary Fuzzy Rule Learning (EFRL). These methods were selected since they offer to the final user, not only a prediction, but also a legible model about the way in which the decision was taken. Techniques are compared in terms of accuracy and complexity of the models generated.
ER  - 

TY  - JOUR
T1  - A bibliometric analysis of research on carbon tax from 1989 to 2014
JO  - Renewable and Sustainable Energy Reviews
VL  - 58
IS  - 
SP  - 297
EP  - 310
PY  - 2016/5//
T2  - 
AU  - Zhang, Kun
AU  - Wang, Qian
AU  - Liang, Qiao-Mei
AU  - Chen, Hao
SN  - 1364-0321
DO  - http://dx.doi.org/10.1016/j.rser.2015.12.089
UR  - http://www.sciencedirect.com/science/article/pii/S1364032115014720
KW  - Carbon tax
KW  - Bibliometric analysis
KW  - Co-Keyword analysis
KW  - Research trends
AB  - Abstract
As one of the most cost-effective means of emission reduction, carbon tax has attracted considerable attention from economists and international organizations and has led to a large number of related research. Using the bibliometric method, this paper characterizes the carbon tax literature from 1989 to 2014 based on the Network Database Platform of Web of Science. The results indicate that the USA occupies a leading position in the carbon tax field. The Vrije University Amsterdam, Massachusetts Institute of Technology and Stanford University were the most productive research institutes. Energy Policy (143) has been the most productive journal followed by Energy Economics (44) and Energy (38). In general, the cooperation of authors, institutes and nations are continuing to strengthen; however, the growth rate at the author level was significantly higher than the others. In addition, the current key research areas in the carbon tax field based on Co-Keyword Analysis are as follows: climate change and relevant policy, carbon emissions trading, socio-economic effects of carbon tax, renewable energy, endogenous technological change and carbon capture and storage. The results of this paper will help researchers grasp the current research in the carbon tax field but also provide a supporting role for future work.
ER  - 

TY  - JOUR
T1  - Mapping the structure of the intellectual field using citation and co-citation analysis of correspondences
JO  - History of European Ideas
VL  - 36
IS  - 3
SP  - 330
EP  - 339
PY  - 2010/9//
T2  - 
AU  - Gingras, Yves
SN  - 0191-6599
DO  - http://dx.doi.org/10.1016/j.histeuroideas.2010.04.002
UR  - http://www.sciencedirect.com/science/article/pii/S0191659910000306
KW  - Republic of letters
KW  - Citation analysis
KW  - Co-citation analysis
KW  - Mersenne
KW  - Oldenburg
KW  - Darwin
KW  - Mapping
KW  - Intellectual networks
KW  - Correspondences
AB  - This article uses the methods of citation and network analysis to map the global structure of the intellectual field and its development over time. Through the case study of Mersenne's, Oldenburg's and Darwin's correspondences, we show how looking at letters as a corpus of data can provide a global representation of the evolving conversation going on in the Republic of Letters and in intellectual and scientific fields. Aggregating general correspondences in electronic format offers a global portrait of the evolving composition of the intellectual and scientific scene, its changing foci of interests and the fortune of the intellectual discussions as expressed in cited persons in the letters. Such tools help replace a purely metaphoric use of the term “network” by a visible map of the intellectual relations between people on which well defined calculations of the centrality of the positions of different actors can be made as well as their evolution over time. These techniques provide welcome additions to the tool kit of scholars in an age where the computer and the web offer new ways of mapping and mining the rich store of information contained in intellectual correspondences.
ER  - 

TY  - JOUR
T1  - Convenience or credibility? A study of college student online research behaviors
JO  - The Internet and Higher Education
VL  - 14
IS  - 3
SP  - 175
EP  - 182
PY  - 2011/7//
T2  - 
AU  - Biddix, J. Patrick
AU  - Chung, Chung Joo
AU  - Park, Han Woo
SN  - 1096-7516
DO  - http://dx.doi.org/10.1016/j.iheduc.2011.01.003
UR  - http://www.sciencedirect.com/science/article/pii/S1096751611000042
KW  - Internet use
KW  - College students
KW  - Academic work
KW  - Semantic network analysis
KW  - Online research
AB  - The purpose of this study was to investigate where students turn for course-related assignments, whether an ordered pattern could be described in terms of which sources students turn to and how students evaluated the information they chose to use. Data were drawn from open-ended questionnaires (n = 282). Semantic network analysis was conducted using CATPAC, artificial neural network software. Results verify previous findings that students turn to the Internet before the library, but a deeper investigation revealed different preferences for study versus project-related research. Specifically, using search engines or Wikipedia was a pre-stage, rather than a final destination, for project work. Interestingly, students were relatively confident in their abilities to discern courses using the Internet. Recommendations for promoting information literacy, as well as recommendations for improving library resource use, are included.
ER  - 

TY  - JOUR
T1  - Anticipating converging industries using publicly available data
JO  - Technological Forecasting and Social Change
VL  - 77
IS  - 3
SP  - 385
EP  - 395
PY  - 2010/3//
T2  - 
AU  - Curran, Clive-Steven
AU  - Bröring, Stefanie
AU  - Leker, Jens
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2009.10.002
UR  - http://www.sciencedirect.com/science/article/pii/S0040162509001425
KW  - Converging industries
KW  - Patent analysis
KW  - Nutraceuticals and Functional Foods
KW  - Cosmeceuticals
KW  - Phytosterols
KW  - Chemical industry
KW  - Bibliometrics
AB  - Industry convergence, described as the blurring of boundaries between industries, plays an increasingly pivotal role in shaping markets and industries. Traditionally, this phenomenon has been discussed in respect to telecommunications, information technologies and electronics, but more recently also the chemical and its related industries find themselves affected by a larger convergence process. With the primary example of phytosterols in the two converging industries of Cosmeceuticals and of Nutraceuticals and Functional Foods, we analyze 7455 scientific and patent references in respect to first indicators for signs of convergence. Furthermore, we present and discuss a multiple indicator concept for monitoring convergence in an R&amp;D-intensive field on the basis of publicly available data.
ER  - 

TY  - JOUR
T1  - Understanding the notion of resilience in spatial planning: A case study of Rotterdam, The Netherlands
JO  - Cities
VL  - 35
IS  - 
SP  - 200
EP  - 212
PY  - 2013/12//
T2  - 
AU  - Lu, Peiwen
AU  - Stead, Dominic
SN  - 0264-2751
DO  - http://dx.doi.org/10.1016/j.cities.2013.06.001
UR  - http://www.sciencedirect.com/science/article/pii/S0264275113000851
KW  - Water management
KW  - Spatial planning
KW  - Resilience
KW  - Rotterdam
KW  - The Netherlands
AB  - Abstract
The notions of urban resilience and the resilient city have gained considerable attention and interest over recent years, not only in relation to environmental management but also in terms of urban planning. The notion of urban resilience is not just confined to academic discourses – it is increasingly prevalent in urban policy documents. This paper examines awareness and understanding of urban resilience in the planning policy arena in Rotterdam, The Netherlands, where planning has a long history of managing water. Specific attention in the paper is paid to the issue of climate change and how planning processes in the city consider or deal with the risks that it presents. The ways in which the city assesses and prepares for these risks or threats form the two main areas of analysis. The paper concludes that evidence of resilient thinking can be found at all levels of decision-making, ranging from the transnational to local levels. However, the notion of resilience is still quite fuzzy and its significance can vary substantially between policy officials and between policy documents, sometimes even within the same administration.
ER  - 

TY  - JOUR
T1  - Analysis of co-occurrence toponyms in web pages based on complex networks
JO  - Physica A: Statistical Mechanics and its Applications
VL  - 466
IS  - 
SP  - 462
EP  - 475
PY  - 2017/1/15/
T2  - 
AU  - Zhong, Xiang
AU  - Liu, Jiajun
AU  - Gao, Yong
AU  - Wu, Lun
SN  - 0378-4371
DO  - http://dx.doi.org/10.1016/j.physa.2016.09.024
UR  - http://www.sciencedirect.com/science/article/pii/S0378437116306409
KW  - Toponym
KW  - Toponym co-occurrence
KW  - Complex network
KW  - Link analysis
KW  - Geographic information retrieval
AB  - Abstract
A large number of geographical toponyms exist in web pages and other documents, providing abundant geographical resources for GIS. It is very common for toponyms to co-occur in the same documents. To investigate these relations associated with geographic entities, a novel complex network model for co-occurrence toponyms is proposed. Then, 12 toponym co-occurrence networks are constructed from the toponym sets extracted from the People’s Daily Paper documents of 2010. It is found that two toponyms have a high co-occurrence probability if they are at the same administrative level or if they possess a part-whole relationship. By applying complex network analysis methods to toponym co-occurrence networks, we find the following characteristics. (1) The navigation vertices of the co-occurrence networks can be found by degree centrality analysis. (2) The networks express strong cluster characteristics, and it takes only several steps to reach one vertex from another one, implying that the networks are small-world graphs. (3) The degree distribution satisfies the power law with an exponent of 1.7, so the networks are free-scale. (4) The networks are disassortative and have similar assortative modes, with assortative exponents of approximately 0.18 and assortative indexes less than 0. (5) The frequency of toponym co-occurrence is weakly negatively correlated with geographic distance, but more strongly negatively correlated with administrative hierarchical distance. Considering the toponym frequencies and co-occurrence relationships, a novel method based on link analysis is presented to extract the core toponyms from web pages. This method is suitable and effective for geographical information retrieval.
ER  - 

TY  - JOUR
T1  - Chemistry, morphology and structural characteristics of synthetic Al–Ni and Al–Co-lizardites
JO  - Applied Clay Science
VL  - 77–78
IS  - 
SP  - 68
EP  - 78
PY  - 2013/6//
T2  - 
AU  - Bentabol, María
AU  - Ruiz Cruz, María Dolores
SN  - 0169-1317
DO  - http://dx.doi.org/10.1016/j.clay.2013.04.001
UR  - http://www.sciencedirect.com/science/article/pii/S0169131713000987
KW  - Amesite
KW  - Brindleyite
KW  - Kaolinite
KW  - Hydrothermal synthesis
KW  - Serpentine
AB  - Abstract
Al–Ni and Al–Co lizardites have been synthesized at hydrothermal conditions. The two phases display different morphologies: thin, dominantly curved platelets (Al–Ni); and stacks of very thin platy particles (Al–Co). The X-ray diffraction and transmission/analytical electron microscopy studies have been used to make accurate distinctions among different structural types and chemical populations. Al–Ni bearing lizardite includes a 1M polytype and probably very subordinate amounts of chlorite. Al–Co bearing lizardite includes two 1M polytypes with different cell-parameters, one of these consisting of an apparently modulated structure. Chemically, Al–Ni- and specially Al–Co lizardite consist of a mixture of two populations with tetrahedral compositions ~ Si1.8Al0.2 and Si2.0. In contrast with previously described Al-rich serpentines, our serpentines are characterized by an asymmetrical Al distribution, with VIAl on the order of 1.0 atom per formula unit.
ER  - 

TY  - JOUR
T1  - Knowledge-Based Risk Management framework for Information Technology project
JO  - International Journal of Information Management
VL  - 32
IS  - 1
SP  - 50
EP  - 65
PY  - 2012/2//
T2  - 
AU  - Alhawari, Samer
AU  - Karadsheh, Louay
AU  - Nehari Talet, Amine
AU  - Mansour, Ebrahim
SN  - 0268-4012
DO  - http://dx.doi.org/10.1016/j.ijinfomgt.2011.07.002
UR  - http://www.sciencedirect.com/science/article/pii/S026840121100096X
KW  - Risk
KW  - Risk management knowledge
KW  - Knowledge management
KW  - Knowledge-Based Risk Management
KW  - Risk response planning
AB  - The purpose of this paper is to explore the field of Risk Management (RM) in relation with Knowledge Management (KM). It attempts to present a conceptual framework, called Knowledge-Based Risk Management (KBRM) that employs KM processes to improve its effectiveness and increase the probability of success in innovative Information Technology (IT) projects. It addresses initiatives towards employing KM processes in RM processes by reviewing, interpreting the related and relevant literature and sheds light on integration with RM in the IT project.

The paper exposes some pertinent elements needed for building the KBRM framework for IT projects and also suggests some instrument about the integration of KM and RM process to improve the RRP (Risk Response Planning) process efficiency.

This paper will contribute to the literature and practice by providing a clear method for employing KBRM as a framework to keep organizations competitive within the business environment.
ER  - 

TY  - JOUR
T1  - The application of knowledge synthesis methods in agri-food public health: Recent advancements, challenges and opportunities
JO  - Preventive Veterinary Medicine
VL  - 113
IS  - 4
SP  - 339
EP  - 355
PY  - 2014/3/1/
T2  - 
AU  - Young, Ian
AU  - Waddell, Lisa
AU  - Sanchez, Javier
AU  - Wilhelm, Barbara
AU  - McEwen, Scott A.
AU  - Rajić, Andrijana
SN  - 0167-5877
DO  - http://dx.doi.org/10.1016/j.prevetmed.2013.11.009
UR  - http://www.sciencedirect.com/science/article/pii/S0167587713003590
KW  - Knowledge synthesis
KW  - Systematic reviews
KW  - Meta-analysis
KW  - Agri-food public health
AB  - Abstract
Knowledge synthesis refers to the integration of findings from individual research studies on a given topic or question into the global knowledge base. The application of knowledge synthesis methods, particularly systematic reviews and meta-analysis, has increased considerably in the agri-food public health sector over the past decade and this trend is expected to continue. The objectives of our review were: (1) to describe the most promising knowledge synthesis methods and their applicability in agri-food public health, and (2) to summarize the recent advancements, challenges, and opportunities in the use of systematic review and meta-analysis methods in this sector. We performed a structured review of knowledge synthesis literature from various disciplines to address the first objective, and used comprehensive insights and experiences in applying these methods in the agri-food public health sector to inform the second objective. We describe five knowledge synthesis methods that can be used to address various agri-food public health questions or topics under different conditions and contexts. Scoping reviews describe the main characteristics and knowledge gaps in a broad research field and can be used to evaluate opportunities for prioritizing focused questions for related systematic reviews. Structured rapid reviews are streamlined systematic reviews conducted within a short timeframe to inform urgent decision-making. Mixed-method and qualitative reviews synthesize diverse sources of contextual knowledge (e.g. socio-cognitive, economic, and feasibility considerations). Systematic reviews are a structured and transparent method used to summarize and synthesize literature on a clearly-defined question, and meta-analysis is the statistical combination of data from multiple individual studies. We briefly describe and discuss key advancements in the use of systematic reviews and meta-analysis, including: risk-of-bias assessments; an overall quality-of-evidence approach; engagement of stakeholders; Bayesian, multivariate, and network meta-analysis; and synthesis of diagnostic test accuracy studies. We also highlight several challenges and opportunities in the conduct of systematic reviews (e.g. inclusion of grey literature, minimizing language bias, and optimizing search strategies) and meta-analysis (e.g. inclusion of observational studies and approaches to address the insufficient reporting of data and significant heterogeneity). Many of these developments have yet to be comprehensively applied and evaluated in an agri-food public health context, and more research is needed in this area. There is a need to strengthen knowledge synthesis capacity and infrastructure at the regional, national, and international levels in this sector to ensure that the best available knowledge is used to inform future decision-making about agri-food public health issues.
ER  - 

TY  - JOUR
T1  - Mediating debate through on-line large-scale argumentation: Evidence from the field
JO  - Information Sciences
VL  - 180
IS  - 19
SP  - 3686
EP  - 3702
PY  - 2010/10/1/
T2  - 
AU  - Gürkan, Ali
AU  - Iandoli, Luca
AU  - Klein, Mark
AU  - Zollo, Giuseppe
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2010.06.011
UR  - http://www.sciencedirect.com/science/article/pii/S0020025510002616
KW  - Large scale argumentation
KW  - On-line deliberation
KW  - Collaborative technologies
KW  - Collective intelligence
AB  - Web 2.0 technologies, such as forums and wikis, are enabling an explosion of global knowledge sharing through distributed large-scale conversations, but they seem to be less successful at supporting collaborative deliberation around complex and controversial questions. In order to cope with this limitation, many scholars have proposed to adopt on-line argumentation platforms to improve information visualization, organization and reuse. However, such research has mostly focused on the design of adequate argument-based knowledge formalisms. Less attention has been paid to the empirical analysis of actual interactions mediated by argumentation technology with reasonably large user communities. In this paper, we present an in-depth analysis of the data obtained in the empirical test of an argumentation platform where a 160-member community created, in 3 weeks, what is to our knowledge the largest single online argument map ever built (around 5000 posts). Our results show that (i) users were able to quickly and comprehensively explore and map the debate on the selected discussion topic; (ii) substantial moderation was needed to ensure that the argument map was well-organized and users were confident with the argumentation formalism; (iii) considerable out-of-the map communication occurred, possibly as a way to allow for conversational flows inhibited by the argumentation formalism, (iv) formal rating of contributions favored exploration of the map, understanding the debate structure, and improving the quality of content.
ER  - 

TY  - JOUR
T1  - Industrial challenges in managing product development knowledge
JO  - Knowledge-Based Systems
VL  - 71
IS  - 
SP  - 101
EP  - 113
PY  - 2014/11//
T2  - 
AU  - Maksimovic, Maksim
AU  - Al-Ashaab, Ahmed
AU  - Shehab, Essam
AU  - Flores, Myrna
AU  - Ewers, Paul
AU  - Haque, Badr
AU  - Furian, Robert
AU  - von Lacroix, Frank
AU  - Sulowski, Robert
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2014.07.016
UR  - http://www.sciencedirect.com/science/article/pii/S0950705114002731
KW  - Product development
KW  - Challenges
KW  - Knowledge management
KW  - Empirical evidence
KW  - Classification
AB  - Abstract
To systematically create and share product development knowledge creates challenges for engineering companies. This paper presents an extensive study regarding the process of identifying such challenges in managing product development knowledge from the perspective of designers and engineers. This research is part of the LeanPPD, a project funded by the EU-PF7 (www.leanppd.eu), to address the need of European manufacturing companies for a new model, which extends beyond lean manufacturing and incorporates lean thinking into the product design and development process. A rigorous research methodology has been employed, which included the use of questionnaires and focused interviews with key informants from industry, involving forty-two product development engineers from nine different companies. The most significant concerns raised during the study concerned knowledge life cycle activities, product development environment and management. Thirty-eight challenges were identified, classified and discussed in order to provide the knowledge management community with practical evidence, and also to inform future research directions in managing product development knowledge.
ER  - 

TY  - JOUR
T1  - Ecosystem-inspired enterprise modelling framework for collaborative and networked manufacturing systems
JO  - Computers in Industry
VL  - 80
IS  - 
SP  - 54
EP  - 68
PY  - 2016/8//
T2  - 
AU  - Fayoumi, Amjad
SN  - 0166-3615
DO  - http://dx.doi.org/10.1016/j.compind.2016.04.003
UR  - http://www.sciencedirect.com/science/article/pii/S0166361516300628
KW  - Collaborative manufacturing network (CMN)
KW  - Enterprise modelling (EM)
KW  - Enterprise simulation
KW  - Ecosystem theory
KW  - Enterprise analysis and design
AB  - Abstract
Rapid changes in the open manufacturing environment are imminent due to the increase of customer demand, global competition, and digital fusion. This has exponentially increased both complexity and uncertainty in the manufacturing landscape, creating serious challenges for competitive enterprises. For enterprises to remain competitive, analysing manufacturing activities and designing systems to address emergent needs, in a timely and efficient manner, is understood to be crucial. However, existing analysis and design approaches adopt a narrow diagnostic focus on either managerial or engineering aspects and neglect to consider the holistic complex behaviour of enterprises in a collaborative manufacturing network (CMN). It has been suggested that reflecting upon ecosystem theory may bring a better understanding of how to analyse the CMN. The research presented in this paper draws on a theoretical discussion with aim to demonstrate a facilitating approach to those analysis and design tasks. This approach was later operationalised using enterprise modelling (EM) techniques in a novel, developed framework that enhanced systematic analysis, design, and business-IT alignment. It is expected that this research view is opening a new field of investigation.
ER  - 

TY  - JOUR
T1  - An improved focused crawler based on Semantic Similarity Vector Space Model
JO  - Applied Soft Computing
VL  - 36
IS  - 
SP  - 392
EP  - 407
PY  - 2015/11//
T2  - 
AU  - Du, Yajun
AU  - Liu, Wenjun
AU  - Lv, Xianjing
AU  - Peng, Guoli
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2015.07.026
UR  - http://www.sciencedirect.com/science/article/pii/S1568494615004664
KW  - Focused crawler
KW  - Semantic similarity
KW  - VSM
KW  - SSRM
AB  - Abstract
A focused crawler is topic-specific and aims selectively to collect web pages that are relevant to a given topic from the Internet. In many studies, the Vector Space Model (VSM) and Semantic Similarity Retrieval Model (SSRM) take advantage of cosine similarity and semantic similarity to compute similarities between web pages and the given topic. However, if there are no common terms between a web page and the given topic, the VSM will not obtain the proper topical similarity of the web page. In addition, if all of the terms between them are synonyms, then the SSRM will also not obtain the proper topical similarity. To address these problems, this paper proposes an improved retrieval model, the Semantic Similarity Vector Space Model (SSVSM), which integrates the TF*IDF values of the terms and the semantic similarities among the terms to construct topic and document semantic vectors that are mapped to the same double-term set, and computes the cosine similarities between these semantic vectors as topic-relevant similarities of documents, including the full texts and anchor texts of unvisited hyperlinks. Next, the proposed model predicts the priorities of the unvisited hyperlinks by integrating the full text and anchor text topic-relevant similarities. The experimental results demonstrate that this approach improves the performance of the focused crawlers and outperforms other focused crawlers based on Breadth-First, VSM and SSRM. In conclusion, this method is significant and effective for focused crawlers.
ER  - 

TY  - JOUR
T1  - A top-down strategy to reverse architecting execution views for a large and complex software-intensive system: An experience report
JO  - Science of Computer Programming
VL  - 76
IS  - 12
SP  - 1098
EP  - 1112
PY  - 2011/12/1/
T2  - Special Issue on Software Evolution, Adaptability and Variability
AU  - Callo Arias, Trosky B.
AU  - Avgeriou, Paris
AU  - America, Pierre
AU  - Blom, Krelis
AU  - Bachynskyy, Sergiy
SN  - 0167-6423
DO  - http://dx.doi.org/10.1016/j.scico.2010.11.008
UR  - http://www.sciencedirect.com/science/article/pii/S0167642310002078
KW  - Architecture reconstruction
KW  - Downstream software development
KW  - Execution views
KW  - Software-intensive systems
AB  - This article is an experience report about the application of a top-down strategy to use and embed an architecture reconstruction approach in the incremental software development process of the Philips MRI scanner, a representative large and complex software-intensive system. The approach is an iterative process to construct execution views without being overwhelmed by the system size and complexity. An execution view contains architectural information that describes what the software of a software-intensive system does at runtime and how it does this. The application of the strategy is illustrated with a case study, the construction of an up-to-date execution view for the start-up process of the Philips MRI scanner. The construction of this view helped the development organization to quickly reduce about 30% the start-up time of the scanner, and set up a new system benchmark for assuring the system performance through future evolution steps. The report provides detailed information about the application of the top-down strategy, including how it supports top-down analysis, communication within the development organization, and the aspects that influence the use of the top-down strategy in other contexts.
ER  - 

TY  - JOUR
T1  - Measurement and segmentation of sport fans using brand association networks: Application to Union of European Football Associations (UEFA) Champions League (UCL)
JO  - Sport Management Review
VL  - 18
IS  - 3
SP  - 407
EP  - 420
PY  - 2015/8//
T2  - 
AU  - Bouzdine-Chameeva, Tatiana
AU  - Ferrand, Alain
AU  - Valette-Florence, Pierre
AU  - Chanavat, Nicolas
SN  - 1441-3523
DO  - http://dx.doi.org/10.1016/j.smr.2014.11.002
UR  - http://www.sciencedirect.com/science/article/pii/S1441352314000916
KW  - Sporting brands
KW  - Brand associations
KW  - Causal mapping
KW  - Segmentation
KW  - Research methods
AB  - Abstract
This article presents a new research methodology for cognitive segmentation based on brand association networks. This application illustrates how brand association networks and cognitive segmentation can identify and describe the UEFA Champions League fans’ segments as a function of their cognitive content and structure. Four segments were identified (show-business lovers, passionate fans, admirers of celebrities and fair play, and event followers). A discussion of the results, directions for future research and managerial contributions are provided.
ER  - 

TY  - JOUR
T1  - An organizational approach to designing an intelligent knowledge-based system: Application to the decision-making process in design projects
JO  - Advanced Engineering Informatics
VL  - 29
IS  - 3
SP  - 696
EP  - 713
PY  - 2015/8//
T2  - 
AU  - Girodon, Julien
AU  - Monticolo, Davy
AU  - Bonjour, Eric
AU  - Perrier, Maggy
SN  - 1474-0346
DO  - http://dx.doi.org/10.1016/j.aei.2015.07.001
UR  - http://www.sciencedirect.com/science/article/pii/S1474034615000671
KW  - Knowledge-based engineering
KW  - Organizational modelling
KW  - Multi-agent systems
KW  - Knowledge-based system
AB  - Abstract
Knowledge-based engineering (KBE) approaches are designed to reduce the time and cost of product development by capturing, retaining and re-using design knowledge. They currently focus on repetitive design tasks where knowledge is considered as a static resource. However, knowledge is intrinsically linked to the organizations and people who use it. Thus, to be efficient, these knowledge-based systems (KBS) have to be able to take into account all the mechanisms of knowledge creation, sharing and evaluation made by the users. Using the agent paradigm, new knowledge-based systems can be designed in order to address this research issue. Indeed, the agents have social abilities and are able to achieve very complex tasks. These two features are necessary for making a knowledge-based system efficient. However, there still exists today a lack of approaches and methodologies to help design such applications. This paper presents DOCK, a methodology to design an intelligent knowledge-based system that aims to support the knowledge management process. In order to take into account all the mechanisms of knowledge generation, sharing and re-use, DOCK is based on the hypothesis that efficient modelling of human organizations, by highlighting their roles, collaborations, skills, goals and knowledge, will help the KBS designer to specify an adapted knowledge-based system. Finally, DOCK is implemented to design the SMA SNOTRA that is dedicated to supporting a decision-making process for design projects.
ER  - 

TY  - JOUR
T1  - An ontology-based knowledge framework for engineering material selection
JO  - Advanced Engineering Informatics
VL  - 29
IS  - 4
SP  - 985
EP  - 1000
PY  - 2015/10//
T2  - Collective Intelligence Modeling, Analysis, and Synthesis for Innovative Engineering Decision MakingSpecial Issue of the 1st International Conference on Civil and Building Engineering Informatics
AU  - Zhang, Yingzhong
AU  - Luo, Xiaofang
AU  - Zhao, Yong
AU  - Zhang, Hong-chao
SN  - 1474-0346
DO  - http://dx.doi.org/10.1016/j.aei.2015.09.002
UR  - http://www.sciencedirect.com/science/article/pii/S147403461500097X
KW  - Engineering materials
KW  - Material selection
KW  - Knowledge representation
KW  - Ontology
AB  - Abstract
Engineering material selection intensively depends on domain knowledge. In the face of the large number and wide variety of engineering materials, it is very necessary to research and develop an open, shared, and scalable knowledge framework for implementing domain-oriented and knowledge-based material selection. In this paper, the fundamental concepts and relationships involved in all aspects of material selection are analyzed in detail. A novel ontology-based knowledge framework is presented. The ontology-based Semantic Web technology is introduced into the semantic representation of material selection knowledge. The implicit material selection knowledge is represented as a set of labeled instances and RDF instance graphs in terms of the concept model, which provides a formal approach to organizing the captured material selection knowledge. A knowledge retrieval and reasoning approach integrating ontology concepts, instances, knowledge rules, and semantic queries encoded with Query-enhanced Web Rule Language (SQWRL) is proposed. The presented knowledge framework can provide powerful knowledge services for material selection. Finally, based on this knowledge framework, a case study on constructing a mold material selection knowledge system is provided. This work is a new attempt to build an open and shared knowledge framework for engineering material selection.
ER  - 

TY  - JOUR
T1  - Modelling Business and Management Systems Using Fuzzy Cognitive Maps: A Critical Overview
JO  - IFAC-PapersOnLine
VL  - 48
IS  - 24
SP  - 207
EP  - 212
PY  - 2015///
T2  - 16th IFAC Conference on Technology, Culture and International Stability TECIS 2015Sozopol, Bulgaria, 24–27 September 2015
AU  - Groumpos, Peter P.
SN  - 2405-8963
DO  - http://dx.doi.org/10.1016/j.ifacol.2015.12.084
UR  - http://www.sciencedirect.com/science/article/pii/S2405896315027081
KW  - Business
KW  - Management. Fuzzy Cognitive Maps
AB  - Abstract
A critical overview of modelling Business and Management (B&amp;M) Systems using Fuzzy Cognitive Maps is presented. A limited but illustrative number of specific applications of Fuzzy Cognitive Maps in diverse B&amp;M systems, such as e business, performance assessment, decision making, human resources management, planning and investment decision making processes is provided and briefly analyzed. The limited survey is given in a table with statics of using FCMs in B&amp;M systems during the last 15 years. The limited survey shows that the applications of Fuzzy Cognitive Maps to today’s Business and Management studies has been steadily increased especially during the last 5-6 years. Interesting conclusions and future research directions are highlighted.
ER  - 

TY  - JOUR
T1  - Mapping the evolution of the impact of economic transition on Central and Eastern European enterprises: A co-word analysis
JO  - Journal of World Business
VL  - 51
IS  - 5
SP  - 744
EP  - 759
PY  - 2016/9//
T2  - 
AU  - Topalli, Margerita
AU  - Ivanaj, Silvester
SN  - 1090-9516
DO  - http://dx.doi.org/10.1016/j.jwb.2016.06.003
UR  - http://www.sciencedirect.com/science/article/pii/S1090951616300438
KW  - Co-word analysis
KW  - Intellectual structure
KW  - Economic transition
KW  - Central and Eastern Europe
KW  - Enterprises
AB  - Abstract
Here we use co-word analysis on extant literature to map the intellectual structure of research addressing the impact of economic transition on Central and Eastern European enterprises during the 1989–2013 period. We collected and analyzed 2053 scholarly papers from the most comprehensive management databases, which were then used to develop. This paper contributes to the economic transition literature by providing an empirically derived framework based on the extant literature. This framework describes the main factors affecting enterprises during the transition process, the relationships among these factors and their evolution.
ER  - 

TY  - JOUR
T1  - Topic analysis and forecasting for science, technology and innovation: Methodology with a case study focusing on big data research
JO  - Technological Forecasting and Social Change
VL  - 105
IS  - 
SP  - 179
EP  - 191
PY  - 2016/4//
T2  - 
AU  - Zhang, Yi
AU  - Zhang, Guangquan
AU  - Chen, Hongshu
AU  - Porter, Alan L.
AU  - Zhu, Donghua
AU  - Lu, Jie
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2016.01.015
UR  - http://www.sciencedirect.com/science/article/pii/S0040162516000160
KW  - Topic analysis
KW  - Technological forecasting
KW  - Text mining
KW  - Text clustering
KW  - Technical intelligence
AB  - Abstract
The number and extent of current Science, Technology &amp; Innovation topics are changing all the time, and their induced accumulative innovation, or even disruptive revolution, will heavily influence the whole of society in the near future. By addressing and predicting these changes, this paper proposes an analytic method to (1) cluster associated terms and phrases to constitute meaningful technological topics and their interactions, and (2) identify changing topical emphases. Our results are carried forward to present mechanisms that forecast prospective developments using Technology Roadmapping, combining qualitative and quantitative methodologies. An empirical case study of Awards data from the United States National Science Foundation, Division of Computer and Communication Foundation, is performed to demonstrate the proposed method. The resulting knowledge may hold interest for R&amp;D management and science policy in practice.
ER  - 

TY  - JOUR
T1  - An approach for environmental risk assessment of engineered nanomaterials using Analytical Hierarchy Process (AHP) and fuzzy inference rules
JO  - Environment International
VL  - 92–93
IS  - 
SP  - 334
EP  - 347
PY  - 2016/7//
Y2  - 2016/8//
T2  - 
AU  - Topuz, Emel
AU  - van Gestel, Cornelis A.M.
SN  - 0160-4120
DO  - http://dx.doi.org/10.1016/j.envint.2016.04.022
UR  - http://www.sciencedirect.com/science/article/pii/S0160412016301520
KW  - Nanoparticles
KW  - Silver
KW  - Titanium dioxide
KW  - Risk assessment
KW  - Fuzzy numbers
AB  - Abstract
The usage of Engineered Nanoparticles (ENPs) in consumer products is relatively new and there is a need to conduct environmental risk assessment (ERA) to evaluate their impacts on the environment. However, alternative approaches are required for ERA of ENPs because of the huge gap in data and knowledge compared to conventional pollutants and their unique properties that make it difficult to apply existing approaches. This study aims to propose an ERA approach for ENPs by integrating Analytical Hierarchy Process (AHP) and fuzzy inference models which provide a systematic evaluation of risk factors and reducing uncertainty about the data and information, respectively. Risk is assumed to be the combination of occurrence likelihood, exposure potential and toxic effects in the environment. A hierarchy was established to evaluate the sub factors of these components. Evaluation was made with fuzzy numbers to reduce uncertainty and incorporate the expert judgements. Overall score of each component was combined with fuzzy inference rules by using expert judgements. Proposed approach reports the risk class and its membership degree such as Minor (0.7). Therefore, results are precise and helpful to determine the risk management strategies. Moreover, priority weights calculated by comparing the risk factors based on their importance for the risk enable users to understand which factor is effective on the risk. Proposed approach was applied for Ag (two nanoparticles with different coating) and TiO2 nanoparticles for different case studies. Results verified the proposed benefits of the approach.
ER  - 

TY  - JOUR
T1  - Is SAM still alive? A bibliometric and interpretive mapping of the strategic alignment research field
JO  - The Journal of Strategic Information Systems
VL  - 25
IS  - 2
SP  - 75
EP  - 103
PY  - 2016/7//
T2  - 
AU  - Renaud, Alexandre
AU  - Walsh, Isabelle
AU  - Kalika, Michel
SN  - 0963-8687
DO  - http://dx.doi.org/10.1016/j.jsis.2016.01.002
UR  - http://www.sciencedirect.com/science/article/pii/S0963868716000032
KW  - Strategic alignment model
KW  - Tri-citation analysis
KW  - Bibliometric methods
KW  - Management of strategic information systems
AB  - Abstract
The strategic use of IS and the alignment of IT with business needs are important managerial issues that need to be addressed if optimal organizational performance is to be achieved. IS research has proposed models to optimize the impact of IS investment on organizational performance. The Strategic Alignment Model (SAM) proposed by Henderson and Venkatraman is the most well-known and widely used of these models. However, 20 years on, there remains a significant disparity between the intended contribution of the literature built around SAM and the apparent practical consequences of its application in organizations. In this study, we explain this disparity using a grounded theory stance with a bibliometric and interpretive approach to help us analyze the literature: We use tri-citation analysis (with bibliometric data collected in 2011, and again in 2014) and investigate interpretatively the contents of the texts highlighted by our statistical results. This allows us to show that the research field built around SAM mostly appears not to challenge its basic assumptions and premises, although these may artificially constrain organizational reality and practices. In turn, this leads us to propose an explanation for practitioners’ apparent failures to fulfill SAM’s intended contribution. Beyond our theoretical and methodological contributions, we propose possible theoretical and practical improvements to adapt this model to the current organizational reality.
ER  - 

TY  - JOUR
T1  - Scoping the field of disaster exercise evaluation - A literature overview and analysis
JO  - International Journal of Disaster Risk Reduction
VL  - 19
IS  - 
SP  - 413
EP  - 446
PY  - 2016/10//
T2  - 
AU  - Beerens, Ralf Josef Johanna
AU  - Tehler, Henrik
SN  - 2212-4209
DO  - http://dx.doi.org/10.1016/j.ijdrr.2016.09.001
UR  - http://www.sciencedirect.com/science/article/pii/S2212420916302072
KW  - Disaster
KW  - Crisis
KW  - Emergency
KW  - Exercise
KW  - Drill
KW  - Evaluation
KW  - Assessment
KW  - Analysis
KW  - Valuation
KW  - Review
KW  - Scoping study
KW  - Literature overview
AB  - Abstract
The evaluation of emergency, disaster and crisis management exercises supports both individual and organisational learning, facilitates the development of response capabilities, and helps to determine whether the current level of preparedness is good enough. Nevertheless, despite its importance in the field of disaster risk management, there is a lack of a comprehensive overview of research in the area. The aim of the paper is to provide such an overview.

A scoping study identified the key contributions on the topic of disaster exercise evaluation, provides an overview of research in the area, and analyses opportunities for future work. The purpose, function and form of the evaluation provided the framework for the analysis, which was applied to the scoping study results.

The results indicate a lack of academic interest. Although exercises take place on a regular basis and are often used for research purposes, their evaluations are seldom the focus of attention per se. Moreover, contributions that do focus on evaluations are spread over several disciplines. Nevertheless, the results indicate that recent contributions are becoming more coherent as they build on each other (or at least refer to each other), even if they are produced within different disciplines.

Despite encouraging signs of a more cohesive scientific corpus on the evaluation of disaster exercises, there is still room for improvement. The scientific discourse would benefit from greater clarity regarding: (1) the purpose and context in which a specific evaluation method is designed to be used; (2) what the method needs to do (or produce) in order for it to fulfil the purpose; and (3) how the method achieves its goal and thereby fulfils its purpose. Moreover, in order to help researchers to build on each other's work and suggest improvements to evaluation methods, it is urgent that the supporting evidence (for example, empirical data or logical reasoning) for claims regarding the usefulness of a specific method is clearly presented. This is likely to lead to a more vigorous scientific discourse, which will result in increasingly relevant and robust arguments related to how to approach the problem of evaluating disaster exercises in practice.
ER  - 

TY  - JOUR
T1  - Advancing theory and knowledge in the business-to-business branding literature
JO  - Journal of Business Research
VL  - 69
IS  - 8
SP  - 2664
EP  - 2677
PY  - 2016/8//
T2  - 
AU  - Seyedghorban, Zahra
AU  - Matanda, Margaret Jekanyika
AU  - LaPlaca, Peter
SN  - 0148-2963
DO  - http://dx.doi.org/10.1016/j.jbusres.2015.11.002
UR  - http://www.sciencedirect.com/science/article/pii/S0148296315005962
KW  - Bibliographic
KW  - B2B branding
KW  - Citations
KW  - Impact
KW  - Research
KW  - Review
AB  - Abstract
This study investigates the intellectual structure, development, and evolution of business-to business (B2B) branding research by undertaking a bibliometric analysis of scholarly articles on B2B branding over the 43-year period from 1972 to 2015. The analysis covers 169 scholarly articles by 395 authors and 10,270 citations from 33 academic journals in which B2B branding articles appeared. By identifying and evaluating the underlying structure and evolution of scholarly research in B2B branding, this study provides an exhaustive review of this discipline as well as a baseline on which future researchers in the field can build a sound theoretical foundation. The bibliometric analysis results reveal the most cited articles, keywords, authors, institutions, and countries in B2B branding discipline. Further, the study identifies major areas of B2B branding research. The study closes with implications of findings and a report on emerging trends as well as directions for future research.
ER  - 

TY  - JOUR
T1  - Basis for an integrated security ontology according to a systematic review of existing proposals
JO  - Computer Standards & Interfaces
VL  - 33
IS  - 4
SP  - 372
EP  - 388
PY  - 2011/6//
T2  - 
AU  - Blanco, Carlos
AU  - Lasheras, Joaquín
AU  - Fernández-Medina, Eduardo
AU  - Valencia-García, Rafael
AU  - Toval, Ambrosio
SN  - 0920-5489
DO  - http://dx.doi.org/10.1016/j.csi.2010.12.002
UR  - http://www.sciencedirect.com/science/article/pii/S0920548911000043
KW  - Ontologies
KW  - Security
KW  - Systematic review
AB  - The use of ontologies to represent knowledge provides us with organization, communication and reusability. The concepts and relations managed by any scientific community need to be formally defined. Since security in information technologies has evolved as a critical aspect and many related topics have been developed, this paper applies the method of systematic review for identifying, extracting and analyzing the principal proposals for security ontologies. The most mature proposals have been selected and compared by using a formal framework, extracting the key requirements that an integrated and unified security ontology should have, and providing the first steps towards its definition.
ER  - 

TY  - JOUR
T1  - Technology transfer organizations: Services and business models
JO  - Technovation
VL  - 33
IS  - 12
SP  - 431
EP  - 449
PY  - 2013/12//
T2  - 
AU  - Landry, Réjean
AU  - Amara, Nabil
AU  - Cloutier, Jean-Samuel
AU  - Halilem, Norrin
SN  - 0166-4972
DO  - http://dx.doi.org/10.1016/j.technovation.2013.09.008
UR  - http://www.sciencedirect.com/science/article/pii/S0166497213001132
KW  - Technology transfer
KW  - Intermediary organizations
KW  - Services provided to firms
KW  - Survey
KW  - Regressions
AB  - Abstract
Knowledge and technology transfer organizations (KTTOs) are crucial nodes connecting suppliers and users of knowledge that support the endogenous potential of innovation in firms. Prior studies on the services provided to firms by KTTOs tend to have weak theoretical foundations, to rely on case study approaches, and to focus attention on one service or a few services provided by a single organization. This study extends and integrates elements from a conceptual knowledge value chain and business model frameworks. The value chain perspective allows integrating the services offered by KTTOs in the value chain of firms. As for the business model perspective, it allows developing hypotheses about how KTTOs create and deliver value for client firms. To test these hypotheses, we collected and analyzed a data set of 281 publicly supported KTTOs located in Canada. The empirical results show that different types of KTTOs tend to specialize in the provision of services at different stages of the value chain of firms, and to benefit from complementarity effects between service offerings. Our analysis also shows that different types of KTTOs devise different types of business models that are centered on services linked to different stages of the value chain. Overall, these results suggest that managers of KTTOs could improve their business models and increase value to client firms by increasing the degree of customization of solutions offered to clients which, in turn, would also increase revenues from clients, and hence reduce KTTOs′ vulnerability to reductions in government funding.
ER  - 

TY  - JOUR
T1  - Geospatial technologies and digital geomorphological mapping: Concepts, issues and research
JO  - Geomorphology
VL  - 137
IS  - 1
SP  - 5
EP  - 26
PY  - 2012/1/15/
T2  - Geospatial Technologies and Geomorphological Mapping Proceedings of the 41st Annual Binghamton Geomorphology Symposium
AU  - Bishop, Michael P.
AU  - James, L. Allan
AU  - Shroder Jr., John F.
AU  - Walsh, Stephen J.
SN  - 0169-555X
DO  - http://dx.doi.org/10.1016/j.geomorph.2011.06.027
UR  - http://www.sciencedirect.com/science/article/pii/S0169555X11003242
KW  - Digital geomorphological mapping
KW  - GIScience
KW  - Geomorphometry
KW  - Landforms
KW  - Remote sensing
KW  - Topography
AB  - Geomorphological mapping plays an essential role in understanding Earth surface processes, geochronology, natural resources, natural hazards and landscape evolution. It involves the partitioning of the terrain into conceptual spatial entities based upon criteria that include morphology (form), genetics (process), composition and structure, chronology, environmental system associations (land cover, soils, ecology), as well as spatial topological relationships of surface features (landforms). Historically, the power of human visualization was primarily relied upon for analysis, introducing subjectivity and biases with respect to selection of criteria for terrain segmentation and placement of boundaries. This paper reviews new spatio-temporal data and geocomputational approaches that now permit Earth scientists to go far beyond traditional mapping, permitting quantitative characterization of landscape morphology and the integration of varied landscape thematic information. Numerous conceptual, theoretical, and information-technology issues are at the heart of digital geomorphological mapping (DGM), and scientific progress has not kept pace with new and rapidly evolving geospatial technologies. Consequently, new capabilities exist but numerous issues have not been adequately addressed. Therefore, this paper discusses conceptual foundations and illustrates how geomorphometry and mapping approaches can be used to produce geomorphological information related to the land surface and landforms, process rates, process–form relationships, and geomorphic systems.
ER  - 

TY  - JOUR
T1  - Promoting the performance of vertical recommendation systems by applying new classification techniques
JO  - Knowledge-Based Systems
VL  - 75
IS  - 
SP  - 192
EP  - 223
PY  - 2015/2//
T2  - 
AU  - Saleh, Ahmed I.
AU  - El Desouky, Ali I.
AU  - Ali, Shereen H.
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2014.12.002
UR  - http://www.sciencedirect.com/science/article/pii/S0950705114004328
KW  - Recommendation system
KW  - Classification
KW  - Naïve Bayes
KW  - KNN
KW  - Association rules
KW  - Fuzzy logic
AB  - Abstract
Recommender systems (RSs) have proven to be valuable means for online users to cope with the information overload and have become one of the most powerful and popular tools in electronic commerce. RSs are software tools providing suggestions for items of interest to users; hence, they typically apply techniques and methodologies from Data Mining. The most frequently used technique is the classification as it matches the aims of RSs that basically classify items based on user’s preferences. The main contribution of this paper is in the area of applying classification techniques to enhance the performance of RSs. In this paper, an Intelligent Adaptive Vertical Recommendation (IAVR) system will be introduced. IAVR recommends text documents related to a specific domain. Basically, the paper concentrates on the first phase of IAVR, which contains two modules; the first is a distiller, while the second is a multi-class classifier. The proposed distiller is employed as a binary classifier that elects documents related to the domain of interest. It is built upon a novel neuro-fuzzy system as well as a modified K Nearest Neighbors (KNN) classifier. On the other hand, the proposed multi-class classifier merges a new instance of Naïve Bayes (NB) classifier, that depends on a proposed learning technique called “accumulative learning”, with association rules. Experimental results have proven the effectiveness of the proposed classifiers, which accordingly promote the overall system’s recommendation accuracy.
ER  - 

TY  - JOUR
T1  - Eight-year climatology of dust optical depth on Mars
JO  - Icarus
VL  - 251
IS  - 
SP  - 65
EP  - 95
PY  - 2015/5/1/
T2  - Dynamic Mars
AU  - Montabone, L.
AU  - Forget, F.
AU  - Millour, E.
AU  - Wilson, R.J.
AU  - Lewis, S.R.
AU  - Cantor, B.
AU  - Kass, D.
AU  - Kleinböhl, A.
AU  - Lemmon, M.T.
AU  - Smith, M.D.
AU  - Wolff, M.J.
SN  - 0019-1035
DO  - http://dx.doi.org/10.1016/j.icarus.2014.12.034
UR  - http://www.sciencedirect.com/science/article/pii/S0019103515000044
KW  - Mars, atmosphere
KW  - Mars, climate
KW  - Data reduction techniques
AB  - Abstract
We have produced a multiannual climatology of airborne dust from martian year 24–31 using multiple datasets of retrieved or estimated column optical depths. The datasets are based on observations of the martian atmosphere from April 1999 to July 2013 made by different orbiting instruments: the Thermal Emission Spectrometer (TES) aboard Mars Global Surveyor, the Thermal Emission Imaging System (THEMIS) aboard Mars Odyssey, and the Mars Climate Sounder (MCS) aboard Mars Reconnaissance Orbiter (MRO). The procedure we have adopted consists of gridding the available retrievals of column dust optical depth (CDOD) from TES and THEMIS nadir observations, as well as the estimates of this quantity from MCS limb observations. Our gridding method calculates averages and uncertainties on a regularly spaced spatio-temporal grid, using an iterative procedure that is weighted in space, time, and retrieval quality. The lack of observations at certain times and locations introduces missing grid points in the maps, which therefore may result in irregularly gridded (i.e. incomplete) fields. In order to evaluate the strengths and weaknesses of the resulting gridded maps, we compare with independent observations of CDOD by PanCam cameras and Mini-TES spectrometers aboard the Mars Exploration Rovers “Spirit” and “Opportunity”, by the Surface Stereo Imager aboard the Phoenix lander, and by the Compact Reconnaissance Imaging Spectrometer for Mars aboard MRO. We have statistically analyzed the irregularly gridded maps to provide an overview of the dust climatology on Mars over eight years, specifically in relation to its interseasonal and interannual variability, in addition to provide a basis for instrument intercomparison. Finally, we have produced regularly gridded maps of CDOD by spatially interpolating the irregularly gridded maps using a kriging method. These complete maps are used as dust scenarios in the Mars Climate Database (MCD) version 5, and are useful in many modeling applications. The two datasets for the eight available martian years are publicly available and distributed with open access on the MCD website.
ER  - 

TY  - JOUR
T1  - Exploration of a collection of documents in neuroscience and extraction of topics by clustering
JO  - Neural Networks
VL  - 21
IS  - 8
SP  - 1205
EP  - 1211
PY  - 2008/10//
T2  - NeuroinformaticsNeuroinformatics
AU  - Naud, Antoine
AU  - Usui, Shiro
SN  - 0893-6080
DO  - http://dx.doi.org/10.1016/j.neunet.2008.05.009
UR  - http://www.sciencedirect.com/science/article/pii/S0893608008000981
KW  - Neuroinformatics
KW  - Document clustering
KW  - Text mining
KW  - Knowledge domain visualization
AB  - This paper presents a preliminary analysis of the neuroscience knowledge domain, and an application of cluster analysis to identify topics in neuroscience. A collection of posters presented at the Society for Neuroscience (SfN) Annual Meeting in 2006 is first explored by viewing existing topics and poster sessions using multidimensional scaling. Based on the Vector Space Model, several Term Spaces were built on the basis of a set of terms extracted from the posters’ abstracts and titles, and a set of free keywords assigned to the posters by their authors. The ensuing Term Spaces were compared from the point of view of retrieving the genuine category titles. Topics were extracted from the abstracts of posters by clustering the documents using a bisecting k -means algorithm and selecting the most salient terms for each cluster by ranking. The terms extracted as topic descriptors were evaluated by comparing them to existing titles assigned to thematic categories defined by human experts in neuroscience. A comparison of two approaches for terms ranking (Document Frequency and Log-Entropy) resulted in better performance of the Log-Entropy scores, allowing to retrieve 31.0% of original title terms in clustered documents (and 37.1% in original thematic categories).
ER  - 

TY  - JOUR
T1  - Combining preference- and content-based approaches for improving document clustering effectiveness
JO  - Information Processing & Management
VL  - 42
IS  - 2
SP  - 350
EP  - 372
PY  - 2006/3//
T2  - 
AU  - Wei, Chih-Ping
AU  - Yang, Chin-Sheng
AU  - Hsiao, Han-Wei
AU  - Cheng, Tsang-Hsiang
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2005.06.008
UR  - http://www.sciencedirect.com/science/article/pii/S0306457305000762
KW  - Document clustering
KW  - Hierarchical agglomerative clustering
KW  - Preference-based document clustering
KW  - Document management
KW  - Digital library
AB  - E-commerce and knowledge management applications generate and consume tremendous amounts of online information that is typically available as textual documents. To facilitate subsequent access of and leverage from these textual documents, the efficient and effective management of the ever-increasing volume of documents is essential to both organizations and individuals. Document management practices suggest the popularity of using categories (e.g., folders) for organizing, archiving, and accessing documents. Document clustering represents an appealing approach to enable organizations or individuals to create and maintain document categories automatically. Existing document clustering techniques usually group together similar documents on the basis of their textual content similarity. However, such content-based approaches operate at the lexical level and suffer greatly from the word mismatch problem. Therefore, this study aims to address this problem by exploiting users’ document grouping preferences, as exhibited in those individuals’ folder sets, to support document clustering. Specifically, we propose a hybrid document clustering technique that combines preference- and content-based approaches. Using a traditional content-based and a preference/content switching document clustering technique as performance benchmarks, our empirical evaluation results show that the proposed hybrid technique improves the clustering effectiveness measured by both cluster precision and cluster recall.
ER  - 

TY  - JOUR
T1  - An active learning framework for semi-supervised document clustering with language modeling
JO  - Data & Knowledge Engineering
VL  - 68
IS  - 1
SP  - 49
EP  - 67
PY  - 2009/1//
T2  - 
AU  - Huang, Ruizhang
AU  - Lam, Wai
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2008.08.008
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X08001183
KW  - Document clustering
KW  - Semi-supervised
KW  - Active learning
KW  - Language modeling
AB  - This paper investigates a framework that actively selects informative document pairs for obtaining user feedback for semi-supervised document clustering. A gain-directed document pair selection method that measures how much we can learn by revealing judgments of selected document pairs is designed. We use the estimation of term co-occurrence probabilities as a clue for finding informative document pairs. Term co-occurrence probabilities are considered in the semi-supervised document clustering process to capture term-to-term dependence relationships. In the semi-supervised document clustering, each cluster is represented by a language model. We have conducted extensive experiments on several real-world corpora. The results demonstrate that our proposed framework is effective.
ER  - 

TY  - JOUR
T1  - Using cluster validation criterion to identify optimal feature subset and cluster number for document clustering
JO  - Information Processing & Management
VL  - 43
IS  - 3
SP  - 730
EP  - 739
PY  - 2007/5//
T2  - Special Issue on Heterogeneous and Distributed IR
AU  - Niu, Zheng-Yu
AU  - Ji, Dong-Hong
AU  - Tan, Chew Lim
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2006.07.022
UR  - http://www.sciencedirect.com/science/article/pii/S0306457306000999
KW  - Document clustering
KW  - Cluster validation
KW  - Feature selection
KW  - Cluster number estimation
AB  - This paper presents a cluster validation based document clustering algorithm, which is capable of identifying an important feature subset and the intrinsic value of model order (cluster number). The important feature subset is selected by optimizing a cluster validity criterion subject to some constraint. For achieving model order identification capability, this feature selection procedure is conducted for each possible value of cluster number. The feature subset and the cluster number which maximize the cluster validity criterion are chosen as our answer. We have evaluated our algorithm using several datasets from the 20Newsgroup corpus. Experimental results show that our algorithm can find the important feature subset, estimate the cluster number and achieve higher micro-averaged precision than previous document clustering algorithms which require the value of cluster number to be provided.
ER  - 

TY  - JOUR
T1  - Discrete and continuous conceptualizations of science: Implications for knowledge domain visualization
JO  - Journal of Informetrics
VL  - 3
IS  - 3
SP  - 233
EP  - 245
PY  - 2009/7//
T2  - Science of Science: Conceptualizations and Models of Science
AU  - Skupin, André
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2009.03.002
UR  - http://www.sciencedirect.com/science/article/pii/S1751157709000261
KW  - Visualization
KW  - Conceptualization
KW  - Spatial concepts
KW  - Geographic information science
KW  - Knowledge domain visualization
KW  - Geography
AB  - Visual depiction of the structure and evolution of science has been proposed as a key strategy for dealing with the large, complex, and increasingly interdisciplinary records of scientific communication. While every such visualization assumes the existence of spatial structures within the system of science, new methods and tools are rarely linked to thorough reflection on the underlying spatial concepts. Meanwhile, geographic information science has adopted a view of geographic space as conceptualized through the duality of discrete objects and continuous fields. This paper argues that conceptualization of science has been dominated by a view of its constituent elements (e.g., authors, articles, journals, disciplines) as discrete objects. It is proposed that, like in geographic information science, alternative concepts could be used for the same phenomenon. For example, one could view an author as either a discrete object at a specific location or as a continuous field occupying all of a discipline. It is further proposed that this duality of spatial concepts can extend to the methods by which low-dimensional geometric models of high-dimensional scientific spaces are created and used. This can result in new methods revealing different kinds of insights. This is demonstrated by a juxtaposition of two visualizations of an author's intellectual evolution on the basis of either a discrete or continuous conceptualization.
ER  - 

TY  - JOUR
T1  - An online document clustering technique for short web contents
JO  - Pattern Recognition Letters
VL  - 30
IS  - 10
SP  - 870
EP  - 876
PY  - 2009/7/15/
T2  - 
AU  - Carullo, Moreno
AU  - Binaghi, Elisabetta
AU  - Gallo, Ignazio
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2009.04.001
UR  - http://www.sciencedirect.com/science/article/pii/S0167865509000701
KW  - Online clustering
KW  - Short documents analysis
KW  - Similarity measures
AB  - Document clustering techniques have been applied in several areas, with the web as one of the most recent and influential. Both general-purpose and text-oriented techniques exist and can be used to cluster a collection of documents in many ways. This work proposes a novel heuristic online document clustering model that can be specialized with a variety of text-oriented similarity measures. An experimental evaluation of the proposed model was conducted in the e-commerce domain. Performances were measured using a clustering-oriented metric based on F-Measure and compared with those obtained by other well-known approaches. The obtained results confirm the validity of the proposed method both for batch scenarios and online scenarios where document collections can grow over time.
ER  - 

TY  - JOUR
T1  - Macromolecule mass spectrometry: citation mining of user documents
JO  - Journal of the American Society for Mass Spectrometry
VL  - 15
IS  - 3
SP  - 281
EP  - 287
PY  - 2004/3//
T2  - 
AU  - Kostoff, Ronald N
AU  - Bedford, Clifford D
AU  - del Río, J.Antonio
AU  - Cortes, Héctor D
AU  - Karypis, George
SN  - 1044-0305
DO  - http://dx.doi.org/10.1016/j.jasms.2003.11.010
UR  - http://www.sciencedirect.com/science/article/pii/S1044030503008468
AB  - Identifying research users, applications, and impact is important for research performers, managers, evaluators, and sponsors. Identification of the user audience and the research impact is complex and time consuming due to the many indirect pathways through which fundamental research can impact applications. This paper identified the literature pathways through which two highly-cited papers of 2002 Chemistry Nobel Laureates Fenn and Tanaka impacted research, technology development, and applications. Citation Mining, an integration of citation bibliometrics and text mining, was applied to the &gt;1600 first generation Science Citation Index (SCI) citing papers to Fenn's 1989 Science paper on Electrospray Ionization for Mass Spectrometry, and to the &gt;400 first generation SCI citing papers to Tanaka's 1988 Rapid Communications in Mass Spectrometry paper on Laser Ionization Time-of-Flight Mass Spectrometry. Bibliometrics was performed on the citing papers to profile the user characteristics. Text mining was performed on the citing papers to identify the technical areas impacted by the research, and the relationships among these technical areas.
ER  - 

TY  - JOUR
T1  - A Latent Semantic Indexing-based approach to multilingual document clustering
JO  - Decision Support Systems
VL  - 45
IS  - 3
SP  - 606
EP  - 620
PY  - 2008/6//
T2  - Special Issue Clusters
AU  - Wei, Chih-Ping
AU  - Yang, Christopher C.
AU  - Lin, Chia-Min
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2007.07.008
UR  - http://www.sciencedirect.com/science/article/pii/S0167923607001339
KW  - Document management
KW  - Text mining
KW  - Document clustering
KW  - Multilingual document clustering
KW  - Multilingual knowledge management
KW  - Latent Semantic Indexing
AB  - The creation and deployment of knowledge repositories for managing, sharing, and reusing tacit knowledge within an organization has emerged as a prevalent approach in current knowledge management practices. A knowledge repository typically contains vast amounts of formal knowledge elements, which generally are available as documents. To facilitate users' navigation of documents within a knowledge repository, knowledge maps, often created by document clustering techniques, represent an appealing and promising approach. Various document clustering techniques have been proposed in the literature, but most deal with monolingual documents (i.e., written in the same language). However, as a result of increased globalization and advances in Internet technology, an organization often maintains documents in different languages in its knowledge repositories, which necessitates multilingual document clustering (MLDC) to create organizational knowledge maps. Motivated by the significance of this demand, this study designs a Latent Semantic Indexing (LSI)-based MLDC technique capable of generating knowledge maps (i.e., document clusters) from multilingual documents. The empirical evaluation results show that the proposed LSI-based MLDC technique achieves satisfactory clustering effectiveness, measured by both cluster recall and cluster precision, and is capable of maintaining a good balance between monolingual and cross-lingual clustering effectiveness when clustering a multilingual document corpus.
ER  - 

TY  - JOUR
T1  - A simplicial complex, a hypergraph, structure in the latent semantic space of document clustering
JO  - International Journal of Approximate Reasoning
VL  - 40
IS  - 1–2
SP  - 55
EP  - 80
PY  - 2005/7//
T2  - Data Mining and Granular Computing
AU  - Lin, Tsau Young
AU  - Chiang, I-Jen
SN  - 0888-613X
DO  - http://dx.doi.org/10.1016/j.ijar.2004.11.005
UR  - http://www.sciencedirect.com/science/article/pii/S0888613X04001409
KW  - Document clustering
KW  - Association rules
KW  - Topology
KW  - Hierarchical clustering
KW  - Simplicial complex
AB  - This paper presents a novel approach to document clustering based on some geometric structure in Combinatorial Topology. Given a set of documents, the set of associations among frequently co-occurring terms in documents forms naturally a simplicial complex. Our general thesis is each connected component of this simplicial complex represents a concept in the collection. Based on these concepts, documents can be clustered into meaningful classes. However, in this paper, we attack a softer notion, instead of connected components, we use maximal simplexes of highest dimension as representative of connected components, the concept so defined is called maximal primitive concepts.

Experiments with three different data sets from Web pages and medical literature have shown that the proposed unsupervised clustering approach performs significantly better than traditional clustering algorithms, such as k-means, AutoClass and Hierarchical Clustering (HAG). This abstract geometric model seems have captured the latent semantic structure of documents.
ER  - 

TY  - JOUR
T1  - Web document clustering using a hybrid neural network
JO  - Applied Soft Computing
VL  - 4
IS  - 4
SP  - 423
EP  - 432
PY  - 2004/9//
T2  - 
AU  - Khan, M.Shamim
AU  - Khor, Sebastian W
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2004.02.003
UR  - http://www.sciencedirect.com/science/article/pii/S1568494604000407
KW  - Hybrid neural network
KW  - PCA
KW  - ART
KW  - Web document clustering
KW  - Information retrieval
KW  - Document features extraction
AB  - The list of documents returned by Internet search engines in response to a query these days can be quite overwhelming. There is an increasing need for organising this information and presenting it in a more compact and efficient manner. This paper describes a method developed for the automatic clustering of World Wide Web documents, according to their relevance to the user’s information needs, by using a hybrid neural network. The objective is to reduce the time and effort the user has to spend to find the information sought after. Clustering documents by features representative of their contents—in this case, key words and phrases—increases the effectiveness and efficiency of the search process. It is shown that a two-dimensional visual presentation of information on retrieved documents, instead of the traditional linear listing, can create a more user-friendly interface between a search engine and the user.
ER  - 

TY  - JOUR
T1  - Comparison of neural models for document clustering
JO  - International Journal of Approximate Reasoning
VL  - 34
IS  - 2–3
SP  - 287
EP  - 305
PY  - 2003/11//
T2  - Soft Computing Applications to Intelligent Information Retrieval on the Internet
AU  - Guerrero-Bote, Vicente P.
AU  - López-Pujalte, Cristina
AU  - de Moya-Anegón, Félix
AU  - Herrero-Solana, Victor
SN  - 0888-613X
DO  - http://dx.doi.org/10.1016/j.ijar.2003.07.012
UR  - http://www.sciencedirect.com/science/article/pii/S0888613X03000963
KW  - Artificial neural networks
KW  - Kohonen networks
KW  - Document clustering
KW  - Adaptive resonance theory
AB  - We compared the application of different algorithms to document clustering. The algorithms studied were Fuzzy C-Means, Fuzzy ART, Fuzzy ART for Fuzzy Clusters, Fuzzy Max-Min, and the Kohonen neural network (only the first is not a neural network). We generated a testbed from LISA, using some of the descriptors corresponding to the different records for the comparison of the results. The best results were found with Kohonen’s algorithm which also organizes the clusters topologically. We end by discussing in more detail the possibilities offered by Kohonen’s algorithm.
ER  - 

TY  - JOUR
T1  - Text document clustering based on neighbors
JO  - Data & Knowledge Engineering
VL  - 68
IS  - 11
SP  - 1271
EP  - 1288
PY  - 2009/11//
T2  - Including Special Section: Conference on Privacy in Statistical Databases (PSD 2008) – Six selected and extended papers on Database Privacy
AU  - Luo, Congnan
AU  - Li, Yanjun
AU  - Chung, Soon M.
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2009.06.007
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X09000974
KW  - Document clustering
KW  - Text mining
KW  - k-means
KW  - Bisecting k-means
KW  - Performance analysis
AB  - Clustering is a very powerful data mining technique for topic discovery from text documents. The partitional clustering algorithms, such as the family of k-means, are reported performing well on document clustering. They treat the clustering problem as an optimization process of grouping documents into k clusters so that a particular criterion function is minimized or maximized. Usually, the cosine function is used to measure the similarity between two documents in the criterion function, but it may not work well when the clusters are not well separated. To solve this problem, we applied the concepts of neighbors and link, introduced in [S. Guha, R. Rastogi, K. Shim, ROCK: a robust clustering algorithm for categorical attributes, Information Systems 25 (5) (2000) 345–366], to document clustering. If two documents are similar enough, they are considered as neighbors of each other. And the link between two documents represents the number of their common neighbors. Instead of just considering the pairwise similarity, the neighbors and link involve the global information into the measurement of the closeness of two documents. In this paper, we propose to use the neighbors and link for the family of k-means algorithms in three aspects: a new method to select initial cluster centroids based on the ranks of candidate documents; a new similarity measure which uses a combination of the cosine and link functions; and a new heuristic function for selecting a cluster to split based on the neighbors of the cluster centroids. Our experimental results on real-life data sets demonstrated that our proposed methods can significantly improve the performance of document clustering in terms of accuracy without increasing the execution time much.
ER  - 

TY  - JOUR
T1  - A relevance feedback mechanism for cluster-based retrieval
JO  - Information Processing & Management
VL  - 42
IS  - 5
SP  - 1176
EP  - 1184
PY  - 2006/9//
T2  - 
AU  - Rooney, Niall
AU  - Patterson, David
AU  - Galushka, Mykola
AU  - Dobrynin, Vladimir
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2006.01.009
UR  - http://www.sciencedirect.com/science/article/pii/S0306457306000136
KW  - Information retrieval
KW  - Document clustering
KW  - Relevance feedback
AB  - Contextual document clustering is a novel approach which uses information theoretic measures to cluster semantically related documents bound together by an implicit set of concepts or themes of narrow specificity. It facilitates cluster-based retrieval by assessing the similarity between a query and the cluster themes’ probability distribution. In this paper, we assess a relevance feedback mechanism, based on query refinement, that modifies the query’s probability distribution using a small number of documents that have been judged relevant to the query. We demonstrate that by providing only one relevance judgment, a performance improvement of 33% was obtained.
ER  - 

TY  - JOUR
T1  - A collaborative filtering-based approach to personalized document clustering
JO  - Decision Support Systems
VL  - 45
IS  - 3
SP  - 413
EP  - 428
PY  - 2008/6//
T2  - Special Issue Clusters
AU  - Wei, Chih-Ping
AU  - Yang, Chin-Sheng
AU  - Hsiao, Han-Wei
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2007.05.008
UR  - http://www.sciencedirect.com/science/article/pii/S0167923607000826
KW  - Document clustering
KW  - Personalization
KW  - Collaborative filtering
KW  - Hierarchical agglomerative clustering (HAC)
KW  - Text mining
AB  - Document clustering is an intentional act that reflects individual preferences with regard to the semantic coherency and relevant categorization of documents. Hence, effective document clustering must consider individual preferences and needs to support personalization in document categorization. Most existing document-clustering techniques, generally anchoring in pure content-based analysis, generate a single set of clusters for all individuals without tailoring to individuals' preferences and thus are unable to support personalization. The partial-clustering-based personalized document-clustering approach, incorporating a target individual's partial clustering into the document-clustering process, has been proposed to facilitate personalized document clustering. However, given a collection of documents to be clustered, the individual might have categorized only a small subset of the collection into his or her personal folders. In this case, the small partial clustering would degrade the effectiveness of the existing personalized document-clustering approach for this particular individual. In response, we extend this approach and propose the collaborative-filtering-based personalized document-clustering (CFC) technique that expands the size of an individual's partial clustering by considering those of other users with similar categorization preferences. Our empirical evaluation results suggest that when given a small-sized partial clustering established by an individual, the proposed CFC technique generally achieves better clustering effectiveness for the individual than does the partial-clustering-based personalized document-clustering technique.
ER  - 

TY  - JOUR
T1  - Designing evolving user profile in e-CRM with dynamic clustering of Web documents
JO  - Data & Knowledge Engineering
VL  - 65
IS  - 2
SP  - 355
EP  - 372
PY  - 2008/5//
T2  - Including Special Section: 3rd XML Schema and Data Management Workshop (XSDM 2006) – Five selected and extended papers
AU  - Mahdavi, Iraj
AU  - Cho, Namjae
AU  - Shirazi, Babak
AU  - Sahebjamnia, Navid
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2007.12.003
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X07002194
KW  - e-CRM
KW  - Data mining
KW  - Web document clustering
KW  - Neuro-fuzzy approach
KW  - User profile
AB  - Internet technology enables companies to capture new customers, track their performances and online behavior, and customize communications, products, services, and prices. Analyses of customers and customer interactions for electronic customer relationship management (e-CRM) can be performed by way of using data mining (DM), optimization methods, or combined approaches. One key issue in the analysis of access patterns on the Web is the clustering and classification of Web documents. Generally, the classification has its base on analytical models which assume a pre-fixed set of keywords (attributes) with predefined list of categories. This assumption is not realistic for large and evolving collections of documents such as World Wide Web. We propose a new approach to solve the problem of unknown number of evolving categories. The approach begins with the classification of test documents into a set of initial categories. A working prototype system which is based on Fuzzy Clustering CRM (FC-CRM) has been developed and presented to validate the proposed approach and illustrate how it handles the dynamic inflow of new documents.
ER  - 

TY  - JOUR
T1  - Exploiting noun phrases and semantic relationships for text document clustering
JO  - Information Sciences
VL  - 179
IS  - 13
SP  - 2249
EP  - 2262
PY  - 2009/6/13/
T2  - Special Section on High Order Fuzzy Sets
AU  - Zheng, Hai-Tao
AU  - Kang, Bo-Yeong
AU  - Kim, Hong-Gee
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2009.02.019
UR  - http://www.sciencedirect.com/science/article/pii/S0020025509001108
KW  - Ontology
KW  - WordNet
KW  - Text document clustering
KW  - Noun phrase
KW  - Hypernymy
KW  - Hyponymy
KW  - Holonymy
KW  - Meronymy
AB  - Text document clustering plays an important role in providing better document retrieval, document browsing, and text mining. Traditionally, clustering techniques do not consider the semantic relationships between words, such as synonymy and hypernymy. To exploit semantic relationships, ontologies such as WordNet have been used to improve clustering results. However, WordNet-based clustering methods mostly rely on single-term analysis of text; they do not perform any phrase-based analysis. In addition, these methods utilize synonymy to identify concepts and only explore hypernymy to calculate concept frequencies, without considering other semantic relationships such as hyponymy. To address these issues, we combine detection of noun phrases with the use of WordNet as background knowledge to explore better ways of representing documents semantically for clustering. First, based on noun phrases as well as single-term analysis, we exploit different document representation methods to analyze the effectiveness of hypernymy, hyponymy, holonymy, and meronymy. Second, we choose the most effective method and compare it with the WordNet-based clustering method proposed by others. The experimental results show the effectiveness of semantic relationships for clustering are (from highest to lowest): hypernymy, hyponymy, meronymy, and holonymy. Moreover, we found that noun phrase analysis improves the WordNet-based clustering method.
ER  - 

TY  - JOUR
T1  - Using backward elimination with a new model order reduction algorithm to select best double mixture model for document clustering
JO  - Expert Systems with Applications
VL  - 36
IS  - 7
SP  - 10485
EP  - 10493
PY  - 2009/9//
T2  - 
AU  - Azadi, Tahereh Emami
AU  - Almasganj, Farshad
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2009.01.068
UR  - http://www.sciencedirect.com/science/article/pii/S0957417409000694
KW  - Model selection
KW  - Document clustering
KW  - PLSA
KW  - Bayesian information criterion (BIC)
KW  - EM algorithm
AB  - Probabilistic latent semantic analysis (PLSA) is a double structure mixture model which has got a wide application in text and web mining. This method is capable of establishing hidden semantic relations among the observed features, using a number of latent variables. In this approach, the selection of the correct number of latent variables is critical. In the most of the previous researches, the number of latent topics was selected based on the number of invoked classes. This paper presents a method, based on backward elimination approach, which is capable of unsupervised order selection in PLSA. This method starts with a model having a number of components more than the needed value, and then prunes the mixtures to reach their optimum size. During the elimination process, proper selection of some latent variables which must be deleted is the most essential problem, and its relation to the final performance of the pruned model is straightforward. To treat this problem, we introduce a new combined pruning method which selects the best options for removal, while keeping a low computational cost, at all. We conducted some experiments on two datasets from Reuters-21578 corpus. The obtained results show that this algorithm leads to an optimized number of latent variables and in turn achieves better clustering performance compared to the conventional model selection methods. It also shows superiority over the case in which a PLSA model with a fixed number of latent variables, equal to the real number of clusters, is exploited.
ER  - 

TY  - JOUR
T1  - Distributed collaborative Web document clustering using cluster keyphrase summaries
JO  - Information Fusion
VL  - 9
IS  - 4
SP  - 465
EP  - 480
PY  - 2008/10//
T2  - Special Issue on Web Information Fusion
AU  - Hammouda, Khaled
AU  - Kamel, Mohamed
SN  - 1566-2535
DO  - http://dx.doi.org/10.1016/j.inffus.2006.12.001
UR  - http://www.sciencedirect.com/science/article/pii/S1566253506001151
KW  - Distributed clustering
KW  - Collaborative clustering
KW  - Document clustering
KW  - Keyphrase extraction
AB  - For the past few decades the mainstream data clustering technologies have been fundamentally based on centralized operation; data sets were of small manageable sizes, and usually resided on one site that belonged to one organization. Today, data is of enormous sizes and is usually located on distributed sites; the primary example being the Web. This created a need for performing clustering in distributed environments. Distributed clustering solves two problems: infeasibility of collecting data at a central site, due to either technical and/or privacy limitations, and intractability of traditional clustering algorithms on huge data sets. In this paper we propose a distributed collaborative clustering approach for clustering Web documents in distributed environments. We adopt a peer-to-peer model, where the main objective is to allow nodes in a network to first form independent opinions of local document clusterings, then collaborate with peers to enhance the local clusterings. Information exchanged between peers is minimized through the use of cluster summaries in the form of keyphrases extracted from the clusters. This summarized view of peer data enables nodes to request merging of remote data selectively to enhance local clusters. Initial clustering, as well as merging peer data with local clusters, utilizes a clustering method, called similarity histogram-based clustering, based on keeping a tight similarity distribution within clusters. This approach achieves significant improvement in local clustering solutions without the cost of centralized clustering, while maintaining the initial local clustering structure. Results show that larger networks exhibit larger improvements, up to 15% improvement in clustering quality, albeit lower absolute clustering quality than smaller networks.
ER  - 

TY  - JOUR
T1  - A flocking based algorithm for document clustering analysis
JO  - Journal of Systems Architecture
VL  - 52
IS  - 8–9
SP  - 505
EP  - 515
PY  - 2006/8//
Y2  - 2006/9//
T2  - Nature-Inspired Applications and Systems
AU  - Cui, Xiaohui
AU  - Gao, Jinzhu
AU  - Potok, Thomas E.
SN  - 1383-7621
DO  - http://dx.doi.org/10.1016/j.sysarc.2006.02.003
UR  - http://www.sciencedirect.com/science/article/pii/S1383762106000191
KW  - Document clustering
KW  - Bio-inspired
KW  - Agent
KW  - Flocking model
KW  - F-measure
AB  - Social animals or insects in nature often exhibit a form of emergent collective behavior known as flocking. In this paper, we present a novel Flocking based approach for document clustering analysis. Our Flocking clustering algorithm uses stochastic and heuristic principles discovered from observing bird flocks or fish schools. Unlike other partition clustering algorithm such as K-means, the Flocking based algorithm does not require initial partitional seeds. The algorithm generates a clustering of a given set of data through the embedding of the high-dimensional data items on a two-dimensional grid for easy clustering result retrieval and visualization. Inspired by the self-organized behavior of bird flocks, we represent each document object with a flock boid. The simple local rules followed by each flock boid result in the entire document flock generating complex global behaviors, which eventually result in a clustering of the documents. We evaluate the efficiency of our algorithm with both a synthetic dataset and a real document collection that includes 100 news articles collected from the Internet. Our results show that the Flocking clustering algorithm achieves better performance compared to the K-means and the Ant clustering algorithm for real document clustering.
ER  - 

TY  - JOUR
T1  - Towards effective document clustering: A constrained K-means based approach
JO  - Information Processing & Management
VL  - 44
IS  - 4
SP  - 1397
EP  - 1409
PY  - 2008/7//
T2  - 
AU  - Hu, Guobiao
AU  - Zhou, Shuigeng
AU  - Guan, Jihong
AU  - Hu, Xiaohua
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2008.03.001
UR  - http://www.sciencedirect.com/science/article/pii/S0306457308000435
KW  - Document clustering
KW  - Semi-supervised learning
KW  - Spectral relaxation
KW  - Clustering with prior knowledge
AB  - Document clustering is an important tool for document collection organization and browsing. In real applications, some limited knowledge about cluster membership of a small number of documents is often available, such as some pairs of documents belonging to the same cluster. This kind of prior knowledge can be served as constraints for the clustering process. We integrate the constraints into the trace formulation of the sum of square Euclidean distance function of K-means. Then,the combined criterion function is transformed into trace maximization, which is further optimized by eigen-decomposition. Our experimental evaluation shows that the proposed semi-supervised clustering method can achieve better performance, compared to three existing methods.
ER  - 

TY  - JOUR
T1  - Clustering of document collection – A weighting approach
JO  - Expert Systems with Applications
VL  - 36
IS  - 4
SP  - 7904
EP  - 7916
PY  - 2009/5//
T2  - 
AU  - Aliguliyev, Ramiz M.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2008.11.017
UR  - http://www.sciencedirect.com/science/article/pii/S0957417408008221
KW  - Text mining
KW  - Weighted partitional clustering
KW  - Adjusted cosine similarity measure
KW  - Validity index
KW  - Differential evolution
AB  - Abstract
Clustering algorithms are used to assess the interaction among documents by organizing documents into clusters such that document within a cluster are more similar to each other than are documents belonging to different clusters. Document clustering has been traditionally investigated as a means of improving the performance of search engines by pre-clustering the entire corpus, and a post-retrieval document browsing technique as well. It has long been studied as a post-retrieval document visualization technique. The purpose of present paper to show that assignment weight to documents improves clustering solution.
ER  - 

TY  - JOUR
T1  - Reliability and validity of a computer-based knowledge mapping system to measure content understanding
JO  - Computers in Human Behavior
VL  - 15
IS  - 3–4
SP  - 315
EP  - 333
PY  - 1999/5/31/
T2  - 
AU  - Herl, H.E
AU  - O'Neil Jr, H.F
AU  - Chung, G.K.W.K
AU  - Schacter, J
SN  - 0747-5632
DO  - http://dx.doi.org/10.1016/S0747-5632(99)00026-6
UR  - http://www.sciencedirect.com/science/article/pii/S0747563299000266
KW  - Knowledge mapping
KW  - Content understanding
KW  - Computer-based
AB  - The motivating concern behind CRESST's knowledge mapping research has been the desire to assess students' understanding of relationships utilizing a format that departs from both standardized multiple-choice testing and discourse-dependent tasks (e.g. essays). Fusing computer technology and knowledge mapping environments creates new instructional and assessment opportunities, primarily by providing the capability for real-time scoring, feedback, reporting, networking, and Internet/Web access. Overall, 149 middle and high school students participated in two computer-based knowledge mapping studies: (1) students constructed group maps while collaborating over a network, and (2) students constructed individual maps, attempting to improve their maps while searching a Web space. Results showed that knowledge map scores increased significantly from fall to spring for students constructing maps individually while searching a web space containing relevant and irrelevant information about environmental science. This finding supports the position that students' abilities in searching and processing information on the Internet may have increased as a result of using computer technology over the course of the school year. On the other hand, virtually no differences were found for group knowledge maps from fall to spring, and therefore no clear relationships among content understanding and collaboration were found. Four teachers' knowledge maps served as ‘expert criteria’ to evaluate individual student's and group's knowledge maps. The most important reliability issue for both studies focused on inter-expert agreement using teachers' maps to score students' maps. In the studies presented here, inter-expert pairwise agreements for both studies were in the 80–90 percentage range.
ER  - 

TY  - JOUR
T1  - A scaleable document clustering approach for large document corpora
JO  - Information Processing & Management
VL  - 42
IS  - 5
SP  - 1163
EP  - 1175
PY  - 2006/9//
T2  - 
AU  - Rooney, Niall
AU  - Patterson, David
AU  - Galushka, Mykola
AU  - Dobrynin, Vladimir
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2005.10.003
UR  - http://www.sciencedirect.com/science/article/pii/S0306457305001494
KW  - Information retrieval
KW  - Document clustering
AB  - In this paper, the scalability and quality of the contextual document clustering (CDC) approach is demonstrated for large data-sets using the whole Reuters Corpus Volume 1 (RCV1) collection. CDC is a form of distributional clustering, which automatically discovers contexts of narrow scope within a document corpus. These contexts act as attractors for clustering documents that are semantically related to each other. Once clustered, the documents are organized into a minimum spanning tree so that the topical similarity of adjacent documents within this structure can be assessed. The pre-defined categories from three different document category sets are used to assess the quality of CDC in terms of its ability to group and structure semantically related documents given the contexts. Quality is evaluated based on two factors, the category overlap between adjacent documents within a cluster, and how well a representative document categorizes all the other documents within a cluster. As the RCV1 collection was collated in a time ordered fashion, it was possible to assess the stability of clusters formed from documents within one time interval when presented with new unseen documents at subsequent time intervals. We demonstrate that CDC is a powerful and scaleable technique with the ability to create stable clusters of high quality. Additionally, to our knowledge this is the first time that a collection as large as RCV1 has been analyzed in its entirety using a static clustering approach.
ER  - 

TY  - JOUR
T1  - Tree view self-organisation of web content
JO  - Neurocomputing
VL  - 63
IS  - 
SP  - 415
EP  - 446
PY  - 2005/1//
T2  - New Aspects in Neurocomputing: 11th European Symposium on Artificial Neural Networks
AU  - Freeman, Richard T.
AU  - Yin, Hujun
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2004.07.005
UR  - http://www.sciencedirect.com/science/article/pii/S0925231204003376
KW  - Self-organising maps
KW  - Document clustering
KW  - Information retrieval
KW  - Browsing and navigation
KW  - Knowledge management
AB  - When browsing a large set of unstructured documents, it is advantageous if the documents have been organised and presented in a way that makes navigation efficient, understanding underlying concepts easy and locating related information quickly. This paper proposes a new method termed Treeview self-organising maps (Treeview SOMs) for clustering and organising text documents by means of a series of independently and automatically created, hierarchical one-dimensional SOMs. The method generates a topological taxonomy tree for a set of unstructured text documents in terms of presentation and visualisation. The documents are organised in a hierarchy of dynamically generated and automatically validated topics extracted from the corpus of the documents. The results presented in a labelled tree view, clearly show underlying contents of the documents and can help browsing the document set more efficiently than those of previous work using SOMs or hierarchical clustering methods. A brief overview on general document clustering and a review on SOM-based document analysis methods are also provided together with a comparison among them.
ER  - 

TY  - JOUR
T1  - The use of computer-based collaborative knowledge mapping to measure team processes and team outcomes
JO  - Computers in Human Behavior
VL  - 15
IS  - 3–4
SP  - 463
EP  - 493
PY  - 1999/5/31/
T2  - 
AU  - Chung, G.K.W.K.
AU  - O'Neil Jr., H.F.
AU  - Herl, H.E.
SN  - 0747-5632
DO  - http://dx.doi.org/10.1016/S0747-5632(99)00032-1
UR  - http://www.sciencedirect.com/science/article/pii/S0747563299000321
KW  - Knowledge mapping
KW  - Team processes
KW  - Team outcomes
KW  - Computer-based
AB  - In this study we examined the feasibility of using a computer-based, networked collaborative knowledge mapping system to measure teamwork skills. A knowledge map is a node–link–node representation of information, where nodes represent concepts and links represent relationships between connected concepts. We studied the nature of the interaction between team members as they jointly constructed a knowledge map. Each team member was randomly assigned to a team and communicated (anonymously) with other members by sending pre defined messages. Teamwork processes were measured by examining message usage. Each message was categorized as belonging to one of six team processes: (1) adaptability; (2) communication; (3) coordination; (4) decision making; (5) interpersonal; and (6) leadership. Team performance was measured by scoring each team's knowledge map using four expert maps as the criterion. No significant correlations were found between the team processes and team outcomes. This unexpected finding may be due in part to a split-attention effect resulting from the design of the user interface. However, students were able to successfully construct knowledge maps using our system, suggesting that our general approach to using networked computers to measure group processes remain viable given existing alternatives.
ER  - 

TY  - JOUR
T1  - Integrating query expansion and conceptual relevance feedback for personalized Web information retrieval
JO  - Computer Networks and ISDN Systems
VL  - 30
IS  - 1–7
SP  - 621
EP  - 623
PY  - 1998/4//
T2  - Proceedings of the Seventh International World Wide Web Conference
AU  - Chang, Chia-Hui
AU  - Hsu, Ching-Chi
SN  - 0169-7552
DO  - http://dx.doi.org/10.1016/S0169-7552(98)00076-2
UR  - http://www.sciencedirect.com/science/article/pii/S0169755298000762
KW  - Query expansion
KW  - Relevance feedback
KW  - Document clustering
AB  - Keyword based querying has been an immediate and efficient way to specify and retrieve related information that the user inquired. However, conventional document ranking based on an automatic assessment of document relevance to the query may not be the best approach when little information is given. In this poster, we propose an idea to integrate two existing techniques: query expansion and relevance feedback to achieve a concept-based information search for the Web.
ER  - 

TY  - CHAP
AU  - Avramenko, Yuri
AU  - Kraslawski, Andrzej
T1  - Mining of graphics for identification of mechanisms and trends of processes
A2  - Valentin Pleşu and Paul Şerban Agachi
BT  - Computer Aided Chemical Engineering
PB  - Elsevier
PY  - 2007///
VL  - Volume 24
SP  - 249
EP  - 254
T2  - 17th European Symposium on Computer Aided Process Engineering
SN  - 1570-7946
DO  - http://dx.doi.org/10.1016/S1570-7946(07)80065-4
UR  - http://www.sciencedirect.com/science/article/pii/S1570794607800654
KW  - shape comparison
KW  - similarity measurement
KW  - concept retrieval
AB  - The paper describes a method for identification of mechanisms and process trends based on combination of subject-driven document clustering, shape analysis, trends understanding and relevant context retrieval via semantic analysis. The goal is to extract potentially interesting knowledge from a set of technical information based on analysis of graphical information in order to find explanation for a specific process behavior.
ER  - 

TY  - JOUR
T1  - Automated ontology instantiation from tabular web sources—The AllRight system
JO  - Web Semantics: Science, Services and Agents on the World Wide Web
VL  - 7
IS  - 3
SP  - 136
EP  - 153
PY  - 2009/9//
T2  - The Web of Data
AU  - Jannach, Dietmar
AU  - Shchekotykhin, Kostyantyn
AU  - Friedrich, Gerhard
SN  - 1570-8268
DO  - http://dx.doi.org/10.1016/j.websem.2009.04.002
UR  - http://www.sciencedirect.com/science/article/pii/S1570826809000055
KW  - Web mining
KW  - Web crawling
KW  - Ontology instantiation
KW  - Knowledge extraction
AB  - The process of populating an ontology-based system with high-quality and up-to-date instance information can be both time-consuming and prone to error. In many domains, however, one possible solution to this problem is to automate the instantiation process for a given ontology by searching (mining) the web for the required instance information.

The primary challenges facing such system include: (a) efficiently locating web pages that most probably contain the desired instance information, (b) extracting the instance information from a page, and (c) clustering documents that describe the same instance in order to exploit data redundancy on the web and thus improve the overall quality of the harvested data. In addition, these steps should require as little seed knowledge as possible.

In this paper, the AllRight ontology instantiation system is presented, which supports the full instantiation life-cycle and addresses the above-mentioned challenges through a combination of new and existing techniques. In particular the system was designed to deal with situations where the instance information is given in tabular form. The main innovative pillars of the system are a new high-recall focused crawling technique (xCrawl), a novel table recognition algorithm, innovative methods for document clustering and instance name recognition, as well as techniques for fact extraction, instance generation and query-based fact validation.

The successful evaluation of the system in different real-world application scenarios shows that the ontology instantiation process can be successfully automated using only a very limited amount of seed knowledge.
ER  - 

TY  - JOUR
T1  - An efficient document clustering algorithm and its application to a document browser
JO  - Information Processing & Management
VL  - 35
IS  - 4
SP  - 541
EP  - 557
PY  - 1999/7//
T2  - 
AU  - Tanaka, Hideki
AU  - Kumano, Tadashi
AU  - Uratani, Noriyoshi
AU  - Terumasa Ehara
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(98)00056-9
UR  - http://www.sciencedirect.com/science/article/pii/S0306457398000569
KW  - Document clustering
KW  - Document retrieval
KW  - Automatic document organization
AB  - We present an efficient document clustering algorithm that uses a term frequency vector for each document instead of using a huge proximity matrix. The algorithm has the following features: (1) it requires a relatively small amount of memory and runs fast, (2) it produces a hierarchy in the form of a document classification tree and (3) the hierarchy obtained by the algorithm explicitly reveals a collection structure. We confirm these features and thus show the algorithm's feasibility through clustering experiments in which we use two collections of Japanese documents, the sizes of which are 83,099 and 14,701 documents. We also introduce an application of this algorithm to a document browser. This browser is used in our Japanese-to-English translation aid system. The browsing module of the system consists of a huge database of Japanese news articles and their English translations. The Japanese article collection is clustered into a hierarchy by our method. Since each node in the hierarchy corresponds to a topic in the collection, we can use the hierarchy to directly access articles by topic. A user can learn general translation knowledge of each topic by browsing the Japanese articles and their English translations. We also discuss techniques of presenting a large tree-formed hierarchy on a computer screen.
ER  - 

TY  - JOUR
T1  - Using Web structure and summarisation techniques for Web content mining
JO  - Information Processing & Management
VL  - 41
IS  - 5
SP  - 1225
EP  - 1242
PY  - 2005/9//
T2  - 
AU  - Lihui, Chen
AU  - Wai Lian, Chue
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2004.08.003
UR  - http://www.sciencedirect.com/science/article/pii/S0306457304001049
KW  - Knowledge representation of Web Documents
KW  - Web structure
KW  - Summarisation
KW  - Web content mining
KW  - Content-based automatic Web Document clustering
AB  - The dynamic nature and size of the Internet can result in difficulty finding relevant information. Most users typically express their information need via short queries to search engines and they often have to physically sift through the search results based on relevance ranking set by the search engines, making the process of relevance judgement time-consuming. In this paper, we describe a novel representation technique which makes use of the Web structure together with summarisation techniques to better represent knowledge in actual Web Documents. We named the proposed technique as Semantic Virtual Document (SVD). We will discuss how the proposed SVD can be used together with a suitable clustering algorithm to achieve an automatic content-based categorization of similar Web Documents. The auto-categorization facility as well as a “Tree-like” Graphical User Interface (GUI) for post-retrieval document browsing enhances the relevance judgement process for Internet users. Furthermore, we will introduce how our cluster-biased automatic query expansion technique can be used to overcome the ambiguity of short queries typically given by users. We will outline our experimental design to evaluate the effectiveness of the proposed SVD for representation and present a prototype called iSEARCH (Intelligent SEarch And Review of Cluster Hierarchy) for Web content mining. Our results confirm, quantify and extend previous research using Web structure and summarisation techniques, introducing novel techniques for knowledge representation to enhance Web content mining.
ER  - 

TY  - JOUR
T1  - The Hidden Structure of Neuropsychology: Text Mining of the Journal Cortex: 1991-2001
JO  - Cortex
VL  - 41
IS  - 2
SP  - 103
EP  - 115
PY  - 2005///
T2  - 
AU  - Kostoff, Ronald N.
AU  - Buchtel, Henry A.
AU  - Andrews, John
AU  - Pfeil, Kirstin M.
SN  - 0010-9452
DO  - http://dx.doi.org/10.1016/S0010-9452(08)70885-2
UR  - http://www.sciencedirect.com/science/article/pii/S0010945208708852
KW  - information technology
KW  - text mining
KW  - bibliometrics
KW  - computational linguistics
KW  - citation mining
KW  - document clustering
KW  - neuropsychology
AB  - Background: The stated mission of Cortex is “the study of the inter-relations of the nervous system and behavior, particularly as these are reflected in the effects of brain lesions on cognitive functions.” The purpose of this paper is to explore the relationship between the stated mission and the executed mission as reflected by the characteristics of papers published in Cortex. In addition, we examine whether the results and conclusions of an analysis of this kind are affected by the level of description of the published papers.

Objectives:

A) Identify characteristics of contributors to Cortex;

B) Identify characteristics of those who cite Cortex;

C) Identify recurring themes;

D) Identify the relationships among the recurring themes;

E) Compare recurring themes and determine their relationships to the mission of Cortex;

F) Identify the sensitivity of these results to the level of description of the Cortex papers used as the source database.

G) Compare Cortex characteristics with those of Neuropsychologia, another Europe-based international neuropsychology journal.

Methods: Text mining (extraction of useful information from text) was used to generate the characteristics of the journal Cortex. Bibliometrics provided the Cortex contributor infrastructure (author/ organization/ country/ citation distributions), and computational linguistics identified the recurring technical themes and their inter-relationships. Citation mining (the integration of citation bibliometrics and text mining) was used to profile the research user community. Four levels of published article description were compared for the analysis: Full Text, Abstract, Title, Keywords.

Results and Conclusions: Highly cited documents were compared among Cortex, Neuropsychologia, andBrain, and a number of interesting parametric trends were observed. The characteristics of the papers that cite Cortex papers were examined, and some interesting insights were generated. Finally, the document clustering taxonomy showed that papers in Cortex can be reasonably divided into four categories (papers in each category in parenthesis): Semantic Memory (151); Handedness (145); Amnesia (119); and Neglect (66).

It is concluded that Cortex needs to take steps to attract a more diverse group of contributors outside its continental Western European base if it wishes to capture a greater share of seminal neuropsychology papers. Further investigation of the critical citation differences reported in the paper is recommended.
ER  - 

TY  - JOUR
T1  - Creating knowledge maps by exploiting dependent relationships
JO  - Knowledge-Based Systems
VL  - 13
IS  - 2–3
SP  - 71
EP  - 79
PY  - 2000/4//
T2  - 
AU  - Gordon, J.L
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/S0950-7051(00)00048-4
UR  - http://www.sciencedirect.com/science/article/pii/S0950705100000484
KW  - Knowledge-mapping
KW  - Knowledge-management
KW  - Learning-dependency
AB  - Knowledge is an interesting concept that has attracted the attention of philosophers for thousands of years. In more recent times, researchers have investigated knowledge in a more applied way with the chief aim of bringing knowledge to life in machines. Artificial Intelligence has provided some degree of rigour to the study of knowledge and Expert Systems are able to use knowledge to solve problems and answer questions.

Current business, social, political and technological pressures have forced organisations to take greater control of the knowledge asset. Software suppliers and others offering valuable solutions in this area have unfortunately clouded the issue of knowledge. Information and data control are seen as implicit knowledge management tools and many have abandoned the search for explicit knowledge management methods.

Knowledge representation schemes help to identify knowledge. They allow for human understanding and machine application and they can support the automated use of knowledge in problem solving. Some of these representation methods also employ spatial techniques that add an extra dimension to human understanding.

Knowledge mapping defined in this work uses learning dependency to organise the map and draws on the ideas of what knowledge is and on spatial representation structures. Knowledge maps can support metrics that provide information about the knowledge asset. Knowledge maps create a visible knowledge framework that supports the explicit management of knowledge by organisation managers and directors. Knowledge maps also offer other advantages to the organisation, the individual and to educational institutions.
ER  - 

TY  - JOUR
T1  - A Document Clustering and Ranking System for Exploring MEDLINE Citations
JO  - Journal of the American Medical Informatics Association
VL  - 14
IS  - 5
SP  - 651
EP  - 661
PY  - 2007/9//
Y2  - 2007/10//
T2  - 
AU  - Lin, Yongjing
AU  - Li, Wenyuan
AU  - Chen, Keke
AU  - Liu, Ying
SN  - 1067-5027
DO  - http://dx.doi.org/10.1197/jamia.M2215
UR  - http://www.sciencedirect.com/science/article/pii/S1067502707001685
AB  - Objective
A major problem faced in biomedical informatics involves how best to present information retrieval results. When a single query retrieves many results, simply showing them as a long list often provides poor overview. With a goal of presenting users with reduced sets of relevant citations, this study developed an approach that retrieved and organized MEDLINE citations into different topical groups and prioritized important citations in each group.
Design
A text mining system framework for automatic document clustering and ranking organized MEDLINE citations following simple PubMed queries. The system grouped the retrieved citations, ranked the citations in each cluster, and generated a set of keywords and MeSH terms to describe the common theme of each cluster.
Measurements
Several possible ranking functions were compared, including citation count per year (CCPY), citation count (CC), and journal impact factor (JIF). We evaluated this framework by identifying as “important” those articles selected by the Surgical Oncology Society.
Results
Our results showed that CCPY outperforms CC and JIF, i.e., CCPY better ranked important articles than did the others. Furthermore, our text clustering and knowledge extraction strategy grouped the retrieval results into informative clusters as revealed by the keywords and MeSH terms extracted from the documents in each cluster.
Conclusions
The text mining system studied effectively integrated text clustering, text summarization, and text ranking and organized MEDLINE retrieval results into different topical groups.
ER  - 

TY  - JOUR
T1  - Adaptive topological tree structure for document organisation and visualisation
JO  - Neural Networks
VL  - 17
IS  - 8–9
SP  - 1255
EP  - 1271
PY  - 2004/10//
Y2  - 2004/11//
T2  - New Developments in Self-Organizing Systems
AU  - Freeman, Richard T.
AU  - Yin, Hujun
SN  - 0893-6080
DO  - http://dx.doi.org/10.1016/j.neunet.2004.08.006
UR  - http://www.sciencedirect.com/science/article/pii/S0893608004001637
KW  - Self-organizing maps
KW  - Document clustering
KW  - Information retrieval
KW  - Growing network
KW  - Unsupervised learning
KW  - Text mining
AB  - The self-organising map (SOM) is finding more and more applications in a wide range of fields, such as clustering, pattern recognition and visualisation. It has also been employed in knowledge management and information retrieval. We propose an alternative to existing 2-dimensional SOM based methods for document analysis. The method, termed Adaptive Topological Tree Structure (ATTS), generates a taxonomy of underlying topics from a set of unclassified, unstructured documents. The ATTS consists of a hierarchy of adaptive self-organising chains, each of which is validated independently using a proposed entropy-based Bayesian information criterion. A node meeting the expansion criterion spans a child chain, with reduced vocabulary and increased specialisation. The ATTS creates a topological tree of topics, which can be browsed like a content hierarchy and reflects the connections between related topics at each level. A review is also given on the existing neural network based methods for document clustering and organisation. Experimental results on real-world datasets using the proposed ATTS method are presented and compared with other approaches. The results demonstrate the advantages of the proposed validation criteria and the efficiency of the ATTS approach for document organisation, visualisation and search. It shows that the proposed methods not only improve the clustering results but also boost the retrieval.
ER  - 

TY  - JOUR
T1  - Discover the semantic topology in high-dimensional data
JO  - Expert Systems with Applications
VL  - 33
IS  - 1
SP  - 256
EP  - 262
PY  - 2007/7//
T2  - 
AU  - Chiang, I-Jen
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2006.05.033
UR  - http://www.sciencedirect.com/science/article/pii/S0957417406001813
KW  - Document clustering
KW  - Association rules
KW  - Hierarchical clustering
KW  - Simplicial complex
AB  - Discovering the homogeneous concept groups in the high-dimensional data sets and clustering them accordingly are contemporary challenge. Conventional clustering techniques often based on Euclidean metric. However, the metric is ad hoc not intrinsic to the semantic of the documents. In this paper, we are proposing a novel approach, in which the semantic space of high-dimensional data is structured as a simplicial complex of Euclidean space (a hypergraph but with different focus). Such a simplicial structure intrinsically captures the semantic of the data; for example, the coherent topics of documents will appear in the same connected component. Finally, we cluster the data by the structure of concepts, which is organized by such a geometry.
ER  - 

TY  - JOUR
T1  - The structure and infrastructure of Mexico's science and technology
JO  - Technological Forecasting and Social Change
VL  - 72
IS  - 7
SP  - 798
EP  - 814
PY  - 2005/9//
T2  - 
AU  - Kostoff, Ronald N.
AU  - Antonio del Río, J.
AU  - Cortés, Héctor D.
AU  - Smith, Charles
AU  - Smith, Andrew
AU  - Wagner, Caroline
AU  - Leydesdorff, Loet
AU  - Karypis, George
AU  - Malpohl, Guido
AU  - Tshiteya, Rene
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2005.02.001
UR  - http://www.sciencedirect.com/science/article/pii/S0040162505000260
KW  - Mexico
KW  - Science and technology
KW  - Bibliometrics
KW  - Computational linguistics
KW  - Core competencies
KW  - Research evaluation
KW  - Factor analysis
KW  - Concept clustering
KW  - Document clustering
KW  - Data compression
KW  - Network analysis
KW  - Leximancer
KW  - CLUTO
KW  - Greedy string tiling
AB  - The structure and infrastructure of the Mexican technical literature was determined. A representative database of technical articles was extracted from the Science Citation Index for the year 2002, with each article containing at least one author with a Mexican address. Many different manual and statistical clustering methods were used to identify the structure of the technical literature (especially the science and technology core competencies). One of the pervasive technical topics identified from the clustering, thin films research, was analyzed further using bibliometrics, in order to identify the infrastructure of this technology.
ER  - 

TY  - JOUR
T1  - Grouper: a dynamic clustering interface to Web search results
JO  - Computer Networks
VL  - 31
IS  - 11–16
SP  - 1361
EP  - 1374
PY  - 1999/5/17/
T2  - 
AU  - Zamir, Oren
AU  - Etzioni, Oren
SN  - 1389-1286
DO  - http://dx.doi.org/10.1016/S1389-1286(99)00054-7
UR  - http://www.sciencedirect.com/science/article/pii/S1389128699000547
KW  - Document clustering
KW  - User interface
KW  - Search engine
KW  - Visualization
AB  - Users of Web search engines are often forced to sift through the long ordered list of document `snippets' returned by the engines. The IR community has explored document clustering as an alternative method of organizing retrieval results, but clustering has yet to be deployed on most major search engines. The NorthernLight search engine organizes its output into `custom folders' based on pre-computed document labels, but does not reveal how the folders are generated or how well they correspond to users' interests. In this paper, we introduce Grouper, an interface to the results of the HuskySearch meta-search engine, which dynamically groups the search results into clusters labeled by phrases extracted from the snippets. In addition, we report on the first empirical comparison of user Web search behavior on a standard ranked-list presentation versus a clustered presentation. By analyzing HuskySearch logs, we are able to demonstrate substantial differences in the number of documents followed, and in the amount of time and effort expended by users accessing search results through these two interfaces.
ER  - 

TY  - JOUR
T1  - Performance evaluation of density-based clustering methods
JO  - Information Sciences
VL  - 179
IS  - 20
SP  - 3583
EP  - 3602
PY  - 2009/9/29/
T2  - 
AU  - Aliguliyev, Ramiz M.
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2009.06.012
UR  - http://www.sciencedirect.com/science/article/pii/S0020025509002564
KW  - Text mining
KW  - Partitional clustering
KW  - Density-based clustering methods
KW  - Validity indices
KW  - Modified DE algorithm
AB  - With the development of the World Wide Web, document clustering is receiving more and more attention as an important and fundamental technique for unsupervised document organization, automatic topic extraction, and fast information retrieval or filtering. A good document clustering approach can assist computers in organizing the document corpus automatically into a meaningful cluster hierarchy for efficient browsing and navigation, which is very valuable for complementing the deficiencies of traditional information retrieval technologies. In this paper, we study the performance of different density-based criterion functions, which can be classified as internal, external or hybrid, in the context of partitional clustering of document datasets. In our study, a weight was assigned to each document, which defined its relative position in the entire collection. To show the efficiency of the proposed approach, the weighted methods were compared to their unweighted variants. To verify the robustness of the proposed approach, experiments were conducted on datasets with a wide variety of numbers of clusters, documents and terms. To evaluate the criterion functions, we used the WebKb, Reuters-21578, 20Newsgroups-18828, WebACE and TREC-5 datasets, as they are currently the most widely used benchmarks in document clustering research. To evaluate the quality of a clustering solution, a wide spectrum of indices, three internal validity indices and seven external validity indices, were used. The internal validity indices were used for evaluating the within-cluster scatter and between cluster separations. The external validity indices were used for comparing the clustering solutions produced by the proposed criterion functions with the “ground truth” results. Experiments showed that our approach significantly improves clustering quality. In this paper, we developed a modified differential evolution (DE) algorithm to optimize the criterion functions. This modification accelerates the convergence of DE and, unlike the basic DE algorithm, guarantees that the received solution will be feasible.
ER  - 

TY  - JOUR
T1  - Modeling user interests by conceptual clustering
JO  - Information Systems
VL  - 31
IS  - 4–5
SP  - 247
EP  - 265
PY  - 2006/6//
Y2  - 2006/7//
T2  - The Semantic Web and Web Services
AU  - Godoy, Daniela
AU  - Amandi, Analía
SN  - 0306-4379
DO  - http://dx.doi.org/10.1016/j.is.2005.02.008
UR  - http://www.sciencedirect.com/science/article/pii/S0306437905000335
KW  - Personal information agents
KW  - Conceptual clustering
KW  - Ontology learning
AB  - As more information becomes available on the Web, there has been a crescent interest in effective personalization techniques. Personal agents providing assistance based on the content of Web documents and the user interests emerged as a viable alternative to this problem. Provided that these agents rely on having knowledge about users contained into user profiles, i.e., models of user preferences and interests gathered by observation of user behavior, the capacity of acquiring and modeling user interest categories has become a critical component in personal agent design. User profiles have to summarize categories corresponding to diverse user information interests at different levels of abstraction in order to allow agents to decide on the relevance of new pieces of information. In accomplishing this goal, document clustering offers the advantage that an a priori knowledge of categories is not needed, therefore the categorization is completely unsupervised. In this paper we present a document clustering algorithm, named WebDCC (Web Document Conceptual Clustering), that carries out incremental, unsupervised concept learning over Web documents in order to acquire user profiles. Unlike most user profiling approaches, this algorithm offers comprehensible clustering solutions that can be easily interpreted and explored by both users and other agents. By extracting semantics from Web pages, this algorithm also produces intermediate results that can be finally integrated in a machine-understandable format such as an ontology. Empirical results of using this algorithm in the context of an intelligent Web search agent proved it can reach high levels of accuracy in suggesting Web pages.
ER  - 

TY  - JOUR
T1  - Recommendation systems for decision support: An editorial introduction
JO  - Decision Support Systems
VL  - 45
IS  - 3
SP  - 385
EP  - 386
PY  - 2008/6//
T2  - Special Issue Clusters
AU  - Liang, Ting-Peng
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2007.05.003
UR  - http://www.sciencedirect.com/science/article/pii/S0167923607000796
KW  - Recommendation systems
KW  - Website browsing
KW  - Personalized decision support
AB  - This special section is focused on recommendation systems, computer-based information systems that provide suggestions based on previous usage behavior. The papers included in this section were selected from the Pacific Asia Conference on Information Systems (PACIS) and Workshop on Electronic Business (WEB). The application domains include website browsing aids, knowledge recommendation, document clustering, and team staff selection. They provide a snapshot of current development in using recommendation systems for decision support.
ER  - 

TY  - JOUR
T1  - Genetic algorithm for text clustering based on latent semantic indexing
JO  - Computers & Mathematics with Applications
VL  - 57
IS  - 11–12
SP  - 1901
EP  - 1907
PY  - 2009/6//
T2  - Proceedings of the International ConferenceBio-Inspired Computing-Theories and Applications BIC-TA 2007 Zhengzhou, China
AU  - Song, Wei
AU  - Park, Soon Cheol
SN  - 0898-1221
DO  - http://dx.doi.org/10.1016/j.camwa.2008.10.010
UR  - http://www.sciencedirect.com/science/article/pii/S0898122108005300
KW  - Document representation model
KW  - Genetic algorithm
KW  - Latent semantic indexing
KW  - Text clustering
AB  - In this paper, we develop a genetic algorithm method based on a latent semantic model (GAL) for text clustering. The main difficulty in the application of genetic algorithms (GAs) for document clustering is thousands or even tens of thousands of dimensions in feature space which is typical for textual data. Because the most straightforward and popular approach represents texts with the vector space model (VSM), that is, each unique term in the vocabulary represents one dimension. Latent semantic indexing (LSI) is a successful technology in information retrieval which attempts to explore the latent semantics implied by a query or a document through representing them in a dimension-reduced space. Meanwhile, LSI takes into account the effects of synonymy and polysemy, which constructs a semantic structure in textual data. GA belongs to search techniques that can efficiently evolve the optimal solution in the reduced space. We propose a variable string length genetic algorithm which has been exploited for automatically evolving the proper number of clusters as well as providing near optimal data set clustering. GA can be used in conjunction with the reduced latent semantic structure and improve clustering efficiency and accuracy. The superiority of GAL approach over conventional GA applied in VSM model is demonstrated by providing good Reuter document clustering results.
ER  - 

TY  - JOUR
T1  - Adaptive document clustering based on query-based similarity
JO  - Information Processing & Management
VL  - 43
IS  - 4
SP  - 887
EP  - 901
PY  - 2007/7//
T2  - 
AU  - Na, Seung-Hoon
AU  - Kang, In-Su
AU  - Lee, Jong-Hyeok
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2006.08.008
UR  - http://www.sciencedirect.com/science/article/pii/S0306457306001385
KW  - Adaptive document clustering
KW  - Query-based similarity
KW  - Cluster-based retrieval
KW  - Language modeling approach
AB  - In information retrieval, cluster-based retrieval is a well-known attempt in resolving the problem of term mismatch. Clustering requires similarity information between the documents, which is difficult to calculate at a feasible time. The adaptive document clustering scheme has been investigated by researchers to resolve this problem. However, its theoretical viewpoint has not been fully discovered. In this regard, we provide a conceptual viewpoint of the adaptive document clustering based on query-based similarities, by regarding the user’s query as a concept. As a result, adaptive document clustering scheme can be viewed as an approximation of this similarity. Based on this idea, we derive three new query-based similarity measures in language modeling framework, and evaluate them in the context of cluster-based retrieval, comparing with K-means clustering and full document expansion. Evaluation result shows that retrievals based on query-based similarities significantly improve the baseline, while being comparable to other methods. This implies that the newly developed query-based similarities become feasible criterions for adaptive document clustering.
ER  - 

TY  - JOUR
T1  - Field independent probabilistic model for clustering multi-field documents
JO  - Information Processing & Management
VL  - 45
IS  - 5
SP  - 555
EP  - 570
PY  - 2009/9//
T2  - 
AU  - Zhu, Shanfeng
AU  - Takigawa, Ichigaku
AU  - Zeng, Jia
AU  - Mamitsuka, Hiroshi
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2009.03.005
UR  - http://www.sciencedirect.com/science/article/pii/S0306457309000284
KW  - Document clustering
KW  - Finite mixture model
KW  - Multivariate Bernoulli model
KW  - Multinomial model
KW  - Field independent clustering model
AB  - We propose a new finite mixture model for clustering multiple-field documents, such as scientific literature with distinct fields: title, abstract, keywords, main text and references. This probabilistic model, which we call field independent clustering model (FICM), incorporates the distinct word distributions of each field to integrate the discriminative abilities of each field as well as to select the most suitable component probabilistic model for each field. We evaluated the performance of FICM by applying it to the problem of clustering three-field (title, abstract and MeSH) biomedical documents from TREC 2004 and 2005 Genomics tracks, and two-field (title and abstract) news reports from Reuters-21578. Experimental results showed that FICM outperformed the classical multinomial model and the multivariate Bernoulli model, being at a statistically significant level for all the three collections. These results indicate that FICM outperformed widely-used probabilistic models for document clustering by considering the characteristics of each field. We further showed that the component model, which is consistent with the nature of the corresponding field, achieved a better performance and considering the diversity of model setting also gave a further performance improvement. An extended abstract of parts of the work presented in this paper has appeared in Zhu et al. [Zhu, S., Takigawa, I., Zhang, S., &amp; Mamitsuka, H. (2007). A probabilistic model for clustering text documents with multiple fields. In Proceedings of the 29th European conference on information retrieval, ECIR 2007. Lecture notes in computer science (Vol. 4425, pp. 331–342)].
ER  - 

TY  - JOUR
T1  - Document organization using Kohonen's algorithm
JO  - Information Processing & Management
VL  - 38
IS  - 1
SP  - 79
EP  - 89
PY  - 2002/1//
T2  - 
AU  - Guerrero Bote, Vicente P
AU  - Moya Anegón, Félix de
AU  - Herrero Solana, Victor
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(00)00066-2
UR  - http://www.sciencedirect.com/science/article/pii/S0306457300000662
KW  - Neural networks
KW  - Self-organizing maps
KW  - Document clustering
KW  - Vectorization
KW  - Browsing
AB  - The classification of documents from a bibliographic database is a task that is linked to processes of information retrieval based on partial matching. A method is described of vectorizing reference documents from LISA which permits their topological organization using Kohonen's algorithm. As an example a map is generated of 202 documents from LISA, and an analysis is made of the possibilities of this type of neural network with respect to the development of information retrieval systems based on graphical browsing.
ER  - 

TY  - JOUR
T1  - Text document clustering based on frequent word meaning sequences
JO  - Data & Knowledge Engineering
VL  - 64
IS  - 1
SP  - 381
EP  - 404
PY  - 2008/1//
T2  - Fourth International Conference on Business Process Management (BPM 2006)8th International Conference on Enterprise Information Systems (ICEIS' 2006)Four selected and extended papersThree selected and extended papers
AU  - Li, Yanjun
AU  - Chung, Soon M.
AU  - Holt, John D.
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2007.08.001
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X07001541
KW  - Text documents
KW  - Clustering
KW  - Frequent word sequences
KW  - Frequent word meaning sequences
KW  - Web search
KW  - WordNet
AB  - Most of existing text clustering algorithms use the vector space model, which treats documents as bags of words. Thus, word sequences in the documents are ignored, while the meaning of natural languages strongly depends on them. In this paper, we propose two new text clustering algorithms, named Clustering based on Frequent Word Sequences (CFWS) and Clustering based on Frequent Word Meaning Sequences (CFWMS). A word is the word form showing in the document, and a word meaning is the concept expressed by synonymous word forms. A word (meaning) sequence is frequent if it occurs in more than certain percentage of the documents in the text database. The frequent word (meaning) sequences can provide compact and valuable information about those text documents. For experiments, we used the Reuters-21578 text collection, CISI documents of the Classic data set [Classic data set, ftp://ftp.cs.cornell.edu/pub/smart/], and a corpus of the Text Retrieval Conference (TREC) [High Accuracy Retrieval from Documents (HARD) Track of Text Retrieval Conference, 2004]. Our experimental results show that CFWS and CFWMS have much better clustering accuracy than Bisecting k-means (BKM) [M. Steinbach, G. Karypis, V. Kumar, A Comparison of Document Clustering Techniques, KDD-2000 Workshop on Text Mining, 2000], a modified bisecting k-means using background knowledge (BBK) [A. Hotho, S. Staab, G. Stumme, Ontologies improve text document clustering, in: Proceedings of the 3rd IEEE International Conference on Data Mining, 2003, pp. 541–544] and Frequent Itemset-based Hierarchical Clustering (FIHC) [B.C.M. Fung, K. Wang, M. Ester, Hierarchical document clustering using frequent itemsets, in: Proceedings of SIAM International Conference on Data Mining, 2003] algorithms.
ER  - 

TY  - JOUR
T1  - Incorporating topic transition in topic detection and tracking algorithms
JO  - Expert Systems with Applications
VL  - 36
IS  - 1
SP  - 227
EP  - 232
PY  - 2009/1//
T2  - 
AU  - Zeng, Jianping
AU  - Zhang, Shiyong
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2007.09.013
UR  - http://www.sciencedirect.com/science/article/pii/S0957417407004289
KW  - Topic transition
KW  - Topic detection and tracking
KW  - Hidden Markov model
AB  - Topics often transit among documents in a document collection. To improve the accuracy of the topic detection and tracking (TDT) algorithms in discovering topics or classifying documents, it is necessary to make full use of this kind of topic transition information. However, TDT algorithms usually find topics based on topic models, such as LDA, pLSI, etc., which are a kind of mixture model and make the topic transition difficult to be denoted and implemented. A topic transition model representation based on hidden Markov model is present, and learning the topic transition from documents is discussed. Based on the model, two TDT algorithms incorporating topic transition, i.e. topic discovering and document classifying, are provided to show the application of the proposed model. Experiments on two real-world document collections are done with the two algorithms, and performance comparison with other similar algorithm shows that the accuracy can achieve 93% for topic discovering in Reuters-21578, and 97.3% in document classifying. Furthermore, topic transition discovered by the algorithm on a dataset which was collected from a BBS website is consistent with the manual analysis results.
ER  - 

TY  - JOUR
T1  - The BankSearch web document dataset: investigating unsupervised clustering and category similarity
JO  - Journal of Network and Computer Applications
VL  - 28
IS  - 2
SP  - 129
EP  - 146
PY  - 2005/4//
T2  - Computational Intelligence on the Internet
AU  - Sinka, Mark P.
AU  - Corne, David W.
SN  - 1084-8045
DO  - http://dx.doi.org/10.1016/j.jnca.2004.01.002
UR  - http://www.sciencedirect.com/science/article/pii/S1084804504000062
KW  - Benchmark dataset
KW  - Clustering
KW  - Text classification
KW  - Unsupervised learning
KW  - Stemming
KW  - Stoplists
AB  - Targeting useful and relevant information on the internet is a highly complicated research area, which is served in part by research into document clustering. A foundational aspect of such research (proven over and over again in other research disciplines) is the use of standard datasets, against which different techniques can be properly benchmarked and assessed. We argue that, so far in this broad area of research, as many datasets have been used as research papers written, thus preventing confident reasoning about the relative performance of different techniques used in different publications. We describe a solution to this problem with the compilation of the BankSearch dataset, a proposed standard dataset suitable for a wide range of web-intelligence related research activities. At the time of writing, this dataset has already become a popular download in the Statlib archive, and is in use for benchmarking of a variety of document processing and web search techniques. Herein we also use the dataset in experiments to investigate certain issues in unsupervised web document clustering. Our main interest is how unsupervised clustering performance varies with the relative ‘distance’ between the categories inherent in the data, and how this is affected by the use of stemming and stoplists. These issues relate to, among other things, the design of useful search engines. We use simple k-means clustering, and find, unsurprisingly, that performance improves as categories become more distant. However, we also find that very close categories can be distinguished with fair accuracy, and there are interesting results concerning the use of stemming. Stop-word removal is confirmed as universally helpful, but stemming is not always to be recommended on ‘distant’ categories.
ER  - 

TY  - JOUR
T1  - Global nanotechnology research literature overview
JO  - Technological Forecasting and Social Change
VL  - 74
IS  - 9
SP  - 1733
EP  - 1747
PY  - 2007/11//
T2  - Three Special Sections: Assessment of China's and India's Science and Technology Literature Nanotechnology Policy Minding the Gap: Previewing the Potential of Breakthrough Technologies
AU  - Kostoff, Ronald N.
AU  - Koytcheff, Raymond G.
AU  - Lau, Clifford G.Y.
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2007.04.004
UR  - http://www.sciencedirect.com/science/article/pii/S0040162507000893
KW  - Nanoparticle
KW  - Nanotube
KW  - Nanotechnology
KW  - Text mining
KW  - Bibliometrics
KW  - Document clustering
AB  - Text mining was used to extract technical intelligence from the open source global nanotechnology and nanoscience research literature (SCI/SSCI databases). Identified were: (1) the nanotechnology/nanoscience research literature infrastructure (prolific authors, key journals/institutions/countries, most cited authors/journals/documents); (2) the technical structure (pervasive technical thrusts and their inter-relationships); (3) nanotechnology instruments and their relationships; (4) potential nanotechnology applications, (5) potential health impacts and applications; and (6) seminal nanotechnology literature. Our results are summarized in this paper.
ER  - 

TY  - JOUR
T1  - Knowledge map for tourist destinations—needs and implications
JO  - Tourism Management
VL  - 26
IS  - 4
SP  - 583
EP  - 594
PY  - 2005/8//
T2  - 
AU  - Pyo, Sungsoo
SN  - 0261-5177
DO  - http://dx.doi.org/10.1016/j.tourman.2004.03.001
UR  - http://www.sciencedirect.com/science/article/pii/S0261517704000627
KW  - Tourist destination
KW  - Knowledge management
KW  - Knowledge map
KW  - Competitiveness
AB  - Destination knowledge management contributes to destinations’ competitiveness. Knowledge mapping is used to organize knowledge in a database so that users can find what they need in a convenient and easy way. This study compares knowledge maps of four destination types (city, mountain, historic and island resort tourism) and suggests different mapping schemes. The supporting data were collected using both open-ended and closed-ended questionnaires. Finally, public sector involvement was suggested in building a tourist destination knowledge depository.
ER  - 

TY  - JOUR
T1  - Novel meta-heuristic algorithms for clustering web documents
JO  - Applied Mathematics and Computation
VL  - 201
IS  - 1–2
SP  - 441
EP  - 451
PY  - 2008/7/15/
T2  - 
AU  - Mahdavi, M.
AU  - Chehreghani, M. Haghir
AU  - Abolhassani, H.
AU  - Forsati, R.
SN  - 0096-3003
DO  - http://dx.doi.org/10.1016/j.amc.2007.12.058
UR  - http://www.sciencedirect.com/science/article/pii/S0096300307012209
KW  - Document clustering
KW  - Harmony search
KW  - K-Means
KW  - Optimization
KW  - Hybridization
AB  - Clustering the web documents is one of the most important approaches for mining and extracting knowledge from the web. Recently, one of the most attractive trends in clustering the high dimensional web pages has been tilt toward the learning and optimization approaches. In this paper, we propose novel hybrid harmony search (HS) based algorithms for clustering the web documents that finds a globally optimal partition of them into a specified number of clusters. By modeling clustering as an optimization problem, first, we propose a pure harmony search-based clustering algorithm that finds near global optimal clusters within a reasonable time. Then, we hybridize K-means and harmony clustering in two ways to achieve better clustering. Experimental results reveal that the proposed algorithms can find better clusters when compared to similar methods and also illustrate the robustness of the hybrid clustering algorithms.
ER  - 

TY  - JOUR
T1  - Re-ranking model based on document clusters
JO  - Information Processing & Management
VL  - 37
IS  - 1
SP  - 1
EP  - 14
PY  - 2001/1/1/
T2  - 
AU  - Lee, Kyung-Soon
AU  - Park, Young-Chan
AU  - Choi, Key-Sun
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(00)00017-0
UR  - http://www.sciencedirect.com/science/article/pii/S0306457300000170
KW  - Document re-ranking
KW  - Inverted-file method
KW  - Cluster analysis
KW  - Dynamic cluster view
KW  - Combining evidence
AB  - In this paper, we describe a model of information retrieval system that is based on a document re-ranking method using document clusters. In the first step, we retrieve documents based on the inverted-file method. Next, we analyze the retrieved documents using document clusters, and re-rank them. In this step, we use static clusters and dynamic cluster view. Consequently, we can produce clusters that are tailored to characteristics of the query. We focus on the merits of the inverted-file method and cluster analysis. In other words, we retrieve documents based on the inverted-file method and analyze all terms in document based on the cluster analysis. By these two steps, we can get the retrieved results which are made by the consideration of the context of all terms in a document as well as query terms. We will show that our method achieves significant improvements over the method based on similarity search ranking alone.
ER  - 

TY  - JOUR
T1  - Assessment of India's research literature
JO  - Technological Forecasting and Social Change
VL  - 74
IS  - 9
SP  - 1574
EP  - 1608
PY  - 2007/11//
T2  - Three Special Sections: Assessment of China's and India's Science and Technology Literature Nanotechnology Policy Minding the Gap: Previewing the Potential of Breakthrough Technologies
AU  - Kostoff, Ronald N.
AU  - Johnson, Dustin
AU  - Bowles, Christine A.
AU  - Bhattacharya, Sujit
AU  - Icenhour, Alan S.
AU  - Nikodym, Kimberly
AU  - Barth, Ryan B.
AU  - Dodbele, Simha
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2007.02.009
UR  - http://www.sciencedirect.com/science/article/pii/S0040162507000558
KW  - India
KW  - Science and technology
KW  - Technology assessment
KW  - Core competencies
KW  - Research evaluation
KW  - Metrics
KW  - Bibliometrics
KW  - Text mining
KW  - Computational linguistics
KW  - Document clustering
KW  - CLUTO
KW  - Auto-correlation mapping
KW  - Cross-correlation mapping
KW  - Factor analysis
KW  - Factor matrix
KW  - Impact Factor
AB  - The structure and infrastructure of the Indian research literature were determined. A representative database of technical articles was extracted from the Science Citation Index/Social Science Citation Index (SCI/SSCI) [SCI. Certain data included herein are derived from the Science Citation Index/Social Science Citation Index prepared by the THOMSON SCIENTIFIC®, Inc. (Thomson®), Philadelphia, Pennsylvania, USA: ©Copyright THOMSON SCIENTIFIC® 2006. All rights reserved. [1]] for 2005, with each article containing at least one author with an India address. Document clustering was used to identify the main technical themes (core competencies) of Indian research. Aggregate India bibliometrics were also performed, emphasizing the value of collaborative research to India. A unique mapping approach was used to identify networks of organizations that published together, networks of organizations with common technical interests, and especially those organizations with common technical interests that did not co-publish extensively. Finally, trend analyses were performed using other year data from the SCI/SSCI to place the 2005 results in their proper historical context.
ER  - 

TY  - JOUR
T1  - Document clustering for electronic meetings: an experimental comparison of two techniques
JO  - Decision Support Systems
VL  - 27
IS  - 1–2
SP  - 67
EP  - 79
PY  - 1999/11//
T2  - 
AU  - Roussinov, Dmitri G
AU  - Chen, Hsinchun
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/S0167-9236(99)00037-8
UR  - http://www.sciencedirect.com/science/article/pii/S0167923699000378
KW  - Group decision support systems
KW  - Text document clustering
KW  - Empirical study
KW  - Self-organizing maps
KW  - Neural networks
KW  - Cluster analysis
AB  - In this article, we report our implementation and comparison of two text clustering techniques. One is based on Ward's clustering and the other on Kohonen's Self-organizing Maps. We have evaluated how closely clusters produced by a computer resemble those created by human experts. We have also measured the time that it takes for an expert to “clean up” the automatically produced clusters. The technique based on Ward's clustering was found to be more precise. Both techniques have worked equally well in detecting associations between text documents. We used text messages obtained from group brainstorming meetings.
ER  - 

TY  - JOUR
T1  - Mining of graphics for information and knowledge retrieval
JO  - Computers & Chemical Engineering
VL  - 33
IS  - 3
SP  - 618
EP  - 627
PY  - 2009/3/20/
T2  - Selected Papers from the 17th European Symposium on Computer Aided Process Engineering held in Bucharest, Romania, May 2007
AU  - Avramenko, Yuri
AU  - Ani, Elisabeta-Cristina
AU  - Kraslawski, Andrzej
AU  - Agachi, Paul Serban
SN  - 0098-1354
DO  - http://dx.doi.org/10.1016/j.compchemeng.2008.10.023
UR  - http://www.sciencedirect.com/science/article/pii/S0098135408002214
KW  - Information retrieval
KW  - Case-based reasoning
KW  - Diffusion calculation
AB  - The oversupply of data, information and knowledge, even after preliminary keywords and topics search, is a well-known problem in R&amp;D activities. One of the approaches aimed at limiting the negative impact of the surplus of information is its automated intelligent preprocessing and reuse.

The paper describes a method for identification of the concepts which is based on combination of subject-driven document clustering, shape analysis, trends understanding and relevant context retrieval via semantic analysis. The goal is to extract potentially interesting knowledge from a set of documents based on analysis of graphical information and next to explain the mechanism of the studied process. The proposed method is implemented in the software suite which contains source searching tool, plot comparator and semantic analyzer. The method has been applied to identify the calculation process, using channel geometry characteristics, of the longitudinal dispersion coefficients for one branch of the Somes river in Romania.
ER  - 

TY  - JOUR
T1  - Integrating knowledge flow mining and collaborative filtering to support document recommendation
JO  - Journal of Systems and Software
VL  - 82
IS  - 12
SP  - 2023
EP  - 2037
PY  - 2009/12//
T2  - 
AU  - Lai, Chin-Hui
AU  - Liu, Duen-Ren
SN  - 0164-1212
DO  - http://dx.doi.org/10.1016/j.jss.2009.06.044
UR  - http://www.sciencedirect.com/science/article/pii/S0164121209001575
KW  - Knowledge flow
KW  - Knowledge flow mining
KW  - Knowledge sharing
KW  - Document recommendation
KW  - Collaborative filtering
KW  - Sequential rule mining
KW  - Recommender system
AB  - Knowledge is a critical resource that organizations use to gain and maintain competitive advantages. In the constantly changing business environment, organizations must exploit effective and efficient methods of preserving, sharing and reusing knowledge in order to help knowledge workers find task-relevant information. Hence, an important issue is how to discover and model the knowledge flow (KF) of workers from their historical work records. The objectives of a knowledge flow model are to understand knowledge workers’ task-needs and the ways they reference documents, and then provide adaptive knowledge support. This work proposes hybrid recommendation methods based on the knowledge flow model, which integrates KF mining, sequential rule mining and collaborative filtering techniques to recommend codified knowledge. These KF-based recommendation methods involve two phases: a KF mining phase and a KF-based recommendation phase. The KF mining phase identifies each worker’s knowledge flow by analyzing his/her knowledge referencing behavior (information needs), while the KF-based recommendation phase utilizes the proposed hybrid methods to proactively provide relevant codified knowledge for the worker. Therefore, the proposed methods use workers’ preferences for codified knowledge as well as their knowledge referencing behavior to predict their topics of interest and recommend task-related knowledge. Using data collected from a research institute laboratory, experiments are conducted to evaluate the performance of the proposed hybrid methods and compare them with the traditional CF method. The results of experiments demonstrate that utilizing the document preferences and knowledge referencing behavior of workers can effectively improve the quality of recommendations and facilitate efficient knowledge sharing.
ER  - 

TY  - JOUR
T1  - A review on the application of evolutionary computation to information retrieval
JO  - International Journal of Approximate Reasoning
VL  - 34
IS  - 2–3
SP  - 241
EP  - 264
PY  - 2003/11//
T2  - Soft Computing Applications to Intelligent Information Retrieval on the Internet
AU  - Cordón, O.
AU  - Herrera-Viedma, E.
AU  - López-Pujalte, C.
AU  - Luque, M.
AU  - Zarco, C.
SN  - 0888-613X
DO  - http://dx.doi.org/10.1016/j.ijar.2003.07.010
UR  - http://www.sciencedirect.com/science/article/pii/S0888613X0300094X
KW  - Information retrieval
KW  - Evolutionary algorithms
KW  - Automatic indexing
KW  - Document clustering
KW  - Query definition
KW  - User profiles
KW  - Internet search agents
KW  - Image retrieval
KW  - Similarity functions
KW  - Web pages
AB  - In this contribution, different proposals found in the specialized literature for the application of evolutionary computation to the field of information retrieval will be reviewed. To do so, different kinds of IR problems that have been solved by evolutionary algorithms are analyzed. Some of the specific existing approaches will be specifically described for some of these problems and the obtained results will be critically evaluated in order to give a clear view of the topic to the reader.
ER  - 

TY  - JOUR
T1  - Assessment of China's and India's science and technology literature — introduction, background, and approach
JO  - Technological Forecasting and Social Change
VL  - 74
IS  - 9
SP  - 1519
EP  - 1538
PY  - 2007/11//
T2  - Three Special Sections: Assessment of China's and India's Science and Technology Literature Nanotechnology Policy Minding the Gap: Previewing the Potential of Breakthrough Technologies
AU  - Kostoff, Ronald N.
AU  - Bhattacharya, Sujit
AU  - Pecht, Michael
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2007.02.004
UR  - http://www.sciencedirect.com/science/article/pii/S0040162507000534
KW  - China
KW  - India
KW  - Science and technology
KW  - Research evaluation
KW  - Research assessment
KW  - Technology assessment
KW  - Text mining
KW  - Bibliometrics
KW  - Computational linguistics
KW  - Document clustering
KW  - Factor analysis
KW  - Correlation mapping
KW  - Core competency
AB  - Science and technology (S&amp;T) allows (1) automation to replace human labor, (2) enhanced human labor capabilities, (3) quicker and cheaper production of goods, and (4) more complex products and processes. In order to maintain competitive advantages, it is critical for any country to understand what other countries are producing in S&amp;T, and what intrinsic S&amp;T capabilities are being developed.

India and China are the two most populous countries in the world. These two dynamic economies are advancing rapidly in S&amp;T, and it is prudent to assess the quantity and quality of their research output as well as to examine trends in their S&amp;T capabilities.

This paper, the first of four in a Special Section on China's and India's S&amp;T, introduces the remaining three papers. Specifically, this paper describes the motivation for the studies, the background for understanding national S&amp;T assessments, an overview of text mining, a brief picture of the Indian and Chinese S&amp;T establishments, and a summary of the analytical techniques used in the assessments.
ER  - 

TY  - JOUR
T1  - Document clustering using nonnegative matrix factorization
JO  - Information Processing & Management
VL  - 42
IS  - 2
SP  - 373
EP  - 386
PY  - 2006/3//
T2  - 
AU  - Shahnaz, Farial
AU  - Berry, Michael W.
AU  - Pauca, V.Paul
AU  - Plemmons, Robert J.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2004.11.005
UR  - http://www.sciencedirect.com/science/article/pii/S0306457304001542
KW  - Nonnegative matrix factorization
KW  - Text mining
KW  - Conjugate gradient
KW  - Constrained least squares
AB  - A methodology for automatically identifying and clustering semantic features or topics in a heterogeneous text collection is presented. Textual data is encoded using a low rank nonnegative matrix factorization algorithm to retain natural data nonnegativity, thereby eliminating the need to use subtractive basis vector and encoding calculations present in other techniques such as principal component analysis for semantic feature abstraction. Existing techniques for nonnegative matrix factorization are reviewed and a new hybrid technique for nonnegative matrix factorization is proposed. Performance evaluations of the proposed method are conducted on a few benchmark text collections used in standard topic detection studies.
ER  - 

TY  - JOUR
T1  - Power source roadmaps using bibliometrics and database tomography
JO  - Energy
VL  - 30
IS  - 5
SP  - 709
EP  - 730
PY  - 2005/4//
T2  - 
AU  - Kostoff, R.N.
AU  - Tshiteya, R.
AU  - Pfeil, K.M.
AU  - Humenik, J.A.
AU  - Karypis, G.
SN  - 0360-5442
DO  - http://dx.doi.org/10.1016/j.energy.2004.04.058
UR  - http://www.sciencedirect.com/science/article/pii/S0360544204002531
AB  - Database Tomography (DT) is a textual database analysis system consisting of two major components: (1) algorithms for extracting multi-word phrase frequencies and phrase proximities (physical closeness of the multi-word technical phrases) from any type of large textual database, to augment (2) interpretative capabilities of the expert human analyst. DT was used to derive technical intelligence from a Power Sources database derived from the Science Citation Index. Phrase frequency analysis by the technical domain experts provided the pervasive technical themes of the Power Sources database, and the phrase proximity analysis provided the relationships among the pervasive technical themes. Bibliometric analysis of the Power Sources literature supplemented the DT results with author/journal/institution/country publication and citation data.
ER  - 

TY  - JOUR
T1  - Anomaly detection in web documents using crisp and fuzzy-based cosine clustering methodology
JO  - Information Sciences
VL  - 177
IS  - 2
SP  - 467
EP  - 475
PY  - 2007/1/15/
T2  - 
AU  - Friedman, Menahem
AU  - Last, Mark
AU  - Makover, Yaniv
AU  - Kandel, Abraham
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2006.03.006
UR  - http://www.sciencedirect.com/science/article/pii/S0020025506000818
KW  - Fuzzy-based clustering
KW  - Document clustering
KW  - Cosine similarity
KW  - Anomaly detection
AB  - Cluster analysis is a primary tool for detecting anomalous behavior in real-world data such as web documents, medical records of patients or other personal data. Most existing methods for document clustering are based on the classical vector-space model, which represents each document by a fixed-size vector of weighted key terms often referred to as key phrases. Since vector representations of documents are frequently very sparse, inverted files are used to prevent a tremendous computational overload which may be caused in large and diverse document collections such as pages downloaded from the World Wide Web. In order to reduce computation costs and space complexity, many popular methods for clustering web documents, including those using inverted files, usually assume a relatively small prefixed number of clusters.

We propose several new crisp and fuzzy approaches based on the cosine similarity principle for clustering documents that are represented by variable-size vectors of key phrases, without limiting the final number of clusters. Each entry in a vector consists of two fields. The first field refers to a key phrase in the document and the second denotes an importance weight associated with this key phrase within the particular document. Removing the restriction on the total number of clusters, may moderately increase computing costs but on the other hand improves the method’s performance in classifying incoming vectors as normal or abnormal, based on their similarity to the existing clusters. All the procedures represented in this work are characterized by two features: (a) the number of clusters is not restricted by some relatively prefixed small number, i.e., an arbitrary new incoming vector which is not similar to any of the existing cluster centers necessarily starts a new cluster and (b) a vector with multiple appearance n in the training set is counted as n distinct vectors rather than a single vector. These features are the main reasons for the high quality performance of the proposed algorithms. We later describe them in detail and show their implementation in a real-world application from the area of web activity monitoring, in particular, by detecting anomalous documents downloaded from the internet by users with abnormal information interests.
ER  - 

TY  - JOUR
T1  - Web document clustering using hyperlink structures
JO  - Computational Statistics & Data Analysis
VL  - 41
IS  - 1
SP  - 19
EP  - 45
PY  - 2002/11/28/
T2  - Matrix Computations and Statistics
AU  - He, Xiaofeng
AU  - Zha, Hongyuan
AU  - H.Q. Ding, Chris
AU  - D. Simon, Horst
SN  - 0167-9473
DO  - http://dx.doi.org/10.1016/S0167-9473(02)00070-1
UR  - http://www.sciencedirect.com/science/article/pii/S0167947302000701
KW  - World Wide Web
KW  - Graph partitioning
KW  - Cheeger constant
KW  - Clustering method
KW  - K-means method
KW  - Normalized cut method
KW  - Eigenvalue decomposition
KW  - Link structure
KW  - Similarity metric
AB  - With the exponential growth of information on the World Wide Web, there is great demand for developing efficient methods for effectively organizing the large amount of retrieved information. Document clustering plays an important role in information retrieval and taxonomy management for the Web. In this paper we examine three clustering methods: K-means, multi-level METIS, and the recently developed normalized-cut method using a new approach of combining textual information, hyperlink structure and co-citation relations into a single similarity metric. We found the normalized-cut method with the new similarity metric is particularly effective, as demonstrated on three datasets of web query results. We also explore some theoretical connections between the normalized-cut method and the K-means method.
ER  - 

TY  - JOUR
T1  - Types of feedback in a computer-based collaborative problem-solving group task
JO  - Computers in Human Behavior
VL  - 18
IS  - 6
SP  - 699
EP  - 715
PY  - 2002/11//
T2  - 
AU  - Hsieh, I-Lin Gloria
AU  - O’Neil Jr., Harold F
SN  - 0747-5632
DO  - http://dx.doi.org/10.1016/S0747-5632(02)00025-0
UR  - http://www.sciencedirect.com/science/article/pii/S0747563202000250
KW  - Feedback
KW  - Computer
KW  - Collaborative problem solving
KW  - Group task
AB  - This study measured collaborative problem-solving processes and outcomes in a computer-based knowledge mapping environment. One hundred and twenty Asian American high school students were randomly assigned to be either a group leader, whose responsibility was to construct the map, or a group searcher, whose responsibility was to seek information and access feedback from a Web environment. Each group was randomly assigned to a feedback condition (knowledge of response feedback or adapted knowledge of response feedback). Results showed that adapted knowledge of response feedback was significantly more beneficial than knowledge of response feedback. Further, most of the study hypotheses were supported regarding the relationship between problem-solving processes and outcomes.
ER  - 

TY  - JOUR
T1  - Testing a Cancer Meta Spider
JO  - International Journal of Human-Computer Studies
VL  - 59
IS  - 5
SP  - 755
EP  - 776
PY  - 2003/11//
T2  - 
AU  - Chen, Hsinchun
AU  - Fan, Haiyan
AU  - Chau, Michael
AU  - Zeng, Daniel
SN  - 1071-5819
DO  - http://dx.doi.org/10.1016/S1071-5819(03)00118-6
UR  - http://www.sciencedirect.com/science/article/pii/S1071581903001186
AB  - As in many other applications, the rapid proliferation and unrestricted Web-based publishing of health-related content have made finding pertinent and useful healthcare information increasingly difficult. Although the development of healthcare information retrieval systems such as medical search engines and peer-reviewed medical Web directories has helped alleviate this information and cognitive overload problem, the effectiveness of these systems has been limited by low search precision, poor presentation of search results, and the required user search effort. To address these challenges, we have developed a domain-specific meta-search tool called Cancer Spider. By leveraging post-retrieval document clustering techniques, this system aids users in querying multiple medical data sources to gain an overview of the retrieved documents and locating answers of high quality to a wide spectrum of health questions. The system presents the retrieved documents to users in two different views: (1) Web pages organized by a list of key phrases, and (2) Web pages clustered into regions discussing different topics on a two-dimensional map (self-organizing map). In this paper, we present the major components of the Cancer Spider system and a user evaluation study designed to evaluate the effectiveness and efficiency of our approach. Initial results comparing Cancer Spider with NLM Gateway, a premium medical search site, have shown that they achieved comparable performances measured by precision, recall, and F-measure. Cancer Spider required less user searching time, fewer documents that need to be browsed, and less user effort.
ER  - 

TY  - JOUR
T1  - Genetic algorithm for text clustering using ontology and evaluating the validity of various semantic similarity measures
JO  - Expert Systems with Applications
VL  - 36
IS  - 5
SP  - 9095
EP  - 9104
PY  - 2009/7//
T2  - 
AU  - Song, Wei
AU  - Li, Cheng Hua
AU  - Park, Soon Cheol
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2008.12.046
UR  - http://www.sciencedirect.com/science/article/pii/S0957417408009123
KW  - Genetic algorithm
KW  - Text clustering
KW  - Ontology
KW  - Wordnet
KW  - Latent semantic indexing
AB  - This paper proposes a self-organized genetic algorithm for text clustering based on ontology method. The common problem in the fields of text clustering is that the document is represented as a bag of words, while the conceptual similarity is ignored. We take advantage of thesaurus-based and corpus-based ontology to overcome this problem. However, the traditional corpus-based method is rather difficult to tackle. A transformed latent semantic indexing (LSI) model which can appropriately capture the associated semantic similarity is proposed and demonstrated as corpus-based ontology in this article. To investigate how ontology methods could be used effectively in text clustering, two hybrid strategies using various similarity measures are implemented. Experiments results show that our method of genetic algorithm in conjunction with the ontology strategy, the combination of the transformed LSI-based measure with the thesaurus-based measure, apparently outperforms that with traditional similarity measures. Our clustering algorithm also efficiently enhances the performance in comparison with standard GA and k-means in the same similarity environments.
ER  - 

TY  - JOUR
T1  - Knowledge map creation and maintenance for virtual communities of practice
JO  - Information Processing & Management
VL  - 42
IS  - 2
SP  - 551
EP  - 568
PY  - 2006/3//
T2  - 
AU  - Lin, Fu-ren
AU  - Hsueh, Chih-ming
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2005.03.026
UR  - http://www.sciencedirect.com/science/article/pii/S030645730500052X
KW  - Knowledge map
KW  - Information retrieval
KW  - Clustering
KW  - Community of practice
KW  - Professional community
AB  - This paper proposes a knowledge map management system to facilitate knowledge management in virtual communities of practice. To realize the proposed knowledge map management, we develop knowledge map creation and maintenance functions by utilizing information retrieval and data mining techniques. The knowledge maps created respectively from the documents of the teachers’ professional community, SCTNet, and the thesis repository at Taiwan’s National Central Library, are evaluated by experts of these two domains. Knowledge maps generated by the system are accepted by domain experts from the evaluation since the degree of their modification of the automatically created knowledge maps is proportionally small. The knowledge structure representing the categories of community documents maintains its high purity, diversity, specificity, and structure adaptation by using the knowledge map maintenance function with limited computational cost. Thus, the knowledge map creation and maintenance mechanisms developed in this research enable the dynamic knowledge management of communities of practice on the Internet.
ER  - 

TY  - JOUR
T1  - The thematic and citation landscape of Data and Knowledge Engineering (1985–2007)
JO  - Data & Knowledge Engineering
VL  - 67
IS  - 2
SP  - 234
EP  - 259
PY  - 2008/11//
T2  - Special Jubilee Issue: DKE 25 Years
AU  - Chen, Chaomei
AU  - Song, Il-Yeol
AU  - Yuan, Xiaojun
AU  - Zhang, Jian
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2008.05.004
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X08000700
KW  - Structural and temporal patterns
KW  - Domain analysis
KW  - Scientometrics
KW  - CiteSpace
KW  - Thematic analysis
KW  - DKE
AB  - The thematic and citation structures of Data and Knowledge Engineering (DKE) (1985–2007) are identified based on text analysis and citation analysis of the bibliographic records of full papers published in the journal. Temporal patterns are identified by detecting abrupt increases of frequencies of noun phrases extracted from titles and abstracts of DKE papers over time. Conceptual structures of the subject domain are identified by clustering analysis. Concept maps and network visualizations are presented to illustrate salient patterns and emerging thematic trends. A variety of statistics are reported to highlight key contributors and DKE papers that have made profound impacts.
ER  - 

TY  - JOUR
T1  - Finding similar academic Web sites with links, bibliometric couplings and colinks
JO  - Information Processing & Management
VL  - 40
IS  - 3
SP  - 515
EP  - 526
PY  - 2004/5//
T2  - 
AU  - Thelwall, Mike
AU  - Wilkinson, David
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(03)00042-6
UR  - http://www.sciencedirect.com/science/article/pii/S0306457303000426
KW  - Document clustering
KW  - Webmetrics
KW  - Web information retrieval
AB  - A common task in both Webmetrics and Web information retrieval is to identify a set of Web pages or sites that are similar in content. In this paper we assess the extent to which links, colinks and couplings can be used to identify similar Web sites. As an experiment, a random sample of 500 pairs of domains from the UK academic Web were taken and human assessments of site similarity, based upon content type, were compared against ratings for the three concepts. The results show that using a combination of all three gives the highest probability of identifying similar sites, but surprisingly this was only a marginal improvement over using links alone. Another unexpected result was that high values for either colink counts or couplings were associated with only a small increased likelihood of similarity. The principal advantage of using couplings and colinks was found to be greater coverage in terms of a much larger number of pairs of sites being connected by these measures, instead of increased probability of similarity. In information retrieval terminology, this is improved recall rather than improved precision.
ER  - 

TY  - JOUR
T1  - Clustered SVD strategies in latent semantic indexing
JO  - Information Processing & Management
VL  - 41
IS  - 5
SP  - 1051
EP  - 1063
PY  - 2005/9//
T2  - 
AU  - Gao, Jing
AU  - Zhang, Jun
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2004.10.005
UR  - http://www.sciencedirect.com/science/article/pii/S0306457304001384
KW  - Latent semantic indexing
KW  - SVD
KW  - Text retrieval
KW  - Clustering
AB  - The text retrieval method using latent semantic indexing (LSI) technique with truncated singular value decomposition (SVD) has been intensively studied in recent years. The SVD reduces the noise contained in the original representation of the term–document matrix and improves the information retrieval accuracy. Recent studies indicate that SVD is mostly useful for small homogeneous data collections. For large inhomogeneous datasets, the performance of the SVD based text retrieval technique may deteriorate. We propose to partition a large inhomogeneous dataset into several smaller ones with clustered structure, on which we apply the truncated SVD. Our experimental results show that the clustered SVD strategies may enhance the retrieval accuracy and reduce the computing and storage costs.
ER  - 

TY  - JOUR
T1  - Possibilistic fuzzy co-clustering of large document collections
JO  - Pattern Recognition
VL  - 40
IS  - 12
SP  - 3452
EP  - 3466
PY  - 2007/12//
T2  - 
AU  - Tjhi, William-Chandra
AU  - Chen, Lihui
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2007.04.017
UR  - http://www.sciencedirect.com/science/article/pii/S0031320307002026
KW  - Co-clustering
KW  - Possibilistic clustering
KW  - Fuzzy clustering
KW  - Document clustering
KW  - Text mining
KW  - Information retrieval
AB  - In this paper we propose a new co-clustering algorithm called possibilistic fuzzy co-clustering (PFCC) for automatic categorization of large document collections. PFCC integrates a possibilistic document clustering technique and a combined formulation of fuzzy word ranking and partitioning into a fast iterative co-clustering procedure. This novel framework brings about simultaneously some benefits including robustness in the presence of document and word outliers, rich representations of co-clusters, highly descriptive document clusters, a good performance in a high-dimensional space, and a reduced sensitivity to the initialization in the possibilistic clustering. We present the detailed formulation of PFCC together with the explanations of the motivations behind. The advantages over other existing works and the algorithm's proof of convergence are provided. Experiments on several large document data sets demonstrate the effectiveness of PFCC.
ER  - 

TY  - JOUR
T1  - A citation-based document retrieval system for finding research expertise
JO  - Information Processing & Management
VL  - 43
IS  - 1
SP  - 248
EP  - 264
PY  - 2007/1//
T2  - 
AU  - Tho, Quan Thanh
AU  - Hui, S.C.
AU  - Fong, A.C.M.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2006.05.015
UR  - http://www.sciencedirect.com/science/article/pii/S0306457306000859
KW  - Clustering
KW  - Indexing
KW  - Data mining
KW  - Information retrieval
KW  - Knowledge discovery
KW  - Ontology generation
AB  - Current citation-based document retrieval systems generally offer only limited search facilities, such as author search. In order to facilitate more advanced search functions, we have developed a significantly improved system that employs two novel techniques: Context-based Cluster Analysis (CCA) and Context-based Ontology Generation frAmework (COGA). CCA aims to extract relevant information from clusters originally obtained from disparate clustering methods by building relationships between them. The built relationships are then represented as formal context using the Formal Concept Analysis (FCA) technique. COGA aims to generate ontology from clusters relationship built by CCA. By combining these two techniques, we are able to perform ontology learning from a citation database using clustering results. We have implemented the improved system and have demonstrated its use for finding research domain expertise. We have also conducted performance evaluation on the system and the results are encouraging.
ER  - 

TY  - JOUR
T1  - Correlation clustering in general weighted graphs
JO  - Theoretical Computer Science
VL  - 361
IS  - 2–3
SP  - 172
EP  - 187
PY  - 2006/9/1/
T2  - Approximation and Online Algorithms
AU  - Demaine, Erik D.
AU  - Emanuel, Dotan
AU  - Fiat, Amos
AU  - Immorlica, Nicole
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/j.tcs.2006.05.008
UR  - http://www.sciencedirect.com/science/article/pii/S0304397506003227
KW  - Clustering
KW  - Partitioning
KW  - Approximation algorithms
KW  - Minimum multicut
AB  - We consider the following general correlation-clustering problem [N. Bansal, A. Blum, S. Chawla, Correlation clustering, in: Proc. 43rd Annu. IEEE Symp. on Foundations of Computer Science, Vancouver, Canada, November 2002, pp. 238–250]: given a graph with real nonnegative edge weights and a 〈 + 〉 / 〈 - 〉 edge labelling, partition the vertices into clusters to minimize the total weight of cut 〈 + 〉 edges and uncut 〈 - 〉 edges. Thus, 〈 + 〉 edges with large weights (representing strong correlations between endpoints) encourage those endpoints to belong to a common cluster while 〈 - 〉 edges with large weights encourage the endpoints to belong to different clusters. In contrast to most clustering problems, correlation clustering specifies neither the desired number of clusters nor a distance threshold for clustering; both of these parameters are effectively chosen to be the best possible by the problem definition.

Correlation clustering was introduced by Bansal et al. [Correlation clustering, in: Proc. 43rd Annu. IEEE Symp. on Foundations of Computer Science, Vancouver, Canada, November 2002, pp. 238–250], motivated by both document clustering and agnostic learning. They proved NP-hardness and gave constant-factor approximation algorithms for the special case in which the graph is complete (full information) and every edge has the same weight. We give an O ( log n ) -approximation algorithm for the general case based on a linear-programming rounding and the “region-growing’’ technique. We also prove that this linear program has a gap of Ω ( log n ) , and therefore our approximation is tight under this approach. We also give an O ( r 3 ) -approximation algorithm for K r , r -minor-free graphs. On the other hand, we show that the problem is equivalent to minimum multicut, and therefore APX-hard and difficult to approximate better than Θ ( log n ) .
ER  - 

TY  - JOUR
T1  - A text mining approach on automatic generation of web directories and hierarchies
JO  - Expert Systems with Applications
VL  - 27
IS  - 4
SP  - 645
EP  - 663
PY  - 2004/11//
T2  - 
AU  - Yang, Hsin-Chang
AU  - Lee, Chung-Hong
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2004.06.009
UR  - http://www.sciencedirect.com/science/article/pii/S0957417404000715
KW  - World wide web
KW  - Web hierarchy construction
KW  - Web directory construction
KW  - Text mining
KW  - Self-organizing map
AB  - The World Wide Web (WWW) has been recognized as the ultimate and unique source of information for information retrieval and knowledge discovery communities. Tremendous amount of knowledge are recorded using various types of media, producing enormous amount of web pages in the WWW. Retrieval of required information from the WWW is thus an arduous task. Different schemes for retrieving web pages have been used by the WWW community. One of the most widely used scheme is to traverse predefined web directories to reach a user's goal. These web directories are compiled or classified folders of web pages and are usually organized into hierarchical structures. The classification of web pages into proper directories and the organization of directory hierarchies are generally performed by human experts. In this work, we provide a corpus-based method that applies a kind of text mining techniques on a corpus of web pages to automatically create web directories and organize them into hierarchies. The method is based on the self-organizing map learning algorithm and requires no human intervention during the construction of web directories and hierarchies. The experiments show that our method can produce comprehensible and reasonable web directories and hierarchies.
ER  - 

TY  - JOUR
T1  - IMMUNOLOGY-BASED MOTION CONTROL FOR MODULAR HYPER-REDUNDANT MANIPULATORS
JO  - IFAC Proceedings Volumes
VL  - 38
IS  - 1
SP  - 163
EP  - 168
PY  - 2005///
T2  - 16th IFAC World Congress
AU  - Lau, H.Y.K.
AU  - Ng, A.K.S.
SN  - 1474-6670
DO  - http://dx.doi.org/10.3182/20050703-6-CZ-1902.01297
UR  - http://www.sciencedirect.com/science/article/pii/S1474667016373098
KW  - Artificial Immune System
KW  - Distributed Control
KW  - Hyer-redundant Robot
KW  - Robot Control
KW  - Robotics
KW  - Modular Robot
KW  - Biological-inspired Robot
AB  - Abstract
Artificial Immune System (AIS) has recently been actively researched with a number of emerging engineering applications that has capitalized from its characteristics including self-organization, distributive control, knowledge mapping and fault tolerance. This paper reports the application of the existing AIS paradigm for the distributive control of a modular multi-jointed, hyper-redundant manipulator. Modular robot usually implemented with simplified mathematical model to cope with the scenario of limited computation power and memory. In this paper, we investigate the viability of a multiagent immunology–based motion control for the trajectory control of modular hyper-redundant manipulators.
ER  - 

TY  - JOUR
T1  - Information navigation on the web by clustering and summarizing query results
JO  - Information Processing & Management
VL  - 37
IS  - 6
SP  - 789
EP  - 816
PY  - 2001/11//
T2  - 
AU  - Roussinov, Dmitri G.
AU  - Chen, Hsinchun
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(00)00062-5
UR  - http://www.sciencedirect.com/science/article/pii/S0306457300000625
KW  - Information retrieval
KW  - Neural networks
KW  - Clustering
KW  - Summarization
KW  - Relevance feedback
KW  - World Wide Web
KW  - Internet spiders
KW  - Search engines
AB  - We report our experience with a novel approach to interactive information seeking that is grounded in the idea of summarizing query results through automated document clustering. We went through a complete system development and evaluation cycle: designing the algorithms and interface for our prototype, implementing them and testing with human users. Our prototype acted as an intermediate layer between the user and a commercial Internet search engine (AltaVista), thus allowing searches of the significant portion of World Wide Web. In our final evaluation, we processed data from 36 users and concluded that our prototype improved search performance over using the same search engine (AltaVista) directly. We also analyzed effects of various related demographic and task related parameters.
ER  - 

TY  - JOUR
T1  - Linear Programming and Genetic Algorithms Methods for Creation of Groups in Networks of Excellence
JO  - CIRP Annals - Manufacturing Technology
VL  - 55
IS  - 1
SP  - 143
EP  - 146
PY  - 2006///
T2  - 
AU  - Guttman, G.
AU  - Shpitalni, M.
SN  - 0007-8506
DO  - http://dx.doi.org/10.1016/S0007-8506(07)60385-0
UR  - http://www.sciencedirect.com/science/article/pii/S0007850607603850
KW  - Knowledge management
KW  - Linear programming
KW  - Genetic algorithm
AB  - Creation of groups in Networks of Excellence (NoEs) based on knowledge mapping and expertise is a set covering problem known to be non-polynomial. Therefore it is usually approached by heuristic methods which yield good but not necessarily optimal coverage. Selecting teams to form a group within NoEs that are comprised of tens of teams can also be formulated and solved as an integer linear programming (ILP) problem whose solution is guaranteed to be optimal. This paper presents the ILP solution for team selection with typical objective functions. Several genetic algorithm-based methods are also compared to the optimal solution in terms of convergence (time and solution). The compared methods differ in selecting next-generation population schemes. The plain vanilla method is shown to be superior to both the roulette-based and the SUS methods.
ER  - 

TY  - JOUR
T1  - State of the stock—What do we know about existing buildings and their future prospects?
JO  - Energy Policy
VL  - 36
IS  - 12
SP  - 4462
EP  - 4470
PY  - 2008/12//
T2  - Foresight Sustainable Energy Management and the Built Environment Project
AU  - Ravetz, Joe
SN  - 0301-4215
DO  - http://dx.doi.org/10.1016/j.enpol.2008.09.026
UR  - http://www.sciencedirect.com/science/article/pii/S0301421508004667
KW  - Housing stock
KW  - Non-domestic buildings
KW  - Maintenance and alterations
AB  - The UK building stock has seen major changes in the last 50 years, in its form, fabric and function. The context is the expansion of the building stock and built infrastructure, which takes place in most areas at 1–2% per year, with the implication that up to 75% of the dwellings of the year 2050 already exist now. This is a major challenge. The energy performance of much of this stock is generally low, while its economic, social and cultural values are often high.

The purpose of this review is to provide a brief outline of the state of knowledge of the existing building stock, and of potential advances in that knowledge. We follow a knowledge mapping approach, set out on several axes. The first is an axis from buildings as physical forms, to buildings as containers of socio-economic activity. Another axis spans between existing buildings, renovations and adaptations, and new buildings. A third axis is that of scale, from building components to large-scale settlements. There are many possible combinations of these parameters. Here we focus on those that are most relevant to the SEMBE goals of sustainable energy management across the whole building stock.
ER  - 

TY  - JOUR
T1  - Topic discovery based on text mining techniques
JO  - Information Processing & Management
VL  - 43
IS  - 3
SP  - 752
EP  - 768
PY  - 2007/5//
T2  - Special Issue on Heterogeneous and Distributed IR
AU  - Pons-Porrata, Aurora
AU  - Berlanga-Llavori, Rafael
AU  - Ruiz-Shulcloper, José
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2006.06.001
UR  - http://www.sciencedirect.com/science/article/pii/S0306457306000914
KW  - Hierarchical clustering
KW  - Text summarization
KW  - Topic detection
AB  - In this paper, we present a topic discovery system aimed to reveal the implicit knowledge present in news streams. This knowledge is expressed as a hierarchy of topic/subtopics, where each topic contains the set of documents that are related to it and a summary extracted from these documents. Summaries so built are useful to browse and select topics of interest from the generated hierarchies. Our proposal consists of a new incremental hierarchical clustering algorithm, which combines both partitional and agglomerative approaches, taking the main benefits from them. Finally, a new summarization method based on Testor Theory has been proposed to build the topic summaries. Experimental results in the TDT2 collection demonstrate its usefulness and effectiveness not only as a topic detection system, but also as a classification and summarization tool.
ER  - 

TY  - JOUR
T1  - On the equivalence between Non-negative Matrix Factorization and Probabilistic Latent Semantic Indexing
JO  - Computational Statistics & Data Analysis
VL  - 52
IS  - 8
SP  - 3913
EP  - 3927
PY  - 2008/4/15/
T2  - 
AU  - Ding, Chris
AU  - Li, Tao
AU  - Peng, Wei
SN  - 0167-9473
DO  - http://dx.doi.org/10.1016/j.csda.2008.01.011
UR  - http://www.sciencedirect.com/science/article/pii/S0167947308000145
AB  - Non-negative Matrix Factorization (NMF) and Probabilistic Latent Semantic Indexing (PLSI) have been successfully applied to document clustering recently. In this paper, we show that PLSI and NMF (with the I-divergence objective function) optimize the same objective function, although PLSI and NMF are different algorithms as verified by experiments. This provides a theoretical basis for a new hybrid method that runs PLSI and NMF alternatively, each jumping out of the local minima of the other method successively, thus achieving a better final solution. Extensive experiments on five real-life datasets show relations between NMF and PLSI, and indicate that the hybrid method leads to significant improvements over NMF-only or PLSI-only methods. We also show that at first-order approximation, NMF is identical to the χ 2 -statistic.
ER  - 

TY  - JOUR
T1  - Integrating contextual information to enhance SOM-based text document clustering
JO  - Neural Networks
VL  - 15
IS  - 8–9
SP  - 1099
EP  - 1106
PY  - 2002/10//
Y2  - 2002/11//
T2  - 
AU  - Pullwitt, Daniel
SN  - 0893-6080
DO  - http://dx.doi.org/10.1016/S0893-6080(02)00082-5
UR  - http://www.sciencedirect.com/science/article/pii/S0893608002000825
KW  - Text clustering
KW  - Representation model
KW  - Vector space model
KW  - Self-organizing map
AB  - Exploration of text corpora using self-organizing maps has shown promising results in recent years. Topographic map approaches usually use the original vector space model known from Information Retrieval for text document representation. In this paper I present a two stage model using features based on sentence categories as alternative approach which includes contextual information. Algorithmic optimizations required by this computationally expensive model are shown and evaluated. Also a method for model independent comparison of document maps by evaluation of document distribution on maps is introduced and used to compare results obtained with both the new model and the vector space model.
ER  - 

TY  - JOUR
T1  - A text mining approach for automatic construction of hypertexts
JO  - Expert Systems with Applications
VL  - 29
IS  - 4
SP  - 723
EP  - 734
PY  - 2005/11//
T2  - 
AU  - Yang, Hsin-Chang
AU  - Lee, Chung-Hong
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2005.05.003
UR  - http://www.sciencedirect.com/science/article/pii/S0957417405000990
KW  - Automatic hypertext construction
KW  - Self-organizing maps
KW  - Text mining
AB  - The research on automatic hypertext construction emerges rapidly in the last decade because there exists a urgent need to translate the gigantic amount of legacy documents into web pages. Unlike traditional ‘flat’ texts, a hypertext contains a number of navigational hyperlinks that point to some related hypertexts or locations of the same hypertext. Traditionally, these hyperlinks were constructed by the creators of the web pages with or without the help of some authoring tools. However, the gigantic amount of documents produced each day prevent from such manual construction. Thus an automatic hypertext construction method is necessary for content providers to efficiently produce adequate information that can be used by web surfers. Although most of the web pages contain a number of non-textual data such as images, sounds, and video clips, text data still contribute the major part of information about the pages. Therefore, it is not surprising that most of automatic hypertext construction methods inherit from traditional information retrieval research. In this work, we will propose a new automatic hypertext construction method based on a text mining approach. Our method applies the self-organizing map algorithm to cluster some at text documents in a training corpus and generate two maps. We then use these maps to identify the sources and destinations of some important hyperlinks within these training documents. The constructed hyperlinks are then inserted into the training documents to translate them into hypertext form. Such translated documents will form the new corpus. Incoming documents can also be translated into hypertext form and added to the corpus through the same approach. Our method had been tested on a set of at text documents collected from a newswire site. Although we only use Chinese text documents, our approach can be applied to any documents that can be transformed to a set of index terms.
ER  - 

TY  - JOUR
T1  - Identifying disgruntled employee systems fraud risk through text mining: A simple solution for a multi-billion dollar problem
JO  - Decision Support Systems
VL  - 46
IS  - 4
SP  - 853
EP  - 864
PY  - 2009/3//
T2  - IT Decisions in Organizations
AU  - Holton, Carolyn
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2008.11.013
UR  - http://www.sciencedirect.com/science/article/pii/S0167923608002078
KW  - IS security
KW  - Occupational fraud
KW  - Text mining
KW  - Design science
KW  - Disgruntled employee
KW  - Organizational communication
AB  - Occupational fraud is a $652 billion problem to which disgruntled employees are a major contributor. Much security research addresses reducing fraud opportunity and increasing fraud detection, but detecting motivational factors like employee disgruntlement is less studied. The Sarbanes–Oxley Act requires that companies archive email, creating an untapped resource for deterring fraud. Herein, protocols to identify disgruntled communications are developed. Messages cluster well according to disgruntled content, giving confidence in the value of email for this task. A highly accurate naïve Bayes model predicts whether messages contain disgruntled communications, providing extremely relevant information not otherwise likely to be revealed in a fraud audit. The model can be incorporated into fraud risk analysis systems to improve their ability to detect and deter fraud.
ER  - 

TY  - JOUR
T1  - Image semantics discovery from web pages for semantic-based image retrieval using self-organizing maps
JO  - Expert Systems with Applications
VL  - 34
IS  - 1
SP  - 266
EP  - 279
PY  - 2008/1//
T2  - 
AU  - Yang, Hsin-Chang
AU  - Lee, Chung-Hong
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2006.09.016
UR  - http://www.sciencedirect.com/science/article/pii/S0957417406002764
KW  - Semantic-based image retrieval
KW  - Text mining
KW  - Self-organizing map
AB  - Traditional content-based image retrieval (CBIR) systems often fail to meet a user’s need due to the ‘semantic gap’ between the extracted features of the systems and the user’s query. The cause of the semantic gap is the failure of extracting real semantics from an image and the query. To extract semantics of images, however, is a difficult task. Most existing techniques apply some predefined semantic categories and assign the images to appropriate categories through some learning processes. Nevertheless, these techniques always need human intervention and rely on content-based features. In this paper we propose a novel approach to bridge the semantic gap which is the major deficiency of CBIR systems. We conquer the deficiency by extracting semantics of an image from the environmental texts around it. Since an image generally co-exists with accompanying texts in various formats, we may rely on such environmental texts to discover the semantics of the image. We apply a text mining process, which adopts the self-organizing map (SOM) learning algorithm as a kernel, on the environmental texts of an image to extract the semantic information from this image. Some implicit semantic information of the images can be discovered after the text mining process. We also define a semantic relevance measure to achieve the semantic-based image retrieval task. We performed experiments on a set of images which are collected from web pages and obtained promising results.
ER  - 

TY  - JOUR
T1  - An aggregated clustering approach using multi-ant colonies algorithms
JO  - Pattern Recognition
VL  - 39
IS  - 7
SP  - 1278
EP  - 1289
PY  - 2006/7//
T2  - 
AU  - Yang, Yan
AU  - Kamel, Mohamed S.
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2006.02.012
UR  - http://www.sciencedirect.com/science/article/pii/S0031320306000471
KW  - Ant algorithm
KW  - Multi-ant colonies
KW  - Clustering
KW  - Aggregated clustering
AB  - This paper presents a multi-ant colonies approach for clustering data that consists of some parallel and independent ant colonies and a queen ant agent. Each ant colony process takes different types of ants moving speed and different versions of the probability conversion function to generate various clustering results with an ant-based clustering algorithm. These results are sent to the queen ant agent and combined by a hypergraph model to calculate a new similarity matrix. The new similarity matrix is returned back to each ant colony process to re-cluster the data using the new information. Experimental evaluation shows that the average performance of the aggregated multi-ant colonies algorithms outperforms that of the single ant-based clustering algorithm and the popular K-means algorithm. The result also shows that the lowest outliers strategy for selecting the current data set has the best performance quality.
ER  - 

TY  - JOUR
T1  - A feature mining based approach for the classification of text documents into disjoint classes
JO  - Information Processing & Management
VL  - 38
IS  - 4
SP  - 583
EP  - 604
PY  - 2002/7//
T2  - 
AU  - Nieto Sánchez, Salvador
AU  - Triantaphyllou, Evangelos
AU  - Kraft, Donald
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(01)00049-8
UR  - http://www.sciencedirect.com/science/article/pii/S0306457301000498
KW  - Document classification
KW  - Document indexing
KW  - Vector space model
KW  - Data mining
KW  - One Clause At a Time (OCAT) algorithm
KW  - Machine learning
AB  - This paper proposes a new approach for classifying text documents into two disjoint classes. The new approach is based on extracting patterns, in the form of two logical expressions, which are defined on various features (indexing terms) of the documents. The pattern extraction is aimed at providing descriptions (in the form of two logical expressions) of the two classes of positive and negative examples. This is achieved by means of a data mining approach, called One Clause At a Time (OCAT), which is based on mathematical logic. The application of a logic-based approach to text document classification is critical when one wishes to be able to justify why a particular document has been assigned to one class versus the other class. This situation occurs, for instance, in declassifying documents that have been previously considered important to national security and thus are currently being kept as secret. Some computational experiments have investigated the effectiveness of the OCAT-based approach and compared it to the well-known vector space model (VSM). These tests also have investigated finding the best indexing terms that could be used in making these classification decisions. The results of these computational experiments on a sample of 2897 text documents from the TIPSTER collection indicate that the first approach has many advantages over the VSM approach for solving this type of text document classification problem. Moreover, a guided strategy for the OCAT-based approach is presented for deciding which document one needs to consider next while building the training example sets.
ER  - 

TY  - JOUR
T1  - Building a scientific knowledge web portal: The NanoPort experience
JO  - Decision Support Systems
VL  - 42
IS  - 2
SP  - 1216
EP  - 1238
PY  - 2006/11//
T2  - 
AU  - Chau, Michael
AU  - Huang, Zan
AU  - Qin, Jialun
AU  - Zhou, Yilu
AU  - Chen, Hsinchun
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2006.01.004
UR  - http://www.sciencedirect.com/science/article/pii/S016792360600008X
KW  - Web portals
KW  - Design
KW  - Web spiders
KW  - Meta-search
KW  - Document summarization
KW  - Document clustering
KW  - Self-organizing maps
KW  - Patent analysis
KW  - Visualization
KW  - Nanotechnology
AB  - There has been a tremendous growth in the amount of information and resources on the World Wide Web that are useful to researchers and practitioners in science domains. While the Web has made the communication and sharing of research ideas and results among scientists easier and faster than ever, its dynamic and unstructured nature also makes the scientists faced with such problems as information overload, vocabulary difference, and lack of analysis tools. To address these problems, it is highly desirable to have an integrated, “one-stop shopping” Web portal to support effective information searching and analysis as well as to enhance communication and collaboration among researchers in various scientific fields. In this paper, we review existing information retrieval techniques and related literature, and propose a framework for developing integrated Web portals that support information searching and analysis for scientific knowledge. Our framework incorporates collection building, meta-searching, keyword suggestion, and various content analysis techniques such as document summarization, document clustering, and topic map visualization. Patent analysis techniques such as citation analysis and content map analysis are also incorporated. To demonstrate the feasibility of our approach, we developed based on our architecture a knowledge portal, called NanoPort, in the field of nanoscale science and engineering. We report our experience and explore the various issues of relevance to developing a Web portal for scientific domains. The system was compared to other search systems in the field and several design issues were identified. An evaluation study was conducted and the results showed that subjects were more satisfied with the NanoPort system than with Scirus, a leading search engine for scientific articles. Through our prototype system, we demonstrated the feasibility of using such an integrated approach and the study brought insight into applying the proposed domain-independent architecture to different areas of science and engineering in the future.
ER  - 

TY  - JOUR
T1  - Literature-related discovery (LRD): Potential treatments for Multiple Sclerosis
JO  - Technological Forecasting and Social Change
VL  - 75
IS  - 2
SP  - 239
EP  - 255
PY  - 2008/2//
T2  - Literature-Related Discovery
AU  - Kostoff, Ronald N.
AU  - Briggs, Michael B.
AU  - Lyons, Terence J.
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2007.11.002
UR  - http://www.sciencedirect.com/science/article/pii/S004016250700193X
KW  - Discovery
KW  - Innovation
KW  - Science and technology
KW  - Text mining
KW  - Literature-based discovery
KW  - Radical discovery
KW  - Innovation
KW  - Information retrieval
KW  - Unconnected disciplines
KW  - Disparate disciplines
KW  - Interdisciplinary
KW  - Multidisciplinary
KW  - Multiple sclerosis
AB  - Literature-related discovery (LRD) is the linking of two or more literature concepts that have heretofore not been linked (i.e., disjoint), in order to produce novel, interesting, plausible, and intelligible knowledge (i.e., potential discovery). The open discovery systems (ODS) component of LRD starts with a problem to be solved, and generates solutions to that problem through potential discovery. We have been using ODS LRD to identify potential treatments or preventative actions for challenging medical problems, among myriad other applications. The previous three papers in this Special Issue describe the application of ODS LRD to Raynaud's Phenomenon (RP), cataracts, and Parkinson's Disease (PD).

Multiple Sclerosis (MS) is a progressive neurodegenerative disorder (typically preceded by periods of remission and relapse), affecting mainly people in their early-mid life. MS is characterized by changes in sensation (hypoesthesia), muscle weakness, abnormal muscle spasms, or difficulty to move; difficulties with coordination and balance (ataxia); problems in speech (Dysarthria) or swallowing (Dysphagia), visual problems (Nystagmus, optic neuritis, or diplopia), fatigue and acute or chronic pain syndromes, bladder and bowel difficulties, cognitive impairment, or emotional symptomatology (mainly depression).

We selected the subject of MS because of its global prevalence, and its apparent intractability to all treatments except for palliative remediation mainly through drugs or surgery. Our first goal was to identify non-drug non-surgical treatments that would 1) prevent the occurrence, or 2) reduce the progression rate, or 3) stop the progression, or 4) maybe even reverse the progression, of MS. Our second goal was to demonstrate that we could again solve an ODS problem (using LRD) with no prior knowledge of any results or prior work (unlike the case of the RP problem). As in the ‘cataract’ and PD examples, we used the MeSH taxonomy of MEDLINE to restrict potential discoveries to selected semantic classes, and to identify potential discoveries efficiently. Our third goal was to generate large amounts of potential discovery in more than an order of magnitude less time than required for the RP study. The discovery generation methodology has been developed to the point where ODS LRD problems can be solved with no results or knowledge of any prior work.
ER  - 

TY  - JOUR
T1  - Literature-Related Discovery (LRD): Potential treatments for Parkinson's Disease
JO  - Technological Forecasting and Social Change
VL  - 75
IS  - 2
SP  - 226
EP  - 238
PY  - 2008/2//
T2  - Literature-Related Discovery
AU  - Kostoff, Ronald N.
AU  - Briggs, Michael B.
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2007.11.007
UR  - http://www.sciencedirect.com/science/article/pii/S0040162507002004
KW  - Text mining
KW  - Literature-Based Discovery
KW  - Document Clustering
KW  - Parkinson's Disease
AB  - Literature-Related Discovery (LRD) is the linking of two or more literature concepts that have heretofore not been linked (i.e., disjoint), in order to produce novel, interesting, plausible, and intelligible knowledge (i.e., potential discovery). The open discovery systems (ODS) component of LRD starts with a problem to be solved, and generates solutions to that problem through potential discovery. We have been using ODS LRD to identify potential treatments or preventative actions for challenging medical problems, among myriad other applications. The previous two papers in this Special Issue describe the application of ODS LRD to Raynaud's Phenomenon (RP) and to cataracts.

Parkinson's Disease (PD) is a progressive neurodegenerative disorder, affecting approximately 1% of individuals older than 60 years, and is characterized by resting tremor, rigidity, bradykinesia, and postural instability. We selected the subject of PD because of its global prevalence, and its apparent intractability to all treatments except for palliative remediation mainly through drugs or surgery.

Our first goal was to identify non-drug non-surgical treatments that would 1) prevent the occurrence, or 2) reduce the progression rate, or 3) stop the progression, or 4) maybe even reverse the progression, of PD. Our second goal was to demonstrate that we could again solve an ODS problem (using LRD) with no prior knowledge of any results or prior work (unlike the case of the RP problem). As in the ‘cataract’ example, we used the MeSH taxonomy of MEDLINE to restrict potential discoveries to selected semantic classes, and to identify potential discoveries efficiently. Our third goal was to generate large amounts of potential discovery in more than an order of magnitude less time than required for the RP study. The discovery generation methodology has been developed to the point where ODS LRD problems can be solved with no results or knowledge of any prior work.
ER  - 

TY  - JOUR
T1  - Text mining techniques for patent analysis
JO  - Information Processing & Management
VL  - 43
IS  - 5
SP  - 1216
EP  - 1247
PY  - 2007/9//
T2  - Patent Processing
AU  - Tseng, Yuen-Hsien
AU  - Lin, Chi-Jen
AU  - Lin, Yu-I
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2006.11.011
UR  - http://www.sciencedirect.com/science/article/pii/S0306457306002020
KW  - Summarization
KW  - Phrase extraction
KW  - Co-word analysis
KW  - Clustering
KW  - Topic mapping
AB  - Patent documents contain important research results. However, they are lengthy and rich in technical terminology such that it takes a lot of human efforts for analyses. Automatic tools for assisting patent engineers or decision makers in patent analysis are in great demand. This paper describes a series of text mining techniques that conforms to the analytical process used by patent analysts. These techniques include text segmentation, summary extraction, feature selection, term association, cluster generation, topic identification, and information mapping. The issues of efficiency and effectiveness are considered in the design of these techniques. Some important features of the proposed methodology include a rigorous approach to verify the usefulness of segment extracts as the document surrogates, a corpus- and dictionary-free algorithm for keyphrase extraction, an efficient co-word analysis method that can be applied to large volume of patents, and an automatic procedure to create generic cluster titles for ease of result interpretation. Evaluation of these techniques was conducted. The results confirm that the machine-generated summaries do preserve more important content words than some other sections for classification. To demonstrate the feasibility, the proposed methodology was applied to a real-world patent set for domain analysis and mapping, which shows that our approach is more effective than existing classification systems. The attempt in this paper to automate the whole process not only helps create final patent maps for topic analyses, but also facilitates or improves other patent analysis tasks such as patent classification, organization, knowledge sharing, and prior art searches.
ER  - 

TY  - JOUR
T1  - The effectiveness of query-specific hierarchic clustering in information retrieval
JO  - Information Processing & Management
VL  - 38
IS  - 4
SP  - 559
EP  - 582
PY  - 2002/7//
T2  - 
AU  - Tombros, Anastasios
AU  - Villa, Robert
AU  - Van Rijsbergen, C.J
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(01)00048-6
UR  - http://www.sciencedirect.com/science/article/pii/S0306457301000486
KW  - Information retrieval
KW  - Query-specific hierarchic clustering
KW  - Effectiveness evaluation
AB  - Hierarchic document clustering has been widely applied to information retrieval (IR) on the grounds of its potential improved effectiveness over inverted file search (IFS). However, previous research has been inconclusive as to whether clustering does bring improvements. In this paper we take the view that if hierarchic clustering is applied to search results (query-specific clustering), then it has the potential to increase the retrieval effectiveness compared both to that of static clustering and of conventional IFS. We conducted a number of experiments using five document collections and four hierarchic clustering methods. Our results show that the effectiveness of query-specific clustering is indeed higher, and suggest that there is scope for its application to IR.
ER  - 

TY  - JOUR
T1  - Document–document similarity approaches and science mapping: Experimental comparison of five approaches
JO  - Journal of Informetrics
VL  - 3
IS  - 1
SP  - 49
EP  - 63
PY  - 2009/1//
T2  - 
AU  - Ahlgren, Per
AU  - Colliander, Cristian
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2008.11.003
UR  - http://www.sciencedirect.com/science/article/pii/S1751157708000680
KW  - Citation data
KW  - Textual data
KW  - Data source combination
KW  - Cluster analysis
KW  - Science mapping
AB  - This paper treats document–document similarity approaches in the context of science mapping. Five approaches, involving nine methods, are compared experimentally. We compare text-based approaches, the citation-based bibliographic coupling approach, and approaches that combine text-based approaches and bibliographic coupling. Forty-three articles, published in the journal Information Retrieval, are used as test documents. We investigate how well the approaches agree with a ground truth subject classification of the test documents, when the complete linkage method is used, and under two types of similarities, first-order and second-order. The results show that it is possible to achieve a very good approximation of the classification by means of automatic grouping of articles. One text-only method and one combination method, under second-order similarities in both cases, give rise to cluster solutions that to a large extent agree with the classification.
ER  - 

TY  - JOUR
T1  - Improving browsing in digital libraries with keyphrase indexes
JO  - Decision Support Systems
VL  - 27
IS  - 1–2
SP  - 81
EP  - 104
PY  - 1999/11//
T2  - 
AU  - Gutwin, Carl
AU  - Paynter, Gordon
AU  - Witten, Ian
AU  - Nevill-Manning, Craig
AU  - Frank, Eibe
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/S0167-9236(99)00038-X
UR  - http://www.sciencedirect.com/science/article/pii/S016792369900038X
KW  - Digital libraries
KW  - Browsing interfaces
KW  - Text mining
KW  - Keyphrase extraction
KW  - Machine learning
AB  - Browsing accounts for much of people's interaction with digital libraries, but it is poorly supported by standard search engines. Conventional systems often operate at the wrong level, indexing words when people think in terms of topics, and returning documents when people want a broader view. As a result, users cannot easily determine what is in a collection, how well a particular topic is covered, or what kinds of queries will provide useful results. We have built a new kind of search engine, Keyphind, that is explicitly designed to support browsing. Automatically extracted keyphrases form the basic unit of both indexing and presentation, allowing users to interact with the collection at the level of topics and subjects rather than words and documents. The keyphrase index also provides a simple mechanism for clustering documents, refining queries, and previewing results. We compared Keyphind to a traditional query engine in a small usability study. Users reported that certain kinds of browsing tasks were much easier with the new interface, indicating that a keyphrase index would be a useful supplement to existing search tools.
ER  - 

TY  - JOUR
T1  - Semidefinite spectral clustering
JO  - Pattern Recognition
VL  - 39
IS  - 11
SP  - 2025
EP  - 2035
PY  - 2006/11//
T2  - 
AU  - Kim, Jaehwan
AU  - Choi, Seungjin
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2006.05.021
UR  - http://www.sciencedirect.com/science/article/pii/S0031320306002305
KW  - Clustering
KW  - Convex optimization
KW  - Multi-way graph equipartitioning
KW  - Semidefinite programming
KW  - Spectral clustering
AB  - Multi-way partitioning of an undirected weighted graph where pairwise similarities are assigned as edge weights, provides an important tool for data clustering, but is an NP-hard problem. Spectral relaxation is a popular way of relaxation, leading to spectral clustering where the clustering is performed by the eigen-decomposition of the (normalized) graph Laplacian. On the other hand, semidefinite relaxation, is an alternative way of relaxing a combinatorial optimization, leading to a convex optimization. In this paper we employ a semidefinite programming (SDP) approach to the graph equipartitioning for clustering, where sufficient conditions for strong duality hold. The method is referred to as semidefinite spectral clustering, where the clustering is based on the eigen-decomposition of the optimal feasible matrix computed by SDP. Numerical experiments with several data sets, demonstrate the useful behavior of our semidefinite spectral clustering, compared to existing spectral clustering methods.
ER  - 

TY  - JOUR
T1  - Mapping Knowledge about Product Lifecycle Engineering for Ontology Construction via Object-Process Methodology
JO  - CIRP Annals - Manufacturing Technology
VL  - 54
IS  - 1
SP  - 117
EP  - 122
PY  - 2005///
T2  - 
AU  - Dori, D.
AU  - Shpitalni, M.
SN  - 0007-8506
DO  - http://dx.doi.org/10.1016/S0007-8506(07)60063-8
UR  - http://www.sciencedirect.com/science/article/pii/S0007850607600638
KW  - Knowledge management
KW  - Lifecycle ontology
KW  - Object-process methodology
AB  - Knowledge mapping is a first and mandatory step in ontology definition. This paper considers the lifecycle of products and systems, and discusses the creation of a knowledge-based ontology. With respect to the life cycle of products and systems, knowledge refers to the processes involved in their creation (design manufacturing and assembly), use and maintenance, and end of life (EOL). Hence, this knowledge should consider what a product is comprised of (its structure), how it operates (its dynamics), and how it interacts with the environment. A clearly defined and consistent mapping of knowledge regarding structure, operation and interaction is necessary to construct an effective and useful ontology. Yet, in order to obtain the required knowledge and to organize it in a consistent and useful form, an appropriate ontology must be used. An interactive, iterative and consistent method is needed to cope with this complex and circular problem. In this paper, the Object-Process Methodology (OPM) approach is considered, along with OPCAT [1], a tool for OPM-based knowledge modeling. OPM is a systems-modeling approach that represents knowledge about systems concurrently and bi-modally through graphics (a set of Object-Process Diagrams, OPDs) and text (Object-Process Language, OPL, a subset of English), yielding a single, unified and consistent view. In this paper we propose a foundational modeling and ontology construction approach for a generic product that incorporates hardware and software components. The ontology can serve as a basis for a knowledge model to cover the entire product lifecycle, from inception to EOL, and can be applied in the VRL-KCiP Network of Excellence.
ER  - 

TY  - JOUR
T1  - Measures for knowledge-based economic development: Introducing data mining techniques to economic developers in the state of Georgia and the US South
JO  - Technological Forecasting and Social Change
VL  - 73
IS  - 8
SP  - 950
EP  - 965
PY  - 2006/10//
T2  - Tech Mining: Exploiting Science and Technology Information ResourcesTech Mining: Exploiting Science and Technology Information Resources
AU  - Shapira, Philip
AU  - Youtie, Jan
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2006.05.017
UR  - http://www.sciencedirect.com/science/article/pii/S0040162506001132
KW  - Economic development
KW  - Innovation
KW  - Knowledge measurement
KW  - Data mining
KW  - Bibliometrics
AB  - The contribution of knowledge to economic growth and competitiveness has attracted increased attention. Publications with a topical focus on areas related to innovation have risen dramatically from 1963 to 2005, but more slowly in local and regional development journals. In contrast to the wide use of aggregate measures of innovation, this paper presents four cases presenting disaggregated knowledge-based approaches into the policy- and decision-making processes of economic developers in the state of Georgia and the US South. The first case uses information obtained from patents and publications to inform traditional out-of-area economic development recruitment strategies in a more knowledge-oriented direction. The second case exemplifies the use of data mining to identify top researchers as part of a strategic state economic development effort. The third case illustrates how local knowledge-based capabilities can be identified in cities not traditionally viewed as innovative. Nanotechnology-related knowledge assets in the southern United States are mapped and assessed in the fourth case. Disaggregated methods used in traditional strategies were most intuitively understood and used, but new knowledge measures were found to encourage local and state economic developers to begin to embrace new paradigms.
ER  - 

TY  - JOUR
T1  - Fishing in murky waters—ethics and politics of research on fisher knowledge
JO  - Marine Policy
VL  - 26
IS  - 3
SP  - 159
EP  - 166
PY  - 2002/5//
T2  - 
AU  - Maurstad, Anita
SN  - 0308-597X
DO  - http://dx.doi.org/10.1016/S0308-597X(01)00045-8
UR  - http://www.sciencedirect.com/science/article/pii/S0308597X01000458
KW  - Fisher knowledge
KW  - Mapping
KW  - Cultural knowledge
KW  - Intellectual property rights
KW  - Small boat
KW  - Norway
AB  - Fisher knowledge is increasingly seen as an important source of information for the management of fisheries and sought by both academics and managers. With reference to interviews with Norwegian fishers I will discuss problematic ethical and methodological aspects of such documentation. Fisher knowledge is embedded in a social and cultural context and transfer of knowledge is relational. Fisher knowledge is a professional asset, and contains information that is often known only to a small group of local people. Transferring fisher knowledge to science and management the question is what it implies for fishers to have their knowledge moved beyond its traditional borders.
ER  - 

TY  - JOUR
T1  - Knowledge based requirement engineering for one-of-a-kind complex systems
JO  - Knowledge-Based Systems
VL  - 16
IS  - 1
SP  - 1
EP  - 5
PY  - 2003/1//
T2  - 
AU  - Ratchev, S
AU  - Urwin, E
AU  - Muller, D
AU  - Pawar, K.S
AU  - Moulek, I
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/S0950-7051(02)00027-8
UR  - http://www.sciencedirect.com/science/article/pii/S0950705102000278
KW  - Requirement engineering
KW  - Knowledge
KW  - Mapping
AB  - The success of requirement specification in new design projects largely depends on an accurate match between customer requirements and company product and process knowledge. Despite the recent developments in the domain there is still a lack of transparency and consistent definition and integration of the activities in requirement engineering (RE). There is also a lack of structured methods for capturing relevant enterprise knowledge and deploying it in support of decision making for requirement specification. This paper reports on the knowledge acquisition and sharing for requirement engineering (KARE) approach for requirement specification of one-of-a-kind complex systems. The approach provides a generic view of key RE processes clustered into three groups of activities: requirement elicitation, analysis and negotiation. The process is supported by a set of knowledge functions aimed at facilitating the requirement engineers in matching customer requirements to product characteristics. The reported research has been developed as part of the ESPRIT collaborative project KARE funded by the European Commission.
ER  - 

TY  - JOUR
T1  - CI Spider: a tool for competitive intelligence on the Web
JO  - Decision Support Systems
VL  - 34
IS  - 1
SP  - 1
EP  - 17
PY  - 2002/12//
T2  - 
AU  - Chen, Hsinchun
AU  - Chau, Michael
AU  - Zeng, Daniel
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/S0167-9236(02)00002-7
UR  - http://www.sciencedirect.com/science/article/pii/S0167923602000027
KW  - Competitive intelligence
KW  - Internet searching and browsing
KW  - Internet spider
KW  - Noun phrasing
KW  - Document clustering
KW  - Experimental research
AB  - Competitive Intelligence (CI) aims to monitor a firm's external environment for information relevant to its decision-making process. As an excellent information source, the Internet provides significant opportunities for CI professionals as well as the problem of information overload. Internet search engines have been widely used to facilitate information search on the Internet. However, many problems hinder their effective use in CI research. In this paper, we introduce the Competitive Intelligence Spider, or CI Spider, designed to address some of the problems associated with using Internet search engines in the context of competitive intelligence. CI Spider performs real-time collection of Web pages from sites specified by the user and applies indexing and categorization analysis on the documents collected, thus providing the user with an up-to-date, comprehensive view of the Web sites of user interest. In this paper, we report on the design of the CI Spider system and on a user study of CI Spider, which compares CI Spider with two other alternative focused information gathering methods: Lycos search constrained by Internet domain, and manual within-site browsing and searching. Our study indicates that CI Spider has better precision and recall rate than Lycos. CI Spider also outperforms both Lycos and within-site browsing and searching with respect to ease of use. We conclude that there exists strong evidence in support of the potentially significant value of applying the CI Spider approach in CI applications.
ER  - 

TY  - JOUR
T1  - Chinese science and technology — Structure and infrastructure
JO  - Technological Forecasting and Social Change
VL  - 74
IS  - 9
SP  - 1539
EP  - 1573
PY  - 2007/11//
T2  - Three Special Sections: Assessment of China's and India's Science and Technology Literature Nanotechnology Policy Minding the Gap: Previewing the Potential of Breakthrough Technologies
AU  - Kostoff, Ronald N.
AU  - Briggs, Michael B.
AU  - Rushenberg, Robert L.
AU  - Bowles, Christine A.
AU  - Icenhour, Alan S.
AU  - Nikodym, Kimberley F.
AU  - Barth, Ryan B.
AU  - Pecht, Michael
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2007.02.008
UR  - http://www.sciencedirect.com/science/article/pii/S0040162507000546
KW  - China
KW  - Science and technology
KW  - Bibliometrics
KW  - Citation analysis
KW  - Impact Factor
KW  - Computational linguistics
KW  - Core competencies
KW  - Research evaluation
KW  - CLUTO
KW  - Nanotechnology
KW  - Clustering
KW  - Taxonomies
AB  - This paper identifies and analyzes the science and technology core competencies of China, based on a sampling of approximately half of the total Chinese publication output in the Science Citation Index/ Social Science Citation Index (SCI/SSCI) [SCI. Certain data included herein are derived from the Science Citation Index/Social Science Citation Index prepared by the Thomson Scientific®, Inc. (Thomson®), Philadelphia, Pennsylvania, USA: © Copyright Thomson Scientific® 2006. All rights reserved. [1]] for 2005. Aggregate China publication and citation bibliometrics were obtained and a hierarchical research taxonomy, based on document clustering, was generated. Additionally, bibliometrics and thematic trends were tracked over the past two decades.

The key findings were that China's output of research articles has significantly expanded in the last decade. In terms of sheer numbers of research articles, especially in cuting-edge technologies, such as nanotechnology and energetic materials, it is among the leaders. Compared to the USA, the bulk of China's articles focus on the physical and engineering sciences, while the USA articles (compared to China) focus on medical, social, and psychological sciences.
ER  - 

TY  - JOUR
T1  - Finding aliases on the web using latent semantic analysis
JO  - Data & Knowledge Engineering
VL  - 49
IS  - 2
SP  - 129
EP  - 143
PY  - 2004/5//
T2  - Web Information and Data Management
AU  - Bhat, Vinay
AU  - Oates, Tim
AU  - Shanbhag, Vishal
AU  - Nicholas, Charles
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2003.10.006
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X03001745
KW  - Aliases
KW  - Latent semantic analysis
KW  - Search engines
AB  - A common problem faced when gathering information from the web is the use of different names to refer to the same entity. For example, the city in India referred to as Bombay in some documents may be referred to as Mumbai in others because its name officially changed from the former to the latter in 1995. Multiplicity of names can cause relevant documents to be missed by search engines. Our goal is to develop an automated system that discovers additional names for an entity given just one of its names. Latent semantic analysis (LSA) is generally thought to be well-suited for this task [Numerical linear algebra with applications 3(4) (1996) 301]. We demonstrate empirically that under a broad range of circumstances LSA performs poorly, and describe a two-stage algorithm based on LSA that performs significantly better.
ER  - 

TY  - JOUR
T1  - Identifying neuronal assemblies with local and global connectivity with scale space spectral clustering
JO  - Neurocomputing
VL  - 70
IS  - 10–12
SP  - 1728
EP  - 1734
PY  - 2007/6//
T2  - Computational Neuroscience: Trends in Research 2007Computational Neuroscience 2006
AU  - Oweiss, Karim
AU  - Jin, Rong
AU  - Suhail, Yasir
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2006.10.072
UR  - http://www.sciencedirect.com/science/article/pii/S0925231206003705
KW  - Multi-neuron recording
KW  - Spectral clustering
KW  - Functional interdependency
KW  - Cross-correlation
KW  - Multi-resolution analysis
AB  - A nonparametric approach is proposed to identify clusters of functionally interdependent neurons, independent of the time scale at which they are maximally correlated. The neural point processes are represented in a N-dimensional scale space using the Haar wavelet transform. A similarity measure between any given pair of neurons is defined in the scale space. Clusters of “similar” neurons are identified by first reducing the N-dimensional scale space representation using principal components to obtain a Q-dimensional space. The weighted principal components are subsequently used to connect each neuron to the others in a graph representation. A probabilistic spectral clustering algorithm is used to perform graph partitioning by maximizing cluster compactness. Performance is compared to that of the k-means and the expectation–maximization algorithms for 120 neurons with time-varying intensity functions consisting of spontaneous background activity and phased response elicited at distinct time scales.
ER  - 

TY  - JOUR
T1  - Performance analysis of filtering software using Signal Detection Theory
JO  - Decision Support Systems
VL  - 42
IS  - 2
SP  - 1015
EP  - 1028
PY  - 2006/11//
T2  - 
AU  - Deshmukh, Ashutosh
AU  - Rajagopalan, Balaji
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2005.08.002
UR  - http://www.sciencedirect.com/science/article/pii/S0167923605001132
KW  - Software filters
KW  - Signal Detection Theory
KW  - Efficiency and effectiveness
AB  - Software filters are increasingly being touted as a solution to restrict access to inappropriate information in a variety of settings. Families want to protect young children from pornographic sites, corporations are searching for ways to minimize trivial use of the Internet by their employees, and non-profit organizations look to control information access to reflect the value system of their communities. Despite the exponential increase in software filter usage, its effectiveness is not clear. In addition, critics of the approach argue that mandated use of filtering software on public computers like libraries may result in denial of vital information to poorer sections of the society who do not have independent access to the Internet, thereby curbing intellectual freedom and creating inequity in access to information. The purpose of this study is to analytically evaluate the performance of software filters using the Signal Detection Theory (SDT) framework. Two types of software filters are modeled and analyzed—simple software filter (single method) and a sequence of software filters (multiple methods). Analysis shows the limited capability of both types of filters, with the multiple-method filter outperforming the simple filter. Results of this study caution proponent of filter-based solution to be realistic with expectations of the benefits of filtering based solutions. Implications of the findings for proper use and design of software filters are discussed.
ER  - 

TY  - JOUR
T1  - Evaluating combinations of ranked lists and visualizations of inter-document similarity
JO  - Information Processing & Management
VL  - 37
IS  - 3
SP  - 435
EP  - 458
PY  - 2001/5//
T2  - Interactivity at the Text Retrieval Conference (TREC)
AU  - Allan, James
AU  - Leuski, Anton
AU  - Swan, Russell
AU  - Byrd, Donald
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(00)00056-X
UR  - http://www.sciencedirect.com/science/article/pii/S030645730000056X
KW  - Information retrieval
KW  - Clustering
KW  - Document visualization
KW  - User study
AB  - We are interested in how ideas from document clustering can be used to improve the retrieval accuracy of ranked lists in interactive systems. In particular, we are interested in ways to evaluate the effectiveness of such systems to decide how they might best be constructed. In this study, we construct and evaluate systems that present the user with ranked lists and a visualization of inter-document similarities. We first carry out a user study to evaluate the clustering/ranked list combination on instance-oriented retrieval, the task of the TREC-6 Interactive Track. We find that although users generally prefer the combination, they are not able to use it to improve effectiveness. In the second half of this study, we develop and evaluate an approach that more directly combines the ranked list with information from inter-document similarities. Using the TREC collections and relevance judgments, we show that it is possible to realize substantial improvements in effectiveness by doing so, and that although users can use the combined information effectively, the system can provide hints that substantially improve on the user's solo effort. The resulting approach shares much in common with an interactive application of incremental relevance feedback. Throughout this study, we illustrate our work using two prototype systems constructed for these evaluations. The first, AspInQuery, is a classic information retrieval system augmented with a specialized tool for recording information about instances of relevance. The other system, Lighthouse, is a Web-based application that combines a ranked list with a portrayal of inter-document similarity. Lighthouse can work with collections such as TREC, as well as the results of Web search engines.
ER  - 

TY  - JOUR
T1  - Contents
JO  - Decision Support Systems
VL  - 45
IS  - 3
SP  - iv
EP  - v
PY  - 2008/6//
T2  - Special Issue Clusters

SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/S0167-9236(08)00106-1
UR  - http://www.sciencedirect.com/science/article/pii/S0167923608001061
ER  - 

TY  - JOUR
T1  - Articles in Press - available online
JO  - Information Fusion
VL  - 9
IS  - 3
SP  - 441
EP  - 
PY  - 2008/7//
T2  - Special Issue on Distributed Sensor Networks

SN  - 1566-2535
DO  - http://dx.doi.org/10.1016/S1566-2535(08)00026-2
UR  - http://www.sciencedirect.com/science/article/pii/S1566253508000262
ER  - 

TY  - JOUR
T1  - Computer-based performance assessments: a solution to the narrow measurement and reporting of problem-solving☆
JO  - Computers in Human Behavior
VL  - 15
IS  - 3–4
SP  - 403
EP  - 418
PY  - 1999/5/31/
T2  - 
AU  - Schacter, J.
AU  - Herl, H.E.
AU  - Chung, G.K.W.K.
AU  - Dennis, R.A.
AU  - O'Neil Jr., H.F.
SN  - 0747-5632
DO  - http://dx.doi.org/10.1016/S0747-5632(99)00029-1
UR  - http://www.sciencedirect.com/science/article/pii/S0747563299000291
KW  - Assessment
KW  - Problem solving
KW  - Computers
KW  - Internet
KW  - Technology
KW  - Education
AB  - Although performance assessments test for higher order thinking and problem solving, they rarely report students' thinking process data back to teachers, students, or the public. Web-based database-backed performance assessments provide a viable means for concurrently reporting both performance and thinking process data. In the research conducted here, we report our findings from a study that assessed student problem solving using networked computers. Both performance and process data could be reported back to teachers and students such that they could diagnose and understand how they performed and what problem-solving processes contributed to or detracted from their performance.
ER  - 

TY  - JOUR
T1  - Mapping the contemporary terrorism research domain
JO  - International Journal of Human-Computer Studies
VL  - 65
IS  - 1
SP  - 42
EP  - 56
PY  - 2007/1//
T2  - Information security in the knowledge economy
AU  - Reid, Edna F.
AU  - Chen, Hsinchun
SN  - 1071-5819
DO  - http://dx.doi.org/10.1016/j.ijhcs.2006.08.006
UR  - http://www.sciencedirect.com/science/article/pii/S1071581906001273
KW  - Terrorism
KW  - Visualization
KW  - Bibliometrics
KW  - Co-citation analysis
KW  - Intellectual structure
AB  - A systematic view of terrorism research to reveal the intellectual structure of the field and empirically discern the distinct set of core researchers, institutional affiliations, publications, and conceptual areas can help us gain a deeper understanding of approaches to terrorism. This paper responds to this need by using an integrated knowledge-mapping framework that we developed to identify the core researchers and knowledge creation approaches in terrorism. The framework uses three types of analysis: (a) basic analysis of scientific output using citation, bibliometric, and social network analyses, (b) content map analysis of large corpora of literature, and (c) co-citation analysis to analyse linkages among pairs of researchers. We applied domain visualization techniques such as content map analysis, block-modeling, and co-citation analysis to the literature and author citation data from the years 1965 to 2003. The data were gathered from ten databases such as the ISI Web of Science. The results reveal: (1) the names of the top 42 core terrorism researchers (e.g., Brian Jenkins, Bruce Hoffman, and Paul Wilkinson) as well as their institutional affiliations; (2) their influential publications; (3) clusters of terrorism researchers who work in similar areas; and (4) that the research focus has shifted from terrorism as a low-intensity conflict to a strategic threat to world powers with increased focus on Osama Bin Laden.
ER  - 

TY  - JOUR
T1  - Risk, gap and strength: key concepts in knowledge management
JO  - Knowledge-Based Systems
VL  - 16
IS  - 1
SP  - 29
EP  - 36
PY  - 2003/1//
T2  - 
AU  - McBriar, Ian
AU  - Smith, Colin
AU  - Bain, Geoff
AU  - Unsworth, Peter
AU  - Magraw, Stephen
AU  - Gordon, John L
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/S0950-7051(02)00049-7
UR  - http://www.sciencedirect.com/science/article/pii/S0950705102000497
KW  - Knowledge-management
KW  - Risk
KW  - Gap
KW  - Strength
KW  - Knowledge-resource
AB  - This paper argues that there are certain concepts within the general domain of Knowledge Management that have not been fully explored. The discipline will benefit from a more detailed look at some of these concepts. The concepts of risk, gap and strength are the particular concepts that are explored in some more detail within this paper. A reason for describing these elements as concepts rather than terms is discussed. More precise definitions for the concepts described can provide management support about the knowledge resource in decision-making. Several function definitions for risk, gap and strength are offered. Finally, the paper considers how these concepts can influence organisational knowledge management schemes.
ER  - 

TY  - JOUR
T1  - Artificial intelligence approaches to achieve strategic control over project cash flows
JO  - Automation in Construction
VL  - 18
IS  - 4
SP  - 386
EP  - 393
PY  - 2009/7//
T2  - 
AU  - Cheng, Min-Yuan
AU  - Tsai, Hsing-Chih
AU  - Liu, Chih-Lung
SN  - 0926-5805
DO  - http://dx.doi.org/10.1016/j.autcon.2008.10.005
UR  - http://www.sciencedirect.com/science/article/pii/S0926580508001581
KW  - Construction industry
KW  - Project success
KW  - Cash flows
KW  - Artificial intelligence
KW  - K-means clustering
KW  - Genetic algorithm
KW  - Fuzzy logic
KW  - Neural network
AB  - The ability over the course of a construction project to make reliable predictions regarding cash flows enhances project cost management. This paper uses artificial intelligence (AI) approaches to predict cash flow trends for such projects in order to develop appropriate strategies that apply factors such as float, process execution time, construction rate and resource demand to project cash flow control. AI approaches involved in this paper include K-means clustering, genetic algorithm (GA), fuzzy logic (FL), and neural network (NN). K-means clustering is employed to categorize similar projects, while the other approaches are used to develop the Evolutionary Fuzzy Neural Inference Model (EFNIM), a knowledge learning model. FL and NN are employed in the EFNIM to develop a neural-fuzzy model that can deal with uncertainties and knowledge mapping. GA is used to optimize the membership functions of FL and NN parameters globally. The major target of this AI learning is to address sequential cash flow trends. This trained result is furthermore applied to a strategic project cash flow control. This cash flow control affects project performance within the banana envelope of the S-curve for project management.
ER  - 

TY  - JOUR
T1  - Who's in and why? A typology of stakeholder analysis methods for natural resource management
JO  - Journal of Environmental Management
VL  - 90
IS  - 5
SP  - 1933
EP  - 1949
PY  - 2009/4//
T2  - 
AU  - Reed, Mark S.
AU  - Graves, Anil
AU  - Dandy, Norman
AU  - Posthumus, Helena
AU  - Hubacek, Klaus
AU  - Morris, Joe
AU  - Prell, Christina
AU  - Quinn, Claire H.
AU  - Stringer, Lindsay C.
SN  - 0301-4797
DO  - http://dx.doi.org/10.1016/j.jenvman.2009.01.001
UR  - http://www.sciencedirect.com/science/article/pii/S0301479709000024
KW  - Stakeholder analysis
KW  - Typology
KW  - Methods
KW  - Identification
KW  - Categorisation
KW  - Inter-relationships
KW  - Participation
KW  - Rural Economy and Land Use programme
AB  - Stakeholder analysis means many things to different people. Various methods and approaches have been developed in different fields for different purposes, leading to confusion over the concept and practice of stakeholder analysis. This paper asks how and why stakeholder analysis should be conducted for participatory natural resource management research. This is achieved by reviewing the development of stakeholder analysis in business management, development and natural resource management. The normative and instrumental theoretical basis for stakeholder analysis is discussed, and a stakeholder analysis typology is proposed. This consists of methods for: i) identifying stakeholders; ii) differentiating between and categorising stakeholders; and iii) investigating relationships between stakeholders. The range of methods that can be used to carry out each type of analysis is reviewed. These methods and approaches are then illustrated through a series of case studies funded through the Rural Economy and Land Use (RELU) programme. These case studies show the wide range of participatory and non-participatory methods that can be used, and discuss some of the challenges and limitations of existing methods for stakeholder analysis. The case studies also propose new tools and combinations of methods that can more effectively identify and categorise stakeholders and help understand their inter-relationships.
ER  - 

TY  - JOUR
T1  - XML structural delta mining: Issues and challenges
JO  - Data & Knowledge Engineering
VL  - 59
IS  - 3
SP  - 627
EP  - 651
PY  - 2006/12//
T2  - Including: ER 2003Selection of papers presented at the 22nd International Conference on Conceptual Modeling22nd International Conference on Conceptual Modeling
AU  - Zhao, Qiankun
AU  - Chen, Ling
AU  - Bhowmick, Sourav S.
AU  - Madria, Sanjay
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2005.10.002
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X05001655
KW  - Versions of XML documents
KW  - Structural delta
KW  - Dynamic metrics
KW  - XML structural delta mining
KW  - Research issues
KW  - Applications
AB  - Recently, there is an increasing research efforts in XML data mining. These research efforts largely assumed that XML documents are static. However, in reality, the documents are rarely static. In this paper, we propose a novel research problem called XML structural delta mining. The objective of XML structural delta mining is to discover knowledge by analyzing structural evolution pattern (also called structural delta) of history of XML documents. Unlike existing approaches, XML structural delta mining focuses on the dynamic and temporal features of XML data. Furthermore, the data source for this novel mining technique is a sequence of historical versions of an XML document rather than a set of snapshot XML documents. Such mining technique can be useful in many applications such as change detection for very large XML documents, efficient XML indexing, XML search engine, etc. Our aim in this paper is not to provide a specific solution to a particular mining problem. Rather, we present the vision of the mining framework and present the issues and challenges for three types of XML structural delta mining: identifying various interesting structures, discovering association rules from structural deltas, and structural change pattern-based classification.
ER  - 

TY  - JOUR
T1  - QCS: A system for querying, clustering and summarizing documents
JO  - Information Processing & Management
VL  - 43
IS  - 6
SP  - 1588
EP  - 1605
PY  - 2007/11//
T2  - Text Summarization
AU  - Dunlavy, Daniel M.
AU  - O’Leary, Dianne P.
AU  - Conroy, John M.
AU  - Schlesinger, Judith D.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2007.01.003
UR  - http://www.sciencedirect.com/science/article/pii/S0306457307000246
KW  - Information retrieval
KW  - Latent semantic indexing
KW  - Clustering
KW  - Summarization
KW  - Text processing
KW  - Sentence trimming
AB  - Information retrieval systems consist of many complicated components. Research and development of such systems is often hampered by the difficulty in evaluating how each particular component would behave across multiple systems. We present a novel integrated information retrieval system—the Query, Cluster, Summarize (QCS) system—which is portable, modular, and permits experimentation with different instantiations of each of the constituent text analysis components. Most importantly, the combination of the three types of methods in the QCS design improves retrievals by providing users more focused information organized by topic.

We demonstrate the improved performance by a series of experiments using standard test sets from the Document Understanding Conferences (DUC) as measured by the best known automatic metric for summarization system evaluation, ROUGE. Although the DUC data and evaluations were originally designed to test multidocument summarization, we developed a framework to extend it to the task of evaluation for each of the three components: query, clustering, and summarization. Under this framework, we then demonstrate that the QCS system (end-to-end) achieves performance as good as or better than the best summarization engines.

Given a query, QCS retrieves relevant documents, separates the retrieved documents into topic clusters, and creates a single summary for each cluster. In the current implementation, Latent Semantic Indexing is used for retrieval, generalized spherical k-means is used for the document clustering, and a method coupling sentence “trimming” and a hidden Markov model, followed by a pivoted QR decomposition, is used to create a single extract summary for each cluster. The user interface is designed to provide access to detailed information in a compact and useful format.

Our system demonstrates the feasibility of assembling an effective IR system from existing software libraries, the usefulness of the modularity of the design, and the value of this particular combination of modules.
ER  - 

TY  - JOUR
T1  - Bibliographic coupling and its application to research-front and other core documents
JO  - Journal of Informetrics
VL  - 1
IS  - 4
SP  - 287
EP  - 307
PY  - 2007///
T2  - 
AU  - Jarneving, Bo
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2007.07.004
UR  - http://www.sciencedirect.com/science/article/pii/S1751157707000594
KW  - Bibliographic coupling
KW  - Science mapping
KW  - Cluster analysis
AB  - Based on previous findings and theoretical considerations, it was suggested that bibliographic coupling could be combined with a cluster method to provide a method for science mapping, complementary to the prevailing co-citation cluster analytical method. The complete link cluster method was on theoretical grounds assumed to provide a suitable cluster method for this purpose. The objective of the study was to evaluate the proposed method's capability to identify coherent research themes. Applying a large multidisciplinary test bed comprising more than 600,000 articles and 17 million references, the proposed method was tested in accordance with two lines of mapping. In the first line of mapping, all significant (strong) links connecting ‘core documents’ (strongly and frequently coupled documents) in clusters with any other core document was mapped. This resulted in a depiction of all significant artificially broken links between core documents in a cluster and core documents extrinsic to that cluster. The second line of mapping involved the application of links between clusters only. They were used to successively merge clusters on two subsequent levels of fusion, where the first generation of clusters were considered objects for a second clustering, and the second generation of clusters gave rise to a final cluster fusion. Changes of cluster composition on the three levels were evaluated with regard to several variables. Findings showed that the proposed method could provide with valid depictions of current research, though some severe restrictions would adhere to its application.
ER  - 

TY  - JOUR
T1  - Graph nodes clustering with the sigmoid commute-time kernel: A comparative study
JO  - Data & Knowledge Engineering
VL  - 68
IS  - 3
SP  - 338
EP  - 361
PY  - 2009/3//
T2  - 
AU  - Yen, Luh
AU  - Fouss, Francois
AU  - Decaestecker, Christine
AU  - Francq, Pascal
AU  - Saerens, Marco
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2008.10.006
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X0800147X
KW  - Kernel clustering
KW  - Graph mining
KW  - Kernel hierarchical clustering
KW  - Laplacian matrix
KW  - Fiedler vector
KW  - Commute-time distance
KW  - Resistance distance
KW  - Community detection
AB  - This work addresses the problem of detecting clusters in a weighted, undirected, graph by using kernel-based clustering methods, directly partitioning the graph according to a well-defined similarity measure between the nodes (a kernel on a graph). The proposed algorithms are based on a two-step procedure. First, a kernel or similarity matrix, providing a meaningful similarity measure between any couple of nodes, is computed from the adjacency matrix of the graph. Then, the nodes of the graph are clustered by performing a kernel clustering on this similarity matrix. Besides the introduction of a prototype-based kernel version of the gaussian mixtures model and Ward’s hierarchical clustering, in addition to the already known kernel k-means and fuzzy k-means, a new kernel, called the sigmoid commute-time kernel ( K CT S ) is presented. The joint use of the K CT S kernel matrix and kernel clustering appears to be quite effective. Indeed, this methodology provides the best results on a systematic comparison with a selection of graph clustering and communities detection algorithms on three real-world databases. Finally, some links between the proposed hierarchical kernel clustering and spectral clustering are examined.
ER  - 

TY  - JOUR
T1  - Information clustering based on fuzzy multisets
JO  - Information Processing & Management
VL  - 39
IS  - 2
SP  - 195
EP  - 213
PY  - 2003/3//
T2  - 
AU  - Miyamoto, Sadaaki
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(02)00047-X
UR  - http://www.sciencedirect.com/science/article/pii/S030645730200047X
KW  - Information retrieval
KW  - Data clustering
KW  - Fuzzy multiset
KW  - Cluster center
KW  - Algorithm
AB  - A fuzzy multiset model for information clustering is proposed with application to information retrieval on the World Wide Web. Noting that a search engine retrieves multiple occurrences of the same subjects with possibly different degrees of relevance, we observe that fuzzy multisets provide an appropriate model of information retrieval on the WWW. Information clustering which means both term clustering and document clustering is considered. Three methods of the hard c-means, fuzzy c-means, and an agglomerative method using cluster centers are proposed. Two distances between fuzzy multisets and algorithms for calculating cluster centers are defined. Theoretical properties concerning the clustering algorithms are studied. Illustrative examples are given to show how the algorithms work.
ER  - 

TY  - JOUR
T1  - Subject index to volume 45
JO  - Decision Support Systems
VL  - 45
IS  - 4
SP  - VI
EP  - IX
PY  - 2008/11//
T2  - Information Technology and Systems in the Internet-Era

SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/S0167-9236(08)00174-7
UR  - http://www.sciencedirect.com/science/article/pii/S0167923608001747
ER  - 

TY  - JOUR
T1  - Subject index
JO  - International Journal of Approximate Reasoning
VL  - 40
IS  - 3
SP  - 325
EP  - 
PY  - 2005/11//
T2  - 

SN  - 0888-613X
DO  - http://dx.doi.org/10.1016/S0888-613X(05)00075-7
UR  - http://www.sciencedirect.com/science/article/pii/S0888613X05000757
ER  - 

TY  - JOUR
T1  - Editors' introduction special issue on multilingual knowledge management
JO  - Decision Support Systems
VL  - 45
IS  - 3
SP  - 551
EP  - 553
PY  - 2008/6//
T2  - Special Issue Clusters
AU  - Yang, Christopher C.
AU  - Wei, Chih-Ping
AU  - Chen, Hsinchun
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2007.07.002
UR  - http://www.sciencedirect.com/science/article/pii/S0167923607001297
ER  - 

TY  - JOUR
T1  - Beyond threaded discussion: Representational guidance in asynchronous collaborative learning environments
JO  - Computers & Education
VL  - 50
IS  - 4
SP  - 1103
EP  - 1127
PY  - 2008/5//
T2  - 
AU  - Suthers, Daniel D
AU  - Vatrapu, Ravi
AU  - Medina, Richard
AU  - Joseph, Samuel
AU  - Dwyer, Nathan
SN  - 0360-1315
DO  - http://dx.doi.org/10.1016/j.compedu.2006.10.007
UR  - http://www.sciencedirect.com/science/article/pii/S0360131506001655
KW  - Computer-mediated communication
KW  - Cooperative/collaborative learning
KW  - Human–computer interface
KW  - Knowledge maps
KW  - Representational guidance
AB  - Although most online learning environments are predominately text based, researchers have argued that representational support for the conceptual structure of a problem would address problems of coherence and convergence that have been shown to be associated with threaded discussions and more effectively support collaborative knowledge construction. The study described in this paper sets out to investigate the merits of knowledge mapping representations as an adjunct to or replacement for threaded discussion in problem solving by asynchronously communicating dyads. Results show that users of knowledge maps created more hypotheses earlier in the experimental sessions and elaborated on them more than users of threaded discussions. Participants using knowledge maps were more likely to converge on the same conclusion and scored significantly higher on post-test questions that required integration of information distributed across dyads in a hidden profile design, suggesting that there was greater collaboration during the session. These results were most consistent when a knowledge map with embedded notes was the primary means of interaction rather than when it augmented a threaded discussion.

The paper also offers a methodological contribution: a paradigm for practical experimental study of asynchronous collaboration. It is crucial to understand how to support collaborative knowledge construction in the asynchronous settings prevalent in online learning, yet prior experimental research has focused on face-to-face and synchronous collaboration due to the pragmatic problems of conducting controlled studies of asynchronous interaction. A protocol is outlined that enables study of asynchronous collaboration in a controlled setting.
ER  - 

TY  - JOUR
T1  - Object-oriented framework for durability assessment and life cycle costing of highway bridges
JO  - Automation in Construction
VL  - 14
IS  - 5
SP  - 611
EP  - 632
PY  - 2005/10//
T2  - 
AU  - Ugwu, O.O.
AU  - Kumaraswamy, M.M.
AU  - Kung, F.
AU  - Ng, S.T.
SN  - 0926-5805
DO  - http://dx.doi.org/10.1016/j.autcon.2005.01.002
UR  - http://www.sciencedirect.com/science/article/pii/S0926580505000038
KW  - Durability
KW  - Sustainability
KW  - Bridge infrastructure
KW  - Life cycle costing
KW  - Knowledge representation
KW  - Computational model
AB  - Design professionals are increasingly faced with challenges to produce innovative designs that are durable and give good value for money to clients. However, durability is impinged upon by the interaction of different factors such as construction materials, construction method, quality systems in use at the construction stages, environmental exposure of the structural elements and their functions, ease of access for inspection and maintenance. It is therefore necessary to investigate frameworks that address the above outlined factors, for use by construction professionals. The framework should integrate the outlined durability factors and facilitate achieving the objectives of durability design that account for life cycle costs and sustainability of design options, rather than just focusing on the initial design and construction cost. This paper highlights the application of an object-oriented (OO) framework to decision-making in designing for durability in the bridge domain, and a prototype implementation of this framework. It discusses how an object-based solution could contribute towards achieving the objectives of durability and minimum maintenance costs at project level. The paper also gives recommendations for further work.
ER  - 

TY  - JOUR
T1  - Semantically driven snippet selection for supporting focused web searches
JO  - Data & Knowledge Engineering
VL  - 68
IS  - 2
SP  - 261
EP  - 277
PY  - 2009/2//
T2  - 
AU  - Varlamis, Iraklis
AU  - Stamou, Sofia
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2008.10.002
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X08001365
KW  - Web passage retrieval
KW  - Semantic similarity
KW  - Coherence
KW  - Information selection
KW  - Performance and evaluation
KW  - Human factors
AB  - Millions of people access the plentiful web content to locate information that is of interest to them. Searching is the primary web access method for many users. During search, the users visit a web search engine and use an interface to specify a query (typically comprising a few keywords) that best describes their information need. Upon query issuing, the engine’s retrieval modules identify a set of potentially relevant pages in the engine’s index, and return them to the users, ordered in a way that reflects the pages’ relevance to the query keywords. Currently, all major search engines display search results as a ranked list of URLs (pointing to the relevant pages’ physical location on the web) accompanied by the returned pages’ titles and small text fragments that summarize the context of search keywords. Such text fragments are widely known as snippets and they serve towards offering a glimpse to the returned pages’ contents. In general, text snippets, extracted from the retrieved pages, are an indicator of the pages’ usefulness to the query intention and they help the users browse search results and decide on the pages to visit. Thus far, the extraction of text snippets from the returned pages’ contents relies on statistical methods in order to determine which text fragments contain most of the query keywords. Typically, the first two text nuggets in the page’s contents that contain the query keywords are merged together to produce the final snippet that accompanies the page’s title and URL in the search results. Unfortunately, statistically generated snippets are not always representative of the pages’ contents and they are not always closely related to the query intention. Such text snippets might mislead web users in visiting pages of little interest or usefulness to them. In this article, we propose a snippet selection technique, which identifies within the contents of the query-relevant pages those text fragments that are both highly relevant to the query intention and expressive of the pages’ entire contents. The motive for our work is to assist web users make informed decisions before clicking on a page in the list of search results. Towards this goal, we firstly show how to analyze search results in order to decipher the query intention. Then, we process the content of the query matching pages in order to identify text fragments that highly correlate to the query semantics. Finally, we evaluate the query-related text fragments in terms of coherence and expressiveness and pick from every retrieved page the text nugget that highly correlates to the query intention and is also very representative of the page’s content. A thorough evaluation over a large number of web pages and queries suggests that the proposed snippet selection technique extracts good quality text snippets with high precision and recall that are superior to existing snippet selection methods. Our study also reveals that the snippets delivered by our method can help web users decide on which results to click. Overall, our study suggests that semantically driven snippet selection can be used to augment traditional snippet extraction approaches that are mainly dependent upon the statistical properties of words within a text.
ER  - 

TY  - JOUR
T1  - The influence of cultural factors on price clustering: Evidence from Asia–Pacific stock markets
JO  - Pacific-Basin Finance Journal
VL  - 10
IS  - 3
SP  - 307
EP  - 332
PY  - 2002/6//
T2  - 13th Annual PACAP/FMA Finance Conference
AU  - Brown, Philip
AU  - Chua, Angeline
AU  - Mitchell, Jason
SN  - 0927-538X
DO  - http://dx.doi.org/10.1016/S0927-538X(02)00049-5
UR  - http://www.sciencedirect.com/science/article/pii/S0927538X02000495
KW  - Price clustering
KW  - Attraction
KW  - Negotiation
KW  - Haziness
AB  - Price clustering is the tendency of prices to be observed more frequently at some numbers than others. It increases with haziness, or imprecision, about underlying value. Most research on price clustering has been conducted in Western financial markets, where there is manifest preference for trading at round numbers.

We focus on number preferences under Chinese culture. Many Chinese believe some numbers are “unlucky” and to be avoided. For instance, the number 4 is inauspicious because the Cantonese pronunciation of 4 is similar to the phrase “to die”. We first document clustering of daily closing prices on six Asia–Pacific stock markets, three with predominantly Chinese populations. Next, we fit binomial logit models within these markets to estimate the association between structural and economic factors, and culture, on price clustering. We find some support for the influence of Chinese culture and superstition on year-round number preferences of traders, but it is located solely in the Hong Kong market. Furthermore, in the Hong Kong market Chinese culture and superstition help explain the increased avoidance of the number 4 during the auspicious Chinese New Year, Dragon Boat and Mid-Autumn festivals.
ER  - 

TY  - JOUR
T1  - What do investment banks charge to underwrite American Depositary Receipts?
JO  - Journal of Banking & Finance
VL  - 33
IS  - 4
SP  - 609
EP  - 618
PY  - 2009/4//
T2  - 
AU  - Chen, Hsuan-Chi
AU  - Fauver, Larry
AU  - Yang, Pei-Ching
SN  - 0378-4266
DO  - http://dx.doi.org/10.1016/j.jbankfin.2008.12.004
UR  - http://www.sciencedirect.com/science/article/pii/S0378426608002902
KW  - American Depositary Receipts (ADRs)
KW  - Gross spread
KW  - Underwriters
KW  - Clustering
KW  - Firm and offer characteristics
AB  - We investigate how investment banks determine the gross spreads paid by American Depositary Receipts (ADRs) from 1980 to 2004. We begin by comparing the gross spreads of ADR IPOs and ADR SEOs to those of matching US IPOs and US SEOs. We document clustering at the 7% level for our ADR IPO sample (44% for the ADR IPO firms without a previous equity listing), whereas our ADR SEO sample exhibits no discernable clustering at any level. We then find that ADR IPO gross spreads can be explained by firm and offer characteristics (similar to our matched sample of US IPOs), and by whether the ADR IPO firm has a previous equity listing. ADR SEO gross spreads can be explained more by offer characteristics (more similar to our matched sample of US SEOs).
ER  - 

TY  - JOUR
T1  - Articles in Press - available online
JO  - Information Fusion
VL  - 9
IS  - 2
SP  - 328
EP  - 
PY  - 2008/4//
T2  - 

SN  - 1566-2535
DO  - http://dx.doi.org/10.1016/S1566-2535(08)00011-0
UR  - http://www.sciencedirect.com/science/article/pii/S1566253508000110
ER  - 

TY  - JOUR
T1  - Subject index to volume 63 (2005)
JO  - Neurocomputing
VL  - 63
IS  - 
SP  - 543
EP  - 544
PY  - 2005/1//
T2  - New Aspects in Neurocomputing: 11th European Symposium on Artificial Neural Networks

SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/S0925-2312(04)00531-4
UR  - http://www.sciencedirect.com/science/article/pii/S0925231204005314
ER  - 

TY  - JOUR
T1  - Identifying and improving retrieval for procedural questions
JO  - Information Processing & Management
VL  - 43
IS  - 1
SP  - 181
EP  - 203
PY  - 2007/1//
T2  - 
AU  - Murdock, Vanessa
AU  - Kelly, Diane
AU  - Croft, W. Bruce
AU  - Belkin, Nicholas J.
AU  - Yuan, Xiaojun
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2006.05.009
UR  - http://www.sciencedirect.com/science/article/pii/S0306457306000781
KW  - Procedural questions
KW  - Question classification
KW  - Document structure
KW  - Document clustering
KW  - Document retrieval
KW  - Reranking
AB  - People use questions to elicit information from other people in their everyday lives and yet the most common method of obtaining information from a search engine is by posing keywords. There has been research that suggests users are better at expressing their information needs in natural language, however the vast majority of work to improve document retrieval has focused on queries posed as sets of keywords or Boolean queries. This paper focuses on improving document retrieval for the subset of natural language questions asking about how something is done. We classify questions as asking either for a description of a process or asking for a statement of fact, with better than 90% accuracy. Further we identify non-content features of documents relevant to questions asking about a process. Finally we demonstrate that we can use these features to significantly improve the precision of document retrieval results for questions asking about a process. Our approach, based on exploiting the structure of documents, shows a significant improvement in precision at rank one for questions asking about how something is done.
ER  - 

TY  - JOUR
T1  - Complete graphs and bibliographic coupling: A test of the applicability of bibliographic coupling for the identification of cognitive cores on the field level
JO  - Journal of Informetrics
VL  - 1
IS  - 4
SP  - 338
EP  - 356
PY  - 2007///
T2  - 
AU  - Jarneving, Bo
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2007.08.001
UR  - http://www.sciencedirect.com/science/article/pii/S1751157707000612
KW  - Bibliographic coupling
KW  - Science mapping
KW  - Research fronts
AB  - The method of bibliographic coupling in combination with the complete link cluster method was applied for mapping of the field of organic chemistry with the purpose of testing the applicability of a proposed mapping method on the field level. The method put forward aimed at the generation of cognitive cores of documents, so-called ‘bibliographic cliques’ in the network of bibliographically coupled research articles. The defining feature of these cliques is that they can be considered complete graphs where each bibliographic coupling link ties an unordered pair of documents. In this way, it was presumed that coherent groups of documents in the research front would be found and that these groups would be intellectually coherent as well. Statistical analysis and subject specialist evaluations confirmed these presumptions. The study also elaborates on the choice of observation period and the application of thresholds in relation to the size of document populations.
ER  - 

TY  - JOUR
T1  - Exploring the effects of direct experience on IT use: An organizational field study
JO  - Information & Management
VL  - 45
IS  - 4
SP  - 249
EP  - 256
PY  - 2008/6//
T2  - 
AU  - Mao, En
AU  - Palvia, Prashant
SN  - 0378-7206
DO  - http://dx.doi.org/10.1016/j.im.2008.02.007
UR  - http://www.sciencedirect.com/science/article/pii/S0378720608000372
KW  - Direct experience
KW  - IT use
KW  - Technology acceptance model
KW  - Invariance analysis
AB  - Empirical studies have investigated the effect of attitude and behavior on IT acceptance in organizations but yielded ambiguous results. Possibly they have not effectively accounted for the moderating effects of experience gained through direct interaction with the target technology. We examined the moderating effect of the length of direct experience on IT acceptance relationships and constructs. Using multi-group invariance analysis, we demonstrated that relationships between key IT acceptance constructs differed, depending on the user's experience. The incorporation of direct experience can lead to convergent results and contribute to further understanding of the process. We discuss some implications from the knowledge that IT use is a dynamic process and suggest that IT management must account for direct experience in their decision making.
ER  - 

TY  - JOUR
T1  - Variable space hidden Markov model for topic detection and analysis
JO  - Knowledge-Based Systems
VL  - 20
IS  - 7
SP  - 607
EP  - 613
PY  - 2007/10//
T2  - Special Issue on Techniques to Produce Intelligent Secure Software
AU  - Zeng, Jianping
AU  - Zhang, Shiyong
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2007.09.001
UR  - http://www.sciencedirect.com/science/article/pii/S0950705107000780
KW  - Topic detection
KW  - Variable space hidden Markov model
KW  - Topic transition
KW  - Hierarchical clustering
AB  - Discovering topics from large amount of documents has become an important task recently. Most of the topic models treat document as a word sequence, whether in discrete character or term frequency form. However, the number of words in a document is greatly different from that in other documents. This will lead to several problems for current topic models in dealing with topics analysis. On the other hand, it is difficult to perform topic transition analysis based on current topic models. In an attempt to overcome these deficiencies, a variable space hidden Markov model (VSHMM) is proposed to represent the topics, and several operations based on space computation are presented. A hierarchical clustering algorithm with dynamically changing of the component number in topic model is proposed to demonstrate the effectiveness of the VSHMM. Method of document partition based on topic transition is also present. Experiments on a real-world dataset show that the VSHMM can improve the accuracy while decreasing the algorithm’s time complexity greatly compared with the algorithm based on current mixture model.
ER  - 

TY  - JOUR
T1  - Special Issue on Multilingual Knowledge Management
JO  - Decision Support Systems
VL  - 39
IS  - 4
SP  - 677
EP  - 678
PY  - 2005/6//
T2  - Collaborative Work and Knowledge Management

SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2004.12.002
UR  - http://www.sciencedirect.com/science/article/pii/S0167923604002970
ER  - 

TY  - JOUR
T1  - Literature-related discovery (LRD): Lessons learned, and future research directions
JO  - Technological Forecasting and Social Change
VL  - 75
IS  - 2
SP  - 276
EP  - 299
PY  - 2008/2//
T2  - Literature-Related Discovery
AU  - Kostoff, Ronald N.
AU  - Block, Joel A.
AU  - Solka, Jeffrey L.
AU  - Briggs, Michael B.
AU  - Rushenberg, Robert L.
AU  - Stump, Jesse A.
AU  - Johnson, Dustin
AU  - Lyons, Terence J.
AU  - Wyatt, Jeffrey R.
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2007.11.003
UR  - http://www.sciencedirect.com/science/article/pii/S0040162507001953
KW  - Literature-based discovery
KW  - Text mining
KW  - Innovation
KW  - Raynaud's Phenomenon
KW  - Cataracts
KW  - Parkinson's Disease
KW  - Multiple Sclerosis
KW  - Water purification
AB  - Literature-related discovery (LRD) is the linking of two or more literature concepts that have heretofore not been linked (i.e., disjoint), in order to produce novel, interesting, plausible, and intelligible knowledge (i.e., potential discovery). The open discovery systems (ODS) component of LRD starts with a problem to be solved, and generates solutions to that problem through potential discovery. We have been using ODS LRD to identify potential treatments or preventative actions for challenging medical problems, among myriad other applications. The five immediately preceding papers in this Special Issue describe the application of ODS LRD to Raynaud's Phenomenon (RP), cataracts, Parkinson's Disease (PD), Multiple Sclerosis (MS), and Water Purification (WP). We describe the lessons learned from each application, and how the techniques can be improved further.

Generation of much potential discovery using ODS LRD is possible when the conceptual roadblocks to discovery are removed. Some of these roadblocks include use of numerical filters that are unrelated to generating discovery, and excessive reliance on literatures directly related to the problem literature of interest. The issue of how to handle large amounts of potential discovery has not been addressed in the literature, since most ODS LRD researchers have tried to find a relatively few potential discovery items. We present a development strategy that capitalizes on the large amounts of potential discovery we have identified.
ER  - 

TY  - JOUR
T1  - Special issue on nature-inspired applications and systems
JO  - Journal of Systems Architecture
VL  - 52
IS  - 8–9
SP  - 441
EP  - 442
PY  - 2006/8//
Y2  - 2006/9//
T2  - Nature-Inspired Applications and Systems
AU  - Farooq, Muddassar
AU  - Menezes, Ronaldo
SN  - 1383-7621
DO  - http://dx.doi.org/10.1016/j.sysarc.2006.02.004
UR  - http://www.sciencedirect.com/science/article/pii/S1383762106000154
ER  - 

TY  - JOUR
T1  - Articles in Press - available online
JO  - Information Fusion
VL  - 8
IS  - 3
SP  - 333
EP  - 334
PY  - 2007/7//
T2  - Special Issue on Concurrent Learning and Fusion

SN  - 1566-2535
DO  - http://dx.doi.org/10.1016/S1566-2535(07)00033-4
UR  - http://www.sciencedirect.com/science/article/pii/S1566253507000334
ER  - 

TY  - JOUR
T1  - Articles in Press - available online
JO  - Information Fusion
VL  - 9
IS  - 1
SP  - 138
EP  - 139
PY  - 2008/1//
T2  - Special Issue on Applications of Ensemble Methods

SN  - 1566-2535
DO  - http://dx.doi.org/10.1016/S1566-2535(07)00078-4
UR  - http://www.sciencedirect.com/science/article/pii/S1566253507000784
ER  - 

TY  - JOUR
T1  - Articles in Press - available online
JO  - Information Fusion
VL  - 8
IS  - 4
SP  - 414
EP  - 415
PY  - 2007/10//
T2  - 

SN  - 1566-2535
DO  - http://dx.doi.org/10.1016/S1566-2535(07)00054-1
UR  - http://www.sciencedirect.com/science/article/pii/S1566253507000541
ER  - 

TY  - JOUR
T1  - Articles in Press - available online
JO  - Information Fusion
VL  - 8
IS  - 2
SP  - 220
EP  - 221
PY  - 2007/4//
T2  - Special Issue on Image Fusion: Advances in the State of the Art

SN  - 1566-2535
DO  - http://dx.doi.org/10.1016/S1566-2535(07)00011-5
UR  - http://www.sciencedirect.com/science/article/pii/S1566253507000115
ER  - 

TY  - JOUR
T1  - Special issue: The Web of Data
JO  - Web Semantics: Science, Services and Agents on the World Wide Web
VL  - 7
IS  - 3
SP  - 135
EP  - 
PY  - 2009/9//
T2  - The Web of Data
AU  - Polleres, Axel
AU  - Huynh, David
SN  - 1570-8268
DO  - http://dx.doi.org/10.1016/S1570-8268(09)00039-0
UR  - http://www.sciencedirect.com/science/article/pii/S1570826809000390
ER  - 

TY  - JOUR
T1  - Preface
JO  - Journal of Network and Computer Applications
VL  - 28
IS  - 2
SP  - 75
EP  - 76
PY  - 2005/4//
T2  - Computational Intelligence on the Internet

SN  - 1084-8045
DO  - http://dx.doi.org/10.1016/j.jnca.2004.01.004
UR  - http://www.sciencedirect.com/science/article/pii/S1084804504000025
ER  - 

TY  - JOUR
T1  - Table of Contents
JO  - Journal of the American Medical Informatics Association
VL  - 14
IS  - 5
SP  - A3
EP  - 
PY  - 2007/9//
Y2  - 2007/10//
T2  - 

SN  - 1067-5027
DO  - http://dx.doi.org/10.1197/S1067-5027(07)00186-7
UR  - http://www.sciencedirect.com/science/article/pii/S1067502707001867
ER  - 

TY  - JOUR
T1  - Interactivity at the Text Retrieval Conference (TREC)
JO  - Information Processing & Management
VL  - 37
IS  - 3
SP  - 365
EP  - 367
PY  - 2001/5//
T2  - Interactivity at the Text Retrieval Conference (TREC)
AU  - Hersh, William
AU  - Over, Paul
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(00)00052-2
UR  - http://www.sciencedirect.com/science/article/pii/S0306457300000522
ER  - 

TY  - JOUR
T1  - A distance-relatedness dynamic model for clustering high dimensional data of arbitrary shapes and densities
JO  - Pattern Recognition
VL  - 42
IS  - 7
SP  - 1193
EP  - 1209
PY  - 2009/7//
T2  - 
AU  - Yousri, Noha A.
AU  - Kamel, Mohamed S.
AU  - Ismail, Mohamed A.
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2008.08.037
UR  - http://www.sciencedirect.com/science/article/pii/S0031320308003701
KW  - Clustering
KW  - Dynamic model
KW  - Arbitrary shaped clusters
KW  - Arbitrary density clusters
KW  - High dimensional data
KW  - Distance-relatedness
AB  - It is important to find the natural clusters in high dimensional data where visualization becomes difficult. A natural cluster is a cluster of any shape and density, and it should not be restricted to a globular shape as a wide number of algorithms assume, or to a specific user-defined density as some density-based algorithms require.

In this work, it is proposed to solve the problem by maximizing the relatedness of distances between patterns in the same cluster. It is then possible to distinguish clusters based on their distance-based densities. A novel dynamic model is proposed based on new distance-relatedness measures and clustering criteria. The proposed algorithm “Mitosis” is able to discover clusters of arbitrary shapes and arbitrary densities in high dimensional data. It has a good computational complexity compared to related algorithms. It performs very well on high dimensional data, discovering clusters that cannot be found by known algorithms. It also identifies outliers in the data as a by-product of the cluster formation process. A validity measure that depends on the main clustering criterion is also proposed to tune the algorithm's parameters. The theoretical bases of the algorithm and its steps are presented. Its performance is illustrated by comparing it with related algorithms on several data sets.
ER  - 

TY  - JOUR
T1  - Automatic discovery of topics and acoustic morphemes from speech
JO  - Computer Speech & Language
VL  - 23
IS  - 2
SP  - 220
EP  - 239
PY  - 2009/4//
T2  - 
AU  - Cerisara, Christophe
SN  - 0885-2308
DO  - http://dx.doi.org/10.1016/j.csl.2008.06.004
UR  - http://www.sciencedirect.com/science/article/pii/S0885230808000387
KW  - Speech processing
KW  - Topic clustering
KW  - Lexical acquisition
AB  - This work deals with automatic lexical acquisition and topic discovery from a speech stream. The proposed algorithm builds a lexicon enriched with topic information in three steps: transcription of an audio stream into phone sequences with a speaker- and task-independent phone recogniser, automatic lexical acquisition based on approximate string matching, and hierarchical topic clustering of the lexical entries based on a knowledge-poor co-occurrence approach. The resulting semantic lexicon is then used to automatically cluster the incoming speech stream into topics. The main advantages of this algorithm are its very low computational requirements and its independence to pre-defined linguistic resources, which makes it easy to port to new languages and to adapt to new tasks. It is evaluated both qualitatively and quantitatively on two corpora and on two tasks related to topic clustering. The results of these evaluations are encouraging and outline future directions of research for the proposed algorithm, such as building automatic orthographic labels of the lexical items.
ER  - 

TY  - JOUR
T1  - Web information fusion
JO  - Information Fusion
VL  - 9
IS  - 4
SP  - 444
EP  - 445
PY  - 2008/10//
T2  - Special Issue on Web Information Fusion
AU  - Yao, JingTao
AU  - Raghavan, Vijay V.
AU  - Wu, Zonghuan
SN  - 1566-2535
DO  - http://dx.doi.org/10.1016/j.inffus.2008.05.001
UR  - http://www.sciencedirect.com/science/article/pii/S1566253508000304
ER  - 

TY  - JOUR
T1  - Building web warehouse for semi-structured data
JO  - Data & Knowledge Engineering
VL  - 39
IS  - 2
SP  - 101
EP  - 103
PY  - 2001/11//
T2  - Building Web warehouse for semi-structured data
AU  - Mohania, Mukesh
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/S0169-023X(01)00035-0
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X01000350
ER  - 

TY  - JOUR
T1  - Special issue on advances in fuzzy logic
JO  - Information Sciences
VL  - 177
IS  - 2
SP  - 329
EP  - 331
PY  - 2007/1/15/
T2  - 
AU  - Kandel, Abraham
AU  - Last, Mark
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2006.03.013
UR  - http://www.sciencedirect.com/science/article/pii/S0020025506000739
ER  - 

TY  - JOUR
T1  - Multi-documents Automatic Abstracting based on text clustering and semantic analysis
JO  - Knowledge-Based Systems
VL  - 22
IS  - 6
SP  - 482
EP  - 485
PY  - 2009/8//
T2  - 
AU  - Guo, Qinglin
AU  - Zhang, Ming
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2009.06.010
UR  - http://www.sciencedirect.com/science/article/pii/S0950705109000999
KW  - Semantic analysis
KW  - Automatic Abstracting
KW  - Multi-documents
KW  - Text clustering
KW  - Natural language understanding
AB  - A method of realization of multi-documents Automatic Abstracting based on text clustering and semantic analysis is brought forward, aimed at overcoming shortages of some current methods about multi-documents. The method makes use of semantic analysis and can realize Automatic Abstracting of multi-documents. The algorithm of twice word segmentation based on the title and first-sentences in paragraphs is brought forward. Its precision and recall is above 95%. For a specific domain on plastics, an Automatic Abstracting system named TCAAS is implemented. The precision and recall of multi-document’s Automatic Abstracting is above 75%. And experiments do prove that it is feasible to use the method to develop a domain Automatic Abstracting system, which is valuable for further study in more depth.
ER  - 

TY  - JOUR
T1  - Mapping of sample collection data: GIS tools for the natural product researcher
JO  - Phytochemistry Letters
VL  - 2
IS  - 1
SP  - 1
EP  - 9
PY  - 2009/2/19/
T2  - 
AU  - Oberlies, Nicholas H.
AU  - Rineer, James I.
AU  - Alali, Feras Q.
AU  - Tawaha, Khaled
AU  - Falkinham III, Joseph O.
AU  - Wheaton, William D.
SN  - 1874-3900
DO  - http://dx.doi.org/10.1016/j.phytol.2008.10.006
UR  - http://www.sciencedirect.com/science/article/pii/S187439000800089X
KW  - Geographic Information Systems (GIS)
KW  - Global positioning systems (GPS)
KW  - OpenGIS® KML Encoding Standard (OGC KML)
KW  - Geospatial science
KW  - Mapping
KW  - Google Earth
AB  - Scientists engaged in the research of natural products often either conduct field collections themselves or collaborate with partners who do, such as botanists, mycologists, or SCUBA divers. The information gleaned from such collecting trips (e.g. longitude/latitude coordinates, geography, elevation, and a multitude of other field observations) have provided valuable data to the scientific community (e.g., biodiversity), even if it is tangential to the direct aims of the natural products research, which are often focused on drug discovery and/or chemical ecology. Geographic Information Systems (GIS) have been used to display, manage, and analyze geographic data, including collection sites for natural products. However, to the uninitiated, these tools are often beyond the financial and/or computational means of the natural product scientist. With new, free, and easy-to-use geospatial visualization tools, such as Google Earth, mapping and geographic imaging of sampling data are now within the reach of natural products scientists. The goals of the present study were to develop simple tools that are tailored for the natural products setting, thereby presenting a means to map such information, particularly via open source software like Google Earth.
ER  - 

TY  - JOUR
T1  - Posting file partitioning and parallel information retrieval
JO  - Journal of Systems and Software
VL  - 63
IS  - 2
SP  - 113
EP  - 127
PY  - 2002/8/15/
T2  - 
AU  - Ma, Yung-Cheng
AU  - Chen, Tien-Fu
AU  - Chung, Chung-Ping
SN  - 0164-1212
DO  - http://dx.doi.org/10.1016/S0164-1212(01)00119-4
UR  - http://www.sciencedirect.com/science/article/pii/S0164121201001194
AB  - The rapid growth in Internet usages brings new challenges on designing a scalable information retrieval system. To reduce the response time of a query to a large database, we parallelize both CPU computation and disk access of Boolean query processing on a cluster of workstations. The key issue is to partition the inverted file such that, during parallel query processing, each workstation consults only its own locally resident data to complete its task. To achieve this goal, we treat the set of all postings referring to a document ID as an object to be allocated in the develop data placement problem. Following the partitioning by document ID principle, we develop posting file partitioning algorithms to transform a sequential information retrieval system to a parallel information retrieval system. The advantage is that a better speed-up can be achieved by deriving from the fast sequential approach – the compressed posting file. The partitioning schemes are designed to balance work-load of workstations in parallel query processing without increasing the average disk access time per posting. The experiment shows that almost linear speed-up can be achieved and the performance bottleneck in previous work, which parallelize only disk access, can be removed. This work shows that, by using parallel processing technique, it is feasible to build a scalable information retrieval system.
ER  - 

TY  - JOUR
T1  - Development of a patent document classification and search platform using a back-propagation network
JO  - Expert Systems with Applications
VL  - 31
IS  - 4
SP  - 755
EP  - 765
PY  - 2006/11//
T2  - Computer Supported Cooperative Work in Design and Manufacturing
AU  - Trappey, Amy J.C.
AU  - Hsu, Fu-Chiang
AU  - Trappey, Charles V.
AU  - Lin, Chia-I.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2006.01.013
UR  - http://www.sciencedirect.com/science/article/pii/S0957417406000121
KW  - Knowledge document management
KW  - Document classification
KW  - Patent search
KW  - Neural networks
AB  - In order to process large numbers of explicit knowledge documents such as patents in an organized manner, automatic document categorization and search are required. In this paper, we develop a document classification and search methodology based on neural network technology that helps companies manage patent documents more effectively. The classification process begins by extracting key phrases from the document set by means of automatic text processing and determining the significance of key phrases according to their frequency in text. In order to maintain a manageable number of independent key phrases, correlation analysis is applied to compute the similarities between key phrases. Phrases with higher correlations are synthesized into a smaller set of phrases. Finally, the back-propagation network model is adopted as a classifier. The target output identifies a patent document’s category based on a hierarchical classification scheme, in this case, the international patent classification (IPC) standard. The methodology is tested using patents related to the design of power hand-tools. Related patents are automatically classified using pre-trained neural network models. In the prototype system, two modules are used for patent document management. The automatic classification module helps the user classify patent documents and the search module helps users find relevant and related patent documents. The result shows an improvement in document classification and identification over previously published methods of patent document management.
ER  - 

TY  - JOUR
T1  - Subject index
JO  - Computer Networks and ISDN Systems
VL  - 30
IS  - 1–7
SP  - 773
EP  - 776
PY  - 1998/4//
T2  - Proceedings of the Seventh International World Wide Web Conference

SN  - 0169-7552
DO  - http://dx.doi.org/10.1016/S0169-7552(98)90003-4
UR  - http://www.sciencedirect.com/science/article/pii/S0169755298900034
ER  - 

TY  - JOUR
T1  - An intelligent information retrieval agent
JO  - Knowledge-Based Systems
VL  - 21
IS  - 6
SP  - 466
EP  - 470
PY  - 2008/8//
T2  - 
AU  - Dhanapal, R.
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2008.03.010
UR  - http://www.sciencedirect.com/science/article/pii/S095070510800049X
KW  - Information retrieval
KW  - Phrase indexing
KW  - Retrieval agent
KW  - Next word index
KW  - Query valuation
KW  - Inverted index
AB  - To augment the information retrieval process, a model is proposed to facilitate simple contextual indexing for a large scale of standard text corpora. An edge index graph model is presented, which clusters documents based on a root index and an edge index created. Intelligent information retrieval is possible with the projected system where the process of querying provides proactive help to users through a knowledge base. The query is provided with automatic phrase completion and word suggestions. A thesaurus is used to provide meaningful search of the query. This model can be utilized for document retrieval, clustering, and phrase browsing.
ER  - 

TY  - JOUR
T1  - A multi-attribute, multi-weight clustering approach to managing “e-mail overload”
JO  - Decision Support Systems
VL  - 42
IS  - 3
SP  - 1350
EP  - 1365
PY  - 2006/12//
T2  - 
AU  - Schuff, David
AU  - Turetken, Ozgur
AU  - D'Arcy, John
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2005.11.003
UR  - http://www.sciencedirect.com/science/article/pii/S0167923605001636
KW  - Electronic mail
KW  - Information overload
KW  - Clustering
KW  - Empirical study
AB  - The increasing volume of electronic mail communication threatens to cause a state of “e-mail overload” where the volume of messages exceeds individuals' capacity to process them. To address this problem, this study extends the application of hierarchical clustering to the domain of e-mail. We report on the design and development of a system that applies a multi-weight, multi-attribute clustering approach to a collection of messages. We found strong evidence that clustering messages improves users' ability to locate messages compared to an ordered list, and promising (though weaker) evidence of even greater improvement when given the ability to adjust attribute weights.
ER  - 

TY  - JOUR
T1  - Clustering e-commerce search engines based on their search interface pages using WISE-Cluster
JO  - Data & Knowledge Engineering
VL  - 59
IS  - 2
SP  - 231
EP  - 246
PY  - 2006/11//
T2  - Including: Sixth ACM International Workshop on Web Information and Data ManagementSixth ACM International Workshop on Web Information and Data Management, in conjunction with the 13th International Conference on Information and Knowledge Management (CIKM 2003)
AU  - Lu, Yiyao
AU  - He, Hai
AU  - Peng, Qian
AU  - Meng, Weiyi
AU  - Yu, Clement
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2006.01.010
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X06000280
KW  - E-commerce
KW  - Search engine
KW  - Clustering
KW  - Categorization
KW  - Web-based information systems
AB  - In this paper, we propose a new approach to clustering e-commerce search engines (ESEs) on the Web. Our approach utilizes the features available on the interface page of each ESE, including the label terms and value terms appearing in the search form, the number of images, normalized price terms as well as other terms. The experimental results based on more than 400 ESEs indicate that the proposed approach has good clustering accuracy. The importance of different types of features is analyzed and the terms in the search form are the most important feature in obtaining quality clusters.
ER  - 

TY  - JOUR
T1  - Unsupervised clustering on dynamic databases
JO  - Pattern Recognition Letters
VL  - 26
IS  - 13
SP  - 2116
EP  - 2127
PY  - 2005/10/1/
T2  - 
AU  - Tasoulis, D.K.
AU  - Vrahatis, M.N.
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2005.03.023
UR  - http://www.sciencedirect.com/science/article/pii/S0167865505000899
KW  - Clustering
KW  - Pattern recognition
KW  - Bkd-tree structure
KW  - Dynamic databases
AB  - Clustering algorithms typically assume that the available data constitute a random sample from a stationary distribution. As data accumulate over time the underlying process that generates them can change. Thus, the development of algorithms that can extract clustering rules in non-stationary environments is necessary. In this paper, we present an extension of the k-windows algorithm that can track the evolution of cluster models in dynamically changing databases, without a significant computational overhead. Experiments show that the k-windows algorithm can effectively and efficiently identify the changes on the pattern structure.
ER  - 

TY  - JOUR
T1  - Ensemble clustering with voting active clusters
JO  - Pattern Recognition Letters
VL  - 29
IS  - 14
SP  - 1947
EP  - 1953
PY  - 2008/10/15/
T2  - 
AU  - Tumer, Kagan
AU  - Agogino, Adrian K.
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2008.06.011
UR  - http://www.sciencedirect.com/science/article/pii/S0167865508002134
KW  - Cluster ensembles
KW  - Consensus clustering
KW  - Distributed clustering
KW  - Adaptive clustering
AB  - Clustering is an integral part of pattern recognition problems and is connected to both the data reduction and the data understanding steps. Combining multiple clusterings into an ensemble clustering is critical in many real world applications, particularly for domains with large data sets, high-dimensional feature sets and proprietary data. This paper presents voting active clusters (VACs), a method for combining multiple “base” clusterings into a single unified “ensemble” clustering that is robust against missing data and does not require all the data to be collected in one central location. In this approach, separate processing centers produce many base clusterings based on some portion of the data. The clusterings of such separate processing centers are then pooled to produce a unified ensemble clustering through a voting mechanism. The major contribution of this work is in providing an adaptive voting method by which the clusterings (e.g., spatially distributed processing centers) update their votes in order to maximize an overall quality measure. Our results show that this method achieves comparable or better performance than traditional cluster ensemble methods in noise-free conditions, and remains effective in noisy scenarios where many traditional methods are inapplicable.
ER  - 

TY  - JOUR
T1  - Marginal median SOM for document organization and retrieval
JO  - Neural Networks
VL  - 17
IS  - 3
SP  - 365
EP  - 377
PY  - 2004/4//
T2  - 
AU  - Georgakis, A.
AU  - Kotropoulos, C.
AU  - Xafopoulos, A.
AU  - Pitas, I.
SN  - 0893-6080
DO  - http://dx.doi.org/10.1016/j.neunet.2003.08.008
UR  - http://www.sciencedirect.com/science/article/pii/S0893608003002995
KW  - Self-organizing maps
KW  - Order statistics
KW  - Marginal median
AB  - The self-organizing map algorithm has been used successfully in document organization. We now propose using the same algorithm for document retrieval. Moreover, we test the performance of the self-organizing map by replacing the linear Least Mean Squares adaptation rule with the marginal median. We present two implementations of the latter variant of the self-organizing map by either quantizing the real valued feature vectors to integer valued ones or not. Experiments performed using both implementations demonstrate a superior performance against the self-organizing map based method in terms of the number of training iterations needed so that the mean square error (i.e. the average distortion) drops to the e−1=36.788% of its initial value. Furthermore, the performance of a document organization and retrieval system employing the self-organizing map architecture and its variant is assessed using the average recall–precision curves evaluated on two corpora; the first comprises of manually selected web pages over the Internet having touristic content and the second one is the Reuters-21578, Distribution 1.0.
ER  - 

TY  - JOUR
T1  - Volume Contents and Author Index
JO  - Information Processing & Management
VL  - 42
IS  - 6
SP  - I
EP  - XIV
PY  - 2006/12//
T2  - Special Issue on Informetrics

SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(06)00081-1
UR  - http://www.sciencedirect.com/science/article/pii/S0306457306000811
ER  - 

TY  - JOUR
T1  - Re-ranking algorithm using post-retrieval clustering for content-based image retrieval
JO  - Information Processing & Management
VL  - 41
IS  - 2
SP  - 177
EP  - 194
PY  - 2005/3//
T2  - 
AU  - Park, Gunhan
AU  - Baek, Yunju
AU  - Lee, Heung-Kyu
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2003.08.002
UR  - http://www.sciencedirect.com/science/article/pii/S0306457303000712
KW  - Image retrieval
KW  - Post-retrieval clustering
KW  - Re-ranking algorithm
KW  - Hierarchical clustering
KW  - Similarity relationship
AB  - In this paper, we propose a re-ranking algorithm using post-retrieval clustering for content-based image retrieval (CBIR). In conventional CBIR systems, it is often observed that images visually dissimilar to a query image are ranked high in retrieval results. To remedy this problem, we utilize the similarity relationship of the retrieved results via post-retrieval clustering. In the first step of our method, images are retrieved using visual features such as color histogram. Next, the retrieved images are analyzed using hierarchical agglomerative clustering methods (HACM) and the rank of the results is adjusted according to the distance of a cluster from a query. In addition, we analyze the effects of clustering methods, query-cluster similarity functions, and weighting factors in the proposed method. We conducted a number of experiments using several clustering methods and cluster parameters. Experimental results show that the proposed method achieves an improvement of retrieval effectiveness of over 10% on average in the average normalized modified retrieval rank (ANMRR) measure.
ER  - 

TY  - JOUR
T1  - Generating overview timelines for major events in an RSS corpus
JO  - Journal of Informetrics
VL  - 1
IS  - 2
SP  - 131
EP  - 144
PY  - 2007/4//
T2  - 
AU  - Prabowo, Rudy
AU  - Thelwall, M.
AU  - Alexandrov, Mikhail
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2006.10.002
UR  - http://www.sciencedirect.com/science/article/pii/S175115770600023X
KW  - Feature selection
KW  - Clustering
KW  - Overview timeline
AB  - Really simple syndication (RSS) is becoming a ubiquitous technology for notifying users of new content in frequently updated web sites, such as blogs and news portals. This paper describes a feature-based, local clustering approach for generating overview timelines for major events, such as the tsunami tragedy, from a general-purpose corpus of RSS feeds. In order to identify significant events, we automatically (1) selected a set of significant terms for each day; (2) built a set of (term–co-term) pairs and (3) clustered the pairs in an attempt to group contextually related terms. The clusters were assessed by 10 people, finding that the average percentage apparently representing significant events was 68.6%. Using these clusters, we generated overview timelines for three major events: the tsunami tragedy, the US election and bird flu. The results indicate that our approach is effective in identifying predominantly genuine events, but can only produce partial timelines.
ER  - 

TY  - JOUR
T1  - Automatic classification of Web resources using Java and Dewey Decimal Classification
JO  - Computer Networks and ISDN Systems
VL  - 30
IS  - 1–7
SP  - 646
EP  - 648
PY  - 1998/4//
T2  - Proceedings of the Seventh International World Wide Web Conference
AU  - Jenkins, Charlotte
AU  - Jackson, Mike
AU  - Burden, Peter
AU  - Wallis, Jon
SN  - 0169-7552
DO  - http://dx.doi.org/10.1016/S0169-7552(98)00035-X
UR  - http://www.sciencedirect.com/science/article/pii/S016975529800035X
KW  - Search
KW  - Retrieval
KW  - Classification
AB  - The Wolverhampton Web Library11http://www.scit.wlv.ac.uk/wwlib/
 (WWLib) is a World Wide Web search engine that provides access to UK based information. The experimental version, developed in 1995, was a success but highlighted the need for a much higher degree of automation. An interesting feature of the experimental WWLib was that it organised information according to Dewey Decimal Classification (DDC) [1]. This paper discusses the advantages of classification and describes the automatic classifier that is being developed in Java as part of the new, fully automated WWLib.
ER  - 

TY  - CHAP
AU  - Becks, A.
AU  - Toebermann, J.-C.
T1  - Mining Textual Project Documentation in Process Engineering
A2  - Johan Grievink and Jan van Schijndel
BT  - Computer Aided Chemical Engineering
PB  - Elsevier
PY  - 2002///
VL  - Volume 10
SP  - 835
EP  - 840
T2  - European Symposium on Computer Aided Process Engineering-1235th European Symposium of the Working Party on Computer Aided Process Engineering
SN  - 1570-7946
DO  - http://dx.doi.org/10.1016/S1570-7946(02)80167-5
UR  - http://www.sciencedirect.com/science/article/pii/S1570794602801675
AB  - Abstract
The aim of Knowledge Management is to systematically create, maintain and distribute intellectual capital. To analyse numerical or structured data, techniques like “online analytical processing” and data mining methods are used. However, a lot of existing corporate information like manuals, guidelines, patents and project documentation is captured in textual, i.e. unstructured, form. Specific requirements for mining such textual data were analysed and reviewed and an according tool “DocMINER” was developed and evaluated. Using an example session with project documentation from the process engineering domain its features and usage are described and its potential to lower the necessary effort during typical work steps are demonstrated.
ER  - 

TY  - JOUR
T1  - Literature-related discovery (LRD): Methodology
JO  - Technological Forecasting and Social Change
VL  - 75
IS  - 2
SP  - 186
EP  - 202
PY  - 2008/2//
T2  - Literature-Related Discovery
AU  - Kostoff, Ronald N.
AU  - Briggs, Michael B.
AU  - Solka, Jeffrey L.
AU  - Rushenberg, Robert L.
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2007.11.010
UR  - http://www.sciencedirect.com/science/article/pii/S0040162507001977
KW  - Literature-Based Discovery
KW  - Text Mining
KW  - Information Retrieval
KW  - Clustering
KW  - Semantic Filters
AB  - Literature-related discovery (LRD) is linking two or more literature concepts that have heretofore not been linked (i.e., disjoint), in order to produce novel, interesting, plausible, and intelligible knowledge. LRD has two components: Literature-based discovery (LBD) generates potential discovery through literature analysis alone, whereas literature-assisted discovery (LAD) generates potential discovery through a combination of literature analysis and interactions among selected literature authors. In turn, there are two types of LBD and LAD: open discovery systems (ODS), where one starts with a problem and arrives at a solution, and closed discovery systems (CDS), where one starts with a problem and a solution, then determines the mechanism(s) that links them.

The generic methodology for identifying potential discovery candidates through ODS LRD, focusing mainly on its ODS LBD component, is described in this paper. A comprehensive flow chart showing the details of our systematic potential discovery generation process, including the evolution of the flow chart steps through each of the studies performed, is presented. Also shown is a vetting procedure that insures potential discoveries claimed are potential discoveries realized. The semantic filters that replace the numerical filters of other ODS LBD approaches are overviewed. The rationale for addressing the five topics studied (Raynaud's Phenomenon (RP), Cataracts, Parkinson's Disease (PD), Multiple Sclerosis (MS), and Water Purification (WP)) is summarized.
ER  - 

TY  - JOUR
T1  - Subject index to volume 42
JO  - Decision Support Systems
VL  - 42
IS  - 4
SP  - IX
EP  - XV
PY  - 2007/1//
T2  - Decision Support Systems in Emerging Economies

SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/S0167-9236(06)00184-9
UR  - http://www.sciencedirect.com/science/article/pii/S0167923606001849
ER  - 

TY  - JOUR
T1  - Advances in information retrieval: An introduction to the special issue
JO  - Information Systems
VL  - 31
IS  - 7
SP  - 569
EP  - 572
PY  - 2006/11//
T2  - (1) SPIRE 2004(2) Multimedia Databases
AU  - Apostolico, Alberto
AU  - Baeza-Yates, Ricardo
AU  - Melucci, Massimo
SN  - 0306-4379
DO  - http://dx.doi.org/10.1016/j.is.2005.11.005
UR  - http://www.sciencedirect.com/science/article/pii/S0306437905000918
ER  - 

TY  - JOUR
T1  - Editorial Board
JO  - Information Processing & Management
VL  - 43
IS  - 3
SP  - CO2
EP  - 
PY  - 2007/5//
T2  - Special Issue on Heterogeneous and Distributed IR

SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(07)00004-0
UR  - http://www.sciencedirect.com/science/article/pii/S0306457307000040
ER  - 

TY  - JOUR
T1  - Evaluating exploratory search systems: Introduction to special topic issue of information processing and management
JO  - Information Processing & Management
VL  - 44
IS  - 2
SP  - 433
EP  - 436
PY  - 2008/3//
T2  - Evaluating Exploratory Search SystemsDigital Libraries in the Context of Users’ Broader Activities
AU  - White, Ryen W.
AU  - Marchionini, Gary
AU  - Muresan, Gheorghe
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2007.09.011
UR  - http://www.sciencedirect.com/science/article/pii/S0306457307001811
ER  - 

TY  - JOUR
T1  - Handling vagueness, subjectivity, and imprecision in information access: an introduction to the special issue
JO  - Information Processing & Management
VL  - 39
IS  - 2
SP  - 161
EP  - 165
PY  - 2003/3//
T2  - 
AU  - Crestani, Fabio
AU  - Pasi, Gabriella
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(02)00086-9
UR  - http://www.sciencedirect.com/science/article/pii/S0306457302000869
ER  - 

TY  - JOUR
T1  - Text mining applied to patent mapping: a practical business case
JO  - World Patent Information
VL  - 25
IS  - 4
SP  - 335
EP  - 342
PY  - 2003/12//
T2  - 
AU  - Fattori, Michele
AU  - Pedrazzi, Giorgio
AU  - Turra, Roberta
SN  - 0172-2190
DO  - http://dx.doi.org/10.1016/S0172-2190(03)00113-3
UR  - http://www.sciencedirect.com/science/article/pii/S0172219003001133
KW  - Text mining
KW  - Data mining
KW  - Patent mapping
KW  - Patent analysis
KW  - Clustering techniques
KW  - Competitive intelligence
KW  - Intellectually assigned patent classifications
KW  - Results validation
KW  - Linguistic technology
KW  - Packaging technology
AB  - Professional patent searchers are traditionally rather suspicious of the alleged “black box” effect inherently attached to intelligent software engines relying upon linguistic technologies for patent analysis and mapping. In this article, the authors propose that such prejudices can be overcome by setting a realistic business objective while experimenting with these new linguistic tools, as well as by applying serious methodology for validating the results of the analysis. The strengths and weaknesses of a particular text mining tool are assessed with reference to a practical business case in the field of packaging technology, and a comparison of the outcome of such an analysis with a traditional one, carried out using conventional patent classifications, is also described.
ER  - 

TY  - JOUR
T1  - Author index to volume 45
JO  - Decision Support Systems
VL  - 45
IS  - 4
SP  - I
EP  - V
PY  - 2008/11//
T2  - Information Technology and Systems in the Internet-Era

SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/S0167-9236(08)00173-5
UR  - http://www.sciencedirect.com/science/article/pii/S0167923608001735
ER  - 

TY  - JOUR
T1  - A partitioning based algorithm to fuzzy co-cluster documents and words
JO  - Pattern Recognition Letters
VL  - 27
IS  - 3
SP  - 151
EP  - 159
PY  - 2006/2//
T2  - 
AU  - Tjhi, William-Chandra
AU  - Chen, Lihui
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2005.07.012
UR  - http://www.sciencedirect.com/science/article/pii/S0167865505002011
KW  - Fuzzy clustering
KW  - Information retrieval
KW  - Co-clustering
AB  - In this paper, a new algorithm fuzzy co-clustering with Ruspini’s condition (FCR) is proposed for co-clustering documents and words. Compared to most existing fuzzy co-clustering algorithms, FCR is able to generate fuzzy word clusters that capture the natural distribution of words, which may be beneficial for information retrieval. We discuss the principle behind the algorithm through some theoretical discussions and illustrations. These, together with experiments on two standard datasets show that FCR can discover the naturally existing document-word co-clusters.
ER  - 

TY  - JOUR
T1  - The nature of indexing: how humans and machines analyze messages and texts for retrieval. Part II: Machine indexing, and the allocation of human versus machine effort
JO  - Information Processing & Management
VL  - 37
IS  - 2
SP  - 255
EP  - 277
PY  - 2001/3//
T2  - 
AU  - Anderson, James D
AU  - Pérez-Carballo, José
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(00)00046-7
UR  - http://www.sciencedirect.com/science/article/pii/S0306457300000467
KW  - Automatic indexing
KW  - Human indexing
KW  - Indexing and abstracting services
KW  - Allocation of indexing effort
AB  - Does human intellectual indexing have a continuing role to play in the face of increasingly sophisticated automatic indexing techniques? In this two-part essay, a computer scientist and long-time TREC participant (Pérez-Carballo) and a practitioner and teacher of human cataloging and indexing (Anderson) pursue this question by reviewing the opinions and research of leading experts on both sides of this divide. We conclude that human analysis should be used on a much more selective basis, and we offer suggestions on how these two types indexing might be allocated to best advantage. Part I of the essay critiques the comparative research, then explores the nature of human analysis of messages or texts and efforts to formulate rules to make human practice more rigorous and predictable. We find that research comparing human versus automatic approaches has done little to change strongly held beliefs, in large part because many associated variables have not been isolated or controlled.

Part II focuses on current methods in automatic indexing, its gradual adoption by major indexing and abstracting services, and ways for allocating human and machine approaches. Overall, we conclude that both approaches to indexing have been found to be effective by researchers and searchers, each with particular advantages and disadvantages. However, automatic indexing has the over-arching advantage of decreasing cost, as human indexing becomes ever more expensive.
ER  - 

TY  - JOUR
T1  - A new algorithm for clustering search results
JO  - Data & Knowledge Engineering
VL  - 62
IS  - 3
SP  - 504
EP  - 522
PY  - 2007/9//
T2  - Including special issue: 20th Brazilian Symposium on Databases (SBBD 2005)
AU  - Mecca, Giansalvatore
AU  - Raunich, Salvatore
AU  - Pappalardo, Alessandro
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2006.10.006
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X06001947
KW  - Web
KW  - Search engines
KW  - Clustering
KW  - Latent semantic indexing
KW  - Document classification
AB  - We develop a new algorithm for clustering search results. Differently from many other clustering systems that have been recently proposed as a post-processing step for Web search engines, our system is not based on phrase analysis inside snippets, but instead uses latent semantic indexing on the whole document content. A main contribution of the paper is a novel strategy – called dynamic SVD clustering – to discover the optimal number of singular values to be used for clustering purposes. Moreover, the algorithm is such that the SVD computation step has in practice good performance, which makes it feasible to perform clustering when term vectors are available. We show that the algorithm has very good classification performance, and that it can be effectively used to cluster results of a search engine to make them easier to browse by users. The algorithm has being integrated into the Noodles search engine, a tool for searching and clustering Web and desktop documents.
ER  - 

TY  - JOUR
T1  - A new sentence similarity measure and sentence based extractive technique for automatic text summarization
JO  - Expert Systems with Applications
VL  - 36
IS  - 4
SP  - 7764
EP  - 7772
PY  - 2009/5//
T2  - 
AU  - Aliguliyev, Ramiz M.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2008.11.022
UR  - http://www.sciencedirect.com/science/article/pii/S0957417408008737
KW  - Similarity measure
KW  - Text mining
KW  - Sentence clustering
KW  - Summarization
KW  - Evolution algorithm
KW  - Sentence extractive technique
AB  - Abstract
The technology of automatic document summarization is maturing and may provide a solution to the information overload problem. Nowadays, document summarization plays an important role in information retrieval. With a large volume of documents, presenting the user with a summary of each document greatly facilitates the task of finding the desired documents. Document summarization is a process of automatically creating a compressed version of a given document that provides useful information to users, and multi-document summarization is to produce a summary delivering the majority of information content from a set of documents about an explicit or implicit main topic. In our study we focus on sentence based extractive document summarization. We propose the generic document summarization method which is based on sentence clustering. The proposed approach is a continue sentence-clustering based extractive summarization methods, proposed in Alguliev [Alguliev, R. M., Aliguliyev, R. M., Bagirov, A. M. (2005). Global optimization in the summarization of text documents. Automatic Control and Computer Sciences 39, 42–47], Aliguliyev [Aliguliyev, R. M. (2006). A novel partitioning-based clustering method and generic document summarization. In Proceedings of the 2006 IEEE/WIC/ACM international conference on web intelligence and intelligent agent technology (WI–IAT 2006 Workshops) (WI–IATW’06), 18–22 December (pp. 626–629) Hong Kong, China], Alguliev and Alyguliev [Alguliev, R. M., Alyguliev, R. M. (2007). Summarization of text-based documents with a determination of latent topical sections and information-rich sentences. Automatic Control and Computer Sciences 41, 132–140] Aliguliyev, [Aliguliyev, R. M. (2007). Automatic document summarization by sentence extraction. Journal of Computational Technologies 12, 5–15.]. The purpose of present paper to show, that summarization result not only depends on optimized function, and also depends on a similarity measure. The experimental results on an open benchmark datasets from DUC01 and DUC02 show that our proposed approach can improve the performance compared to sate-of-the-art summarization approaches.
ER  - 

TY  - JOUR
T1  - A document classification and retrieval system for R&amp;D in semiconductor industry – A hybrid approach
JO  - Expert Systems with Applications
VL  - 36
IS  - 3, Part 1
SP  - 4753
EP  - 4764
PY  - 2009/4//
T2  - 
AU  - Lin, Shui-Shun
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2008.06.024
UR  - http://www.sciencedirect.com/science/article/pii/S0957417408002972
KW  - Document classification and retrieval
KW  - Vector space model
KW  - Document management system
AB  - In this paper, a hybrid methodology with a vector space model (VSM) and process-oriented attributes for document management is proposed. The VSM is fine-tuned for classifying documents generated during R&amp;D processes. The document correlation values are computed with the VSM for efficient retrieval. Only documents with high correlation values are presented to meet the specific retrieval purpose, which results in efficient and effective document retrieval. We further design a document classification and retrieval prototype system. The prototype is implemented to facilitate R&amp;D document management in semiconductor industries.
ER  - 

TY  - JOUR
T1  - Hybrid clustering for validation and improvement of subject-classification schemes
JO  - Information Processing & Management
VL  - 45
IS  - 6
SP  - 683
EP  - 702
PY  - 2009/11//
T2  - 
AU  - Janssens, Frizo
AU  - Zhang, Lin
AU  - Moor, Bart De
AU  - Glänzel, Wolfgang
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2009.06.003
UR  - http://www.sciencedirect.com/science/article/pii/S0306457309000673
KW  - Subject classification
KW  - Journal cross-citation
KW  - Mapping of science
KW  - Hybrid clustering
AB  - A hybrid text/citation-based method is used to cluster journals covered by the Web of Science database in the period 2002–2006. The objective is to use this clustering to validate and, if possible, to improve existing journal-based subject-classification schemes. Cross-citation links are determined on an item-by-paper procedure for individual papers assigned to the corresponding journal. Text mining for the textual component is based on the same principle; textual characteristics of individual papers are attributed to the journals in which they have been published. In a first step, the 22-field subject-classification scheme of the Essential Science Indicators (ESI) is evaluated and visualised. In a second step, the hybrid clustering method is applied to classify the about 8300 journals meeting the selection criteria concerning continuity, size and impact. The hybrid method proves superior to its two components when applied separately. The choice of 22 clusters also allows a direct field-to-cluster comparison, and we substantiate that the science areas resulting from cluster analysis form a more coherent structure than the “intellectual” reference scheme, the ESI subject scheme. Moreover, the textual component of the hybrid method allows labelling the clusters using cognitive characteristics, while the citation component allows visualising the cross-citation graph and determining representative journals suggested by the PageRank algorithm. Finally, the analysis of journal ‘migration’ allows the improvement of existing classification schemes on the basis of the concordance between fields and clusters.
ER  - 

TY  - JOUR
T1  - Implementation of a modified Fuzzy C-Means clustering algorithm for real-time applications
JO  - Microprocessors and Microsystems
VL  - 29
IS  - 8–9
SP  - 375
EP  - 380
PY  - 2005/11/1/
T2  - Special Issue on FPGAs: Case Studies in Computer Vision and Image Processing
AU  - Lázaro, Jesús
AU  - Arias, Jagoba
AU  - Martín, José L.
AU  - Cuadrado, Carlos
AU  - Astarloa, Armando
SN  - 0141-9331
DO  - http://dx.doi.org/10.1016/j.micpro.2004.09.002
UR  - http://www.sciencedirect.com/science/article/pii/S0141933104001437
KW  - FPGA
KW  - Segmentation
KW  - Fuzzy C-Means
KW  - Image processing
AB  - Every month new applications of fuzzy logic to image processing appear. The lightly tight nature of fuzzy algorithms simulates human vision and thus, the field of applications widens. This paper implements in hardware a very popular fuzzy algorithm, the Fuzzy C-Means algorithm. The version of the algorithm allows a high degree of parallelism, which makes the hardware implementation suited for real-time video applications.
ER  - 

TY  - JOUR
T1  - Recent advances in computer vision and image processing using reconfigurable hardware
JO  - Microprocessors and Microsystems
VL  - 29
IS  - 8–9
SP  - 359
EP  - 362
PY  - 2005/11/1/
T2  - Special Issue on FPGAs: Case Studies in Computer Vision and Image Processing
AU  - Vega-Rodríguez, Miguel A.
AU  - Sánchez-Pérez, Juan M.
AU  - Gómez-Pulido, Juan A.
SN  - 0141-9331
DO  - http://dx.doi.org/10.1016/j.micpro.2005.06.001
UR  - http://www.sciencedirect.com/science/article/pii/S014193310500058X
ER  - 

TY  - JOUR
T1  - Deciphering cluster representations
JO  - Information Processing & Management
VL  - 37
IS  - 4
SP  - 593
EP  - 601
PY  - 2001/7//
T2  - 
AU  - Kural, Yasemin
AU  - Robertson, Steve
AU  - Jones, Susan
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(00)00037-6
UR  - http://www.sciencedirect.com/science/article/pii/S0306457300000376
KW  - Clustering
KW  - Information retrieval
KW  - Information seeking
KW  - Browsing
AB  - There are several recent studies that propose search output clustering as an alternative representation method to ranked output. Users are provided with cluster representations instead of lists of titles and invited to make decisions on groups of documents. This paper discusses the difficulties involved in representing clusters for users’ evaluation in a concise but easily interpretable form. The discussion is based on findings and user feedback from a user study investigating the effectiveness of search output clustering. The overall impression created by the experiment results and users’ feedback is that clusters cannot be relied on to consistently produce meaningful document groups that can easily be recognised by the users. They also seem to lead to unrealistic user expectations.
ER  - 

TY  - JOUR
T1  - Using text classification and multiple concepts to answer e-mails
JO  - Expert Systems with Applications
VL  - 26
IS  - 4
SP  - 529
EP  - 543
PY  - 2004/5//
T2  - 
AU  - Weng, Sung-Shun
AU  - Liu, Chih-Kai
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2003.10.011
UR  - http://www.sciencedirect.com/science/article/pii/S095741740300191X
KW  - Information retrieval
KW  - Text mining
KW  - Text classification
KW  - Multiple concepts
KW  - E-mail answering
AB  - In text mining, the applications domain of text classification techniques is very broad to include text filtering, word identification, and web page classification, etc. Through text classification techniques, documents can be placed into previously defined classifications in order to save on time costs especially when manual document search methods are employed. This research uses text classification techniques applied to e-mail reply template suggestions in order to lower the burden of customer service personnel in responding to e-mails. Suggested templates allows customer service personnel, using a pre-determined number of templates, to find the needed reply template, and not waste time in searching for relevant answers from too much information available. Current text classification techniques are still single-concept based. This research hopes to use a multiple concept method to integrate the relationship between concepts and classifications which will thus allow easy text classification. Through integration of different concepts and classifications, a dynamically unified e-mail concept can recommend different appropriate reply templates. In so doing, the differences between e-mails can be definitely determined, effectively improving the accuracy of the suggested template. In addition, for e-mails with two or more questions, this research tries to come up with an appropriate reply template. Based on experimental verification, the method proposed in this research effectively proposes a template for e-mails of multiple questions. Therefore, using multiple concepts to display the document topic is definitely a clearer way of extracting information that a document wants to convey when the vector of similar documents is used.
ER  - 

TY  - JOUR
T1  - CLAGen: A tool for clustering and annotating gene sequences using a suffix tree algorithm
JO  - Biosystems
VL  - 84
IS  - 3
SP  - 175
EP  - 182
PY  - 2006/6//
T2  - 
AU  - Han, Sang il
AU  - Lee, Sung Gun
AU  - Kim, Kyung-Hoon
AU  - Choi, Chung Jung
AU  - Kim, Young Han
AU  - Hwang, Kyu Suk
SN  - 0303-2647
DO  - http://dx.doi.org/10.1016/j.biosystems.2005.11.001
UR  - http://www.sciencedirect.com/science/article/pii/S0303264705001899
KW  - Multiple sequence alignment
KW  - CLAGen
KW  - Clustering
KW  - Gene sequence
KW  - BLAST
KW  - TCA cycle
AB  - Most multiple gene sequence alignment methods rely on conventions regarding the score of a multiple alignment in pairwise fashion. Therefore, as the number of sequences increases, the runtime of sequencing expands exponentially. In order to solve the problem, this paper presents a multiple sequence alignment method using a linear-time suffix tree algorithm to cluster similar sequences at one time without pairwise alignment. After searching for common subsequences, cross-matching common subsequences were generated, and sometimes inexact matching was found. So, a procedure aimed at masking the inexact cross-matching pairs was suggested here. In addition, BLAST was combined with a clustering tool in order to annotate the clusters generated by suffix tree clustering. The proposed method for clustering and annotating genes consists of the following steps: (1) construction of a suffix tree; (2) searching and overlapping common subsequences; (3) grouping subsequence pairs; (4) masking cross-matching pairs; (5) clustering gene sequences; (6) annotating gene clusters by the BLAST search. The performance of the proposed system, CLAGen, was successfully evaluated with 42 gene sequences in a TCA cycle (a citrate cycle) of bacteria. The system generated 11 clusters and found the longest subsequences of each cluster, which are biologically significant.
ER  - 

TY  - JOUR
T1  - SpidersRUs: Creating specialized search engines in multiple languages
JO  - Decision Support Systems
VL  - 45
IS  - 3
SP  - 621
EP  - 640
PY  - 2008/6//
T2  - Special Issue Clusters
AU  - Chau, Michael
AU  - Qin, Jialun
AU  - Zhou, Yilu
AU  - Tseng, Chunju
AU  - Chen, Hsinchun
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2007.07.006
UR  - http://www.sciencedirect.com/science/article/pii/S0167923607001340
KW  - Search engine development
KW  - Multilingual search engines
KW  - Information retrieval
AB  - While small-scale search engines in specific domains and languages are increasingly used by Web users, most existing search engine development tools do not support the development of search engines in languages other than English, cannot be integrated with other applications, or rely on proprietary software. A tool that supports search engine creation in multiple languages is thus highly desired. To study the research issues involved, we review related literature and suggest the criteria for an ideal search tool. We present the design of a toolkit, called SpidersRUs, developed for multilingual search engine creation. The design and implementation of the tool, consisting of a Spider module, an Indexer module, an Index Structure, a Search module, and a Graphical User Interface module, are discussed in detail. A sample user session and a case study on using the tool to develop a medical search engine in Chinese are also presented. The technical issues involved and the lessons learned in the project are then discussed. This study demonstrates that the proposed architecture is feasible in developing search engines easily in different languages such as Chinese, Spanish, Japanese, and Arabic.
ER  - 

TY  - JOUR
T1  - SVM-based feature selection of latent semantic features
JO  - Pattern Recognition Letters
VL  - 25
IS  - 9
SP  - 1051
EP  - 1057
PY  - 2004/7/2/
T2  - 
AU  - Shima, K.
AU  - Todoriki, M.
AU  - Suzuki, A.
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2004.03.002
UR  - http://www.sciencedirect.com/science/article/pii/S0167865504000686
KW  - Support Vector Machines
KW  - Text categorization
KW  - Latent Semantic Indexing
KW  - Feature selection
AB  - Latent Semantic Indexing (LSI) is an effective method to extract features that captures underlying latent semantic structure in the word usage across documents. However, subspace selected by this method may not be the most appropriate one to classify documents, since it orders extracted features according to their variances, not the classification power. We propose to apply feature ordering method based on support vector machines in order to select LSI-features that is suited for classification. Experimental results suggest that the method improves classification performance with considerably more compact representation.
ER  - 

TY  - JOUR
T1  - A fuzzy clustering approach for finding similar documents using a novel similarity measure
JO  - Expert Systems with Applications
VL  - 33
IS  - 3
SP  - 600
EP  - 605
PY  - 2007/10//
T2  - 
AU  - Saraçoğlu, Rıdvan
AU  - Tütüncü, Kemal
AU  - Allahverdi, Novruz
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2006.06.002
UR  - http://www.sciencedirect.com/science/article/pii/S0957417406001850
KW  - Text mining
KW  - Document similarity
KW  - Fuzzy clustering
KW  - Fuzzy similarity measure
KW  - Distance based similarity
AB  - Searching for similar documents has a crucial role in document management. This paper aims for developing a fast and high quality method of searching similar documents based on fuzzy clustering in large document collections. In order to perform these requirements, a two layers structure is proposed. Formerly, finding the similarity in documents is based on the strategy that uses word-by-word comparison. The proposed method in this study uses two layers structure and lets the documents pass through it to find the similarities. In this system, predefined fuzzy clusters are used to extract feature vectors of related documents for finding similar documents of them. Similarity measure is estimated based on these vectors. To do this, a distance based similarity measure is proposed. It has been seen in empirical results that the proposed system uses new similarity measure and has better performance compared with conventional similarity measurement systems.
ER  - 

TY  - JOUR
T1  - Visual text mining using association rules
JO  - Computers & Graphics
VL  - 31
IS  - 3
SP  - 316
EP  - 326
PY  - 2007/6//
T2  - 
AU  - Lopes, A.A.
AU  - Pinho, R.
AU  - Paulovich, F.V.
AU  - Minghim, R.
SN  - 0097-8493
DO  - http://dx.doi.org/10.1016/j.cag.2007.01.023
UR  - http://www.sciencedirect.com/science/article/pii/S0097849307000544
KW  - Visual text mining
KW  - Association rules
KW  - Data mining
KW  - Information visualization
AB  - In many situations, individuals or groups of individuals are faced with the need to examine sets of documents to achieve understanding of their structure and to locate relevant information. In that context, this paper presents a framework for visual text mining to support exploration of both general structure and relevant topics within a textual document collection. Our approach starts by building a visualization from the text data set. On top of that, a novel technique is presented that generates and filters association rules to detect and display topics from a group of documents. Results have shown a very consistent match between topics extracted using this approach to those actually present in the data set.
ER  - 

TY  - JOUR
T1  - Knowledge management perspective on e-learning effectiveness
JO  - Knowledge-Based Systems
VL  - 22
IS  - 4
SP  - 324
EP  - 325
PY  - 2009/5//
T2  - Artificial Intelligence (AI) in Blended Learning(AI) in Blended Learning
AU  - Lau, Adela
AU  - Tsui, Eric
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2009.02.014
UR  - http://www.sciencedirect.com/science/article/pii/S0950705109000513
KW  - Learning grid
KW  - Knowledge management
KW  - e-learning effectiveness
AB  - The synergies, functional effectiveness and integration of KM within an e-learning environment have attracted little interest for serious research, despite the overarching importance of knowledge acquisition by students for fostering their innovation and creativity. Learners often fail to reach their desired learning objects due to the failure of indexing methods to provide them with a ubiquitous learning grid. The aim of this paper is to discuss how knowledge management can be used effectively in e-learning, and how it can provide a learning grid to enable the learner to identify the right learning objects in an environment which is based on the learner’s context and personal preferences.
ER  - 

TY  - JOUR
T1  - Developing knowledge management awareness in public relations students
JO  - Public Relations Review
VL  - 30
IS  - 1
SP  - 107
EP  - 115
PY  - 2004/3//
T2  - 
AU  - Hiscock, Jane
SN  - 0363-8111
DO  - http://dx.doi.org/10.1016/j.pubrev.2003.11.010
UR  - http://www.sciencedirect.com/science/article/pii/S0363811103001036
KW  - Communication
KW  - Organization
KW  - Management
KW  - Knowledge management
AB  - Students completing the postgraduate qualification, Graduate Diploma in Communication (Public Relations) at the University of South Australia, undertake a field research project, the Graduate Communication Management project, as the final course in their program. Students design their own research (mainly interpretive and qualitative in nature) to investigate communication and organizational culture within their chosen organization. This paper suggests that knowledge management concepts provide another useful framework in which the students can research organizational culture and communication.
ER  - 

TY  - JOUR
T1  - Improving the performance of focused web crawlers
JO  - Data & Knowledge Engineering
VL  - 68
IS  - 10
SP  - 1001
EP  - 1013
PY  - 2009/10//
T2  - 
AU  - Batsakis, Sotiris
AU  - Petrakis, Euripides G.M.
AU  - Milios, Evangelos
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2009.04.002
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X0900055X
KW  - Focused crawler
KW  - Learning crawler
KW  - Hidden Markov Model (HMM) crawler
KW  - World Wide Web
AB  - This work addresses issues related to the design and implementation of focused crawlers. Several variants of state-of-the-art crawlers relying on web page content and link information for estimating the relevance of web pages to a given topic are proposed. Particular emphasis is given to crawlers capable of learning not only the content of relevant pages (as classic crawlers do) but also paths leading to relevant pages. A novel learning crawler inspired by a previously proposed Hidden Markov Model (HMM) crawler is described as well. The crawlers have been implemented using the same baseline implementation (only the priority assignment function differs in each crawler) providing an unbiased evaluation framework for a comparative analysis of their performance. All crawlers achieve their maximum performance when a combination of web page content and (link) anchor text is used for assigning download priorities to web pages. Furthermore, the new HMM crawler improved the performance of the original HMM crawler and also outperforms classic focused crawlers in searching for specialized topics.
ER  - 

TY  - JOUR
T1  - A method for computing lexical semantic distance using linear functionals
JO  - Web Semantics: Science, Services and Agents on the World Wide Web
VL  - 6
IS  - 2
SP  - 99
EP  - 108
PY  - 2008/4//
T2  - Semantic Multimedia
AU  - Jensen, Del
AU  - Giraud-Carrier, Christophe
AU  - Davis, Nathan
SN  - 1570-8268
DO  - http://dx.doi.org/10.1016/j.websem.2007.11.001
UR  - http://www.sciencedirect.com/science/article/pii/S1570826807000492
KW  - Semantic distance
KW  - Knowledge-based semantics
KW  - Topological embedding
AB  - This paper presents a novel, knowledge-based method for measuring semantic similarity in support of applications aimed at organizing and retrieving relevant textual information. We show how a quantitative context may be established for what is essentially qualitative in nature by effecting a topological transformation of the lexicon into a metric space where distance is well-defined. We illustrate the technique with a simple example and report on promising experimental results with a significant word similarity problem.
ER  - 

TY  - JOUR
T1  - Exploring ant-based algorithms for gene expression data analysis
JO  - Artificial Intelligence in Medicine
VL  - 47
IS  - 2
SP  - 105
EP  - 119
PY  - 2009/10//
T2  - 
AU  - He, Yulan
AU  - Hui, Siu Cheung
SN  - 0933-3657
DO  - http://dx.doi.org/10.1016/j.artmed.2009.03.004
UR  - http://www.sciencedirect.com/science/article/pii/S0933365709000542
KW  - Gene expression data analysis
KW  - Ant colony optimization
KW  - Clustering
KW  - Associative classification
KW  - Swarm intelligence
AB  - SummaryObjective
Recently, much research has been proposed using nature inspired algorithms to perform complex machine learning tasks. Ant colony optimization (ACO) is one such algorithm based on swarm intelligence and is derived from a model inspired by the collective foraging behavior of ants. Taking advantage of the ACO in traits such as self-organization and robustness, this paper investigates ant-based algorithms for gene expression data clustering and associative classification.
Methods and material
An ant-based clustering (Ant-C) and an ant-based association rule mining (Ant-ARM) algorithms are proposed for gene expression data analysis. The proposed algorithms make use of the natural behavior of ants such as cooperation and adaptation to allow for a flexible robust search for a good candidate solution.
Results
Ant-C has been tested on the three datasets selected from the Stanford Genomic Resource Database and achieved relatively high accuracy compared to other classical clustering methods. Ant-ARM has been tested on the acute lymphoblastic leukemia (ALL)/acute myeloid leukemia (AML) dataset and generated about 30 classification rules with high accuracy.
Conclusions
Ant-C can generate optimal number of clusters without incorporating any other algorithms such as K-means or agglomerative hierarchical clustering. For associative classification, while a few of the well-known algorithms such as Apriori, FP-growth and Magnum Opus are unable to mine any association rules from the ALL/AML dataset within a reasonable period of time, Ant-ARM is able to extract associative classification rules.
ER  - 

TY  - JOUR
T1  - Enhanced bisecting -means clustering using intermediate cooperation
JO  - Pattern Recognition
VL  - 42
IS  - 11
SP  - 2557
EP  - 2569
PY  - 2009/11//
T2  - 
AU  - Kashef, R.
AU  - Kamel, M.S.
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2009.03.011
UR  - http://www.sciencedirect.com/science/article/pii/S003132030900096X
KW  - Bisecting clustering
KW  - Cooperative clustering
KW  - Quality measures
AB  - Bisecting k-means (BKM) is very attractive in many applications as document-retrieval/indexing and gene expression analysis problems. However, in some scenarios when a fraction of the dataset is left behind with no other way to re-cluster it again at each level of the binary tree, a “refinement” is needed to re-cluster the resulting solutions. Current approaches to refine the clustering solutions produced by the BKM employ end-result enhancement using k-means (KM) clustering. In this hybrid model, KM waits for the former BKM to finish its clustering and then it takes the final set of centroids as initial seeds for a better refinement. In this paper, a cooperative bisecting k-means (CBKM) clustering algorithm is presented. The CBKM concurrently combines the results of the BKM and KM at each level of the binary hierarchical tree using cooperative and merging matrices. Undertaken experimental results show that the CBKM achieves better clustering quality than that of KM, BKM, and single linkage (SL) algorithms with comparable time performance over a number of artificial, text documents, and gene expression datasets.
ER  - 

TY  - JOUR
T1  - Development, implementation, and a cognitive evaluation of a definitional question answering system for physicians
JO  - Journal of Biomedical Informatics
VL  - 40
IS  - 3
SP  - 236
EP  - 251
PY  - 2007/6//
T2  - 
AU  - Yu, Hong
AU  - Lee, Minsuk
AU  - Kaufman, David
AU  - Ely, John
AU  - Osheroff, Jerome A.
AU  - Hripcsak, George
AU  - Cimino, James
SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2007.03.002
UR  - http://www.sciencedirect.com/science/article/pii/S1532046407000202
KW  - Question answering
KW  - Information retrieval
KW  - Question analysis
KW  - Text summarization
KW  - Machine-learning
KW  - Evaluation
AB  - The published medical literature and online medical resources are important sources to help physicians make patient treatment decisions. Traditional sources used for information retrieval (e.g., PubMed) often return a list of documents in response to a user’s query. Frequently the number of returned documents from large knowledge repositories is large and makes information seeking practical only “after hours” and not in the clinical setting. This study developed novel algorithms, and designed, implemented, and evaluated a medical definitional question answering system (MedQA). MedQA automatically analyzed a large number of electronic documents to generate short and coherent answers in response to definitional questions (i.e., questions with the format of “What is X?”). Our preliminary cognitive evaluation shows that MedQA out-performed three other online information systems (Google, OneLook, and PubMed) in two important efficiency criteria; namely, time spent and number of actions taken for a physician to identify a definition. It is our contention that question answering systems that aggregate pertinent information scattered across different documents have the potential to address clinical information needs within a timeframe necessary to meet the demands of clinicians.
ER  - 

TY  - JOUR
T1  - An information filtering model on the Web and its application in JobAgent
JO  - Knowledge-Based Systems
VL  - 13
IS  - 5
SP  - 285
EP  - 296
PY  - 2000/10//
T2  - 
AU  - Li, Y.
AU  - Zhang, C.
AU  - Swan, J.R.
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/S0950-7051(00)00088-5
UR  - http://www.sciencedirect.com/science/article/pii/S0950705100000885
KW  - Information filtering
KW  - Rough set
KW  - Intelligent information agent
AB  - Machine-learning techniques play the important roles for information filtering. The main objective of machine-learning is to obtain users' profiles. To decrease the burden of on-line learning, it is important to seek suitable structures to represent user information needs. This paper proposes a model for information filtering on the Web. The user information need is described into two levels in this model: profiles on category level, and Boolean queries on document level. To efficiently estimate the relevance between the user information need and documents, the user information need is treated as a rough set on the space of documents. The rough set decision theory is used to classify the new documents according to the user information need. In return for this, the new documents are divided into three parts: positive region, boundary region, and negative region. An experimental system JobAgent is also presented to verify this model, and it shows that the rough set based model can provide an efficient approach to solve the information overload problem.
ER  - 

TY  - JOUR
T1  - Arthritis care: Comparison of physicians' and patients' views
JO  - Seminars in Arthritis and Rheumatism
VL  - 30
IS  - 2
SP  - 100
EP  - 110
PY  - 2000/10//
T2  - 
AU  - Lambert, Bruce L.
AU  - Butin, Danielle N.
AU  - Moran, Diane
AU  - Zhao, Sean Z.
AU  - Carr, Barbara C.
AU  - Chen, Connie
AU  - Kizis, F.J.
SN  - 0049-0172
DO  - http://dx.doi.org/10.1053/sarh.2000.9203
UR  - http://www.sciencedirect.com/science/article/pii/S0049017200100964
KW  - Arthritis
KW  - focus group
KW  - doctors
KW  - patients
KW  - patient education
KW  - self-care preferences
KW  - beliefs
AB  - Objectives: To understand the expressed needs of physicians and their patients with respect to arthritis care, identify areas of agreement and disagreement in doctor and patient views of arthritis care, and to determine the types of educational programs needed. Methods: Focus group interviews were conducted with 14 physicians of varied specialties and 12 patients with arthritis from Oxford Health Plans. Interviews were audiotaped and transcribed. Analyses were performed by using text processing programs from the Unix computer operating system. Common themes were identified and summarized. Results: Physicians and patients agreed that pain and loss of functioning were the most important problems patients with arthritis faced and that arthritis was incurable. Both agreed that doctors need more time to discuss individual concerns with their patients. More information about diet and exercise and strategies for reducing social isolation were needed. Doctors and patients disagreed about the value of nutritional supplements, joint replacement, and referrals to specialists. Disagreement also existed regarding the belief that pain was an inevitable part of the aging process, and with respect to the use of drug and surgical therapy. Conclusions: Areas of agreement and disagreement were discussed. Collaboration and negotiation were identified as constructive responses to conflicts between physicians and patients. Patients need to be taught self-care strategies to minimize the impact of arthritis on their daily lives. The specific continuing education needs of physicians involved training in exercise, nutrition, occupational and physical therapy, prescriptions, and alternative medicine. Semin Arthritis Rheum 30:100-110. Copyright © 2000 by W.B. Saunders Company
ER  - 

TY  - JOUR
T1  - Literature-related discovery (LRD): Water purification
JO  - Technological Forecasting and Social Change
VL  - 75
IS  - 2
SP  - 256
EP  - 275
PY  - 2008/2//
T2  - Literature-Related Discovery
AU  - Kostoff, Ronald N.
AU  - Solka, Jeffrey L.
AU  - Rushenberg, Robert L.
AU  - Wyatt, Jeffrey A.
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2007.11.009
UR  - http://www.sciencedirect.com/science/article/pii/S0040162507001941
KW  - Literature-related discovery
KW  - Literature-based discovery
KW  - Literature-assisted discovery
KW  - Text mining
KW  - Cluster filtering
KW  - Latent semantic indexing
KW  - Water purification
KW  - Drinking water
AB  - Literature-related discovery (LRD) is the linking of two or more literature concepts that have heretofore not been linked (i.e., disjoint), in order to produce novel, interesting, plausible, and intelligible knowledge (i.e., potential discovery). LRD has two main components that differ in their methodological approach to discovery: Literature-based discovery (LBD) produces potential discovery through analysis of the technical literature alone; Literature-assisted discovery (LAD) produces potential discovery through both analysis of the technical literature and use of selected authors of that literature. These authors generate potential discovery as proposers, workshop/panel participants, or in other active roles.

The open discovery systems (ODS) component of LRD starts with a problem to be solved, and generates solutions to that problem through potential discovery. We have been using ODS LRD to identify potential treatments or preventative actions for challenging medical problems, among myriad other applications. The previous four papers in this Special Issue describe the application of ODS LRD (specifically, the ODS LBD variant) to Raynaud's Phenomenon (RP), cataracts, Parkinson's Disease (PD), and Multiple Sclerosis (MS).

One goal of the present study was to determine whether LRD could be successfully applied (for the first time) to a challenging non-medical technical problem to generate potential discovery. The second goal was to explore the use of both LRD variants (LBD and LAD) to a non-medical technical problem. We selected the problem of water purification (WP) because of universal applicability and sponsor interest.

We used LRD to identify purification concepts, technology components and systems that could lead to improved water purification techniques. We accessed many disparate disciplines to identify purification concepts from literatures not normally associated with water purification. We used two LBD approaches, Cluster Filtering and Latent Semantic Indexing (LSI), to search for potential discovery. We generated voluminous amounts of potential discovery, and believe we have only scratched the surface of what is possible. We also ran a short experiment using LAD to identify experts associated with potential discovery concepts, and use their expertise to generate potential discovery for water purification.
ER  - 

TY  - JOUR
T1  - Improving search results with data mining in a thematic search engine
JO  - Computers & Operations Research
VL  - 31
IS  - 14
SP  - 2387
EP  - 2404
PY  - 2004/12//
T2  - 
AU  - Caramia, M
AU  - Felici, G
AU  - Pezzoli, A
SN  - 0305-0548
DO  - http://dx.doi.org/10.1016/S0305-0548(03)00194-1
UR  - http://www.sciencedirect.com/science/article/pii/S0305054803001941
KW  - Search engines
KW  - Web mining
KW  - Clustering
KW  - Genetic algorithms
AB  - The problem of obtaining relevant results in web searching has been tackled with several approaches. Although very effective techniques are currently used by the most popular search engines when no a priori knowledge on the user's desires beside the search keywords is available, in different settings it is conceivable to design search methods that operate on a thematic database of web pages that refer to a common body of knowledge or to specific sets of users. We have considered such premises to design and develop a search method that deploys data mining and optimization techniques to provide a more significant and restricted set of pages as the final result of a user search. We adopt a vectorization method based on search context and user profile to apply clustering techniques that are then refined by a specially designed genetic algorithm. In this paper we describe the method, its implementation, the algorithms applied, and discuss some experiments that has been run on test sets of web pages.
ER  - 

TY  - JOUR
T1  - A new document representation using term frequency and vectorized graph connectionists with application to document retrieval
JO  - Expert Systems with Applications
VL  - 36
IS  - 10
SP  - 12023
EP  - 12035
PY  - 2009/12//
T2  - 
AU  - Chow, Tommy W.S.
AU  - Zhang, Haijun
AU  - Rahman, M.K.M.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2009.03.008
UR  - http://www.sciencedirect.com/science/article/pii/S0957417409002590
KW  - Graph representation
KW  - Multiple features
KW  - Document retrieval
KW  - Self-organizing map
AB  - This paper presents a new document representation with vectorized multiple features including term frequency and term-connection-frequency. A document is represented by undirected and directed graph, respectively. Then terms and vectorized graph connectionists are extracted from the graphs by employing several feature extraction methods. This hybrid document feature representation more accurately reflects the underlying semantics that are difficult to achieve from the currently used term histograms, and it facilitates the matching of complex graph. In application level, we develop a document retrieval system based on self-organizing map (SOM) to speed up the retrieval process. We perform extensive experimental verification, and the results suggest that the proposed method is computationally efficient and accurate for document retrieval.
ER  - 

TY  - JOUR
T1  - Testing the cluster hypothesis in distributed information retrieval
JO  - Information Processing & Management
VL  - 42
IS  - 5
SP  - 1137
EP  - 1150
PY  - 2006/9//
T2  - 
AU  - Crestani, Fabio
AU  - Wu, Shengli
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2005.12.002
UR  - http://www.sciencedirect.com/science/article/pii/S0306457305001627
KW  - Information retrieval
KW  - Retrieval results presentation
KW  - Clustering
KW  - Experimental study
KW  - Distributed information retrieval
AB  - How to merge and organise query results retrieved from different resources is one of the key issues in distributed information retrieval. Some previous research and experiments suggest that cluster-based document browsing is more effective than a single merged list. Cluster-based retrieval results presentation is based on the cluster hypothesis, which states that documents that cluster together have a similar relevance to a given query. However, while this hypothesis has been demonstrated to hold in classical information retrieval environments, it has never been fully tested in heterogeneous distributed information retrieval environments. Heterogeneous document representations, the presence of document duplicates, and disparate qualities of retrieval results, are major features of an heterogeneous distributed information retrieval environment that might disrupt the effectiveness of the cluster hypothesis. In this paper we report on an experimental investigation into the validity and effectiveness of the cluster hypothesis in highly heterogeneous distributed information retrieval environments. The results show that although clustering is affected by different retrieval results representations and quality, the cluster hypothesis still holds and that generating hierarchical clusters in highly heterogeneous distributed information retrieval environments is still a very effective way of presenting retrieval results to users.
ER  - 

TY  - JOUR
T1  - Volume Contents and Author Index
JO  - Information Processing & Management
VL  - 43
IS  - 6
SP  - I
EP  - XVII
PY  - 2007/11//
T2  - Text Summarization

SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(07)00147-1
UR  - http://www.sciencedirect.com/science/article/pii/S0306457307001471
ER  - 

TY  - JOUR
T1  - Comment on: “Orpin, A.R. and Kostylev, V.E., 2006. Towards a statistically valid method of textural sea floor characterization of benthic habitats [Mar. Geol. 225 (1–4), 209–222.]”
JO  - Marine Geology
VL  - 232
IS  - 1–2
SP  - 105
EP  - 110
PY  - 2006/10/18/
T2  - 
AU  - Hamilton, L.J.
SN  - 0025-3227
DO  - http://dx.doi.org/10.1016/j.margeo.2006.08.001
UR  - http://www.sciencedirect.com/science/article/pii/S0025322706001745
ER  - 

TY  - JOUR
T1  - Locality sensitive semi-supervised feature selection
JO  - Neurocomputing
VL  - 71
IS  - 10–12
SP  - 1842
EP  - 1849
PY  - 2008/6//
T2  - Neurocomputing for Vision ResearchAdvances in Blind Signal Processing
AU  - Zhao, Jidong
AU  - Lu, Ke
AU  - He, Xiaofei
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2007.06.014
UR  - http://www.sciencedirect.com/science/article/pii/S092523120800115X
KW  - Feature selection
KW  - Semi-supervised learning
KW  - Fisher score
AB  - In many computer vision tasks like face recognition and image retrieval, one is often confronted with high-dimensional data. Procedures that are analytically or computationally manageable in low-dimensional spaces can become completely impractical in a space of several hundreds or thousands dimensions. Thus, various techniques have been developed for reducing the dimensionality of the feature space in the hope of obtaining a more manageable problem. The most popular feature selection and extraction techniques include Fisher score, Principal Component Analysis (PCA), and Laplacian score. Among them, PCA and Laplacian score are unsupervised methods, while Fisher score is supervised method. None of them can take advantage of both labeled and unlabeled data points. In this paper, we introduce a novel semi-supervised feature selection algorithm, which makes use of both labeled and unlabeled data points. Specifically, the labeled points are used to maximize the margin between data points from different classes, while the unlabeled points are used to discover the geometrical structure of the data space. We compare our proposed algorithm with Fisher score and Laplacian score on face recognition. Experimental results demonstrate the efficiency and effectiveness of our algorithm.
ER  - 

TY  - JOUR
T1  - Rich document representation and classification: An analysis
JO  - Knowledge-Based Systems
VL  - 22
IS  - 1
SP  - 67
EP  - 71
PY  - 2009/1//
T2  - 
AU  - Keikha, Mostafa
AU  - Khonsari, Ahmad
AU  - Oroumchian, Farhad
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2008.06.002
UR  - http://www.sciencedirect.com/science/article/pii/S0950705108001330
KW  - Text classification
KW  - Rich document representation
KW  - Ordered weighted average
AB  - There are three factors involved in text classification. These are classification model, similarity measure and document representation model. In this paper, we will focus on document representation and demonstrate that the choice of document representation has a profound impact on the quality of the classifier. In our experiments, we have used the centroid-based text classifier, which is a simple and robust text classification scheme. We will compare four different types of document representations: N-grams, Single terms, phrases and RDR which is a logic-based document representation. The N-gram representation is a string-based representation with no linguistic processing. The Single term approach is based on words with minimum linguistic processing. The phrase approach is based on linguistically formed phrases and single words. The RDR is based on linguistic processing and representing documents as a set of logical predicates. We have experimented with many text collections and we have obtained similar results. Here, we base our arguments on experiments conducted on Reuters-21578. We show that RDR, the more complex representation, produces more effective classifier on Reuters-21578, followed by the phrase approach.
ER  - 

TY  - JOUR
T1  - Cape: extending Clips for the internet
JO  - Knowledge-Based Systems
VL  - 13
IS  - 2–3
SP  - 151
EP  - 157
PY  - 2000/4//
T2  - 
AU  - Inder, R
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/S0950-7051(00)00056-3
UR  - http://www.sciencedirect.com/science/article/pii/S0950705100000563
KW  - Rule-based programming
KW  - Knowledge-based systems
AB  - This paper describes Cape, a programming environment combining Clips And Perl with Extensions. Clips is an efficient and expressive forward-chaining rule-based system with a flexible object system. Perl is a popular procedural language with extremely powerful regular expression matching facilities, and a huge library of freely available software. Cape closely integrates these languages, and provides extensions to facilitate building systems with an intimate mixture of the two. The paper describes the facilities Cape offers programmers and the demonstration systems and “component applications” distributed with it. The use of the system is then discussed with reference to dime (Distributed Information Manipulation Environment), a toolkit being developed to support identifying and coordinating the use of external knowledge sources. Finally, planned developments of the system are indicated.
ER  - 

TY  - JOUR
T1  - Requirements-oriented methodology for evaluating ontologies
JO  - Information Systems
VL  - 34
IS  - 8
SP  - 766
EP  - 791
PY  - 2009/12//
T2  - Sixteenth ACM Conference on Information Knowledge and Management (CIKM 2007)
AU  - Yu, Jonathan
AU  - Thom, James A.
AU  - Tam, Audrey
SN  - 0306-4379
DO  - http://dx.doi.org/10.1016/j.is.2009.04.002
UR  - http://www.sciencedirect.com/science/article/pii/S0306437909000337
KW  - Ontology evaluation
KW  - Browsing
KW  - User studies
KW  - Wikipedia
AB  - Many applications benefit from the use of a suitable ontology but it can be difficult to determine which ontology is best suited to a particular application. Although ontology evaluation techniques are improving as more measures and methodologies are proposed, the literature contains few specific examples of cohesive evaluation activity that links ontologies, applications and their requirements, and measures and methodologies. In this paper, we present ROMEO, a requirements-oriented methodology for evaluating ontologies, and apply it to the task of evaluating the suitability of some general ontologies (variants of sub-domains of the Wikipedia category structure) for supporting browsing in Wikipedia. The ROMEO methodology identifies requirements that an ontology must satisfy, and maps these requirements to evaluation measures. We validate part of this mapping with a task-based evaluation method involving users, and report on our findings from this user study.
ER  - 

TY  - JOUR
T1  - An overview on XML similarity: Background, current trends and future directions
JO  - Computer Science Review
VL  - 3
IS  - 3
SP  - 151
EP  - 173
PY  - 2009/8//
T2  - 
AU  - Tekli, Joe
AU  - Chbeir, Richard
AU  - Yetongnon, Kokou
SN  - 1574-0137
DO  - http://dx.doi.org/10.1016/j.cosrev.2009.03.001
UR  - http://www.sciencedirect.com/science/article/pii/S1574013709000136
AB  - In recent years, XML has been established as a major means for information management, and has been broadly utilized for complex data representation (e.g. multimedia objects). Owing to an unparalleled increasing use of the XML standard, developing efficient techniques for comparing XML-based documents becomes essential in the database and information retrieval communities. In this paper, we provide an overview of XML similarity/comparison by presenting existing research related to XML similarity. We also detail the possible applications of XML comparison processes in various fields, ranging over data warehousing, data integration, classification/clustering and XML querying, and discuss some required and emergent future research directions.
ER  - 

TY  - JOUR
T1  - The Term Vector Database: fast access to indexing terms for Web pages
JO  - Computer Networks
VL  - 33
IS  - 1–6
SP  - 247
EP  - 255
PY  - 2000/6//
T2  - 
AU  - Stata, Raymie
AU  - Bharat, Krishna
AU  - Maghoul, Farzin
SN  - 1389-1286
DO  - http://dx.doi.org/10.1016/S1389-1286(00)00046-3
UR  - http://www.sciencedirect.com/science/article/pii/S1389128600000463
KW  - Page classification
KW  - Term vectors
KW  - Topic distillation
KW  - Web connectivity
KW  - Web search
AB  - We have built a database that provides term vector information for large numbers of pages (hundreds of millions). The basic operation of the database is to take URLs and return term vectors. Compared to computing vectors by downloading pages via HTTP, the Term Vector Database is several orders of magnitude faster, enabling a large class of applications that would be impractical without such a database. This paper describes the Term Vector Database in detail. It also reports on two applications built on top of the database. The first application is an optimization of connectivity-based topic distillation. The second application is a Web page classifier used to annotate results returned by a Web search engine.
ER  - 

TY  - JOUR
T1  - Literature-related discovery (LRD): Potential treatments for Raynaud's Phenomenon
JO  - Technological Forecasting and Social Change
VL  - 75
IS  - 2
SP  - 203
EP  - 214
PY  - 2008/2//
T2  - Literature-Related Discovery
AU  - Kostoff, Ronald N.
AU  - Block, Joel A.
AU  - Stump, Jesse A.
AU  - Johnson, Dustin
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2007.11.005
UR  - http://www.sciencedirect.com/science/article/pii/S0040162507001989
KW  - Literature-based discovery
KW  - Text mining
KW  - Information retrieval
KW  - Clustering
KW  - Semantic filters
KW  - Raynaud's Phenomenon
KW  - Raynaud's Disease
KW  - Raynaud's Syndrome
AB  - Literature-related discovery (LRD) is the linking of two or more literature concepts that have heretofore not been linked (i.e., disjoint), in order to produce novel, interesting, plausible, and intelligible knowledge (i.e., potential discovery). The open discovery systems (ODS) component of LRD starts with a problem to be solved, and generates solutions to that problem through potential discovery. We have been using ODS LRD to identify potential treatments or preventative actions for challenging medical problems, among myriad other applications.

Raynaud's Phenomenon (RP) is a condition in which small arteries, most commonly in fingers and toes, contract and cause the skin to turn pale or a patchy red to blue. We selected the subject of RP for analysis by LRD because of RP's global prevalence, and its apparent intractability to all treatments except for palliative remediation mainly through drugs or surgery. Our main goal was to identify non-drug non-surgical treatments that would 1) prevent the occurrence, or 2) reduce the progression rate, or 3) stop the progression, or 4) maybe even reverse the progression, of RP. Our secondary goal was to compare our ODS LRD approach to the RP problem with other investigators who have addressed the RP problem since Swanson's pioneering 1986 ODS LRD paper on potential RP treatments [D.R. Swanson, Fish oil, Raynauds syndrome, and undiscovered public knowledge, Perspectives in Biology and Medicine 30 (1) (1986) 7–18].

We used Medline from 1965–1985 to identify potential discovery for RP. We differ from all the other authors who have addressed this problem in two major respects: we make no numerically-based filtering assumptions, and we generate substantial potential discovery (∼ 130 potential discoveries). Further, we believe our reported results are the tip of the iceberg. Much more potential discovery is possible with an adequately resourced study using the lessons learned from this demonstration study and the other demonstration studies that follow in this Special Issue.
ER  - 

TY  - JOUR
T1  - Literature-related discovery (LRD): Potential treatments for cataracts
JO  - Technological Forecasting and Social Change
VL  - 75
IS  - 2
SP  - 215
EP  - 225
PY  - 2008/2//
T2  - Literature-Related Discovery
AU  - Kostoff, Ronald N.
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2007.11.006
UR  - http://www.sciencedirect.com/science/article/pii/S0040162507001990
KW  - Literature-based discovery
KW  - Text mining
KW  - Information retrieval
KW  - Clustering
KW  - Semantic filters
KW  - Cataracts
KW  - Lens opacification
AB  - Literature-related discovery (LRD) is the linking of two or more literature concepts that have heretofore not been linked (i.e., disjoint), in order to produce novel, interesting, plausible, and intelligible knowledge (i.e., potential discovery). The open discovery systems (ODS) component of LRD starts with a problem to be solved, and generates solutions to that problem through potential discovery. We have been using ODS LRD to identify potential treatments or preventative actions for challenging medical problems, among myriad other applications.

This paper describes the second medical problem we addressed (cataract) using ODS LRD; the first problem addressed was Raynaud's Phenomenon (RP), and was described in the third paper of this Special Issue. Cataract was selected because it is ubiquitous globally, appears intractable to all forms of treatment other than surgical removal of cataracts, and is a major cause of blindness in many developing countries.

The ODS LRD study had three objectives: a) identify non-drug non-surgical treatments that would 1) help prevent cataracts, or 2) reduce the progression rate of cataracts, or 3) stop the progression of cataracts, or 4) maybe even reverse the progression of cataracts; b) demonstrate that we could solve an ODS LRD problem with no prior knowledge of any results or prior work (unlike the case with the RP problem); c) determine whether large time savings in the discovery process were possible relative to the time required for conducting the RP study. To that end, we used the MeSH taxonomy of MEDLINE to restrict potential discoveries to selected semantic classes, as a substitute for the manually-intensive process used in the RP study to restrict potential discoveries to selected semantic classes. We also used additional semantic filtering to identify potential discovery within the selected semantic classes.

All these goals were achieved. As will be shown, we generated large amounts of potential discovery in more than an order of magnitude less time than required for the RP study. We identified many non-drug non-surgical treatments that may be able to reduce or even stop the progression rate of cataracts. Time, and much testing, will determine whether this is possible. Finally, the methodology has been developed to the point where ODS LRD problems can be solved with no results or knowledge of any prior work.
ER  - 

TY  - JOUR
T1  - Multilingual news clustering: Feature translation vs. identification of cognate named entities
JO  - Pattern Recognition Letters
VL  - 28
IS  - 16
SP  - 2305
EP  - 2311
PY  - 2007/12/1/
T2  - 
AU  - Montalvo, S.
AU  - Martínez, R.
AU  - Casillas, A.
AU  - Fresno, V.
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2007.07.011
UR  - http://www.sciencedirect.com/science/article/pii/S016786550700236X
KW  - Multilingual clustering
KW  - Feature selection
KW  - Cognate identification
KW  - Named entity
KW  - Document representation
AB  - In this paper we evaluate the influence of different document representations in the results of multilingual news clustering. We aim at proving whether or not the use of only named entities is a good source of knowledge for multilingual news clustering. We compare two approaches: one based on feature translation, and another based on cognate identification. Our main contribution is using only some categories of cognate named entities like document representation features to perform multilingual news clustering, without the need of translation resources. The results show that the use of cognate named entities, as the only type of features to represent news, leads to good multilingual clustering performance, comparable to the one obtained by using the feature translation approach.
ER  - 

TY  - JOUR
T1  - Korean–Japanese story link detection based on distributional and contrastive properties of event terms
JO  - Information Processing & Management
VL  - 42
IS  - 2
SP  - 538
EP  - 550
PY  - 2006/3//
T2  - 
AU  - Lee, Kyung-Soon
AU  - Kageura, Kyo
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2005.02.005
UR  - http://www.sciencedirect.com/science/article/pii/S030645730500021X
KW  - Story link detection
KW  - Event term
KW  - Multilingual space
KW  - Distributional property
KW  - Space density
AB  - In this paper, we propose a novel approach for multilingual story link detection. Our approach utilized the distributional features of terms in timelines and multilingual spaces, together with selected types of named entities in order to get distinctive weights for terms that constitute linguistic representation of events. On timelines term significance is calculated by comparing term distribution of the documents on a day with that of the total document collection. Since two languages can provide more information than one language, term significance is measured on each language space, which is then used as a bridge between two languages on multilingual spaces. Evaluating the method on Korean and Japanese news articles, our method achieved 14.3% improvement for monolingual story pairs, and 16.7% improvement for multilingual story pairs. By measuring the space density, the proposed weighting components are verified with a high density of the intra-event stories and a low density of the inter-events stories. This result indicates that the proposed method is helpful for multilingual story link detection.
ER  - 

TY  - JOUR
T1  - Visual conceptualizations and models of science
JO  - Journal of Informetrics
VL  - 3
IS  - 3
SP  - 161
EP  - 172
PY  - 2009/7//
T2  - Science of Science: Conceptualizations and Models of Science
AU  - Börner, Katy
AU  - Scharnhorst, Andrea
SN  - 1751-1577
DO  - http://dx.doi.org/10.1016/j.joi.2009.03.008
UR  - http://www.sciencedirect.com/science/article/pii/S1751157709000315
KW  - Conceptualization
KW  - Models
KW  - Scientometrics
KW  - Science of Science
KW  - Sociology of science
KW  - Webometrics
KW  - Informetrics
KW  - History of science
KW  - Cultural studies of science
KW  - Statistical analysis
KW  - Mathematical modeling
KW  - Science policy
KW  - Evolution
AB  - This is the Guest Editor's introduction to the Special Issue on “Science of Science: Conceptualizations and Models of Science”, Journal of Informetrics. The introduction discusses challenges towards a theoretically grounded and practically useful science of science. It provides a brief chronological review of relevant work and argues for (1) the development of common frameworks for the comparison and combination of existing approaches, theories, laws, and measurements, (2) the combination of quantitative and qualitative studies of science, and (3) the operationalization of theoretical concepts in terms of measurement and empirical evidence. Next, three visual conceptualizations of science are discussed and compared. Each of them provides a framework for the comparison and combination of existing works, means to combine quantitative and qualitative data, and helps to operationalize and communicate theoretical concepts using empirical data. Last but not least, the contributions of and interlinkages among the papers included in this issue are discussed.
ER  - 

TY  - JOUR
T1  - The Gifts of Athena: Historical Origins of the Knowledge Economy: Joel Mokyr (Ed.); Princeton University Press, Princeton, NJ, 2003, 376 pages, Index (US$ 35.00)
JO  - Journal of Economic Behavior & Organization
VL  - 55
IS  - 1
SP  - 99
EP  - 102
PY  - 2004/9//
T2  - 
AU  - Rosser, M.V.
SN  - 0167-2681
DO  - http://dx.doi.org/10.1016/j.jebo.2004.03.001
UR  - http://www.sciencedirect.com/science/article/pii/S016726810400037X
ER  - 

TY  - JOUR
T1  - Interactive text retrieval based on document similarities
JO  - Physics and Chemistry of the Earth, Part A: Solid Earth and Geodesy
VL  - 25
IS  - 8
SP  - 649
EP  - 654
PY  - 2000///
T2  - DUST-2: An Improved Interactive Access to Information about the Earth atmosphere
AU  - Klose, A
AU  - Nürnberger, A
AU  - Kruse, R
AU  - Hartmann, G
AU  - Richards, M
SN  - 1464-1895
DO  - http://dx.doi.org/10.1016/S1464-1895(00)00100-9
UR  - http://www.sciencedirect.com/science/article/pii/S1464189500001009
AB  - In this article we present a prototypical implementation of a software tool for document retrieval which groups/arranges (pre-processed) documents based on a similarity measure. The prototype was developed based on self-organising maps to realise interactive associative search and visual exploration of document databases. This helps a user to navigate through similar documents. The navigation, especially the search for the first appropriate document, is supported by conventional keyword search methods. The usability of the presented approach is shown by a sample search.
ER  - 

TY  - JOUR
T1  - A subexponential algorithm for the coloured tree partition problem
JO  - Discrete Applied Mathematics
VL  - 155
IS  - 10
SP  - 1326
EP  - 1335
PY  - 2007/5/15/
T2  - 
AU  - Cordone, Roberto
SN  - 0166-218X
DO  - http://dx.doi.org/10.1016/j.dam.2007.02.001
UR  - http://www.sciencedirect.com/science/article/pii/S0166218X07000236
KW  - Tree partition
KW  - Divide-and-conquer
AB  - Given a tree of n vertices and a list of feasible colours for each vertex, the coloured tree partition problem (CTPP) consists in partitioning the tree into p vertex-disjoint subtrees of minimum total cost, and assigning to each subtree a different colour, which must be feasible for all of its vertices. The problem is strongly NP -hard on general graphs, as well as on grid and bipartite graphs. This paper deals with the previously open case of tree graphs, showing that it is strongly NP -complete to determine whether a feasible solution exists. It presents reduction, decomposition and bounding procedures to simplify the problem and an exact algorithm of O ( np log 2 ( a p - 2 ) ) complexity (with a &gt; 3 2 ) for the special case in which a vertex of each subtree is given.
ER  - 

TY  - JOUR
T1  - Collected by Didier DUBOIS, Henri PRADE and Salvatore SESSA
JO  - Fuzzy Sets and Systems
VL  - 160
IS  - 5
SP  - 706
EP  - 713
PY  - 2009/3/1/
T2  - Theme: Decision, Games, and Optimisation

SN  - 0165-0114
DO  - http://dx.doi.org/10.1016/j.fss.2008.10.001
UR  - http://www.sciencedirect.com/science/article/pii/S0165011408004570
ER  - 

TY  - JOUR
T1  - Partitioning-based clustering for Web document categorization
JO  - Decision Support Systems
VL  - 27
IS  - 3
SP  - 329
EP  - 341
PY  - 1999/12//
T2  - 
AU  - Boley, Daniel
AU  - Gini, Maria
AU  - Gross, Robert
AU  - Han, Eui-Hong (Sam)
AU  - Hastings, Kyle
AU  - Karypis, George
AU  - Kumar, Vipin
AU  - Mobasher, Bamshad
AU  - Moore, Jerome
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/S0167-9236(99)00055-X
UR  - http://www.sciencedirect.com/science/article/pii/S016792369900055X
KW  - Clustering
KW  - Categorization
KW  - World Wide Web documents
KW  - Graph partitioning
KW  - Association rules
KW  - Principal component analysis
AB  - Clustering techniques have been used by many intelligent software agents in order to retrieve, filter, and categorize documents available on the World Wide Web. Clustering is also useful in extracting salient features of related Web documents to automatically formulate queries and search for other similar documents on the Web. Traditional clustering algorithms either use a priori knowledge of document structures to define a distance or similarity among these documents, or use probabilistic techniques such as Bayesian classification. Many of these traditional algorithms, however, falter when the dimensionality of the feature space becomes high relative to the size of the document space. In this paper, we introduce two new clustering algorithms that can effectively cluster documents, even in the presence of a very high dimensional feature space. These clustering techniques, which are based on generalizations of graph partitioning, do not require pre-specified ad hoc distance functions, and are capable of automatically discovering document similarities or associations. We conduct several experiments on real Web data using various feature selection heuristics, and compare our clustering schemes to standard distance-based techniques, such as hierarchical agglomeration clustering, and Bayesian classification methods, such as AutoClass.
ER  - 

TY  - JOUR
T1  - Efficient layered density-based clustering of categorical data
JO  - Journal of Biomedical Informatics
VL  - 42
IS  - 2
SP  - 365
EP  - 376
PY  - 2009/4//
T2  - 
AU  - Andreopoulos, Bill
AU  - An, Aijun
AU  - Wang, Xiaogang
AU  - Labudde, Dirk
SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2008.11.004
UR  - http://www.sciencedirect.com/science/article/pii/S1532046408001469
KW  - Clustering
KW  - Bioinformatics
KW  - Categorical
KW  - Network
KW  - Index
KW  - Scalable
KW  - Layered
AB  - A challenge involved in applying density-based clustering to categorical biomedical data is that the ”cube” of attribute values has no ordering defined, making the search for dense subspaces slow. We propose the HIERDENC algorithm for hierarchical density-based clustering of categorical data, and a complementary index for searching for dense subspaces efficiently. The HIERDENC index is updated when new objects are introduced, such that clustering does not need to be repeated on all objects. The updating and cluster retrieval are efficient. Comparisons with several other clustering algorithms showed that on large datasets HIERDENC achieved better runtime scalability on the number of objects, as well as cluster quality. By fast collapsing the bicliques in large networks we achieved an edge reduction of as much as 86.5%. HIERDENC is suitable for large and quickly growing datasets, since it is independent of object ordering, does not require re-clustering when new data emerges, and requires no user-specified input parameters.
ER  - 

TY  - JOUR
T1  - Getting to the (c)ore of knowledge: mining biomedical literature
JO  - International Journal of Medical Informatics
VL  - 67
IS  - 1–3
SP  - 7
EP  - 18
PY  - 2002/12/4/
T2  - 
AU  - de Bruijn, Berry
AU  - Martin, Joel
SN  - 1386-5056
DO  - http://dx.doi.org/10.1016/S1386-5056(02)00050-3
UR  - http://www.sciencedirect.com/science/article/pii/S1386505602000503
KW  - Natural language processing
KW  - Medline
KW  - Molecular biology
KW  - Knowledge acquisition (computer)
KW  - Semantics
KW  - Indexing and abstracting
AB  - Literature mining is the process of extracting and combining facts from scientific publications. In recent years, many computer programs have been designed to extract various molecular biology findings from Medline abstracts or full-text articles. The present article describes the range of text mining techniques that have been applied to scientific documents. It divides ‘automated reading’ into four general subtasks: text categorization, named entity tagging, fact extraction, and collection-wide analysis. Literature mining offers powerful methods to support knowledge discovery and the construction of topic maps and ontologies. An overview is given of recent developments in medical language processing. Special attention is given to the domain particularities of molecular biology, and the emerging synergy between literature mining and molecular databases accessible through Internet.
ER  - 

TY  - JOUR
T1  - Classification of multivariate time series using locality preserving projections
JO  - Knowledge-Based Systems
VL  - 21
IS  - 7
SP  - 581
EP  - 587
PY  - 2008/10//
T2  - 
AU  - Weng, Xiaoqing
AU  - Shen, Junyi
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2008.03.027
UR  - http://www.sciencedirect.com/science/article/pii/S0950705108000634
KW  - Locality preserving projection
KW  - Multivariate time series
KW  - Classification
AB  - Multivariate time series (MTS) are used in very broad areas such as multimedia, medicine, finance and speech recognition. A new approach for MTS classification using locality preserving projections (LPP) is proposed. By using LPP, the MTS samples can be projected into a lower-dimensional space in which the MTS samples related to the same class are close to each other, the MTS samples in testing set can be identified by one-nearest-neighbor classifier in the lower-dimensional space. Experimental results performed on five real-world datasets demonstrate the effectiveness of our proposed approach for MTS classification.
ER  - 

TY  - JOUR
T1  - Text classification based on multi-word with support vector machine
JO  - Knowledge-Based Systems
VL  - 21
IS  - 8
SP  - 879
EP  - 886
PY  - 2008/12//
T2  - 
AU  - Zhang, Wen
AU  - Yoshida, Taketoshi
AU  - Tang, Xijin
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2008.03.044
UR  - http://www.sciencedirect.com/science/article/pii/S0950705108000968
KW  - Text classification
KW  - Multi-word
KW  - Feature selection
KW  - Information gain
KW  - Support vector machine
AB  - One of the main themes which support text mining is text representation; that is, its task is to look for appropriate terms to transfer documents into numerical vectors. Recently, many efforts have been invested on this topic to enrich text representation using vector space model (VSM) to improve the performances of text mining techniques such as text classification and text clustering. The main concern in this paper is to investigate the effectiveness of using multi-words for text representation on the performances of text classification. Firstly, a practical method is proposed to implement the multi-word extraction from documents based on the syntactical structure. Secondly, two strategies as general concept representation and subtopic representation are presented to represent the documents using the extracted multi-words. In particular, the dynamic k-mismatch is proposed to determine the presence of a long multi-word which is a subtopic of the content of a document. Finally, we carried out a series of experiments on classifying the Reuters-21578 documents using the representations with multi-words. We used the performance of representation in individual words as the baseline, which has the largest dimension of feature set for representation without linguistic preprocessing. Moreover, linear kernel and non-linear polynomial kernel in support vector machines (SVM) are examined comparatively for classification to investigate the effect of kernel type on their performances. Index terms with low information gain (IG) are removed from the feature set at different percentages to observe the robustness of each classification method. Our experiments demonstrate that in multi-word representation, subtopic representation outperforms the general concept representation and the linear kernel outperforms the non-linear kernel of SVM in classifying the Reuters data. The effect of applying different representation strategies is greater than the effect of applying the different SVM kernels on classification performance. Furthermore, the representation using individual words outperforms any representation using multi-words. This is consistent with the major opinions concerning the role of linguistic preprocessing on documents’ features when using SVM for text classification.
ER  - 

TY  - JOUR
T1  - Nonlinear ranking function representations in genetic programming-based ranking discovery for personalized search
JO  - Decision Support Systems
VL  - 42
IS  - 3
SP  - 1338
EP  - 1349
PY  - 2006/12//
T2  - 
AU  - Fan, Weiguo
AU  - Pathak, Praveen
AU  - Wallace, Linda
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2005.11.002
UR  - http://www.sciencedirect.com/science/article/pii/S0167923605001624
KW  - Information routing
KW  - Information retrieval
KW  - Genetic programming
KW  - Ranking function
AB  - Ranking function is instrumental in affecting the performance of a search engine. Designing and optimizing a search engine's ranking function remains a daunting task for computer and information scientists. Recently, genetic programming (GP), a machine learning technique based on evolutionary theory, has shown promise in tackling this very difficult problem. Ranking functions discovered by GP have been found to be significantly better than many of the other existing ranking functions. However, current GP implementations for ranking function discovery are all designed utilizing the Vector Space model in which the same term weighting strategy is applied to all terms in a document. This may not be an ideal representation scheme at the individual query level considering the fact that many query terms should play different roles in the final ranking. In this paper, we propose a novel nonlinear ranking function representation scheme and compare this new design to the well-known Vector Space model. We theoretically show that the new representation scheme subsumes the traditional Vector Space model representation scheme as a special case and hence allows for additional flexibility in term weighting. We test the new representation scheme with the GP-based discovery framework in a personalized search (information routing) context using a TREC web corpus. The experimental results show that the new ranking function representation design outperforms the traditional Vector Space model for GP-based ranking function discovery.
ER  - 

TY  - JOUR
T1  - Text-based knowledge discovery: search and mining of life-sciences documents
JO  - Drug Discovery Today
VL  - 7
IS  - 11
SP  - S89
EP  - S98
PY  - 2002/5/6/
T2  - 
AU  - Mack, Robert
AU  - Hehenberger, Michael
SN  - 1359-6446
DO  - http://dx.doi.org/10.1016/S1359-6446(02)02286-9
UR  - http://www.sciencedirect.com/science/article/pii/S1359644602022869
KW  - information retrieval
KW  - information extraction
KW  - text mining
KW  - knowledge discovery
KW  - biomedical ontologies
AB  - Text literature is playing an increasingly important role in biomedical discovery. The challenge is to manage the increasing volume, complexity and specialization of knowledge expressed in this literature. Although information retrieval or text searching is useful, it is not sufficient to find specific facts and relations. Information extraction methods are evolving to extract automatically specific, fine-grained terms corresponding to the names of entities referred to in the text, and the relationships that connect these terms. Information extraction is, in turn, a means to an end, and knowledge discovery methods are evolving for the discovery of still more-complex structures and connections among facts. These methods provide an interpretive context for understanding the meaning of biological data.
ER  - 

TY  - JOUR
T1  - A grid-based architecture for personalized federation of digital libraries
JO  - Library Collections, Acquisitions, and Technical Services
VL  - 30
IS  - 3–4
SP  - 139
EP  - 153
PY  - 2006/9//
Y2  - 2006/12//
T2  - 
AU  - Trnkoczy, Jernej
AU  - Turk, Žiga
AU  - Stankovski, Vlado
SN  - 1464-9055
DO  - http://dx.doi.org/10.1016/j.lcats.2006.12.004
UR  - http://www.sciencedirect.com/science/article/pii/S1464905506000807
KW  - Open archives
KW  - Metadata harvesting
KW  - Grid
KW  - Federated digital libraries
KW  - Service oriented knowledge utility
AB  - Federated Digital Libraries (FDLs) unify metadata from geographically distributed digital libraries and implement advanced information retrieval services for the users. Currently, the growing number of users and digital libraries on the World Wide Web (WWW) as well as the use of computationally intensive indexing and search algorithms causes scalability and performance problems. In order to build efficient and effective personalized FDLs, we developed a novel architecture and a system prototype, which is based on state-of-the-art grid technology. When using the system, the user selects a set of geographically distributed DLs. Then, the system harvests metadata from the selected DLs and computes and stores an index. Following this procedure, the user can use the generated index for searching her or his personalized FDL. It is shown that the proposed architecture is generic and scalable, and it can, as such, accommodate a number of different FDL applications.
ER  - 

TY  - JOUR
T1  - Extreme price clustering in the London equity index futures and options markets
JO  - Journal of Banking & Finance
VL  - 22
IS  - 9
SP  - 1193
EP  - 1206
PY  - 1998/9//
T2  - 
AU  - ap Gwilym, Owain
AU  - Clare, Andrew
AU  - Thomas, Stephen
SN  - 0378-4266
DO  - http://dx.doi.org/10.1016/S0378-4266(98)00054-5
UR  - http://www.sciencedirect.com/science/article/pii/S0378426698000545
KW  - Clustering
KW  - NASDAQ
KW  - Tick size
KW  - Bid–ask spreads
KW  - Intraday data
AB  - Price clustering and optimal tick sizes have recently been topics of substantial public policy interest, and this paper presents evidence which is relevant to both debates. Around 98% of quoted and traded prices for LIFFE stock index derivatives are found to occur at even ticks. We report that clustering increases with volatility and transaction frequency, and decreases with trade size, and find that the proportion of odd ticks is significantly lower near the market open and higher near the close. Further, an inverse relationship is reported between bid–ask spreads and the number of odd ticks, and spreads cluster at even-tick values. This evidence of extreme price clustering is the first to be presented for financial derivatives. The results support both the price resolution and the negotiation hypotheses of price clustering.
ER  - 

TY  - JOUR
T1  - Normalized compression distance for visual analysis of document collections
JO  - Computers & Graphics
VL  - 31
IS  - 3
SP  - 327
EP  - 337
PY  - 2007/6//
T2  - 
AU  - Telles, G.P.
AU  - Minghim, R.
AU  - Paulovich, F.V.
SN  - 0097-8493
DO  - http://dx.doi.org/10.1016/j.cag.2007.01.024
UR  - http://www.sciencedirect.com/science/article/pii/S0097849307000556
KW  - Kolmogorov complexity
KW  - Normalized compression distance
KW  - Text collection visualization
KW  - Multi-dimensional projection
KW  - Document visualization
AB  - In a world flooded by text of various sources, it is of strategic importance to find ways to map information present in written documents in a form that helps users locate and associate important information within a particular text data set. Content-based maps can support extremely useful explorations of text data sets. This paper proposes and evaluates the use of Kolmogorov complexity approximations as a means to detect similarity between general textual documents, in order to support mapping and visualization techniques for corpora exploration. The calculation of this similarity measure requires no intermediate representation of a corpus (such as vector representation) and therefore no pre-processing or parametrization steps. That makes it very attractive for a wider range of exploratory applications compared to conventional measures that need vector-based text representations. The visual layout used here is based on fast distance multi-dimensional projections. It is shown that the similarity measure and the resulting maps present very good precision and that the approach can be used successfully for visual analysis of automatically generated text maps.
ER  - 

TY  - JOUR
T1  - Category cluster discovery from distributed WWW directories
JO  - Information Sciences
VL  - 155
IS  - 3–4
SP  - 181
EP  - 197
PY  - 2003/10/15/
T2  - Knowledge Discovery from Distributed Information Sources
AU  - Shyu, Mei-Ling
AU  - Haruechaiyasak, Choochart
AU  - Chen, Shu-Ching
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/S0020-0255(03)00169-5
UR  - http://www.sciencedirect.com/science/article/pii/S0020025503001695
KW  - Distributed information sources
KW  - Information integration
KW  - Cluster analysis
KW  - Web mining
KW  - Document classification
AB  - Due to the inherently distributed nature of many networks, including the Internet, information and knowledge are generated and organized independently by different groups of people. To discover and exploit all the knowledge from different sources, a method of knowledge integration is usually required. Considering the document category sets as information sources, we define a problem of information integration called category merging. The purpose of category merging is to automatically construct a unified category set which represents and exploits document information from several different sources. This merging process is based on the clustering concept where categories with similar characteristics are merged into the same cluster under certain distributed constraints. To evaluate the quality of the merged category set, we measure the precision and recall values under three classification methods, Naive Bayes, Vector Space Model, and K-Nearest Neighbor. In addition, we propose a performance measure called cluster entropy, which determines how well the categories from different sources are distributed over the resulting clusters. We perform the merging process by using the real data sets collected from three different Web directories. The results show that our merging process improves the classification performance over the non-merged approach and also provides a better representation for all categories from distributed directories.
ER  - 

TY  - JOUR
T1  - A note on the inapproximability of correlation clustering
JO  - Information Processing Letters
VL  - 108
IS  - 5
SP  - 331
EP  - 335
PY  - 2008/11/15/
T2  - 
AU  - Tan, Jinsong
SN  - 0020-0190
DO  - http://dx.doi.org/10.1016/j.ipl.2008.06.004
UR  - http://www.sciencedirect.com/science/article/pii/S0020019008001889
KW  - Correlation clustering
KW  - Inapproximability
KW  - Randomized rounding
KW  - Graph algorithms
AB  - We consider inapproximability of the correlation clustering problem defined as follows: Given a graph G = ( V , E ) where each edge is labeled either “+” (similar) or “−” (dissimilar), correlation clustering seeks to partition the vertices into clusters so that the number of pairs correctly (resp., incorrectly) classified with respect to the labels is maximized (resp., minimized). The two complementary problems are called MaxAgree and MinDisagree, respectively, and have been studied on complete graphs, where every edge is labeled, and general graphs, where some edge might not have been labeled. Natural edge-weighted versions of both problems have been studied as well. Let S -MaxAgree denote the weighted problem where all weights are taken from set S , we show that S -MaxAgree with weights bounded by O ( | V | 1 / 2 − δ ) essentially belongs to the same hardness class in the following sense: if there is a polynomial time algorithm that approximates S -MaxAgree within a factor of λ = O ( log | V | ) with high probability, then for any choice of S ′ , S ′ -MaxAgree can be approximated in polynomial time within a factor of ( λ + ϵ ) , where ϵ &gt; 0 can be arbitrarily small, with high probability. A similar statement also holds for S -MinDisagree. This result implies it is hard (assuming NP ≠ RP ) to approximate unweighted MaxAgree within a factor of 80 / 79 − ϵ , improving upon a previous known factor of 116 / 115 − ϵ by Charikar et al. [M. Charikar, V. Guruswami, A. Wirth, Clustering with qualitative information, Journal of Computer and System Sciences 71 (2005) 360–383].1 1Throughout the paper, when we talk about approximation factors we adopt the convention of assuming the factor is greater than 1 for both maximization and minimization problems.
ER  - 

TY  - JOUR
T1  - A novel document similarity measure based on earth mover’s distance
JO  - Information Sciences
VL  - 177
IS  - 18
SP  - 3718
EP  - 3730
PY  - 2007/9/15/
T2  - 
AU  - Wan, Xiaojun
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2007.02.045
UR  - http://www.sciencedirect.com/science/article/pii/S0020025507001363
KW  - Document similarity measure
KW  - Document similarity search
KW  - Earth mover’s distance
KW  - TextTiling
KW  - Subtopic structure
AB  - In this paper we propose a novel measure based on the earth mover’s distance (EMD) to evaluate document similarity by allowing many-to-many matching between subtopics. First, each document is decomposed into a set of subtopics, and then the EMD is employed to evaluate the similarity between two sets of subtopics for two documents by solving the transportation problem. The proposed measure is an improvement of the previous OM-based measure, which allows only one-to-one matching between subtopics. Experiments have been performed on the TDT3 dataset to evaluate existing similarity measures and the results show that the EMD-based measure outperforms the optimal matching (OM) based measure and all other measures. In addition to the TextTiling algorithm, the sentence clustering algorithm is adopted for document decomposition, and the experimental results show that the proposed EMD-based measure does not rely on the document decomposition algorithm and thus it is more robust than the OM-based measure.
ER  - 

TY  - JOUR
T1  - Online algorithm for the self-organizing map of symbol strings
JO  - Neural Networks
VL  - 17
IS  - 8–9
SP  - 1231
EP  - 1239
PY  - 2004/10//
Y2  - 2004/11//
T2  - New Developments in Self-Organizing Systems
AU  - Somervuo, Panu J.
SN  - 0893-6080
DO  - http://dx.doi.org/10.1016/j.neunet.2004.08.004
UR  - http://www.sciencedirect.com/science/article/pii/S0893608004001522
KW  - Dynamic time warping
KW  - Self-organizing map
KW  - Subsymbolic representation
KW  - Symbol string
KW  - String average
AB  - In this work an online algorithm is presented for the construction of the self-organizing map (SOM) of symbol strings. Each node of the SOM grid is associated with a model string which is a variable–vector sequence. Smooth interpolation method is applied in the training which performs simultaneous adaptation of the symbol content and the length of the model string. The efficiency of the method is demonstrated by the clustering of a 100,000-word English dictionary.
ER  - 

TY  - JOUR
T1  - Maximum likelihood combination of multiple clusterings
JO  - Pattern Recognition Letters
VL  - 27
IS  - 13
SP  - 1457
EP  - 1464
PY  - 2006/10/1/
T2  - 
AU  - Hu, Tianming
AU  - Yu, Ying
AU  - Xiong, Jinzhi
AU  - Sung, Sam Yuan
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2006.02.013
UR  - http://www.sciencedirect.com/science/article/pii/S0167865506000626
KW  - Cluster analysis
KW  - Consensus clustering
KW  - Centroid clustering
KW  - Markov random field
KW  - Metric distance function
AB  - A promising direction for more robust clustering is to derive multiple candidate clusterings over a common set of objects and then combine them into a consolidated one, which is expected to be better than any candidate. Given a candidate clustering set, we show that with a particular pairwise potential used in Markov random fields, the maximum likelihood estimation is the one closest to the set in terms of a metric distance between clusterings. To minimize such a distance, we present two combining methods based on the new similarity determined by the whole candidate set. We evaluate them on both artificial and real datasets, with candidate clusterings either from full space or subspace. Experiments show that they not only lead to a closer distance to the candidate set, but also achieve a smaller or comparable distance to the true clustering.
ER  - 

TY  - JOUR
T1  - Non-negative matrix factorization with α-divergence
JO  - Pattern Recognition Letters
VL  - 29
IS  - 9
SP  - 1433
EP  - 1440
PY  - 2008/7/1/
T2  - 
AU  - Cichocki, Andrzej
AU  - Lee, Hyekyoung
AU  - Kim, Yong-Deok
AU  - Choi, Seungjin
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2008.02.016
UR  - http://www.sciencedirect.com/science/article/pii/S0167865508000767
KW  - α-Divergence
KW  - Multiplicative updates
KW  - Non-negative matrix factorization
KW  - Projected gradient
AB  - Non-negative matrix factorization (NMF) is a popular technique for pattern recognition, data analysis, and dimensionality reduction, the goal of which is to decompose non-negative data matrix X into a product of basis matrix A and encoding variable matrix S with both A and S allowed to have only non-negative elements. In this paper, we consider Amari’s α-divergence as a discrepancy measure and rigorously derive a multiplicative updating algorithm (proposed in our recent work) which iteratively minimizes the α-divergence between X and AS . We analyze and prove the monotonic convergence of the algorithm using auxiliary functions. In addition, we show that the same algorithm can be also derived using Karush–Kuhn–Tucker (KKT) conditions as well as the projected gradient. We provide two empirical study for image denoising and EEG classification, showing the interesting and useful behavior of the algorithm in cases where different values of α ( α = 0.5 , 1 , 2 ) are used.
ER  - 

TY  - JOUR
T1  - On the quality of ART1 text clustering
JO  - Neural Networks
VL  - 16
IS  - 5–6
SP  - 771
EP  - 778
PY  - 2003/6//
Y2  - 2003/7//
T2  - Advances in Neural Networks Research: IJCNN '03
AU  - Massey, Louis
SN  - 0893-6080
DO  - http://dx.doi.org/10.1016/S0893-6080(03)00088-1
UR  - http://www.sciencedirect.com/science/article/pii/S0893608003000881
KW  - Adaptive resonance theory
KW  - Text clustering
KW  - Text categorization
AB  - There is a large and continually growing quantity of electronic text available, which contain essential human and organization knowledge. An important research endeavor is to study and develop better ways to access this knowledge. Text clustering is a popular approach to automatically organize textual document collections by topics to help users find the information they need. Adaptive Resonance Theory (ART) neural networks possess several interesting properties that make them appealing in the area of text clustering. Although ART has been used in several research works as a text clustering tool, the level of quality of the resulting document clusters has not been clearly established yet. In this paper, we present experimental results with binary ART that address this issue by determining how close clustering quality is to an upper bound on clustering quality.
ER  - 

TY  - JOUR
T1  - Personalized mining of web documents using link structures and fuzzy concept networks
JO  - Applied Soft Computing
VL  - 7
IS  - 1
SP  - 398
EP  - 410
PY  - 2007/1//
T2  - 
AU  - Kim, Kyung-Joong
AU  - Cho, Sung-Bae
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2005.09.002
UR  - http://www.sciencedirect.com/science/article/pii/S1568494605000815
KW  - Web mining
KW  - Fuzzy concept networks
KW  - Personalization
KW  - Link-based search
KW  - Search engines
AB  - Personalized search engines are important tools for finding web documents for specific users, because they are able to provide the location of information on the WWW as accurately as possible, using efficient methods of data mining and knowledge discovery. The types and features of traditional search engines are various, including support for different functionality and ranking methods. New search engines that use link structures have produced improved search results which can overcome the limitations of conventional text-based search engines. Going a step further, this paper presents a system that provides users with personalized results derived from a search engine that uses link structures. The fuzzy document retrieval system (constructed from a fuzzy concept network based on the user's profile) personalizes the results yielded from link-based search engines with the preferences of the specific user. A preliminary experiment with six subjects indicates that the developed system is capable of searching not only relevant but also personalized web pages, depending on the preferences of the user.
ER  - 

TY  - JOUR
T1  - Clustering terms in the Bayesian network retrieval model: a new approach with two term-layers
JO  - Applied Soft Computing
VL  - 4
IS  - 2
SP  - 149
EP  - 158
PY  - 2004/5//
T2  - 
AU  - de Campos, Luis M.
AU  - Fernández-Luna, Juan M.
AU  - Huete, Juan F.
SN  - 1568-4946
DO  - http://dx.doi.org/10.1016/j.asoc.2003.11.003
UR  - http://www.sciencedirect.com/science/article/pii/S1568494604000298
KW  - Bayesian networks
KW  - Information retrieval models
KW  - Learning
KW  - Term clustering
AB  - The retrieval performance of an information retrieval system usually increases when it uses the relationships among the terms contained in a given document collection. However, this creates the problem of how to obtain these relationships efficiently, and how to then use them to retrieve documents given a user’s query. This paper presents a new retrieval model based on a Bayesian network that represents and exploits term relationships, overcoming these two drawbacks. An efficient learning method to capture these relationships, based on term clustering, as well as their use for retrieval purposes, is also shown.
ER  - 

TY  - JOUR
T1  - Literature listing
JO  - World Patent Information
VL  - 31
IS  - 4
SP  - 352
EP  - 357
PY  - 2009/12//
T2  - 

SN  - 0172-2190
DO  - http://dx.doi.org/10.1016/j.wpi.2009.07.001
UR  - http://www.sciencedirect.com/science/article/pii/S0172219009000830
ER  - 

TY  - JOUR
T1  - HIV-1 Integration in the Human Genome Favors Active Genes and Local Hotspots
JO  - Cell
VL  - 110
IS  - 4
SP  - 521
EP  - 529
PY  - 2002/8/23/
T2  - 
AU  - Schröder, Astrid R.W.
AU  - Shinn, Paul
AU  - Chen, Huaming
AU  - Berry, Charles
AU  - Ecker, Joseph R.
AU  - Bushman, Frederic
SN  - 0092-8674
DO  - http://dx.doi.org/10.1016/S0092-8674(02)00864-4
UR  - http://www.sciencedirect.com/science/article/pii/S0092867402008644
AB  - A defining feature of HIV replication is integration of the proviral cDNA into human DNA. The selection of chromosomal targets for integration is crucial for efficient viral replication, but the mechanism is poorly understood. Here we describe mapping of 524 sites of HIV cDNA integration on the human genome sequence. Genes were found to be strongly favored as integration acceptor sites. Global analysis of cellular transcription indicated that active genes were preferential integration targets, particularly genes that were activated in cells after infection by HIV-1. Regional hotspots for integration were also found, including a 2.4 kb region containing 1% of sites. These data document unexpectedly strong biases in integration site selection and suggest how selective targeting promotes aggressive HIV replication.
ER  - 

TY  - JOUR
T1  - Global term weights in distributed environments
JO  - Information Processing & Management
VL  - 44
IS  - 3
SP  - 1049
EP  - 1061
PY  - 2008/5//
T2  - 
AU  - Witschel, Hans Friedrich
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2007.09.003
UR  - http://www.sciencedirect.com/science/article/pii/S0306457307001744
KW  - Distributed information retrieval
KW  - Term weighting
KW  - Language modeling
AB  - This paper examines the estimation of global term weights (such as IDF) in information retrieval scenarios where a global view on the collection is not available. In particular, the two options of either sampling documents or of using a reference corpus independent of the target retrieval collection are compared using standard IR test collections. In addition, the possibility of pruning term lists based on frequency is evaluated.

The results show that very good retrieval performance can be reached when just the most frequent terms of a collection – an “extended stop word list” – are known and all terms which are not in that list are treated equally. However, the list cannot always be fully estimated from a general-purpose reference corpus, but some “domain-specific stop words” need to be added. A good solution for achieving this is to mix estimates from small samples of the target retrieval collection with ones derived from a reference corpus.
ER  - 

TY  - JOUR
T1  - High-performance FAQ retrieval using an automatic clustering method of query logs
JO  - Information Processing & Management
VL  - 42
IS  - 3
SP  - 650
EP  - 661
PY  - 2006/5//
T2  - 
AU  - Kim, Harksoo
AU  - Seo, Jungyun
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2005.04.002
UR  - http://www.sciencedirect.com/science/article/pii/S0306457305000543
KW  - Lexical disagreement problem
KW  - Query log clustering
KW  - FAQ retrieval
KW  - Cluster-based retrieval
AB  - To resolve some of lexical disagreement problems between queries and FAQs, we propose a reliable FAQ retrieval system using query log clustering. On indexing time, the proposed system clusters the logs of users’ queries into predefined FAQ categories. To increase the precision and the recall rate of clustering, the proposed system adopts a new similarity measure using a machine readable dictionary. On searching time, the proposed system calculates the similarities between users’ queries and each cluster in order to smooth FAQs. By virtue of the cluster-based retrieval technique, the proposed system could partially bridge lexical chasms between queries and FAQs. In addition, the proposed system outperforms the traditional information retrieval systems in FAQ retrieval.
ER  - 

TY  - JOUR
T1  - Volume Contents and Author Index
JO  - Information Processing & Management
VL  - 44
IS  - 6
SP  - I
EP  - XV
PY  - 2008/11//
T2  - Adaptive Information Retrieval

SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(08)00099-X
UR  - http://www.sciencedirect.com/science/article/pii/S030645730800099X
ER  - 

TY  - JOUR
T1  - Bibliometric maps of field of science
JO  - Information Processing & Management
VL  - 41
IS  - 6
SP  - 1534
EP  - 1547
PY  - 2005/12//
T2  - Special Issue on Infometrics
AU  - Marshakova-Shaikevich, Irina
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2005.03.027
UR  - http://www.sciencedirect.com/science/article/pii/S0306457305000270
KW  - Journal co-citation analysis
KW  - Lexical analysis of keywords
KW  - Network
KW  - JCR:SSE
KW  - SSCI
AB  - The present paper is devoted to two directions in algorithmic classificatory procedures: the journal co-citation analysis as an example of citation networks and lexical analysis of keywords in the titles and texts. What is common to those approaches is the general idea of normalization of deviations of the observed data from the mathematical expectation. The application of the same formula leads to discovery of statistically significant links between objects (journals in one case, keywords — in the other). The results of the journal co-citation analysis are reflected in tables and map for field “Women’s Studies” and for field “Information Science and Library Science”. An experimental attempt at establishing textual links between words was carried out on two samples from SSCI Data base: (1) EDUCATION and (2) ETHICS. The EDUCATION file included 2180 documents (of which 751 had abstracts); the ETHICS file included 807 documents (289 abstracts). Some examples of the results of this pilot study are given in tabular form . The binary links between words discovered in this way may form triplets or other groups with more than two member words.
ER  - 

TY  - JOUR
T1  - A semantic Bayesian network approach to retrieving information with intelligent conversational agents
JO  - Information Processing & Management
VL  - 43
IS  - 1
SP  - 225
EP  - 236
PY  - 2007/1//
T2  - 
AU  - Kim, Kyoung-Min
AU  - Hong, Jin-Hyuk
AU  - Cho, Sung-Bae
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2006.04.001
UR  - http://www.sciencedirect.com/science/article/pii/S030645730600063X
KW  - Conversational agents
KW  - Pattern matching
KW  - Semantic Bayesian networks
KW  - User interface
KW  - Mixed-initiative interaction
AB  - As access to information becomes more intensive in society, a great deal of that information is becoming available through diverse channels. Accordingly, users require effective methods for accessing this information. Conversational agents can act as effective and familiar user interfaces. Although conversational agents can analyze the queries of users based on a static process, they cannot manage expressions that are more complex. In this paper, we propose a system that uses semantic Bayesian networks to infer the intentions of the user based on Bayesian networks and their semantic information. Since conversation often contains ambiguous expressions, the managing of context and uncertainty is necessary to support flexible conversational agents. The proposed method uses mixed-initiative interaction (MII) to obtain missing information and clarify spurious concepts in order to understand the intention of users correctly. We applied this to an information retrieval service for websites to verify the usefulness of the proposed method.
ER  - 

TY  - JOUR
T1  - Mining a Web Citation Database for author co-citation analysis
JO  - Information Processing & Management
VL  - 38
IS  - 4
SP  - 491
EP  - 508
PY  - 2002/7//
T2  - 
AU  - He, Yulan
AU  - Cheung Hui, Siu
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(01)00046-2
UR  - http://www.sciencedirect.com/science/article/pii/S0306457301000462
KW  - Author co-citation analysis
KW  - Data mining
KW  - Web Citation Database
KW  - Intelligent information retrieval
AB  - Author co-citation analysis (ACA) has been widely used in bibliometrics as an analytical method in analyzing the intellectual structure of science studies. It can be used to identify authors from the same or similar research fields. However, such analysis method relies heavily on statistical tools to perform the analysis and requires human interpretation. Web Citation Database is a data warehouse used for storing citation indices of Web publications. In this paper, we propose a mining process to automate the ACA based on the Web Citation Database. The mining process uses agglomerative hierarchical clustering (AHC) as the mining technique for author clustering and multidimensional scaling (MDS) for displaying author cluster maps. The clustering results and author cluster map have been incorporated into a citation-based retrieval system known as PubSearch to support author retrieval of Web publications.
ER  - 

TY  - JOUR
T1  - Implicit ambiguity resolution using incremental clustering in cross-language information retrieval
JO  - Information Processing & Management
VL  - 40
IS  - 1
SP  - 145
EP  - 159
PY  - 2004/1//
T2  - 
AU  - Lee, Kyung-Soon
AU  - Kageura, Kyo
AU  - Choi, Key-Sun
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(03)00028-1
UR  - http://www.sciencedirect.com/science/article/pii/S0306457303000281
KW  - Implicit ambiguity resolution
KW  - Cross-language information retrieval
KW  - Incremental clustering
KW  - Document context
KW  - Document re-rank
AB  - This paper presents a method to implicitly resolve ambiguities using dynamic incremental clustering in cross-language information retrieval (CLIR) such as Korean-to-English and Japanese-to-English CLIR. The main objective of this paper shows that document clusters can effectively resolve the ambiguities tremendously increased in translated queries as well as take into account the context of all the terms in a document. In the framework we propose, a query in Korean/Japanese is first translated into English by looking up bilingual dictionaries, then documents are retrieved for the translated query terms based on the vector space retrieval model or the probabilistic retrieval model. For the top-ranked retrieved documents, query-oriented document clusters are incrementally created and the weight of each retrieved document is re-calculated by using the clusters. In the experiment based on TREC CLIR test collection, our method achieved 39.41% and 36.79% improvement for translated queries without ambiguity resolution in Korean-to-English CLIR, and 17.89% and 30.46% improvements in Japanese-to-English CLIR, on the vector space retrieval and on the probabilistic retrieval, respectively. Our method achieved 12.30% improvement for all translation queries, compared with blind feedback for the probabilistic retrieval in Korean-to-English CLIR. These results indicate that cluster analysis help to resolve ambiguity.
ER  - 

TY  - JOUR
T1  - Exploration of textual document archives using a fuzzy hierarchical clustering algorithm in the GAMBAL system
JO  - Information Processing & Management
VL  - 41
IS  - 3
SP  - 587
EP  - 598
PY  - 2005/5//
T2  - Cross-Language Information Retrieval
AU  - Torra, Vicenç
AU  - Miyamoto, Sadaaki
AU  - Lanau, Sergi
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2004.01.001
UR  - http://www.sciencedirect.com/science/article/pii/S0306457304000032
KW  - Information retrieval
KW  - Hierarchical clustering
KW  - Fuzzy clustering
AB  - The Internet, together with the large amount of textual information available in document archives, has increased the relevance of information retrieval related tools. In this work we present an extension of the Gambal system for clustering and visualization of documents based on fuzzy clustering techniques. The tool allows to structure the set of documents in a hierarchical way (using a fuzzy hierarchical structure) and represent this structure in a graphical interface (a 3D sphere) over which the user can navigate.

Gambal allows the analysis of the documents and the computation of their similarity not only on the basis of the syntactic similarity between words but also based on a dictionary (Wordnet 1.7) and latent semantics analysis.
ER  - 

TY  - JOUR
T1  - Content locality in distributed digital libraries
JO  - Information Processing & Management
VL  - 35
IS  - 3
SP  - 317
EP  - 336
PY  - 1999/5//
T2  - 
AU  - Viles, Charles L.
AU  - French, James C.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(98)00064-8
UR  - http://www.sciencedirect.com/science/article/pii/S0306457398000648
AB  - In this paper we introduce the notion of content locality in distributed document collections. Content locality is the degree to which content-similar documents are colocated in a distributed collection. We propose two metrics for measurement of content locality, one based on topic signatures and the other based on collection statistics. We provide derivations and analysis of both metrics and use them to measure the content locality in two kinds of document collections, the well-known TREC corpus and the Networked Computer Science Technical Report Library (NCSTRL), an operational digital library. We also show that content locality can be thought of temporally as well as spatially and provide evidence of its existence in temporally ordered document collections like news feeds.
ER  - 

TY  - JOUR
T1  - Empirical comparison of fast partitioning-based clustering algorithms for large data sets
JO  - Expert Systems with Applications
VL  - 24
IS  - 4
SP  - 351
EP  - 363
PY  - 2003/5//
T2  - 
AU  - Wei, Chih-Ping
AU  - Lee, Yen-Hsien
AU  - Hsu, Che-Ming
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/S0957-4174(02)00185-9
UR  - http://www.sciencedirect.com/science/article/pii/S0957417402001859
KW  - Data mining
KW  - Clustering analysis
KW  - Clustering algorithm comparison
AB  - Several fast algorithms for clustering very large data sets have been proposed in the literature, including CLARA, CLARANS, GAC-R3, and GAC-RARw. CLARA is a combination of a sampling procedure and the classical PAM algorithm, while CLARANS adopts a serial randomized search strategy to find the optimal set of medoids. GAC-R3 and GAC-RARw exploit genetic search heuristics for solving clustering problems. In this research, we conducted an empirical comparison of these four clustering algorithms over a wide range of data characteristics described by data size, number of clusters, cluster distinctness, cluster asymmetry, and data randomness. According to the experimental results, CLARANS outperforms its counterparts both in clustering quality and execution time when the number of clusters increases, clusters are more closely related, more asymmetric clusters are present, or more random objects exist in the data set. With a specific number of clusters, CLARA can efficiently achieve satisfactory clustering quality when the data size is larger, whereas GAC-R3 and GAC-RARw can achieve satisfactory clustering quality and efficiency when the data size is small, the number of clusters is small, and clusters are more distinct and symmetric.
ER  - 

TY  - JOUR
T1  - Support for seamless data exchanges between web services through information mapping analysis using kernel methods
JO  - Expert Systems with Applications
VL  - 36
IS  - 1
SP  - 358
EP  - 365
PY  - 2009/1//
T2  - 
AU  - Jeong, Buhwan
AU  - Lee, Daewon
AU  - Lee, Jaewook
AU  - Cho, Hyunbo
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2007.10.021
UR  - http://www.sciencedirect.com/science/article/pii/S0957417407004940
KW  - Data exchange
KW  - Information mapping
KW  - Kernel method
KW  - Schema matching
KW  - Structural similarity
KW  - Web service
AB  - A challenging issue to web services interoperability is seamless data exchanges between web services to be composed. A solution to this problem is to establish semantic mappings from an information item to another. To do that, we present an approximate information mapping analysis. We propose a kernel-based structural similarity measure for XML documents. Simulation results with industrial XML data show that the proposed kernel-based measure outperforms other existing methods.
ER  - 

TY  - JOUR
T1  - Construction of supervised and unsupervised learning systems for multilingual text categorization
JO  - Expert Systems with Applications
VL  - 36
IS  - 2, Part 1
SP  - 2400
EP  - 2410
PY  - 2009/3//
T2  - 
AU  - Lee, Chung-Hong
AU  - Yang, Hsin-Chang
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2007.12.052
UR  - http://www.sciencedirect.com/science/article/pii/S0957417407006835
KW  - Text categorization
KW  - Text mining
KW  - Machine learning
KW  - Supervised learning
KW  - Unsupervised learning
AB  - Due to the availability of a huge amount of textual data from a variety of sources, users of internationally distributed information regions need effective methods and tools that enable them to discover, retrieve and categorize relevant information, in whatever language and form it may have been stored. This drives a convergence of numerous interests from diverse research communities focusing on the issues related to multilingual text categorization. In this work, we implemented and measured the performance of the leading supervised and unsupervised approaches for multilingual text categorization. We selected support vector machines (SVM) as representative of supervised techniques as well as latent semantic indexing (LSI) and self-organizing maps (SOM) techniques as our selective ones of unsupervised methods for system implementation. The preliminary results show that our platform models including both supervised and unsupervised learning methods have the potentials for multilingual text categorization.
ER  - 

TY  - JOUR
T1  - A new approach on search for similar documents with multiple categories using fuzzy clustering
JO  - Expert Systems with Applications
VL  - 34
IS  - 4
SP  - 2545
EP  - 2554
PY  - 2008/5//
T2  - 
AU  - Saraçoğlu, Rıdvan
AU  - Tütüncü, Kemal
AU  - Allahverdi, Novruz
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2007.04.003
UR  - http://www.sciencedirect.com/science/article/pii/S0957417407001467
KW  - Text mining
KW  - Document similarity
KW  - Similarity search
KW  - Fuzzy clustering
KW  - Multiple categories
AB  - Searching for similar document has an important role in text mining and document management. In whether similar document search or in other text mining applications generally document classification is focused and class or category that the documents belong to is tried to be determined. The aim of the present study is the investigation of the case which includes the documents that belong to more than one category. The system used in the present study is a similar document search system that uses fuzzy clustering. The situation of belonging to more than one category for the documents is included by this system. The proposed approach consists of two stages to solve multicategories problem. The first stage is to find out the documents belonging to more than one category. The second stage is the determination of the categories to which these found documents belong to. For these two aims α-threshold Fuzzy Similarity Classification Method (α-FSCM) and Multiple Categories Vector Method (MCVM) are proposed as written order. Experimental results showed that proposed system can distinguish the documents that belong to more than one category efficiently. Regarding to the finding which documents belong to which classes, proposed system has better performance and success than the traditional approach.
ER  - 

TY  - JOUR
T1  - A systematic approach to the Kansei factors of tactile sense regarding the surface roughness
JO  - Applied Ergonomics
VL  - 38
IS  - 1
SP  - 53
EP  - 63
PY  - 2007/1//
T2  - 
AU  - Choi, Kyungmee
AU  - Jun, Changrim
SN  - 0003-6870
DO  - http://dx.doi.org/10.1016/j.apergo.2006.01.003
UR  - http://www.sciencedirect.com/science/article/pii/S0003687006000147
KW  - Kansei engineering
KW  - Cluster analysis
KW  - Tactile sense
AB  - Designing products to satisfy customers’ emotion requires the information gathered through the human senses, which are visual, auditory, olfactory, gustatory, or tactile senses. By controlling certain design factors, customers’ emotion can be evaluated, designed, and satisfied. In this study, a systematic approach is proposed to study the tactile sense regarding the surface roughness. Numerous pairs of antonymous tactile adjectives are collected and clustered. The optimal number of adjective clusters is estimated based on the several criterion functions. The representative average preferences of the final clusters are obtained as the estimates of engineering parameters to control the surface roughness of the commercial polymer-based products.
ER  - 

TY  - JOUR
T1  - DISCOVERY OF INTERMINGLED EVENT PATTERNS IN DISCRETE MONITORING DATA
JO  - IFAC Proceedings Volumes
VL  - 40
IS  - 6
SP  - 55
EP  - 60
PY  - 2007///
T2  - 1st IFAC Workshop on Dependable Control of Discrete Systems
AU  - Wang, Xi
AU  - Johnson, Timothy L.
SN  - 1474-6670
DO  - http://dx.doi.org/10.3182/20070613-3-FR-4909.00012
UR  - http://www.sciencedirect.com/science/article/pii/S1474667015310958
KW  - Fault detection
KW  - identification
KW  - monitoring
KW  - diagnosis
KW  - automata
KW  - dependability assessment
KW  - discrete event systems
AB  - Abstract
This paper considers the discovery and detection of repeating patterns in event sequence data, where the event patterns may be of variable duration, may be intermingled, and may be of variable length. These properties are characteristic of many types of monitoring and diagnostic alarm sequence data, and may be used in detecting both normal and abnormal behaviours of complex dynamic systems.
ER  - 

TY  - JOUR
T1  - An algorithmic approach for checking closure properties of temporal logic specifications and ω-regular languages
JO  - Theoretical Computer Science
VL  - 195
IS  - 2
SP  - 183
EP  - 203
PY  - 1998/3/30/
T2  - Concurrency Theory
AU  - Peled, Doron
AU  - Wilke, Thomas
AU  - Wolper, Pierre
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/S0304-3975(97)00219-3
UR  - http://www.sciencedirect.com/science/article/pii/S0304397597002193
KW  - Concurrency
KW  - Semantics
KW  - Closure properties
KW  - Temporal logic
AB  - In concurrency theory, there are several examples where the interleaved model of concurrency can distinguish between execution sequences which are not significantly different. One such example is sequences that differ from each other by stuttering, i.e., the number of times a state can adjacently repeat. Another example is executions that differ only by the ordering of independently executed events. Considering these sequences as different is semantically rather meaningless. Nevertheless, specification languages that are based on interleaving semantics, such as linear temporal logic (LTL), can distinguish between them. This situation has led to several attempts to define languages that cannot distinguish between such equivalent sequences. In this paper, we take a different approach to this problem: we develop algorithms for deciding if a property cannot distinguish between equivalent sequences, i.e., is closed under the equivalence relation. We focus on properties represented by regular languages, ω-regular languages, or prepositional LTL formulas and show that for such properties there is a wide class of equivalence relations for which determining closure is decidable, in fact is in PSPACE. Hence, checking the closure of a specification is no more difficult than checking satisfiability of a temporal formula. Among the closure properties we are able to handle, one finds trace closedness, stutter closedness and projective closedness, for all of which we are also able to prove a PSPACE lower bound. Being able to check that a property is closed under an equivalence relation has an immediate application in state-space exploration based verification. Indeed, the knowledge that the specification does not distinguish between equivalent execution sequences allows constructing a reduced state space where it is sufficient that at least one sequence per equivalence class is represented.
ER  - 

TY  - JOUR
T1  - Towards understanding hierarchical clustering: A data distribution perspective
JO  - Neurocomputing
VL  - 72
IS  - 10–12
SP  - 2319
EP  - 2330
PY  - 2009/6//
T2  - Lattice Computing and Natural Computing (JCIS 2007) / Neural Networks in Intelligent Systems Designn (ISDA 2007)
AU  - Wu, Junjie
AU  - Xiong, Hui
AU  - Chen, Jian
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2008.12.011
UR  - http://www.sciencedirect.com/science/article/pii/S0925231208005663
KW  - Hierarchical clustering
KW  - F-measure
KW  - Measure normalization
KW  - Unweighted pair group method with arithmetic mean (UPGMA)
KW  - Coefficient of variation (CV)
AB  - A very important category of clustering methods is hierarchical clustering. There are considerable research efforts which have been focused on algorithm-level improvements of the hierarchical clustering process. In this paper, our goal is to provide a systematic understanding of hierarchical clustering from a data distribution perspective. Specifically, we investigate the issues about how the “true” cluster distribution can make impact on the clustering performance, and what is the relationship between hierarchical clustering schemes and validation measures with respect to different data distributions. To this end, we provide an organized study to illustrate these issues. Indeed, one of our key findings reveals that hierarchical clustering tends to produce clusters with high variation on cluster sizes regardless of “true” cluster distributions. Also, our results show that F-measure, an external clustering validation measure, has bias towards hierarchical clustering algorithms which tend to increase the variation on cluster sizes. Viewed in light of this, we propose F norm , the normalized version of the F-measure, to solve the cluster validation problem for hierarchical clustering. Experimental results show that F norm is indeed more suitable than the unnormalized F-measure in evaluating the hierarchical clustering results across data sets with different data distributions.
ER  - 

TY  - JOUR
T1  - SOPHIA-TCBR: A knowledge discovery framework for textual case-based reasoning
JO  - Knowledge-Based Systems
VL  - 21
IS  - 5
SP  - 404
EP  - 414
PY  - 2008/7//
T2  - 
AU  - Patterson, David
AU  - Rooney, Niall
AU  - Galushka, Mykola
AU  - Dobrynin, Vladimir
AU  - Smirnova, Elena
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2008.02.006
UR  - http://www.sciencedirect.com/science/article/pii/S0950705108000178
KW  - Textual case-based reasoning
KW  - Clustering
KW  - Knowledge discovery
AB  - In this paper, we present a novel textual case-based reasoning system called SOPHIA-TCBR which provides a means of clustering semantically related textual cases where individual clusters are formed through the discovery of narrow themes which then act as attractors for related cases. During this process, SOPHIA-TCBR automatically discovers appropriate case and similarity knowledge. It then is able to organize the cases within each cluster by forming a minimum spanning tree, based on their semantic similarity. SOPHIA’s capability as a case-based text classifier is benchmarked against the well known and widely utilised k-Means approach. Results show that SOPHIA either equals or outperforms k-Means based on 2 different case-bases, and as such is an attractive approach for case-based classification. We demonstrate the quality of the knowledge discovery process by showing the high level of topic similarity between adjacent cases within the minimum spanning tree. We show that the formation of the minimum spanning tree makes it possible to identify a kernel region within the cluster, which has a higher level of similarity between cases than the cluster in its entirety, and that this corresponds directly to a higher level of topic homogeneity. We demonstrate that the topic homogeneity increases as the average semantic similarity between cases in the kernel increases. Finally having empirically demonstrated the quality of the knowledge discovery process in SOPHIA, we show how it can be competently applied to case-based retrieval.
ER  - 

TY  - JOUR
T1  - CMedPort: An integrated approach to facilitating Chinese medical information seeking
JO  - Decision Support Systems
VL  - 42
IS  - 3
SP  - 1431
EP  - 1448
PY  - 2006/12//
T2  - 
AU  - Zhou, Yilu
AU  - Qin, Jialun
AU  - Chen, Hsinchun
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2005.11.006
UR  - http://www.sciencedirect.com/science/article/pii/S0167923605001685
KW  - Information retrieval
KW  - Internet searching and browsing
KW  - Search engine
KW  - Cross-regional search
KW  - Meta-search
KW  - Summarization
KW  - Categorization
AB  - As the number of non-English resources available on the Web is increasing rapidly, developing information retrieval techniques for non-English languages is becoming an urgent and challenging issue. In this research to facilitate information seeking in a multilingual world, we focused on discovering how search-engine techniques developed for English could be generalized for use with other languages. We proposed a general framework incorporating a focused collection-building technique, a generic language processing ability, an integration of information resources, and a post-retrieval analysis module. Based on this approach, we developed CMedPort, a Chinese Web portal in the medical domain that not only allows users to search for Web pages from local collections and meta-search engines but also provides encoding conversion between simplified and traditional Chinese to support cross-regional search and document summarization and categorization. User studies were conducted to compare the effectiveness and efficiency of CMedPort with those of three major Chinese search engines. Results indicate that CMedPort achieved similar accuracy for search tasks, but exhibited significantly higher recall than each of the three search engines as well as higher precision than two of the search engines for browse tasks. There were no significant differences among the efficiency measures for CMedPort and benchmarks systems. A post-questionnaire regarding system usability indicated that CMedPort achieved significantly higher user satisfaction than any of the three benchmark systems. The subjects especially liked CMedPort's categorizer, commenting that it helped improve understanding of search results. These encouraging outcomes suggest a promising future for applying our approach to Internet searching and browsing in a multilingual world.
ER  - 

TY  - CHAP
AU  - Ceravolo, Paolo
AU  - Corallo, Angelo
AU  - Damiani, Ernesto
AU  - Elia, Gianluca
AU  - Viviani, Marco
AU  - Zilli, Antonio
T1  - Chapter 13 Bottom-up extraction and maintenance of ontology-based metadata
A2  - Elie Sanchez
BT  - Capturing Intelligence
PB  - Elsevier
PY  - 2006///
VL  - Volume 1
SP  - 265
EP  - 282
T2  - Fuzzy Logic and the Semantic Web
SN  - 1574-9576
DO  - http://dx.doi.org/10.1016/S1574-9576(06)80015-8
UR  - http://www.sciencedirect.com/science/article/pii/S1574957606800158
KW  - community of practice
KW  - semantic-web
KW  - bottom-up ontology
KW  - ad-hoc conceptualization
KW  - metadata extraction and maintaining
KW  - fuzzy techniques
KW  - clustering techniques
KW  - trusted metadata
AB  - In this chapter, several flexible techniques aimed at extracting, maintaining and enriching semantic-web style metadata are discussed. Such techniques were designed for being applied in the framework of dynamic Communities of Practice (CoP) interactions. Namely, we present a way of building ontologies that proceeds in a bottom-up fashion, defining concepts as clusters of concrete objects. Unlike huge, “supply-side” normative ontologies, our bottom-up ontologies are based on use of implicit and, therefore, parsimonious part-whole and is-a relations. This makes them suitable for the ad-hoc style of conceptualization used within communities of practice and peer-to-peer (P2P) communities. Also we discuss how metadata based on bottom-up ontologies can be associated with a flexible degree of trust by collecting user feedback. Our bottom-up extraction method complements current practice, where, as a rule, ontologies are built top-down. It is not claimed that bottom-up construction is a generally valid recipe; rather, the approach is intended to enrich the ontology developer's palette when designing and implementing Semantic Web applications.
ER  - 

TY  - JOUR
T1  - Towards content-oriented patent document processing
JO  - World Patent Information
VL  - 30
IS  - 1
SP  - 21
EP  - 33
PY  - 2008/3//
T2  - 
AU  - Wanner, Leo
AU  - Baeza-Yates, Ricardo
AU  - Brügmann, Sören
AU  - Codina, Joan
AU  - Diallo, Barrou
AU  - Escorsa, Enric
AU  - Giereth, Mark
AU  - Kompatsiaris, Yiannis
AU  - Papadopoulos, Symeon
AU  - Pianta, Emanuele
AU  - Piella, Gemma
AU  - Puhlmann, Ingo
AU  - Rao, Gautam
AU  - Rotard, Martin
AU  - Schoester, Pia
AU  - Serafini, Luciano
AU  - Zervaki, Vasiliki
SN  - 0172-2190
DO  - http://dx.doi.org/10.1016/j.wpi.2007.03.008
UR  - http://www.sciencedirect.com/science/article/pii/S0172219007000762
KW  - Patent content representation
KW  - Patent retrieval
KW  - Content extraction
KW  - Paraphrasing
KW  - Summarization
KW  - Visualization
KW  - Navigation
KW  - Valuing
KW  - PATExpert
KW  - Classification
KW  - Translation
KW  - Documentation ontologies
KW  - Knowledge base
AB  - In this article, we present ongoing work on an advanced patent processing service PATExpert. The central assumption underlying PATExpert is that in order to meet the needs of the users of patent processing services, recourse must be made to the content of patent material. We introduce a content representation schema for patent documentation and sketch the design of techniques that facilitate the integration of this schema into the patent processing cycle. Two types of techniques are discussed. Techniques of the first type facilitate the access to the content of patent documentation provided in a textual format – be it by the human reader or by the machine – in that they rephrase and summarize the documentation and map it onto a formal semantic representation. Techniques of the second type operate on the content representation. At this stage, PATExpert is explored in two technology areas – optical recording devices and machine tools. The work is being carried out in the framework of an R&amp;D-project partially funded by the European Commission.
ER  - 

TY  - JOUR
T1  - Using clustering and SuperConcepts within SMART: TREC 6
JO  - Information Processing & Management
VL  - 36
IS  - 1
SP  - 109
EP  - 131
PY  - 2000/1//
T2  - 
AU  - Buckley, Chris
AU  - Mitra, Mandar
AU  - Walz, Janet
AU  - Cardie, Claire
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(99)00047-3
UR  - http://www.sciencedirect.com/science/article/pii/S0306457399000473
AB  - The SMART information retrieval project emphasizes completely automatic approaches to the understanding and retrieval of large quantities of text. We continue our work in TREC 6, performing runs in the routing, ad hoc, and foreign language environments, including cross-lingual runs. The major focus for TREC 6 is on trying to maintain the balance of the query — attempting to ensure the various aspects of the original query are appropriately addressed, especially while adding expansion terms. Exactly the same procedure is used for foreign language environments as for English; our tenet is that good information retrieval techniques are more powerful than linguistic knowledge. We also give an interesting cross-lingual run, assuming that French and English are closely enough related so that a query in one language can be run directly on a collection in the other language by just ‘correcting’ the spelling of the query words. This is quite successful for most queries.
ER  - 

TY  - JOUR
T1  - The impact of information richness on information security awareness training effectiveness
JO  - Computers & Education
VL  - 52
IS  - 1
SP  - 92
EP  - 100
PY  - 2009/1//
T2  - 
AU  - Shaw, R.S.
AU  - Chen, Charlie C.
AU  - Harris, Albert L.
AU  - Huang, Hui-Jou
SN  - 0360-1315
DO  - http://dx.doi.org/10.1016/j.compedu.2008.06.011
UR  - http://www.sciencedirect.com/science/article/pii/S0360131508001012
KW  - Information richness
KW  - Information security
KW  - Security awareness
KW  - Hypermedia
KW  - Multimedia
KW  - Hypertext
AB  - In recent years, rapid progress in the use of the internet has resulted in huge losses in many organizations due to lax security. As a result, information security awareness is becoming an important issue to anyone using the Internet. To reduce losses, organizations have made information security awareness a top priority. The three main barriers to information security awareness are: (1) general security awareness, (2) employees’ computer skills, and (3) organizational budgets. Online learning appears a feasible alternative to providing information security awareness and countering these three barriers. Research has identified three levels of security awareness: perception, comprehension and projection. This paper reports on a laboratory experiment that investigates the impacts of hypermedia, multimedia and hypertext to increase information security awareness among the three awareness levels in an online training environment. The results indicate that: (1) learners who have the better understanding at the perception and comprehension levels can improve understanding at the projection level; (2) learners with text material perform better at the perception level; and (3) learners with multimedia material perform better at the comprehension level and projection level. The results could be used by educators and training designers to create meaningful information security awareness materials.
ER  - 

TY  - JOUR
T1  - Dynamic Knowledge Map: reusing experts' tacit knowledge in the AEC industry
JO  - Automation in Construction
VL  - 13
IS  - 2
SP  - 203
EP  - 207
PY  - 2004/3//
T2  - Conference of the Association for Computer Aided Design in Architecture
AU  - Woo, Jeong-Han
AU  - Clayton, Mark J.
AU  - Johnson, Robert E.
AU  - Flores, Benito E.
AU  - Ellis, Christopher
SN  - 0926-5805
DO  - http://dx.doi.org/10.1016/j.autcon.2003.09.003
UR  - http://www.sciencedirect.com/science/article/pii/S0926580503001067
KW  - Internet
KW  - Dynamic Knowledge Map
KW  - AEC
AB  - Much knowledge in the Architecture, Engineering and Construction (AEC) industry is experience-based and tacit. Nevertheless, the typical strategy for knowledge management is focused on computer-based approaches for capturing and disseminating explicit knowledge. AEC firms have been successful at collecting and storing explicit information in enterprise databases, but they are poor at knowledge retrieval and exchange. Consequently, AEC professionals find it difficult to reuse core experts' knowledge for highly knowledge-intensive AEC activities. This situation calls for a method for disseminating tacit knowledge from experts' brains to achieve higher quality AEC projects.

The primary purpose of this paper is to set a theoretical foundation for clarifying the contribution of experts' tacit knowledge in the AEC industry. The secondary purpose is to describe the concept for prototype software, Dynamic Knowledge Map, that can assist in the reuse of experts' tacit knowledge. Dynamic Knowledge Map is a Web-based knowledge navigator that searches for experts and facilitates communication with those experts by using internet technology. Higher performance levels theoretically can be achieved while accelerating the knowledge transfer processes. Future research will test the suitability of Dynamic Knowledge Map for tacit knowledge utilization in AEC organizations.
ER  - 

TY  - JOUR
T1  - A resource-based perspective on knowledge management capability and competitive advantage: an empirical investigation
JO  - Expert Systems with Applications
VL  - 27
IS  - 3
SP  - 459
EP  - 465
PY  - 2004/10//
T2  - 
AU  - Chuang, Shu-Hui
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2004.05.008
UR  - http://www.sciencedirect.com/science/article/pii/S0957417404000569
KW  - Knowledge management
KW  - Competitive advantage
KW  - KM resources
KW  - KM capability
AB  - The concept of knowledge management (KM) as a powerful competitive weapon has been strongly emphasized in the strategic management literature, yet the sustainability of the competitive advantage provided by KM capability is not well-explained. To fill this gap, this paper develops the concept of KM as an organizational capability and empirically examines the association between KM capabilities and competitive advantage. In order to provide a better presentation of significant relationships, through resource-based view of the firm explicitly recognizes important of KM resources and capabilities. Firm specific KM resources are classified as social KM resources, and technical KM resources. Surveys collected from 177 firms were analyzed and tested. The results confirmed the impact of social KM resource on competitive advantage. Technical KM resource is negatively related with competitive advantage, and KM capability is significantly related with competitive advantage.
ER  - 

TY  - JOUR
T1  - Developing a knowledge map for construction scheduling using a novel approach
JO  - Automation in Construction
VL  - 16
IS  - 6
SP  - 806
EP  - 815
PY  - 2007/9//
T2  - 
AU  - Yang, Jyh-Bin
SN  - 0926-5805
DO  - http://dx.doi.org/10.1016/j.autcon.2007.02.005
UR  - http://www.sciencedirect.com/science/article/pii/S0926580507000210
KW  - Knowledge map
KW  - Knowledge management
KW  - Construction management
KW  - Scheduling technique
AB  - A knowledge map is a vital tool for better knowledge management and learning. While application of knowledge maps in the construction domain remains in the initial stages of development, the construction industry is experience-oriented and therefore suited to knowledge maps. This study presents a novel approach for developing a knowledge map for construction scheduling. According to framework-based classification, this study utilizes a science-specific search engine to search for literature on construction scheduling knowledge. Search results are then used to develop a file cabinet knowledge map consisting of a contour map, and several trend and density charts. This map representation compensates for the lack of various meanings in a single knowledge map. For novices interested in learning construction scheduling knowledge, results of this study provide constructive information to know the key issues and research trends in the construction domain. In summary, this study presents a suitable procedure for extracting knowledge from public knowledge sources for development of a knowledge map. The proposed approach can be used for rapid generation of knowledge maps.
ER  - 

TY  - JOUR
T1  - Influence of temperature and composition on the small-angle neutron scattering from polydiene star diblock copolymers and mixtures with homopolymers
JO  - Polymer
VL  - 41
IS  - 7
SP  - 2557
EP  - 2567
PY  - 2000/3//
T2  - 
AU  - Brunacci, A.S.
AU  - Kiff, F.T.
AU  - Richards, R.W.
AU  - Thompson, R.L.
AU  - King, S.M.
SN  - 0032-3861
DO  - http://dx.doi.org/10.1016/S0032-3861(99)00441-3
UR  - http://www.sciencedirect.com/science/article/pii/S0032386199004413
KW  - Small-angle neutron scattering
KW  - Polydiene
KW  - Diblock
AB  - The small-angle scattering from star diblock copolymers (SDCs) has been calculated using the incompressible random phase approximation (RPA) and methodologies recently developed. The influence of the interaction parameter and incorporation of homopolymer has been explored theoretically for SDCs of deuteriopolybutadiene and polymethylpentadiene with four arms. For the copolymer where the polybutadiene was the outer block of the arm, the scattering over a temperature range from 298 to 418 K has been explored. Fits to the data have been obtained using the random phase expressions providing values of the interaction parameter and radius of gyration of the inner block. The dimensions of the inner block are unaltered from the unperturbed dimensions of the linear polymer of the same degree of polymerisation. The temperature variation of scattered intensity suggests a spinodal temperature for microphase separation of 196 K. Although the scattering of the mixtures of the SDC with either of the homopolymer exhibited features predicted by the random phase approximation theory, data could only be fitted by using unrealistic values of intermolecular and intramolecular interaction parameters or using radius of gyration values of the homopolymer that indicated phase separation between SDC and homopolymer. SDC data provide support for phase separation being the pertinent explanation for these phenomena.
ER  - 

TY  - JOUR
T1  - Patinformatics: Tasks to tools
JO  - World Patent Information
VL  - 25
IS  - 3
SP  - 211
EP  - 221
PY  - 2003/9//
T2  - 
AU  - Trippe, Anthony J.
SN  - 0172-2190
DO  - http://dx.doi.org/10.1016/S0172-2190(03)00079-6
UR  - http://www.sciencedirect.com/science/article/pii/S0172219003000796
KW  - Patinformatics
KW  - Patent information analysis
KW  - Software analysis tools
KW  - Patent intelligence
KW  - List cleanup
KW  - Concept grouping
KW  - List generation
KW  - Co-occurrency matrices
KW  - Circle graphs
KW  - Data clustering
KW  - Mapping document clusters
KW  - Citation analysis
AB  - This article starts with an overview of the field of patinformatics––the science of analyzing patent information to discover relationships and trends. This is followed by a survey of many common analysis tasks in this field, and many of the software tools available to tackle these tasks. The survey is set out under the tasks of list cleanup and grouping of concepts; list generation; co-occurrency matrices and circle graphs; clustering of structured data; clustering of unstructured data; mapping document clusters; adding temporal component to cluster map; citation analysis; subject/action/object functions. The author concludes that patinformatics has developed very rapidly over the last few years, and provides continuing challenges and opportunities in making optimal use of the resources available to achieve reliable and meaningful results. Useful tables summarizing aspects of this survey are included.
ER  - 

TY  - JOUR
T1  - Discriminative clustering
JO  - Neurocomputing
VL  - 69
IS  - 1–3
SP  - 18
EP  - 41
PY  - 2005/12//
T2  - Neural Networks in Signal Processing2003 IEEE International Workshop on Neural Networks for Signal Processing
AU  - Kaski, Samuel
AU  - Sinkkonen, Janne
AU  - Klami, Arto
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2005.02.012
UR  - http://www.sciencedirect.com/science/article/pii/S0925231205001748
KW  - Discriminative clustering
KW  - Information metric
KW  - Learning metrics
KW  - Regularization
KW  - Vector quantization
AB  - A distributional clustering model for continuous data is reviewed and new methods for optimizing and regularizing it are introduced and compared. Based on samples of discrete-valued auxiliary data associated to samples of the continuous primary data, the continuous data space is partitioned into Voronoi regions that are maximally homogeneous in terms of the discrete data. Then only variation in the primary data associated to variation in the discrete data affects the clustering; the discrete data “supervises” the clustering. Because the whole continuous space is partitioned, new samples can be easily clustered by the continuous part of the data alone. In experiments, the approach is shown to produce more homogeneous clusters than alternative methods. Two regularization methods are demonstrated to further improve the results: an entropy-type penalty for unequal cluster sizes, and the inclusion of a model for the marginal density of the primary data. The latter is also interpretable as special kind of joint distribution modeling with tunable emphasis for discrimination and the marginal density.
ER  - 

TY  - JOUR
T1  - Rough clustering of sequential data
JO  - Data & Knowledge Engineering
VL  - 63
IS  - 2
SP  - 183
EP  - 199
PY  - 2007/11//
T2  - 
AU  - Kumar, Pradeep
AU  - Krishna, P. Radha
AU  - Bapi, Raju. S.
AU  - De, Supriya Kumar
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2007.01.003
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X07000055
KW  - Clustering
KW  - Rough sets
KW  - Constrained-similarity upper approximation
KW  - Web mining
KW  - Similarity metric
KW  - Sequential data
AB  - This paper presents a new indiscernibility-based rough agglomerative hierarchical clustering algorithm for sequential data. In this approach, the indiscernibility relation has been extended to a tolerance relation with the transitivity property being relaxed. Initial clusters are formed using a similarity upper approximation. Subsequent clusters are formed using the concept of constrained-similarity upper approximation wherein a condition of relative similarity is used as a merging criterion. We report results of experimentation on msnbc web navigation dataset that are intrinsically sequential in nature. We have compared the results of the proposed approach with that of the traditional hierarchical clustering algorithm using vector coding of sequences. The results establish the viability of the proposed approach. The rough clusters resulting from the proposed algorithm provide interpretations of different navigation orientations of users present in the sessions without having to fit each object into only one group. Such descriptions can help web miners to identify potential and meaningful groups of users.
ER  - 

TY  - JOUR
T1  - The phrase-based vector space model for automatic retrieval of free-text medical documents
JO  - Data & Knowledge Engineering
VL  - 61
IS  - 1
SP  - 76
EP  - 92
PY  - 2007/4//
T2  - Business Process ManagementWhere business processes and web services meet
AU  - Mao, Wenlei
AU  - Chu, Wesley W.
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2006.02.008
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X06000735
KW  - Information storage and retrieval/methods
KW  - Computing methodologies
KW  - Vector space model
KW  - Concept-based vector space model
KW  - Phrase-based vector space model
KW  - Information systems
KW  - Unified medical language system
AB  - Objective
To develop a document indexing scheme that improves the retrieval effectiveness for free-text medical documents.
Design
The phrase-based vector space model (VSM) uses multi-word phrases as indexing terms. Each phrase consists of a concept in the unified medical language system (UMLS) and its corresponding component word stems. The similarity between concepts are defined by their relations in a hypernym hierarchy derived from UMLS. After defining the similarity between two phrases by their stem overlaps and the similarity between the concepts they represent, we define the similarity between two documents as the cosine of the angle between their corresponding phrase vectors. This paper reports the development and the validation of the phrase-based VSM.
Measurement
We compare the retrieval effectiveness of different vector space models using two standard test collections, OHSUMED and Medlars. OHSUMED contains 105 queries and 14,430 documents, and Medlars contains 30 queries and 1033 documents. Each document in the test collections is judged by human experts to be either relevant or non-relevant to each query. The retrieval effectiveness is measured by precision and recall.
Results
The phrase-based VSM is significantly more effective than the current gold standard—the stem-based VSM. Such significant retrieval effectiveness improvements are observed in both the exhaustive search and cluster-based document retrievals.
Conclusion
The phrase-based VSM is a better indexing scheme than the stem-based VSM. Medical document retrieval using the phrase-based VSM is significantly more effective than that using the stem-based VSM.
ER  - 

TY  - JOUR
T1  - From keywords to semantic queries—Incremental query construction on the semantic web
JO  - Web Semantics: Science, Services and Agents on the World Wide Web
VL  - 7
IS  - 3
SP  - 166
EP  - 176
PY  - 2009/9//
T2  - The Web of Data
AU  - Zenz, Gideon
AU  - Zhou, Xuan
AU  - Minack, Enrico
AU  - Siberski, Wolf
AU  - Nejdl, Wolfgang
SN  - 1570-8268
DO  - http://dx.doi.org/10.1016/j.websem.2009.07.005
UR  - http://www.sciencedirect.com/science/article/pii/S1570826809000250
KW  - Semantic web
KW  - Keyword search
KW  - Query construction
AB  - Constructing semantic queries is a demanding task for human users, as it requires mastering a query language as well as the schema which has been used for storing the data. In this paper, we describe QUICK, a novel system for helping users to construct semantic queries in a given domain. QUICK combines the convenience of keyword search with the expressivity of semantic queries. Users start with a keyword query and then are guided through a process of incremental refinement steps to specify the query intention. We describe the overall design of QUICK, present the core algorithms to enable efficient query construction, and finally demonstrate the effectiveness of our system through an experimental study.
ER  - 

TY  - JOUR
T1  - TDM modeling and evaluation of different domain transforms for LSI
JO  - Neurocomputing
VL  - 72
IS  - 10–12
SP  - 2406
EP  - 2417
PY  - 2009/6//
T2  - Lattice Computing and Natural Computing (JCIS 2007) / Neural Networks in Intelligent Systems Designn (ISDA 2007)
AU  - Jaber, Tareq
AU  - Amira, Abbes
AU  - Milligan, Peter
SN  - 0925-2312
DO  - http://dx.doi.org/10.1016/j.neucom.2008.12.010
UR  - http://www.sciencedirect.com/science/article/pii/S0925231208005535
KW  - Latent semantic indexing
KW  - Information retrieval
KW  - Discrete cosine transform
KW  - Singular value decomposition
KW  - Cohen Daubechies Feauveau 9/7
KW  - Hard thresholding
KW  - Soft thresholding
AB  - Latent semantic indexing (LSI) is a popular technique used in information retrieval (IR) applications. This paper presents a novel evaluation strategy based on the use of image processing tools. The authors evaluate the use of the discrete cosine transform (DCT) and Cohen Daubechies Feauveau 9/7 (CDF9/7) wavelet transform as a preprocessing step for the singular value decomposition (SVD) step of the LSI system. In addition, the effect of different threshold types on the search results is examined. The results show that accuracy can be increased by applying both transforms as a preprocessing step, with better performance for the hard-threshold function. The choice of the best threshold value is a key factor in the transform process. This paper also describes the most effective structure for the database to facilitate efficient searching in the LSI system.
ER  - 

TY  - JOUR
T1  - External validation measures for K-means clustering: A data distribution perspective
JO  - Expert Systems with Applications
VL  - 36
IS  - 3, Part 2
SP  - 6050
EP  - 6061
PY  - 2009/4//
T2  - 
AU  - Wu, Junjie
AU  - Chen, Jian
AU  - Xiong, Hui
AU  - Xie, Ming
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2008.06.093
UR  - http://www.sciencedirect.com/science/article/pii/S0957417408004028
KW  - Cluster validation
KW  - K-means
KW  - External criteria
KW  - Normalization
AB  - Cluster validation is an important part of any cluster analysis. External measures such as entropy, purity and mutual information are often used to evaluate K-means clustering. However, whether these measures are indeed suitable for K-means clustering remains unknown. Along this line, in this paper, we show that a data distribution view is of great use to selecting the right measures for K-means clustering. Specifically, we first introduce the data distribution view of K-means, and the resultant uniform effect on highly imbalanced data sets. Eight external measures widely used in recent data mining tasks are also collected as candidates for K-means evaluation. Then, we demonstrate that only three measures, namely the variation of information (VI), the van Dongen criterion (VD) and the Mirkin metric (M), can detect the negative uniform effect of K-means in the clustering results. We also provide new normalization schemes for these three measures, i.e., VI norm ′ , VD norm ′ and M norm ′ , which enables the cross-data comparisons of clustering qualities. Finally, we explore some properties such as the consistency and sensitivity of the three measures, and give some advice on how to use them in K-means practice.
ER  - 

TY  - JOUR
T1  - Searching the world wide web: an evaluation of available tools and methodologies
JO  - Information and Software Technology
VL  - 39
IS  - 14–15
SP  - 985
EP  - 994
PY  - 1998///
T2  - 
AU  - Jenkins, Charlotte
AU  - Jackson, Mike
AU  - Burden, Peter
AU  - Wallis, Jon
SN  - 0950-5849
DO  - http://dx.doi.org/10.1016/S0950-5849(97)00061-X
UR  - http://www.sciencedirect.com/science/article/pii/S095058499700061X
KW  - Web
KW  - Search
KW  - Retrieval
AB  - Search Engines and Classified Directories have become essential tools for locating information on the World Wide Web. A consequence of increasing demand, as the volume of information on the Web has expanded, has been a vast growth in the number of tools available. Each one claims to be more comprehensive, more accurate and more intuitive to use than the last. This paper attempts to organise the available tools into a number of categories, according to their information acquisition and retrieval methods, with the intention of exposing the strengths and weaknesses of the various approaches. The importance and implications of Information Retrieval (IR) techniques are discussed. Description of the evolution of automated tools enables an insight into the aims of recent and future implementations
ER  - 

TY  - JOUR
T1  - Event detection from online news documents for supporting environmental scanning
JO  - Decision Support Systems
VL  - 36
IS  - 4
SP  - 385
EP  - 401
PY  - 2004/3//
T2  - Knowledge Management Technique
AU  - Wei, Chih-Ping
AU  - Lee, Yen-Hsien
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/S0167-9236(03)00028-9
UR  - http://www.sciencedirect.com/science/article/pii/S0167923603000289
KW  - Event detection
KW  - Environmental scanning
KW  - Information extraction
KW  - Text categorization
KW  - Event tracking
AB  - Environmental scanning, the acquisition and use of the information about events, trends, and relationships in an organization's external environment, permits an organization to adapt to its environment and to develop effective responses to secure or improve the organization's position in the future. Event detection technique that identifies the onset of new events from streams of news stories would facilitate the process of organization's environmental scanning. However, traditional event detection techniques generally adopted the feature co-occurrence approach that identifies whether a news story contains an unseen event by comparing the similarity of features between the new story and past news stories. Such feature-based event detection techniques greatly suffer from the word mismatch and inconsistent orientation problems and do not directly support event categorization and news stories filtering. In this study, we developed an information extraction-based event detection (NEED) technique that combines information extraction and text categorization techniques to address the problems inherent to traditional feature-based event detection techniques. Using a traditional feature-based event detection technique (i.e., INCR) as benchmarks, the empirical evaluation results showed that the proposed NEED technique improved the effectiveness of event detection measured by the tradeoff between miss and false alarm rates.
ER  - 

TY  - JOUR
T1  - Integrating information retrieval and data mining to discover project team coordination patterns
JO  - Decision Support Systems
VL  - 42
IS  - 2
SP  - 745
EP  - 758
PY  - 2006/11//
T2  - 
AU  - Lin, Fu-ren
AU  - Huang, Kuen-jin
AU  - Chen, Nian-shing
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2005.04.003
UR  - http://www.sciencedirect.com/science/article/pii/S0167923605000643
KW  - Information retrieval
KW  - Data mining
KW  - Sequential pattern analysis
KW  - Coordination pattern
AB  - This study integrates information retrieval and data mining techniques to discover project team coordination patterns from project documents written in Chinese. The coordination pattern of a project team describes the project execution process, including task category, execution sequence and duration, as well as the team member cooperation. The integration comprises two phases. The first phase extracts the most relevant keywords describing tasks executed by projects from unstructured or semi-structured documents using the mutual information estimate and the term weighting system. A concept hierarchy tree generated using the hierarchical clustering technique represents multiple levels of task categories. The second phase discovers project team coordination patterns through sequential pattern analysis. The proposed approach obtains encouraging results by mining coordination patterns from information system development projects. In the present era of the knowledge economy, the application of groupware to facilitate team coordination and collaboration streamlines the collection and analysis of project documents throughout the project life cycle. A project manager can visualize the project execution process of a team, and can anticipate the project outcomes based on discovered team coordination patterns. Accordingly, the proposed approach can be adapted to team projects that share certain characteristics with information system development projects.
ER  - 

TY  - JOUR
T1  - Status of text-mining techniques applied to biomedical text
JO  - Drug Discovery Today
VL  - 11
IS  - 7–8
SP  - 315
EP  - 325
PY  - 2006/4//
T2  - 
AU  - Erhardt, Ramón A-A.
AU  - Schneider, Reinhard
AU  - Blaschke, Christian
SN  - 1359-6446
DO  - http://dx.doi.org/10.1016/j.drudis.2006.02.011
UR  - http://www.sciencedirect.com/science/article/pii/S1359644606000122
AB  - Scientific progress is increasingly based on knowledge and information. Knowledge is now recognized as the driver of productivity and economic growth, leading to a new focus on the role of information in the decision-making process. Most scientific knowledge is registered in publications and other unstructured representations that make it difficult to use and to integrate the information with other sources (e.g. biological databases). Making a computer understand human language has proven to be a complex achievement, but there are techniques capable of detecting, distinguishing and extracting a limited number of different classes of facts. In the biomedical field, extracting information has specific problems: complex and ever-changing nomenclature (especially genes and proteins) and the limited representation of domain knowledge.
ER  - 

TY  - JOUR
T1  - Category Classification and Topic Discovery of Japanese and English News Articles
JO  - Electronic Notes in Theoretical Computer Science
VL  - 225
IS  - 
SP  - 51
EP  - 65
PY  - 2009/1/2/
T2  - Proceedings of the Irish Conference on the Mathematical Foundations of Computer Science and Information Technology (MFCSIT 2006)
AU  - Bracewell, David B.
AU  - Yan, Jiajun
AU  - Ren, Fuji
AU  - Kuroiwa, Shingo
SN  - 1571-0661
DO  - http://dx.doi.org/10.1016/j.entcs.2008.12.066
UR  - http://www.sciencedirect.com/science/article/pii/S157106610800529X
KW  - Category Classification
KW  - Topic Discovery
KW  - Topic Classification
KW  - Information Retrieval
KW  - News Domain
AB  - This paper presents algorithms for topic analysis of news articles. Topic analysis entails category classification and topic discovery and classification. Dealing with news has special requirements that standard classification approaches typically cannot handle. The algorithms proposed in this paper are able to do online training for both category and topic classification as well as discover new topics as they arise. Both algorithms are based on a keyword extraction algorithm that is applicable to any language that has basic morphological analysis tools. As such, both the category classification and topic discovery and classification algorithms can be easily used by multiple languages. Through experimentation the algorithms are shown to have high precision and recall in tests on English and Japanese.
ER  - 

TY  - JOUR
T1  - Clustering files of chemical structures using the Székely–Rizzo generalization of Ward's method
JO  - Journal of Molecular Graphics and Modelling
VL  - 28
IS  - 2
SP  - 187
EP  - 195
PY  - 2009/9//
T2  - 
AU  - Varin, Thibault
AU  - Bureau, Ronan
AU  - Mueller, Christoph
AU  - Willett, Peter
SN  - 1093-3263
DO  - http://dx.doi.org/10.1016/j.jmgm.2009.06.006
UR  - http://www.sciencedirect.com/science/article/pii/S109332630900076X
KW  - Clustering method
KW  - Distance coefficient
KW  - Energy clustering
KW  - Fingerprint
KW  - Fragment substructure
KW  - Joint between-within distance
KW  - Minimum variance clustering method
KW  - Soergel coefficient
KW  - Székely–Rizzo clustering method
KW  - Ward's clustering method
AB  - Ward's method is extensively used for clustering chemical structures represented by 2D fingerprints. This paper compares Ward clusterings of 14 datasets (containing between 278 and 4332 molecules) with those obtained using the Székely–Rizzo clustering method, a generalization of Ward's method. The clusters resulting from these two methods were evaluated by the extent to which the various classifications were able to group active molecules together, using a novel criterion of clustering effectiveness. Analysis of a total of 1400 classifications (Ward and Székely–Rizzo clustering methods, 14 different datasets, 5 different fingerprints and 10 different distance coefficients) demonstrated the general superiority of the Székely–Rizzo method. The distance coefficient first described by Soergel performed extremely well in these experiments, and this was also the case when it was used in simulated virtual screening experiments.
ER  - 

TY  - JOUR
T1  - On principal component analysis, cosine and Euclidean measures in information retrieval
JO  - Information Sciences
VL  - 177
IS  - 22
SP  - 4893
EP  - 4905
PY  - 2007/11/15/
T2  - 
AU  - Korenius, Tuomo
AU  - Laurikkala, Jorma
AU  - Juhola, Martti
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2007.05.027
UR  - http://www.sciencedirect.com/science/article/pii/S0020025507002630
KW  - Information retrieval
KW  - Cosine measure
KW  - Euclidean distance measure
KW  - Principal component analysis
KW  - Clustering
KW  - Documents
AB  - Clustering groups document objects represented as vectors. An extensive vector space may cause obstacles to applying these methods. Therefore, the vector space was reduced with principal component analysis (PCA). The conventional cosine measure is not the only choice with PCA, which involves the mean-correction of data. Since mean-correction changes the location of the origin, the angles between the document vectors also change. To avoid this, we used a connection between the cosine measure and the Euclidean distance in association with PCA, and grounded searching on the latter. We applied the single and complete linkage and Ward clustering to Finnish documents utilizing their relevance assessment as a new feature. After the normalization of the data PCA was run and relevant documents were clustered.
ER  - 

TY  - JOUR
T1  - Design of a multi-dimensional query expression for document warehouses
JO  - Information Sciences
VL  - 174
IS  - 1–2
SP  - 55
EP  - 79
PY  - 2005/6/28/
T2  - 
AU  - Tseng, Frank S.C.
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2004.08.010
UR  - http://www.sciencedirect.com/science/article/pii/S0020025504002427
KW  - Data warehousing
KW  - Document warehousing
KW  - Knowledge management
KW  - Multi-Dimensional eXpressions (MDX)
KW  - OLAP
AB  - During the past decade, data warehousing has been widely adopted in the business community. It provides multi-dimensional analyses on cumulated historical business data for helping contemporary administrative decision-makings. However, many data warehousing query language in present only provides on-line analytical processing (OLAP) for numeric data. For example, MDX (Multi-Dimensional eXpressions) has been proposed as a query language to allow describing multi-dimensional queries over databases with OLAP capabilities. Nevertheless, it is believed there is only about 20% information can be extracted from data warehouses concerning numeric data only, the other 80% information is hidden in non-numeric data or even in documents. Therefore, many researchers now advocate it is time to conduct research works on document warehousing to capture complete business intelligence. Document warehouses, unlike traditional document management systems, include extensive semantic information about documents, cross-document feature relations, and document grouping or clustering to provide a more accurate and more efficient access to text-oriented business intelligence. In this paper, we extend the structure of MDX into a new one containing complete constructs for querying document warehouses. The traditional MDX only contains SELECT, FROM, and WHERE clauses, which is not rich enough for document warehousing. In this paper, we present how to extend the language constructs to include GROUP BY, HAVING, and ORDER BY to design an SQL-like query language for document warehousing. The work is essential for establishing an infrastructure to help combining text processing with numeric OLAP processing technologies. Hopefully, the combination of data warehousing and document warehousing will be one of the most important kernels of knowledge management and customer relationship management applications.
ER  - 

TY  - JOUR
T1  - Aggregation pheromone density based data clustering
JO  - Information Sciences
VL  - 178
IS  - 13
SP  - 2816
EP  - 2831
PY  - 2008/7/1/
T2  - 
AU  - Ghosh, Ashish
AU  - Halder, Anindya
AU  - Kothari, Megha
AU  - Ghosh, Susmita
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2008.02.015
UR  - http://www.sciencedirect.com/science/article/pii/S0020025508000728
KW  - Aggregation pheromone
KW  - Ant colony optimization
KW  - Swarm intelligence
KW  - Data clustering
AB  - Ants, bees and other social insects deposit pheromone (a type of chemical) in order to communicate between the members of their community. Pheromone, that causes clumping or clustering behavior in a species and brings individuals into a closer proximity, is called aggregation pheromone. This article presents a new algorithm (called, APC) for clustering data sets based on this property of aggregation pheromone found in ants. An ant is placed at each location of a data point, and the ants are allowed to move in the search space to find points with higher pheromone density. The movement of an ant is governed by the amount of pheromone deposited at different points of the search space. More the deposited pheromone, more is the aggregation of ants. This leads to the formation of homogenous groups of data. The proposed algorithm is evaluated on a number of well-known benchmark data sets using different cluster validity measures. Results are compared with those obtained using two popular standard clustering techniques namely average linkage agglomerative and k-means clustering algorithm and with an ant-based method called adaptive time-dependent transporter ants for clustering (ATTA-C). Experimental results justify the potentiality of the proposed APC algorithm both in terms of the solution (clustering) quality as well as execution time compared to other algorithms for a large number of data sets.
ER  - 

TY  - JOUR
T1  - XML schema clustering with semantic and hierarchical similarity measures
JO  - Knowledge-Based Systems
VL  - 20
IS  - 4
SP  - 336
EP  - 349
PY  - 2007/5//
T2  - 
AU  - Nayak, Richi
AU  - Iryadi, Wina
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/j.knosys.2006.08.006
UR  - http://www.sciencedirect.com/science/article/pii/S095070510600150X
KW  - Clustering
KW  - Data mining
KW  - Document mining
KW  - XML
KW  - Semi-structured data
KW  - Semantic similarity
KW  - Structural similarity
KW  - Schema matching
AB  - With the growing popularity of XML as the data representation language, collections of the XML data are exploded in numbers. The methods are required to manage and discover the useful information from them for the improved document handling. We present a schema clustering process by organising the heterogeneous XML schemas into various groups. The methodology considers not only the linguistic and the context of the elements but also the hierarchical structural similarity. We support our findings with experiments and analysis.
ER  - 

TY  - JOUR
T1  - The perceived utility of standard ontologies in document management for specialized domains
JO  - International Journal of Human-Computer Studies
VL  - 64
IS  - 1
SP  - 15
EP  - 26
PY  - 2006/1//
T2  - 
AU  - Kim, Mihye
AU  - Compton, Paul
SN  - 1071-5819
DO  - http://dx.doi.org/10.1016/j.ijhcs.2005.06.006
UR  - http://www.sciencedirect.com/science/article/pii/S1071581905001503
KW  - Utility of standard ontologies
KW  - User-based document management
AB  - A user-based document management system has been developed for small communities on the Web. The system is based on the free annotation of documents by users. A number of annotation support tools are used to suggest possible annotations, including suggesting terms from external ontologies. This paper outlines some evaluation data on how users actually interact with the system in annotating their document especially on the use of standard ontologies. Results indicate that although an established external taxonomy can be useful in proposing annotation terms, users appear to be very selective in their use of the terms proposed and to have little interest in adhering to the particular hierarchical structure provided.
ER  - 

TY  - JOUR
T1  - Query routing for Web search engines: architecture and experiments
JO  - Computer Networks
VL  - 33
IS  - 1–6
SP  - 417
EP  - 429
PY  - 2000/6//
T2  - 
AU  - Sugiura, Atsushi
AU  - Etzioni, Oren
SN  - 1389-1286
DO  - http://dx.doi.org/10.1016/S1389-1286(00)00059-1
UR  - http://www.sciencedirect.com/science/article/pii/S1389128600000591
KW  - Web search
KW  - Query routing
KW  - Query expansion
KW  - Search engines
AB  - General-purpose search engines such as AltaVista and Lycos are notorious for returning irrelevant results in response to user queries. Consequently, thousands of specialized, topic-specific search engines (from VacationSpot.com to KidsHealth.org) have proliferated on the Web. Typically, topic-specific engines return far better results for `on topic' queries as compared with standard Web search engines. However, it is difficult for the casual user to identify the appropriate specialized engine for any given search. It is more natural for a user to issue queries at a particular Web site, and have these queries automatically routed to the appropriate search engine(s). This paper describes an automatic query routing system called Q-Pilot. Q-Pilot has an off-line component that creates an approximate model of each specialized search engine's topic. On line, Q-Pilot attempts to dynamically route each user query to the appropriate specialized search engines. In our experiments, Q-Pilot was able to identify the appropriate query category 70% of the time. In addition, Q-Pilot picked the best search engine for the query, as one of the top three picks out of its repository of 144 engines, about 40% of the time. This paper reports on Q-Pilot's architecture, the query expansion and clustering algorithms it relies on, and the results of our preliminary experiments.
ER  - 

TY  - JOUR
T1  - Large-scale data exploration with the hierarchically growing hyperbolic SOM
JO  - Neural Networks
VL  - 19
IS  - 6–7
SP  - 751
EP  - 761
PY  - 2006/7//
Y2  - 2006/8//
T2  - Advances in Self Organising Maps - WSOM’05Advances in Self-Organizing Maps - WSOM’05
AU  - Ontrup, Jörg
AU  - Ritter, Helge
SN  - 0893-6080
DO  - http://dx.doi.org/10.1016/j.neunet.2006.05.015
UR  - http://www.sciencedirect.com/science/article/pii/S0893608006000797
KW  - Hyperbolic self-organizing maps
KW  - Growing network
KW  - Hierarchical clustering
KW  - Text mining
AB  - We introduce the Hierarchically Growing Hyperbolic Self-Organizing Map (H2SOM) featuring two extensions of the HSOM (hyperbolic SOM): (i) a hierarchically growing variant that allows for incremental training with an automated adaptation of lattice size to achieve a prescribed quantization error and (ii) an approximate best match search that utilizes the special structure of the hyperbolic lattice to achieve a tremendous speed-up for large map sizes. Using the MNIST and the Reuters-21578 database as benchmark datasets, we show that the H2SOM yields a highly efficient visualization algorithm that combines the virtues of the SOM with extremely rapid training and low quantization and classification errors.
ER  - 

TY  - JOUR
T1  - Comparisons of the structure and infrastructure of Chinese and Indian Science and Technology
JO  - Technological Forecasting and Social Change
VL  - 74
IS  - 9
SP  - 1609
EP  - 1630
PY  - 2007/11//
T2  - Three Special Sections: Assessment of China's and India's Science and Technology Literature Nanotechnology Policy Minding the Gap: Previewing the Potential of Breakthrough Technologies
AU  - Kostoff, Ronald N.
AU  - Briggs, Michael B.
AU  - Rushenberg, Robert L.
AU  - Bowles, Christine A.
AU  - Pecht, Michael
AU  - Johnson, Dustin
AU  - Bhattacharya, Sujit
AU  - Icenhour, Alan S.
AU  - Nikodym, Kimberly
AU  - Barth, Ryan B.
AU  - Dodbele, Simha
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/j.techfore.2007.02.007
UR  - http://www.sciencedirect.com/science/article/pii/S004016250700056X
KW  - India
KW  - China
KW  - Science and Technology
KW  - Technology assessment
KW  - Research evaluation
KW  - Text mining
KW  - Bibliometrics
KW  - Computational linguistics
KW  - Clustering
KW  - Metrics
AB  - A comparison was made of the research output literatures of India and China. Both bibliometric and computational linguistics approaches were used in the comparison. China has rapidly outpaced India in both volume and citation performance of publications. China's rapid publication growth rate over the past two decades is continuing, while India's is re-starting after a relatively dormant period of almost two decades.
ER  - 

TY  - JOUR
T1  - Findex: improving search result use through automatic filtering categories
JO  - Interacting with Computers
VL  - 17
IS  - 2
SP  - 187
EP  - 206
PY  - 2005/3//
T2  - 
AU  - Käki, Mika
AU  - Aula, Anne
SN  - 0953-5438
DO  - http://dx.doi.org/10.1016/j.intcom.2005.01.001
UR  - http://www.sciencedirect.com/science/article/pii/S0953543805000020
KW  - Web search
KW  - Search user interface
KW  - Categorization
KW  - Clustering
KW  - Information access
AB  - Long result lists from web search engines can be tedious to use. We designed a text categorization algorithm and a filtering user interface to address the problem. The Findex system provides an overview of the results by presenting a list of the most frequent words and phrases as result categories next to the actual results. Selecting a category (word or phrase) filters the result list to show only the results containing it. An experiment with 20 participants was conducted to compare the category design to the de facto standard solution (Google-type ranked list interface). Results show that the users were 25% faster and 21% more accurate with our system. In particular, participants' speed of finding relevant results was 40% higher with the proposed system. Subjective ratings revealed significantly more positive attitudes towards the new system. Results indicate that the proposed design is feasible and beneficial.
ER  - 

TY  - JOUR
T1  - Visualized cognitive knowledge map integration for P2P networks
JO  - Decision Support Systems
VL  - 46
IS  - 4
SP  - 774
EP  - 785
PY  - 2009/3//
T2  - IT Decisions in Organizations
AU  - Lin, Fu-ren
AU  - Yu, Jen-Hung
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2008.11.020
UR  - http://www.sciencedirect.com/science/article/pii/S0167923608002169
KW  - Self-organizing map (SOM)
KW  - Knowledge map
KW  - Peer-to-peer (P2P)
KW  - Egocentric SOM (ESOM)
AB  - This study proposes a visualized cognitive knowledge map integration system, called VisCog, to facilitate knowledge management on P2P networks. By using the SOM (self-organized map)-like model, Egocentric SOM (ESOM), VisCog can merge the other peers' knowledge artifacts (e.g., documents) under a focal peer's knowledge structure and visually present the cognitive knowledge map of the P2P network. The experimental results from evaluating VisCog performance show that VisCog can retain an individual peer's knowledge structure while articulating with those of other peers to build its cognitive knowledge map.
ER  - 

TY  - JOUR
T1  - Genetic-based approaches in ranking function discovery and optimization in information retrieval — A framework
JO  - Decision Support Systems
VL  - 47
IS  - 4
SP  - 398
EP  - 407
PY  - 2009/11//
T2  - Smart Business Networks: Concepts and Empirical Evidence
AU  - Fan, Weiguo
AU  - Pathak, Praveen
AU  - Zhou, Mi
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2009.04.005
UR  - http://www.sciencedirect.com/science/article/pii/S016792360900089X
KW  - Information retrieval
KW  - Artificial intelligence
KW  - Evolutionary computations
KW  - Data fusion
KW  - Genetic algorithms
AB  - An Information Retrieval (IR) system consists of document collection, queries issued by users, and the matching/ranking functions used to rank documents in the predicted order of relevance for a given query. A variety of ranking functions have been used in the literature. But studies show that these functions do not perform consistently well across different contexts. In this paper we propose a two-stage integrated framework for discovering and optimizing ranking functions used in IR. The first stage, discovery process, is accomplished by intelligently leveraging the structural and statistical information available in HTML documents by using Genetic Programming techniques to yield novel ranking functions. In the second stage, the optimization process, document retrieval scores of various well-known ranking functions are combined using Genetic Algorithms. The overall discovery and optimization framework is tested on the well-known TREC collection of web documents for both the ad-hoc retrieval task and the routing task. Utilizing our framework we observe a significant increase in retrieval performance compared to some of the well-known stand alone ranking functions.
ER  - 

TY  - JOUR
T1  - Generating large-scale repositories of reusable artifacts for conceptual design of information systems
JO  - Decision Support Systems
VL  - 45
IS  - 4
SP  - 665
EP  - 680
PY  - 2008/11//
T2  - Information Technology and Systems in the Internet-Era
AU  - Han, Taedong
AU  - Purao, Sandeep
AU  - Storey, Veda C.
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2007.12.004
UR  - http://www.sciencedirect.com/science/article/pii/S0167923607002163
KW  - Reusable artifact
KW  - Domain fragment
KW  - Analysis pattern
KW  - Object-oriented design
KW  - Conceptual design
KW  - Knowledge reuse
KW  - Clustering
KW  - Automated reuse
AB  - The design and construction of reusable artifacts is a labor-intensive and demands significant time and effort from expert designers. The up-front investment needed for constructing repositories of reusable artifacts is, therefore, often difficult to justify without immediate benefits. This research proposes a methodology, called the Domain Fragment Creator (DFC), to overcome this problem. It relies on a new type of reusable artifact, called domain fragments that can be generated by examining commonalities and variations in existing designs. The paper describes the methodology and evaluates the quality of the resulting repository using metrics such as domain coverage.
ER  - 

TY  - JOUR
T1  - The concept of document warehousing for multi-dimensional modeling of textual-based business intelligence
JO  - Decision Support Systems
VL  - 42
IS  - 2
SP  - 727
EP  - 744
PY  - 2006/11//
T2  - 
AU  - Tseng, Frank S.C.
AU  - Chou, Annie Y.H.
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2005.02.011
UR  - http://www.sciencedirect.com/science/article/pii/S016792360500062X
KW  - Data warehousing
KW  - Document warehousing
KW  - Knowledge management
KW  - OLAP
AB  - During the past decade, data warehousing has been widely adopted in the business community. It provides multi-dimensional analyses on cumulated historical business data for helping contemporary administrative decision-making. Nevertheless, it is believed that only about 20% information can be extracted from data warehouses concerning numeric data only, the other 80% information is hidden in non-numeric data or even in documents. Therefore, many researchers now advocate that it is time to conduct research work on document warehousing to capture complete business intelligence. Document warehouses, unlike traditional document management systems, include extensive semantic information about documents, cross-document feature relations, and document grouping or clustering to provide a more accurate and more efficient access to text-oriented business intelligence. In this paper, we discuss the basic concept of document warehousing and present its formal definitions. Then, we propose a general system framework and elaborate some useful applications to illustrate the importance of document warehousing. The work is essential for establishing an infrastructure to help combine text processing with numeric OLAP processing technologies. The combination of data warehousing and document warehousing will be one of the most important kernels of knowledge management and customer relationship management applications.
ER  - 

TY  - JOUR
T1  - Recommender system based on workflow
JO  - Decision Support Systems
VL  - 48
IS  - 1
SP  - 237
EP  - 245
PY  - 2009/12//
T2  - Information product markets
AU  - Zhen, Lu
AU  - Huang, George Q.
AU  - Jiang, Zuhua
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2009.08.002
UR  - http://www.sciencedirect.com/science/article/pii/S0167923609001985
KW  - Recommender system
KW  - Workflow
KW  - Collaborative filtering
KW  - Knowledge management
AB  - This paper proposes a workflow-based recommender system model on supplying proper knowledge to proper members in collaborative team contexts rather than daily life scenarios, e.g., recommending commodities, films, news, etc. Within collaborative team contexts, more information could be utilized by recommender systems than ordinary daily life contexts. The workflow in collaborative team contains information about relationships among members, roles and tasks, which could be combined with collaborative filtering to obtain members' demands for knowledge. In addition, the work schedule information contained in the workflow could also be employed to determine the proper volume of knowledge that should be recommended to each member. In this paper, we investigate the mechanism of the workflow-based recommender system, and conduct a series of experiments referring to several real-world collaborative teams to validate the effectiveness and efficiency of the proposed methods.
ER  - 

TY  - JOUR
T1  - Nonnegative matrix factorization for spectral data analysis
JO  - Linear Algebra and its Applications
VL  - 416
IS  - 1
SP  - 29
EP  - 47
PY  - 2006/7/1/
T2  - Special Issue devoted to the Haifa 2005 conference on matrix theory
AU  - Pauca, V. Paul
AU  - Piper, J.
AU  - Plemmons, Robert J.
SN  - 0024-3795
DO  - http://dx.doi.org/10.1016/j.laa.2005.06.025
UR  - http://www.sciencedirect.com/science/article/pii/S002437950500340X
KW  - Nonnegative matrix factorization
KW  - Spectral data
KW  - Blind source separation
KW  - Data mining
KW  - Space object identification and classification
AB  - Data analysis is pervasive throughout business, engineering and science. Very often the data to be analyzed is nonnegative, and it is often preferable to take this constraint into account in the analysis process. Here we are concerned with the application of analyzing data obtained using astronomical spectrometers, which provide spectral data, which is inherently nonnegative. The identification and classification of space objects that cannot be imaged in the normal way with telescopes is an important but difficult problem for tracking thousands of objects, including satellites, rocket bodies, debris, and asteroids, in orbit around the earth. In this paper, we develop an effective nonnegative matrix factorization algorithm with novel smoothness constraints for unmixing spectral reflectance data for space object identification and classification purposes. Promising numerical results are presented using laboratory and simulated datasets.
ER  - 

TY  - JOUR
T1  - Use of aggregation pheromone density for image segmentation
JO  - Pattern Recognition Letters
VL  - 30
IS  - 10
SP  - 939
EP  - 949
PY  - 2009/7/15/
T2  - 
AU  - Ghosh, Susmita
AU  - Kothari, Megha
AU  - Halder, Anindya
AU  - Ghosh, Ashish
SN  - 0167-8655
DO  - http://dx.doi.org/10.1016/j.patrec.2009.03.004
UR  - http://www.sciencedirect.com/science/article/pii/S0167865509000464
KW  - Aggregation pheromone
KW  - Ant colony optimization
KW  - Clustering
KW  - Image segmentation
AB  - Ants, bees and other social insects deposit pheromone (a type of chemical) in order to communicate between the members of their community. Pheromone that causes clumping or clustering behavior in a species and brings individuals into a closer proximity, is called aggregation pheromone. This paper presents a novel method for image segmentation considering the aggregation behavior of ants. Image segmentation is viewed as a clustering problem which aims to partition a given set of pixels into a number of homogenous clusters/segments. At each location of a data point, representing a pixel, an ant is placed; and the ants are allowed to move in the search space to find out positions with higher pheromone density. The movement of an ant is governed by the amount of pheromone deposited at different positions of the search space. More the deposited pheromone, more is the aggregation of ants. This leads to the formation of homogenous groups of data. The proposed algorithm is evaluated on a number of different types of images using various cluster validity measures. Results are compared with those obtained using k-means and mean shift clustering algorithms and are found to be superior.
ER  - 

TY  - JOUR
T1  - Use of place information for improved event tracking
JO  - Information Processing & Management
VL  - 43
IS  - 2
SP  - 365
EP  - 378
PY  - 2007/3//
T2  - Special issue on AIRS2005: Information Retrieval Research in Asia
AU  - Jin, Yun
AU  - Myaeng, Sung Hyon
AU  - Jung, Yuchul
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2006.07.007
UR  - http://www.sciencedirect.com/science/article/pii/S0306457306001257
KW  - Place information
KW  - Event tracking
KW  - TDT
KW  - News article
AB  - The main purpose of topic detection and tracking (TDT) is to detect, group, and organize newspaper articles reporting on the same event. Since an event is a reported occurrence at a specific time and place and the unavoidable consequences, TDT can benefit from an explicit use of time and place information. In this work, we focused on place information, using time information as in the previous research. News articles were analyzed for their characteristics of place information, and a new topic tracking method was proposed to incorporate the analysis results on place information. Experiments show that appropriate use of place information extracted automatically from news articles indeed helps event tracking that identify news articles reporting on the same events.
ER  - 

TY  - JOUR
T1  - A comparison of feature selection methods for an evolving RSS feed corpus
JO  - Information Processing & Management
VL  - 42
IS  - 6
SP  - 1491
EP  - 1512
PY  - 2006/12//
T2  - Special Issue on Informetrics
AU  - Prabowo, Rudy
AU  - Thelwall, Mike
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2006.03.018
UR  - http://www.sciencedirect.com/science/article/pii/S0306457306000392
KW  - Feature selection
KW  - Chi-square
KW  - Mutual information
KW  - Information gain
AB  - Previous researchers have attempted to detect significant topics in news stories and blogs through the use of word frequency-based methods applied to RSS feeds. In this paper, the three statistical feature selection methods: χ2, Mutual Information (MI) and Information Gain (I) are proposed as alternative approaches for ranking term significance in an evolving RSS feed corpus. The extent to which the three methods agree with each other on determining the degree of the significance of a term on a certain date is investigated as well as the assumption that larger values tend to indicate more significant terms. An experimental evaluation was carried out with 39 different levels of data reduction to evaluate the three methods for differing degrees of significance. The three methods showed a significant degree of disagreement for a number of terms assigned an extremely large value. Hence, the assumption that the larger a value, the higher the degree of the significance of a term should be treated cautiously. Moreover, MI and I show significant disagreement. This suggests that MI is different in the way it ranks significant terms, as MI does not take the absence of a term into account, although I does. I, however, has a higher degree of term reduction than MI and χ2. This can result in loosing some significant terms. In summary, χ2 seems to be the best method to determine term significance for RSS feeds, as χ2 identifies both types of significant behavior. The χ2 method, however, is far from perfect as an extremely high value can be assigned to relatively insignificant terms.
ER  - 

TY  - JOUR
T1  - An empirical study of query expansion and cluster-based retrieval in language modeling approach
JO  - Information Processing & Management
VL  - 43
IS  - 2
SP  - 302
EP  - 314
PY  - 2007/3//
T2  - Special issue on AIRS2005: Information Retrieval Research in Asia
AU  - Na, Seung-Hoon
AU  - Kang, In-Su
AU  - Roh, Ji-Eun
AU  - Lee, Jong-Hyeok
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2006.07.003
UR  - http://www.sciencedirect.com/science/article/pii/S0306457306001294
KW  - Parsimonious translation model
KW  - Query expansion
KW  - Cluster-based retrieval
KW  - Information retrieval
KW  - Language model
AB  - The term mismatch problem in information retrieval is a critical problem, and several techniques have been developed, such as query expansion, cluster-based retrieval and dimensionality reduction to resolve this issue. Of these techniques, this paper performs an empirical study on query expansion and cluster-based retrieval. We examine the effect of using parsimony in query expansion and the effect of clustering algorithms in cluster-based retrieval. In addition, query expansion and cluster-based retrieval are compared, and their combinations are evaluated in terms of retrieval performance by performing experimentations on seven test collections of NTCIR and TREC.
ER  - 

TY  - JOUR
T1  - Inference and evaluation of the multinomial mixture model for text clustering
JO  - Information Processing & Management
VL  - 43
IS  - 5
SP  - 1260
EP  - 1280
PY  - 2007/9//
T2  - Patent Processing
AU  - Rigouste, Loïs
AU  - Cappé, Olivier
AU  - Yvon, François
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2006.11.001
UR  - http://www.sciencedirect.com/science/article/pii/S0306457306001944
KW  - Multinomial mixture model
KW  - Expectation-maximization
KW  - Gibbs sampling
KW  - Text clustering
AB  - In this article, we investigate the use of a probabilistic model for unsupervised clustering in text collections. Unsupervised clustering has become a basic module for many intelligent text processing applications, such as information retrieval, text classification or information extraction.

Recent proposals have been made of probabilistic clustering models, which build “soft” theme-document associations. These models allow to compute, for each document, a probability vector whose values can be interpreted as the strength of the association between documents and clusters. As such, these vectors can also serve to project texts into a lower-dimensional “semantic” space. These models however pose non-trivial estimation problems, which are aggravated by the very high dimensionality of the parameter space.

The model considered in this paper consists of a mixture of multinomial distributions over the word counts, each component corresponding to a different theme. We propose a systematic evaluation framework to contrast various estimation procedures for this model. Starting with the expectation-maximization (EM) algorithm as the basic tool for inference, we discuss the importance of initialization and the influence of other features, such as the smoothing strategy or the size of the vocabulary, thereby illustrating the difficulties incurred by the high dimensionality of the parameter space. We empirically show that, in the case of text processing, these difficulties can be alleviated by introducing the vocabulary incrementally, due to the specific profile of the word count distributions. Using the fact that the model parameters can be analytically integrated out, we finally show that Gibbs sampling on the theme configurations is tractable and compares favorably to the basic EM approach.
ER  - 

TY  - JOUR
T1  - Automatic new topic identification using multiple linear regression
JO  - Information Processing & Management
VL  - 42
IS  - 4
SP  - 934
EP  - 950
PY  - 2006/7//
T2  - 
AU  - Ozmutlu, Seda
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2005.10.002
UR  - http://www.sciencedirect.com/science/article/pii/S0306457305001378
KW  - Search engine
KW  - Topic identification
KW  - Regression
KW  - ANOVA
KW  - Information retrieval
AB  - The purpose of this study is to provide automatic new topic identification of search engine query logs, and estimate the effect of statistical characteristics of search engine queries on new topic identification. By applying multiple linear regression and multi-factor ANOVA on a sample data log from the Excite search engine, we demonstrated that the statistical characteristics of Web search queries, such as time interval, search pattern and position of a query in a user session, are effective on shifting to a new topic. Multiple linear regression is also a successful tool for estimating topic shifts and continuations. The findings of this study provide statistical proof for the relationship between the non-semantic characteristics of Web search queries and the occurrence of topic shifts and continuations.
ER  - 

TY  - JOUR
T1  - Bayesian network model for semi-structured document classification
JO  - Information Processing & Management
VL  - 40
IS  - 5
SP  - 807
EP  - 827
PY  - 2004/9//
T2  - Bayesian Networks and Information Retrieval
AU  - Denoyer, Ludovic
AU  - Gallinari, Patrick
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2004.04.009
UR  - http://www.sciencedirect.com/science/article/pii/S030645730400041X
KW  - Statistical learning
KW  - Bayesian networks
KW  - Categorization
KW  - Structured documents
KW  - XML
KW  - Machine learning
AB  - Recently, a new community has started to emerge around the development of new information research methods for searching and analyzing semi-structured and XML like documents. The goal is to handle both content and structural information, and to deal with different types of information content (text, image, etc.). We consider here the task of structured document classification. We propose a generative model able to handle both structure and content which is based on Bayesian networks. We then show how to transform this generative model into a discriminant classifier using the method of Fisher kernel. The model is then extended for dealing with different types of content information (here text and images). The model was tested on three databases: the classical webKB corpus composed of HTML pages, the new INEX corpus which has become a reference in the field of ad-hoc retrieval for XML documents, and a multimedia corpus of Web pages.
ER  - 

TY  - JOUR
T1  - Adapting a diagnostic problem-solving model to information retrieval
JO  - Information Processing & Management
VL  - 36
IS  - 2
SP  - 313
EP  - 330
PY  - 2000/3/1/
T2  - 
AU  - Syu, Inien
AU  - Lang, S.D
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(99)00037-0
UR  - http://www.sciencedirect.com/science/article/pii/S0306457399000370
KW  - Information retrieval
KW  - Bayesian networks
KW  - Neural networks
KW  - Competitive–activation mechanism
AB  - In this paper, a competition-based connectionist model for diagnostic problem-solving is adapted to information retrieval. In this model, we treat documents as ‘disorders’ and user information needs as ‘manifestations’, and a competitive activation mechanism is used which converges to a set of documents that best explain the given user information needs. By combining the ideas of Bayesian inferencing and diagnostic inferencing using parsimonious covering theory, this model removes many difficulties of direct application of Bayesian inference, such as the unrealistically large number of conditional probabilities required in the knowledge base, the computational complexity, and certain unreasonable independence assumptions. Also, Bayesian inference strengthens the parsimonious covering theory by providing a likelihood measure which can be used to rank documents as well as to guide the retrieval to the most likely set of documents. We also incorporate thesaurus information to provide semantic relevance among the index terms. Our experimental results using 4 standard document collections demonstrate the efficiency and the retrieval effectiveness of the thesaurus-based model, comparable to or better than that of various information retrieval models reported in the literature.
ER  - 

TY  - JOUR
T1  - Turning telecommunications call details to churn prediction: a data mining approach
JO  - Expert Systems with Applications
VL  - 23
IS  - 2
SP  - 103
EP  - 112
PY  - 2002/8//
T2  - 
AU  - Wei, Chih-Ping
AU  - Chiu, I-Tang
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/S0957-4174(02)00030-1
UR  - http://www.sciencedirect.com/science/article/pii/S0957417402000301
KW  - Data mining
KW  - Telecommunications data mining
KW  - Churn prediction
KW  - Churn management
KW  - Classification analysis
KW  - Decision tree induction
KW  - Multi-classifier class-combiner approach
AB  - As deregulation, new technologies, and new competitors open up the mobile telecommunications industry, churn prediction and management has become of great concern to mobile service providers. A mobile service provider wishing to retain its subscribers needs to be able to predict which of them may be at-risk of changing services and will make those subscribers the focus of customer retention efforts. In response to the limitations of existing churn-prediction systems and the unavailability of customer demographics in the mobile telecommunications provider investigated, we propose, design, and experimentally evaluate a churn-prediction technique that predicts churning from subscriber contractual information and call pattern changes extracted from call details. This proposed technique is capable of identifying potential churners at the contract level for a specific prediction time-period. In addition, the proposed technique incorporates the multi-classifier class-combiner approach to address the challenge of a highly skewed class distribution between churners and non-churners. The empirical evaluation results suggest that the proposed call-behavior-based churn-prediction technique exhibits satisfactory predictive effectiveness when more recent call details are employed for the churn prediction model construction. Furthermore, the proposed technique is able to demonstrate satisfactory or reasonable predictive power within the one-month interval between model construction and churn prediction. Using a previous demographics-based churn-prediction system as a reference, the lift factors attained by our proposed technique appear largely satisfactory.
ER  - 

TY  - JOUR
T1  - Two novel feature selection approaches for web page classification
JO  - Expert Systems with Applications
VL  - 36
IS  - 1
SP  - 260
EP  - 272
PY  - 2009/1//
T2  - 
AU  - Chen, Chih-Ming
AU  - Lee, Hahn-Ming
AU  - Chang, Yu-Jung
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2007.09.008
UR  - http://www.sciencedirect.com/science/article/pii/S0957417407004253
KW  - Feature selection
KW  - Fuzzy decision making
KW  - Web page classification
KW  - Discriminating power measure
AB  - To help the growing qualitative and quantitative demands for information from the WWW, efficient automatic Web page classifiers are urgently needed. However, a classifier applied to the WWW faces a huge-scale dimensionality problem since it must handle millions of Web pages, tens of thousands of features, and hundreds of categories. When it comes to practical implementation, reducing the dimensionality is a critically important challenge. In this paper, we propose a fuzzy ranking analysis paradigm together with a novel relevance measure, discriminating power measure (DPM), to effectively reduce the input dimensionality from tens of thousands to a few hundred with zero rejection rate and small decrease in accuracy. The two-level promotion method based on fuzzy ranking analysis is proposed to improve the behavior of each relevance measure and combine those measures to produce a better evaluation of features. Additionally, the DPM measure has low computation cost and emphasizes on both positive and negative discriminating features. Also, it emphasizes classification in parallel order, rather than classification in serial order. In our experimental results, the fuzzy ranking analysis is useful for validating the uncertain behavior of each relevance measure. Moreover, the DPM reduces input dimensionality from 10,427 to 200 with zero rejection rate and with less than 5% decline (from 84.5% to 80.4%) in the test accuracy. Furthermore, to consider the impacts on classification accuracy for the proposed DPM, the experimental results of China Time and Reuter-21578 datasets have demonstrated that the DPM provides major benefit to promote document classification accuracy rate. The results also show that the DPM indeed can reduce both redundancy and noise features to set up a better classifier.
ER  - 

TY  - JOUR
T1  - Enhancement of fuzzy clustering by mechanisms of partial supervision
JO  - Fuzzy Sets and Systems
VL  - 157
IS  - 13
SP  - 1733
EP  - 1759
PY  - 2006/7/1/
T2  - 
AU  - Bouchachia, Abdelhamid
AU  - Pedrycz, Witold
SN  - 0165-0114
DO  - http://dx.doi.org/10.1016/j.fss.2006.02.015
UR  - http://www.sciencedirect.com/science/article/pii/S0165011406000960
KW  - Semi-supervised clustering
KW  - FCM
KW  - Distance functions
KW  - Quality of clustering
KW  - Kernel-based distance
KW  - Classification
AB  - Semi-supervised (or partial) fuzzy clustering plays an important and unique role in discovering hidden structure in data realized in presence of a certain quite limited fraction of labeled patterns. The objective of this study is to investigate and quantify the effect of various distance functions (distances) on the performance of the clustering mechanisms. The underlying goal of endowing the clustering algorithms with a higher level of flexibility is done via the use of various distances. The enhancement of this character is evaluated by means of a comprehensive assessment of quality of clusters, their ensuing discrimination abilities and the accuracy of clusters themselves. In addition to the standard Euclidean distance being commonly exploited in fuzzy clustering, three more versatile and adaptive distance measures are considered such as its weighted version, a full adaptive distance, and a kernel-based distance. Using Fuzzy C-Means (FCM) coming in its generic format, we show its semi-supervised enhancements, derive detailed formulas and analyze their effectiveness. The improvements of semi-supervised clustering are empirically evaluated and numerically quantified with the use of several Machine Learning data sets.
ER  - 

TY  - CHAP
AU  - Perugini, Saverio
AU  - Ramakrishnan, Naren
T1  - Personalizing Interactions with Information Systems
A2  - 
BT  - Advances in Computers
PB  - Elsevier
PY  - 2003///
VL  - Volume 57
SP  - 323
EP  - 382
T2  - 
SN  - 0065-2458
DO  - http://dx.doi.org/10.1016/S0065-2458(03)57007-3
UR  - http://www.sciencedirect.com/science/article/pii/S0065245803570073
AB  - Personalization constitutes the mechanisms and technologies necessary to customize information access to the end-user. It can be defined as the automatic adjustment of information content, structure, and presentation tailored to the individual. In this chapter, we study personalization from the viewpoint of personalizing interaction. The survey covers mechanisms for information-finding on the web, advanced information retrieval systems, dialog-based applications, and mobile access paradigms. Specific emphasis is placed on studying how users interact with an information system and how the system can encourage and foster interaction. This helps bring out the role of the personalization system as a facilitator which reconciles the user's mental model with the underlying information system's organization. Three tiers of personalization systems are presented, paying careful attention to interaction considerations. These tiers show how progressive levels of sophistication in interaction can be achieved. The chapter also surveys systems support technologies and niche application domains.
ER  - 

TY  - JOUR
T1  - A symbolic approach to automatic multiword term structuring
JO  - Computer Speech & Language
VL  - 19
IS  - 4
SP  - 524
EP  - 542
PY  - 2005/10//
T2  - Special issue on Multiword Expression
AU  - SanJuan, Eric
AU  - Dowdall, James
AU  - Ibekwe-SanJuan, Fidelia
AU  - Rinaldi, Fabio
SN  - 0885-2308
DO  - http://dx.doi.org/10.1016/j.csl.2005.02.002
UR  - http://www.sciencedirect.com/science/article/pii/S0885230805000057
AB  - This paper presents a three-level structuring of multiword terms basing on lexical inclusion, WordNet similarity and a clustering approach. Term clustering by automatic data analysis methods offers an interesting way of organizing a domain’s knowledge structure, useful for several information-oriented tasks like science and technology watch, textmining, computer-assisted ontology population, Question Answering (Q–A). This paper explores how this three-level term structuring brings to light the knowledge structures from a corpus of genomics and compares the mapping of the domain topics against a hand-built ontology (the GENIA ontology). Ways of integrating the results into a Q–A system are discussed.
ER  - 

TY  - JOUR
T1  - Understanding knowledge management system usage antecedents: An integration of social cognitive theory and task technology fit
JO  - Information & Management
VL  - 45
IS  - 6
SP  - 410
EP  - 417
PY  - 2008/9//
T2  - 
AU  - Lin, Tung-Ching
AU  - Huang, Chien-Chih
SN  - 0378-7206
DO  - http://dx.doi.org/10.1016/j.im.2008.06.004
UR  - http://www.sciencedirect.com/science/article/pii/S0378720608000839
KW  - Knowledge management systems
KW  - Self-efficacy
KW  - Social cognitive theory
KW  - Task technology fit
AB  - The factors influencing KMS usage are of major concern to the MIS community. Among the diverse theories employed to help understand this is task technology fit (TTF), which considers the needed technological characteristics of the task as a major factor determining usage. This theory, however, ignores the personal cognition dimension, which has been found to affect the use of an IS. By integrating TTF and social cognitive theory (SCT), we attempted to determine the key factors affecting KMS usage in IT, the organizational task, and personal cognition. Through a survey of 192 KMS users, task interdependence, perceived task technology fit, KMS self-efficacy, and personal outcome expectations were found to have substantial influences on KMS usage. Among the key factors, KMS self-efficacy was found to be especially important as it was substantially and positively correlated to perceived task technology fit, personal and performance-related outcome expectations, and KMS usage.
ER  - 

TY  - JOUR
T1  - Book reports
JO  - Computers & Mathematics with Applications
VL  - 50
IS  - 10–12
SP  - 1801
EP  - 1824
PY  - 2005/11//
Y2  - 2005/12//
T2  - 

SN  - 0898-1221
DO  - http://dx.doi.org/10.1016/j.camwa.2005.10.001
UR  - http://www.sciencedirect.com/science/article/pii/S0898122105004281
ER  - 

TY  - JOUR
T1  - Knowledge management system architecture: a bridge between KM consultants and technologists
JO  - International Journal of Information Management
VL  - 24
IS  - 1
SP  - 87
EP  - 98
PY  - 2004/2//
T2  - 
AU  - Chua, Alton
SN  - 0268-4012
DO  - http://dx.doi.org/10.1016/j.ijinfomgt.2003.10.003
UR  - http://www.sciencedirect.com/science/article/pii/S0268401203001233
KW  - Knowledge management
KW  - System architecture
KW  - KM products
KW  - KM technology
AB  - Many scholars and practitioners recognise the power of technology in supporting knowledge management (KM) activities. However, in most KM literatures, the discussion on related technology is either given cursory treatment or confined largely to product-specific features. This reflects a division between KM consultants and KM technologists. For this reason, the objective of this paper is to develop a knowledge management systems architecture that seeks to bridge the gap between consultants and technologists. The architecture is intended to provide a common framework for both to review how technologies are used to support KM processes.
ER  - 

TY  - JOUR
T1  - The intelligent approach to register-transfer level synthesis
JO  - Artificial Intelligence in Engineering
VL  - 12
IS  - 3
SP  - 143
EP  - 147
PY  - 1998/7//
T2  - 
AU  - Zongfu, Yan
AU  - Mingye, Liu
AU  - Hantao, Song
SN  - 0954-1810
DO  - http://dx.doi.org/10.1016/S0954-1810(96)00027-1
UR  - http://www.sciencedirect.com/science/article/pii/S0954181096000271
KW  - intelligent CAD
KW  - high-level synthesis
KW  - RTL synthesis
KW  - technology mapping
KW  - intelligent binding component library
AB  - This paper describes a VHDL high-level synthesis system HLS/BIT with the emphasis on its register-transfer level (RTL) binding and technology mapping subsystem that adopts an intelligent technique to build the intelligent binding component library (IBCL). The component instantiated mechanism and the knowledge-based approach to RTL technology mapping are also presented.
ER  - 

TY  - CHAP
AU  - Sanford, Anthony J.
AU  - Moxey, Linda M.
T1  - 3 What are mental models made of?
A2  - Gert Rickheit and Christopher Habel
BT  - Advances in Psychology
PB  - North-Holland
PY  - 1999///
VL  - Volume 128
SP  - 57
EP  - 76
T2  - Mental Models in Discourse Processing and Reasoning
SN  - 0166-4115
DO  - http://dx.doi.org/10.1016/S0166-4115(99)80047-8
UR  - http://www.sciencedirect.com/science/article/pii/S0166411599800478
AB  - Publisher Summary
This chapter examines the utility of the mental model as an explanatory device for characterizing the comprehension of discourse. The chapter focuses on two specific points: the kind of mental representations result from language input and the kind of representations are utilized in the process of comprehension or production. The mental models can only be understood in terms of content. The chapter focuses on models that relate to number and quantification and to a lesser extent on ones that are about space. The notion of mental model is relatively hollow unless it is integrated with ideas about the way situation-specific knowledge is recruited and organized and the way language manipulates the content of the models. It is the content of specific mental models that is important for understanding text comprehension. The chapter illustrates the ways background knowledge might serve to influence interpretation by defining the kind of model results by using examples from the work on quantification. The argument is that all of the interesting things to say about mental models are about content rather than form.
ER  - 

TY  - JOUR
T1  - Clinical concept maps in nursing education: An effective way to link theory and practice
JO  - Nurse Education in Practice
VL  - 5
IS  - 6
SP  - 348
EP  - 352
PY  - 2005/11//
T2  - 
AU  - Hicks-Moore, Sandee L.
SN  - 1471-5953
DO  - http://dx.doi.org/10.1016/j.nepr.2005.05.003
UR  - http://www.sciencedirect.com/science/article/pii/S1471595305000636
KW  - Concept maps
KW  - Critical thinking
KW  - Clinical instruction
AB  - Summary
Historically, nursing care plans have been utilized in nursing education to identify actual and potential health problems. The rigid structure of these plans often makes it challenging for students to assimilate data to identify and understand the many diverse patient problems. To promote critical thinking, improve problem-solving skills and foster understanding of the interrelationships among patient’s health concerns, second year baccalaureate students developed and implemented concept maps using the nursing process in the clinical setting. An overview of what concept maps are, how the concept maps were developed and utilized in the clinical setting, implications for clinical teaching and outcomes of the experience are highlighted.
ER  - 

TY  - JOUR
T1  - A knowledge-based approach for retrieving scenario-specific medical text documents
JO  - Control Engineering Practice
VL  - 13
IS  - 9
SP  - 1105
EP  - 1121
PY  - 2005/9//
T2  - Modelling and Control of Biomedical SystemsModelling and Control of Biomedical Systems
AU  - Chu, Wesley W.
AU  - Liu, Zhenyu
AU  - Mao, Wenlei
AU  - Zou, Qinghua
SN  - 0967-0661
DO  - http://dx.doi.org/10.1016/j.conengprac.2004.12.011
UR  - http://www.sciencedirect.com/science/article/pii/S096706610500002X
KW  - Knowledge-based information retrieval
KW  - Indexing
KW  - Vector space model
KW  - Query expansion
AB  - Medical free-text queries often share the same scenario. A scenario represents a repeating task in healthcare. For example, a specific scenario is searching for treatment methods for a specific disease, where “treatment” is a term indicating the scenario. To support scenario-specific retrieval, in this paper we present a new knowledge-based approach to address these problems. In addition, we describe a testbed system developed using the approach. Our specific implementation uses the UMLS Metathesaurus and semantic structure to extract key concepts from a free text. The approach uses phrase-based indexing to represent similar concepts, and query expansion to improve matching query terms with the terms in the document. The system formulates the query based on the user's input and the selected scenario template such as “disease, treatment” or “disease, diagnosis.” Thus, it is able to retrieve documents relevant to the specific scenario. Evaluating the system using the standard OSHMED corpus, our empirical results validate the effectiveness of this new approach over the traditional text retrieval techniques.
ER  - 

TY  - JOUR
T1  - Databases and the geometry of knowledge
JO  - Data & Knowledge Engineering
VL  - 61
IS  - 2
SP  - 207
EP  - 227
PY  - 2007/5//
T2  - 
AU  - Brazhnik, Olga
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2006.05.005
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X06000917
KW  - Data models
KW  - Knowledge acquisition
KW  - Ontologies
KW  - Concept mapping
KW  - Data integration
AB  - Based on a geometrical interpretation of knowledge space, this work defines relationships between data, concepts and models, and establishes a framework for their integration. Concepts encapsulate our knowledge and provide a basis for data acquisition. They change as we learn more. Every discipline operates with a specific set of concepts organized in models. In order to co-process data collected against different concepts, we need to map the underlying concepts. Modal Intentional Actual (MIA) structure, derived from knowledge representation theory, enables the separation of data from hypotheses, and provides a consistent approach for building data models, concept mapping and defining complex relationships, which are represented by morphisms in category theory. Essential data elements from enterprise modeling techniques provide specifications for storing concepts and morphisms in a database.
ER  - 

TY  - JOUR
T1  - Discovering shared conceptualizations in folksonomies
JO  - Web Semantics: Science, Services and Agents on the World Wide Web
VL  - 6
IS  - 1
SP  - 38
EP  - 53
PY  - 2008/2//
T2  - Semantic Web and Web 2.0
AU  - Jäschke, Robert
AU  - Hotho, Andreas
AU  - Schmitz, Christoph
AU  - Ganter, Bernhard
AU  - Stumme, Gerd
SN  - 1570-8268
DO  - http://dx.doi.org/10.1016/j.websem.2007.11.004
UR  - http://www.sciencedirect.com/science/article/pii/S1570826807000546
KW  - Folksonomies
KW  - Tagging
KW  - Formal Concept Analysis
AB  - Social bookmarking tools are rapidly emerging on the Web. In such systems users are setting up lightweight conceptual structures called folksonomies. Unlike ontologies, shared conceptualizations are not formalized, but rather implicit. We present a new data mining task, the mining of all frequent tri-concepts, together with an efficient algorithm, for discovering these implicit shared conceptualizations. Our approach extends the data mining task of discovering all closed itemsets to three-dimensional data structures to allow for mining folksonomies. We provide a formal definition of the problem, and present an efficient algorithm for its solution. Finally, we show the applicability of our approach on three large real-world examples.
ER  - 

TY  - JOUR
T1  - An adaptive flocking algorithm for performing approximate clustering
JO  - Information Sciences
VL  - 179
IS  - 18
SP  - 3059
EP  - 3078
PY  - 2009/8/21/
T2  - 
AU  - Folino, Gianluigi
AU  - Forestiero, Agostino
AU  - Spezzano, Giandomenico
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2009.05.017
UR  - http://www.sciencedirect.com/science/article/pii/S0020025509002321
KW  - Swarm intelligence
KW  - Spatial clustering
KW  - Bioinspired algorithms
AB  - This paper presents an approach based on an adaptive bio-inspired method to make state of the art clustering algorithms scalable and to provide them with an any-time behavior. The method is based on the biology-inspired paradigm of a flock of birds, i.e. a population of simple agents interacting locally with each other and with the environment. The flocking algorithm provides a model of decentralized adaptive organization useful to solve complex optimization, classification and distributed control problems. This approach avoids the sequential search of canonical clustering algorithms and permits a scalable implementation.

The method is applied to design two novel clustering algorithms based on the main principles of two popular clustering algorithms: DBSCAN and SNN. This apporach can identify clusters of widely varying shapes and densities and is able to extract an approximate view of the clusters whenever it is required. Both the algorithms have been evaluated on synthetic and real world data sets and the impact of the flocking strategy on performance has been evaluated.
ER  - 

TY  - JOUR
T1  - Efficient semantic search on DHT overlays
JO  - Journal of Parallel and Distributed Computing
VL  - 67
IS  - 5
SP  - 604
EP  - 616
PY  - 2007/5//
T2  - 
AU  - Zhu, Yingwu
AU  - Hu, Yiming
SN  - 0743-7315
DO  - http://dx.doi.org/10.1016/j.jpdc.2007.01.005
UR  - http://www.sciencedirect.com/science/article/pii/S0743731507000196
KW  - Peer-to-peer
KW  - Vector space model
KW  - Locality sensitive hashing
KW  - Semantic indexing
KW  - Semantic locating
KW  - Top term
KW  - Recall
AB  - Distributed hash tables (DHTs) excel at exact-match lookups, but they do not directly support complex queries such as semantic search that is based on content. In this paper, we propose a novel approach to efficient semantic search on DHT overlays. The basic idea is to place indexes of semantically close files into same peer nodes with high probability by exploiting information retrieval algorithms and locality sensitive hashing. A query for retrieving semantically close files is answered with high recall by consulting only a small number (e.g., 10–20) of nodes that stores the indexes of the files semantically close to the query. Our approach adds only index information to peer nodes, imposing only a small storage overhead. Via detailed simulations, we show that our approach achieves high recall for queries at very low cost, i.e., the number of nodes visited for a query is about 10–20, independent of the overlay size.
ER  - 

TY  - JOUR
T1  - Algorithms and applications for approximate nonnegative matrix factorization
JO  - Computational Statistics & Data Analysis
VL  - 52
IS  - 1
SP  - 155
EP  - 173
PY  - 2007/9/15/
T2  - 
AU  - Berry, Michael W.
AU  - Browne, Murray
AU  - Langville, Amy N.
AU  - Pauca, V. Paul
AU  - Plemmons, Robert J.
SN  - 0167-9473
DO  - http://dx.doi.org/10.1016/j.csda.2006.11.006
UR  - http://www.sciencedirect.com/science/article/pii/S0167947306004191
KW  - Nonnegative matrix factorization
KW  - Text mining
KW  - Spectral data analysis
KW  - Email surveillance
KW  - Conjugate gradient
KW  - Constrained least squares
AB  - The development and use of low-rank approximate nonnegative matrix factorization (NMF) algorithms for feature extraction and identification in the fields of text mining and spectral data analysis are presented. The evolution and convergence properties of hybrid methods based on both sparsity and smoothness constraints for the resulting nonnegative matrix factors are discussed. The interpretability of NMF outputs in specific contexts are provided along with opportunities for future work in the modification of NMF algorithms for large-scale and time-varying data sets.
ER  - 

TY  - JOUR
T1  - Biomedical knowledge navigation by literature clustering
JO  - Journal of Biomedical Informatics
VL  - 40
IS  - 2
SP  - 114
EP  - 130
PY  - 2007/4//
T2  - 
AU  - Yamamoto, Yasunori
AU  - Takagi, Toshihisa
SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2006.07.004
UR  - http://www.sciencedirect.com/science/article/pii/S1532046406000815
KW  - Clustering
KW  - Text-mining
KW  - Automatic labeling
KW  - Summarization
AB  - There is an urgent need for a system that facilitates surveys by biomedical researchers and the subsequent formulation of hypotheses based on the knowledge stored in literature. One approach is to cluster papers discussing a topic of interest and reveal its sub-topics that allow researchers to acquire an overview of the topic. We developed such a system called McSyBi. It accepts a set of citation data retrieved with PubMed and hierarchically and non-hierarchically clusters them based on the titles and the abstracts using statistical and natural language processing methods. A novel point is that McSyBi allows its users to change the clustering by entering a MeSH term or UMLS Semantic Type, and therefore they can see a set of citation data from multiple aspects. We evaluated McSyBi quantitatively and qualitatively: clustering of 27 sets of citation data (40643 different papers) and scrutiny of several resultant clusters. While non-hierarchical clustering provides us with an overview of the target topic, hierarchical clustering allows us to see more details and relationships among citation data. McSyBi is freely available at http://textlens.hgc.jp/McSyBi/.
ER  - 

TY  - JOUR
T1  - Expertise visualization: An implementation and study based on cognitive fit theory
JO  - Decision Support Systems
VL  - 42
IS  - 3
SP  - 1539
EP  - 1557
PY  - 2006/12//
T2  - 
AU  - Huang, Zan
AU  - Chen, Hsinchun
AU  - Guo, Fei
AU  - Xu, Jennifer J.
AU  - Wu, Soushan
AU  - Chen, Wun-Hwa
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/j.dss.2006.01.006
UR  - http://www.sciencedirect.com/science/article/pii/S0167923606000054
KW  - Expertise management
KW  - Information visualization
KW  - Self-organizing map
KW  - Multidimensional scaling
KW  - Visualization evaluation
KW  - Cognitive fit theory
AB  - Expertise management systems are being widely adopted in organizations to manage tacit knowledge. These systems have successfully applied many information technologies developed for document management to support collection, processing, and distribution of expertise information. In this paper, we report a study on the potential of applying visualization techniques to support more effective and efficient exploration of the expertise information space. We implemented two widely applied dimensionality reduction visualization techniques, the self-organizing map (SOM) and multidimensional scaling (MDS), to generate compact but distorted (due to the dimensionality reduction) map visualizations for an expertise data set. We tested cognitive fit theory in our context by comparing the SOM and MDS displays with a standard table display for five tasks selected from a low-level, domain-independent visual task taxonomy. The experimental results based on a survey data set of research expertise of the business school professors suggested that using both SOM and MDS visualizations is more efficient than using the table display for the associate, compare, distinguish, and cluster tasks, but not the rank task. Users generally achieved comparable effectiveness for all tasks using the tabular and map displays in our study.
ER  - 

TY  - JOUR
T1  - Data clustering analysis in a multidimensional space
JO  - Information Sciences
VL  - 112
IS  - 1–4
SP  - 267
EP  - 295
PY  - 1998/12//
T2  - 
AU  - Bouguettaya, A.
AU  - Le Viet, Q.
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/S0020-0255(98)10037-3
UR  - http://www.sciencedirect.com/science/article/pii/S0020025598100373
AB  - Cluster analysis techniques are used to classify objects into groups based on their similarities. There is a wide choice of methods with different requirements in computer resources. We present the result of a fairly exhaustive study to evaluate three commonly used clustering algorithms, namely, single linkage, complete linkage, and centroid. The cluster analysis study is conducted in the two dimensional (2-D) space. Three types of statistical distribution are used. Two different types of distances to compare lists of objects are also used. The results point to some startling similarities in the behavior and stability of all clustering methods.
ER  - 

TY  - JOUR
T1  - Integration of complex archeology digital libraries: An ETANA-DL experience
JO  - Information Systems
VL  - 33
IS  - 7–8
SP  - 699
EP  - 723
PY  - 2008/11//
Y2  - 2008/12//
T2  - Advances in Data and Service Integration
AU  - Shen, Rao
AU  - Vemuri, Naga Srinivas
AU  - Fan, Weiguo
AU  - Fox, Edward A.
SN  - 0306-4379
DO  - http://dx.doi.org/10.1016/j.is.2008.02.006
UR  - http://www.sciencedirect.com/science/article/pii/S0306437908000173
KW  - Information integration
KW  - Digital library integration
KW  - Metadata
KW  - Integration
KW  - 5S
KW  - Schema mapping
KW  - Information visualization
KW  - Archaeology
KW  - Semantic interoperability
KW  - Exploring service
KW  - Multi-dimensional browsing
AB  - In this paper, we formalize the digital library (DL) integration problem and propose an overall approach based on the 5S (streams, structures, spaces, scenarios, and societies) framework. We then apply that framework to integrate domain-specific (archeological) DLs, illustrating our solutions for key problems in DL integration. An integrated Archeological DL, ETANA-DL, is used as a case study to justify and evaluate our DL integration approach. More specifically, we develop a minimal metamodel for archeological DLs within the 5S theory. We implement the 5SSuite tool set to cover the process of union DL generation, including requirements gathering, conceptual modeling, rapid prototyping, and code generation. 5SSuite consists of 5SGraph, 5SGen, and SchemaMapper, each of which plays an important role in DL integration. We also propose an approach to integrated DLs based on the 5S formalism, which provides a systematic method to design and implement DL exploring services.
ER  - 

TY  - CHAP
AU  - Van Horn, John Darrell
AU  - Wolfe, John
AU  - Agnoli, Autumn
AU  - Woodward, Jeffrey
AU  - Schmitt, Michael
AU  - Dobson, James
AU  - Schumacher, Sarene
AU  - Vance, Bennet
T1  - Neuroimaging Databases as a Resource for Scientific Discovery
A2  - 
BT  - International Review of Neurobiology
PB  - Academic Press
PY  - 2005///
VL  - Volume 66
SP  - 55
EP  - 87
T2  - Neuroimaging, Part A
SN  - 0074-7742
DO  - http://dx.doi.org/10.1016/S0074-7742(05)66002-3
UR  - http://www.sciencedirect.com/science/article/pii/S0074774205660023
ER  - 

TY  - JOUR
T1  - A framework for mining evolving trends in Web data streams using dynamic learning and retrospective validation
JO  - Computer Networks
VL  - 50
IS  - 10
SP  - 1488
EP  - 1512
PY  - 2006/7/14/
T2  - I. Web DynamicsII. Algorithms for Distributed Systems
AU  - Nasraoui, Olfa
AU  - Rojas, Carlos
AU  - Cardona, Cesar
SN  - 1389-1286
DO  - http://dx.doi.org/10.1016/j.comnet.2005.10.021
UR  - http://www.sciencedirect.com/science/article/pii/S1389128605003671
KW  - Mining evolving data streams
KW  - Web clickstreams
KW  - Web mining
KW  - Text mining
KW  - User profiles
AB  - The expanding and dynamic nature of the Web poses enormous challenges to most data mining techniques that try to extract patterns from Web data, such as Web usage and Web content. While scalable data mining methods are expected to cope with the size challenge, coping with evolving trends in noisy data in a continuous fashion, and without any unnecessary stoppages and reconfigurations is still an open challenge. This dynamic and single pass setting can be cast within the framework of mining evolving data streams. The harsh restrictions imposed by the “you only get to see it once” constraint on stream data calls for different computational models that may furthermore bring some interesting surprises when it comes to the behavior of some well known similarity measures during clustering, and even validation. In this paper, we study the effect of similarity measures on the mining process and on the interpretation of the mined patterns in the harsh single pass requirement scenario. We propose a simple similarity measure that has the advantage of explicitly coupling the precision and coverage criteria to the early learning stages. Even though the cosine similarity, and its close relative such as the Jaccard measure, have been prevalent in the majority of Web data clustering approaches, they may fail to explicitly seek profiles that achieve high coverage and high precision simultaneously. We also formulate a validation strategy and adapt several metrics rooted in information retrieval to the challenging task of validating a learned stream synopsis in dynamic environments. Our experiments confirm that the performance of the MinPC similarity is generally better than the cosine similarity, and that this outperformance can be expected to be more pronounced for data sets that are more challenging in terms of the amount of noise and/or overlap, and in terms of the level of change in the underlying profiles/topics (known sub-categories of the input data) as the input stream unravels. In our simulations, we study the task of mining and tracking trends and profiles in evolving text and Web usage data streams in a single pass, and under different trend sequencing scenarios.
ER  - 

TY  - JOUR
T1  - Clustering distributed data streams in peer-to-peer environments
JO  - Information Sciences
VL  - 176
IS  - 14
SP  - 1952
EP  - 1985
PY  - 2006/7/22/
T2  - Streaming Data Mining
AU  - Bandyopadhyay, Sanghamitra
AU  - Giannella, Chris
AU  - Maulik, Ujjwal
AU  - Kargupta, Hillol
AU  - Liu, Kun
AU  - Datta, Souptik
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2005.11.007
UR  - http://www.sciencedirect.com/science/article/pii/S0020025505003038
KW  - Data mining
KW  - Data streams
KW  - Cluster analysis
KW  - Peer-to-peer
AB  - This paper describes a technique for clustering homogeneously distributed data in a peer-to-peer environment like sensor networks. The proposed technique is based on the principles of the K-Means algorithm. It works in a localized asynchronous manner by communicating with the neighboring nodes. The paper offers extensive theoretical analysis of the algorithm that bounds the error in the distributed clustering process compared to the centralized approach that requires downloading all the observed data to a single site. Experimental results show that, in contrast to the case when all the data is transmitted to a central location for application of the conventional clustering algorithm, the communication cost (an important consideration in sensor networks which are typically equipped with limited battery power) of the proposed approach is significantly smaller. At the same time, the accuracy of the obtained centroids is high and the number of samples which are incorrectly labeled is also small.
ER  - 

TY  - JOUR
T1  - Advanced structural joins using element distribution
JO  - Information Sciences
VL  - 176
IS  - 22
SP  - 3300
EP  - 3331
PY  - 2006/11/22/
T2  - 
AU  - Kim, Jongik
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2006.01.002
UR  - http://www.sciencedirect.com/science/article/pii/S0020025506000132
KW  - XML
KW  - Path query
KW  - Structural join
KW  - Element tree
AB  - For accelerating a structural join operation, current techniques focus on skipping elements that do not contribute to the results. They make use of external index structures (e.g. B+ tree) to determine a bunch of elements to be skipped. However, external indexes are too heavy for a structural join and the overhead of index lookups can reduce the benefit of skipping. In this paper, we proposed element trees and distribution encoded bitmaps for efficient element skipping. With proposed techniques, we can exploit the distribution of elements as well as the context information of a query for efficient skipping of unnecessary elements.
ER  - 

TY  - JOUR
T1  - Bottom-up discovery of frequent rooted unordered subtrees
JO  - Information Sciences
VL  - 179
IS  - 1–2
SP  - 70
EP  - 88
PY  - 2009/1/2/
T2  - 
AU  - Bei, Yijun
AU  - Chen, Gang
AU  - Shou, Lidan
AU  - Li, Xiaoyan
AU  - Dong, Jinxiang
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2008.08.020
UR  - http://www.sciencedirect.com/science/article/pii/S0020025508003617
KW  - Rooted unordered tree
KW  - Frequent tree
KW  - Tree mining
KW  - XML mining
KW  - Bottom-up mining
AB  - In the past decade, XML has emerged as the standard language for information exchanging over the Internet. Due to its tree-structure paradigm, XML is superior for its capability of storing, querying, and manipulating complex data. Therefore, discovering frequent tree patterns over tree-structured data has become an interesting topic for XML data management. In this paper, we propose a tree mining algorithm, named BUXMiner, for finding a special class of frequent trees, called rooted unordered trees, from a tree-structured database. BUXMiner employs an efficient bottom-up approach to enumerate all candidate trees over a compact global tree guide and computes the frequent trees based on the tree guide. In addition to BUXMiner, we also propose a mining approach called BUMXMiner to discover the maximal frequent rooted unordered trees. We compare BUXMiner with previous tree-structure mining algorithms, namely XQPMinerTID and FastXMiner, which were also proposed to discover rooted unordered trees. The experimental results show that our algorithm outperforms XQPMinerTID and FastXMiner in terms of efficiency. The performance results from real-world applications also indicate the usefulness of our proposed tree mining algorithms in a variety of web applications, such as analysis of web page access patterns and mining frequent XML query patterns for caching.
ER  - 

TY  - JOUR
T1  - UPGMA clustering revisited: A weight-driven approach to transitive approximation
JO  - International Journal of Approximate Reasoning
VL  - 42
IS  - 3
SP  - 174
EP  - 191
PY  - 2006/8//
T2  - 
AU  - Dawyndt, Peter
AU  - De Meyer, Hans
AU  - De Baets, Bernard
SN  - 0888-613X
DO  - http://dx.doi.org/10.1016/j.ijar.2005.11.001
UR  - http://www.sciencedirect.com/science/article/pii/S0888613X05000940
KW  - Hierarchical clustering
KW  - Similarity-based clustering
KW  - Similarity matrix
KW  - Transitive approximation
KW  - Transitivity
KW  - UPGMA clustering
AB  - A new algorithm is proposed for generating min-transitive approximations of a given similarity matrix (i.e. a symmetric matrix with elements in the unit interval and diagonal elements equal to one). Different approximations are generated depending on the choice of an aggregation operator that plays a central role in the algorithm. If the maximum operator is chosen, then the approximation coincides with the min-transitive closure of the given similarity matrix. In case of the arithmetic mean, a transitive approximation is generated which is, on the average, as close to the given similarity matrix as the approximation generated by the UPGMA hierarchical clustering algorithm. The new algorithm also allows to generate approximations in a purely ordinal setting. As this new approach is weight-driven, the partition tree associated to the corresponding min-transitive approximation can be built layer by layer. Numerical tests carried out on synthetic data are used for comparing different approximations generated by the new algorithm with certain approximations obtained by classical methods.
ER  - 

TY  - JOUR
T1  - Distributed data mining and agents
JO  - Engineering Applications of Artificial Intelligence
VL  - 18
IS  - 7
SP  - 791
EP  - 807
PY  - 2005/10//
T2  - 
AU  - da Silva, Josenildo C.
AU  - Giannella, Chris
AU  - Bhargava, Ruchita
AU  - Kargupta, Hillol
AU  - Klusch, Matthias
SN  - 0952-1976
DO  - http://dx.doi.org/10.1016/j.engappai.2005.06.004
UR  - http://www.sciencedirect.com/science/article/pii/S095219760500076X
KW  - Multi-agent systems
KW  - Distributed data mining
KW  - Clustering
AB  - Multi-agent systems (MAS) offer an architecture for distributed problem solving. Distributed data mining (DDM) algorithms focus on one class of such distributed problem solving tasks—analysis and modeling of distributed data. This paper offers a perspective on DDM algorithms in the context of multi-agents systems. It discusses broadly the connection between DDM and MAS. It provides a high-level survey of DDM, then focuses on distributed clustering algorithms and some potential applications in multi-agent-based problem solving scenarios. It reviews algorithms for distributed clustering, including privacy-preserving ones. It describes challenges for clustering in sensor-network environments, potential shortcomings of the current algorithms, and future work accordingly. It also discusses confidentiality (privacy preservation) and presents a new algorithm for privacy-preserving density-based clustering.
ER  - 

TY  - JOUR
T1  - Linear manifold clustering in high dimensional spaces by stochastic search
JO  - Pattern Recognition
VL  - 40
IS  - 10
SP  - 2672
EP  - 2684
PY  - 2007/10//
T2  - 
AU  - Haralick, Robert
AU  - Harpaz, Rave
SN  - 0031-3203
DO  - http://dx.doi.org/10.1016/j.patcog.2007.01.020
UR  - http://www.sciencedirect.com/science/article/pii/S0031320307000477
KW  - Clustering
KW  - Linear manifold
KW  - Subspace
KW  - Histogram thresholding
KW  - Data exploration
KW  - Random projections
AB  - Classical clustering algorithms are based on the concept that a cluster center is a single point. Clusters which are not compact around a single point are not candidates for classical clustering approaches. In this paper we present a new clustering paradigm in which the cluster center is a linear manifold. Clusters are groups of points compact around a linear manifold. A linear manifold of dimension 0 is a point. So clustering around a center point is a special case of linear manifold clustering. Linear manifold clustering (LMCLUS) identifies subsets of the data which are embedded in arbitrary oriented lower dimensional linear manifolds. Minimal subsets of points are repeatedly sampled to construct trial linear manifolds of various dimensions. Histograms of the distances of the points to each trial manifold are computed. The sampling corresponding to the histogram having the best separation between a mode near zero and the rest is selected and the data points are partitioned on the basis of the best separation. The repeated sampling then continues recursively on each block of the partitioned data. A broad evaluation of some 100 experiments over real and synthetic data sets demonstrates the general superiority of this algorithm over any of the competing algorithms in terms of accuracy and computation time. Its expected computational time is linearly proportional to the data set dimension and data set size. Its accuracy ranges from near 0.90 to 0.99 depending on the experiment and is generally much higher than the accuracy of the competing clustering algorithms.
ER  - 

TY  - JOUR
T1  - Neurolinguistic approach to natural language processing with applications to medical text analysis
JO  - Neural Networks
VL  - 21
IS  - 10
SP  - 1500
EP  - 1510
PY  - 2008/12//
T2  - ICONIP 2007
AU  - Duch, Włodzisław
AU  - Matykiewicz, Paweł
AU  - Pestian, John
SN  - 0893-6080
DO  - http://dx.doi.org/10.1016/j.neunet.2008.05.008
UR  - http://www.sciencedirect.com/science/article/pii/S0893608008000956
KW  - Natural language processing
KW  - Semantic networks
KW  - Spreading activation networks
KW  - Medical ontologies
KW  - Vector models in NLP
AB  - Understanding written or spoken language presumably involves spreading neural activation in the brain. This process may be approximated by spreading activation in semantic networks, providing enhanced representations that involve concepts not found directly in the text. The approximation of this process is of great practical and theoretical interest. Although activations of neural circuits involved in representation of words rapidly change in time snapshots of these activations spreading through associative networks may be captured in a vector model. Concepts of similar type activate larger clusters of neurons, priming areas in the left and right hemisphere. Analysis of recent brain imaging experiments shows the importance of the right hemisphere non-verbal clusterization. Medical ontologies enable development of a large-scale practical algorithm to re-create pathways of spreading neural activations. First concepts of specific semantic type are identified in the text, and then all related concepts of the same type are added to the text, providing expanded representations. To avoid rapid growth of the extended feature space after each step only the most useful features that increase document clusterization are retained. Short hospital discharge summaries are used to illustrate how this process works on a real, very noisy data. Expanded texts show significantly improved clustering and may be classified with much higher accuracy. Although better approximations to the spreading of neural activations may be devised a practical approach presented in this paper helps to discover pathways used by the brain to process specific concepts, and may be used in large-scale applications.
ER  - 

TY  - JOUR
T1  - Comparing clusterings—an information based distance
JO  - Journal of Multivariate Analysis
VL  - 98
IS  - 5
SP  - 873
EP  - 895
PY  - 2007/5//
T2  - 
AU  - Meilă, Marina
SN  - 0047-259X
DO  - http://dx.doi.org/10.1016/j.jmva.2006.11.013
UR  - http://www.sciencedirect.com/science/article/pii/S0047259X06002016
KW  - Agreement measures
KW  - Clustering
KW  - Comparing partitions
KW  - Information theory
KW  - Mutual information
KW  - Similarity measures
AB  - This paper proposes an information theoretic criterion for comparing two partitions, or clusterings, of the same data set. The criterion, called variation of information (VI), measures the amount of information lost and gained in changing from clustering C to clustering C ′ . The basic properties of VI are presented and discussed. We focus on two kinds of properties: (1) those that help one build intuition about the new criterion (in particular, it is shown the VI is a true metric on the space of clusterings), and (2) those that pertain to the comparability of VI values over different experimental conditions. As the latter properties have rarely been discussed explicitly before, other existing comparison criteria are also examined in their light. Finally we present the VI from an axiomatic point of view, showing that it is the only “sensible” criterion for comparing partitions that is both aligned to the lattice and convexely additive. As a consequence, we prove an impossibility result for comparing partitions: there is no criterion for comparing partitions that simultaneously satisfies the above two desirable properties and is bounded.
ER  - 

TY  - JOUR
T1  - A matching algorithm for measuring the structural similarity between an XML document and a DTD and its applications
JO  - Information Systems
VL  - 29
IS  - 1
SP  - 23
EP  - 46
PY  - 2004/3//
T2  - 
AU  - Bertino, Elisa
AU  - Guerrini, Giovanna
AU  - Mesiti, Marco
SN  - 0306-4379
DO  - http://dx.doi.org/10.1016/S0306-4379(03)00031-0
UR  - http://www.sciencedirect.com/science/article/pii/S0306437903000310
KW  - Structural similarity
KW  - Document classification
KW  - Structure evolution
KW  - Structural queries
KW  - Selective dissemination of documents
KW  - Document protection
AB  - In this paper we propose a matching algorithm for measuring the structural similarity between an XML document and a DTD. The matching algorithm, by comparing the document structure against the one the DTD requires, is able to identify commonalities and differences. Differences can be due to the presence of extra elements with respect to those the DTD requires and to the absence of required elements. The evaluation of commonalities and differences gives raise to a numerical rank of the structural similarity. Moreover, in the paper, some applications of the matching algorithm are discussed. Specifically, the matching algorithm is exploited for the classification of XML documents against a set of DTDs, the evolution of the DTD structure, the evaluation of structural queries, the selective dissemination of XML documents, and the protection of XML document contents.
ER  - 

TY  - JOUR
T1  - Automatic construction of hypertexts for self-referencing: the Hyper-TextBook project
JO  - Information Systems
VL  - 28
IS  - 7
SP  - 769
EP  - 790
PY  - 2003/10//
T2  - 
AU  - Crestani, Fabio
AU  - Melucci, Massimo
SN  - 0306-4379
DO  - http://dx.doi.org/10.1016/S0306-4379(02)00082-0
UR  - http://www.sciencedirect.com/science/article/pii/S0306437902000820
AB  - We present the results of the Hyper-TextBook project. The aim of the project was to design, develop and test a methodology and a tool for the fully automatic authoring of hypertexts from full-text documents. The target documents were textbooks because of their specific characteristics and usage, and the project aimed at automatically creating hypertextual versions of textbooks, i.e. hyper-textbooks. In this first phase of the project hyper-textbooks have been designed and implemented to be used mostly as self-reference sources. The results of a formative design evaluation of a hyper-textbook support the conclusion that our conceptual structure and navigation enhance the usability of the textbook with respect to both paper and online versions of the same textbook. Yet, this evaluation indicates a number of possible ways to improve it.
ER  - 

TY  - JOUR
T1  - Query representation by structured concept threads with application to interactive video retrieval
JO  - Journal of Visual Communication and Image Representation
VL  - 20
IS  - 2
SP  - 104
EP  - 116
PY  - 2009/2//
T2  - Special issue on Emerging Techniques for Multimedia Content Sharing, Search and Understanding
AU  - Wang, Dong
AU  - Wang, Zhikun
AU  - Li, Jianmin
AU  - Zhang, Bo
AU  - Li, Xirong
SN  - 1047-3203
DO  - http://dx.doi.org/10.1016/j.jvcir.2008.12.001
UR  - http://www.sciencedirect.com/science/article/pii/S104732030800120X
KW  - Interactive video retrieval
KW  - Query concept mapping
KW  - Concept thread
KW  - Structured query formulation
KW  - Concept tf-idf
KW  - Semantic feedback
KW  - Query representation
KW  - TRECVID
AB  - In this paper, we provide a new formulation for video queries as structured combination of concept threads, contributing to the general query-by-concept paradigm. Occupying a low-dimensional region in the concept space, concept thread defines a ranked list of video documents ordered by their combined concept predictions. This localized representation incorporates the previous concept based formulation as a special case and extends the restricted AND concept combination logic to a two-level concept inference network. We apply this new formulation to interactive video retrieval and utilize abundant feedback information to mine the latent semantic concept threads for answering complex query semantics. Simulative experiments which are conducted on two years’ TRECVID data sets with two sets of concept lexicons demonstrate the advantage of the proposed formulation. The proposed query formulation offers some 60% improvements over the simple browsing search baseline in nearly real time. It has clear advantages over c-tf-idf and achieves better results over the state-of-the-art online ordinal reranking approach. Meanwhile, it not only alleviates user’s workload significantly but also is robust to user mislabeling errors.
ER  - 

TY  - JOUR
T1  - Modeling share dynamics by extracting competition structure
JO  - Physica D: Nonlinear Phenomena
VL  - 198
IS  - 1–2
SP  - 51
EP  - 73
PY  - 2004/11/1/
T2  - 
AU  - Kimura, Masahiro
AU  - Saito, Kazumi
AU  - Ueda, Naonori
SN  - 0167-2789
DO  - http://dx.doi.org/10.1016/j.physd.2004.08.022
UR  - http://www.sciencedirect.com/science/article/pii/S0167278904003331
KW  - Web dynamics
KW  - Multivariate time-series modeling
KW  - Learning algorithm
KW  - Clustering
KW  - Prediction
AB  - We propose a new method for analyzing multivariate time-series data governed by competitive dynamics such as fluctuations in the number of visitors to Web sites that form a market. To achieve this aim, we construct a probabilistic dynamical model using a replicator equation and derive its learning algorithm. This method is implemented for both categorizing the sites into groups of competitors and predicting the future shares of the sites based on the observed time-series data. We confirmed experimentally, using synthetic data, that the method successfully identifies the true model structure, and exhibits better prediction performance than conventional methods that leave competitive dynamics out of consideration. We also experimentally demonstrated, using real data of visitors to 20 Web sites offering streaming video contents, that the method suggested a reasonable competition structure that conventional methods failed to find and that it outperformed them in terms of predictive performance.
ER  - 

TY  - JOUR
T1  - The PRET A Rapporter framework: Evaluating digital libraries from the perspective of information work
JO  - Information Processing & Management
VL  - 44
IS  - 1
SP  - 4
EP  - 21
PY  - 2008/1//
T2  - Evaluation of Interactive Information Retrieval Systems
AU  - Blandford, Ann
AU  - Adams, Anne
AU  - Attfield, Simon
AU  - Buchanan, George
AU  - Gow, Jeremy
AU  - Makri, Stephann
AU  - Rimmer, Jon
AU  - Warwick, Claire
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2007.01.021
UR  - http://www.sciencedirect.com/science/article/pii/S0306457307000362
KW  - Digital library
KW  - Usability evaluation
KW  - HCI
KW  - Case study
AB  - The strongest tradition of IR systems evaluation has focused on system effectiveness; more recently, there has been a growing interest in evaluation of Interactive IR systems, balancing system and user-oriented evaluation criteria. In this paper we shift the focus to considering how IR systems, and particularly digital libraries, can be evaluated to assess (and improve) their fit with users’ broader work activities. Taking this focus, we answer a different set of evaluation questions that reveal more about the design of interfaces, user–system interactions and how systems may be deployed in the information working context. The planning and conduct of such evaluation studies share some features with the established methods for conducting IR evaluation studies, but come with a shift in emphasis; for example, a greater range of ethical considerations may be pertinent. We present the PRET A Rapporter framework for structuring user-centred evaluation studies and illustrate its application to three evaluation studies of digital library systems.
ER  - 

TY  - JOUR
T1  - Evaluating WordBars in exploratory Web search scenarios
JO  - Information Processing & Management
VL  - 44
IS  - 2
SP  - 485
EP  - 510
PY  - 2008/3//
T2  - Evaluating Exploratory Search SystemsDigital Libraries in the Context of Users’ Broader Activities
AU  - Hoeber, Orland
AU  - Yang, Xue Dong
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2007.07.003
UR  - http://www.sciencedirect.com/science/article/pii/S0306457307001288
KW  - Web search
KW  - Query refinement
KW  - Search results exploration
KW  - Visualization
KW  - Interaction
KW  - User evaluations
AB  - Web searchers commonly have difficulties crafting queries to fulfill their information needs; even after they are able to craft a query, they often find it challenging to evaluate the results of their Web searches. Sources of these problems include the lack of support for constructing and refining queries, and the static nature of the list-based representations of Web search results. WordBars has been developed to assist users in their Web search and exploration tasks. This system provides a visual representation of the frequencies of the terms found in the first 100 document surrogates returned from an initial query, in the form of a histogram. Exploration of the search results is supported through term selection in the histogram, resulting in a re-sorting of the search results based on the use of the selected terms in the document surrogates. Terms from the histogram can be easily added or removed from the query, generating a new set of search results. Examples illustrate how WordBars can provide valuable support for query refinement and search results exploration, both when vague and specific initial queries are provided. User evaluations with both expert and intermediate Web searchers illustrate the benefits of the interactive exploration features of WordBars in terms of effectiveness as well as subjective measures. Although differences were found in the demographics of these two user groups, both were able to benefit from the features of WordBars.
ER  - 

TY  - JOUR
T1  - Text mining without document context
JO  - Information Processing & Management
VL  - 42
IS  - 6
SP  - 1532
EP  - 1552
PY  - 2006/12//
T2  - Special Issue on Informetrics
AU  - SanJuan, Eric
AU  - Ibekwe-SanJuan, Fidelia
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2006.03.017
UR  - http://www.sciencedirect.com/science/article/pii/S0306457306000380
KW  - Multi-word term clustering
KW  - Lexico-syntactic relations
KW  - Text mining
KW  - Informetrics
KW  - Cluster evaluation
AB  - We consider a challenging clustering task: the clustering of multi-word terms without document co-occurrence information in order to form coherent groups of topics. For this task, we developed a methodology taking as input multi-word terms and lexico-syntactic relations between them. Our clustering algorithm, named CPCL is implemented in the TermWatch system. We compared CPCL to other existing clustering algorithms, namely hierarchical and partitioning (k-means, k-medoids). This out-of-context clustering task led us to adapt multi-word term representation for statistical methods and also to refine an existing cluster evaluation metric, the editing distance in order to evaluate the methods. Evaluation was carried out on a list of multi-word terms from the genomic field which comes with a hand built taxonomy. Results showed that while k-means and k-medoids obtained good scores on the editing distance, they were very sensitive to term length. CPCL on the other hand obtained a better cluster homogeneity score and was less sensitive to term length. Also, CPCL showed good adaptability for handling very large and sparse matrices.
ER  - 

TY  - JOUR
T1  - Technical issues of cross-language information retrieval: a review
JO  - Information Processing & Management
VL  - 41
IS  - 3
SP  - 433
EP  - 455
PY  - 2005/5//
T2  - Cross-Language Information Retrieval
AU  - Kishida, Kazuaki
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2004.06.007
UR  - http://www.sciencedirect.com/science/article/pii/S0306457304000767
KW  - Cross-language information retrieval
KW  - Machine translation
KW  - Word sense disambiguation
KW  - Language model
AB  - This paper reviews state-of-the-art techniques and methods for enhancing effectiveness of cross-language information retrieval (CLIR). The following research issues are covered: (1) matching strategies and translation techniques, (2) methods for solving the problem of translation ambiguity, (3) formal models for CLIR such as application of the language model, (4) the pivot language approach, (5) methods for searching multilingual document collection, (6) techniques for combining multiple language resources, etc.
ER  - 

TY  - JOUR
T1  - Using clustering and classification approaches in interactive retrieval
JO  - Information Processing & Management
VL  - 37
IS  - 3
SP  - 459
EP  - 484
PY  - 2001/5//
T2  - Interactivity at the Text Retrieval Conference (TREC)
AU  - Wu, Mingfang
AU  - Fuller, Michael
AU  - Wilkinson, Ross
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(00)00057-1
UR  - http://www.sciencedirect.com/science/article/pii/S0306457300000571
KW  - Clustering
KW  - Classification
KW  - Interactive retrieval
AB  - Satisfying non-trivial information needs involves collecting information from multiple resources, and synthesizing an answer that organizes that information. Traditional recall/precision-oriented information retrieval focuses on just one phase of that process: how to efficiently and effectively identify documents likely to be relevant to a specific, focused query. The TREC Interactive Track has as its goal the location of documents that pertain to different instances of a query topic, with no reward for duplicated coverage of topic instances. This task is similar to the task of organizing answer components into a complete answer. Clustering and classification are two mechanisms for organizing documents into groups. In this paper, we present an ongoing series of experiments that test the feasibility and effectiveness of using clustering and classification as an aid to instance retrieval and, ultimately, answer construction. Our results show that users prefer such structured presentations of candidate result set to a list-based approach. Assessment of the structured organizations based on the subjective judgement of the experiment subjects suggests that the structured organization can be more effective; however, assessment based on objective judgements shows mixed results. These results indicate that a full determination of the success of the approach depends on assessing the quality of the final answers generated by users, rather than on performance during the intermediate stages of answer construction.
ER  - 

TY  - JOUR
T1  - Discriminating meta-search: a framework for evaluation
JO  - Information Processing & Management
VL  - 35
IS  - 3
SP  - 337
EP  - 362
PY  - 1999/5//
T2  - 
AU  - Chignell, Mark H
AU  - Gwizdka, Jacek
AU  - Bodner, Richard C
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(98)00065-X
UR  - http://www.sciencedirect.com/science/article/pii/S030645739800065X
AB  - There was a proliferation of electronic information sources and search engines in the 1990s. Many of these information sources became available through the ubiquitous interface of the Web browser. Diverse information sources became accessible to information professionals and casual end users alike. Much of the information was also hyperlinked, so that information could be explored by browsing as well as searching. While vast amounts of information were now just a few keystrokes and mouseclicks away, as the choices multiplied, so did the complexity of choosing where and how to look for the electronic information. Much of the complexity in information exploration at the turn of the twenty-first century arose because there was no common cataloguing and control system across the various electronic information sources. In addition, the many search engines available differed widely in terms of their domain coverage, query methods and efficiency.

Meta-search engines were developed to improve search performance by querying multiple search engines at once. In principle, meta-search engines could greatly simplify the search for electronic information by selecting a subset of first-level search engines and digital libraries to submit a query to based on the characteristics of the user, the query/topic, and the search strategy. This selection would be guided by diagnostic knowledge about which of the first-level search engines works best under what circumstances. Programmatic research is required to develop this diagnostic knowledge about first-level search engine performance.

This paper introduces an evaluative framework for this type of research and illustrates its use in two experiments. The experimental results obtained are used to characterize some properties of leading search engines (as of 1998). Significant interactions were observed between search engine and two other factors (time of day and Web domain). These findings supplement those of earlier studies, providing preliminary information about the complex relationship between search engine functionality and performance in different contexts. While the specific results obtained represent a time-dependent snapshot of search engine performance in 1998, the evaluative framework proposed should be generally applicable in the future.
ER  - 

TY  - JOUR
T1  - Changing the obesogenic environment: insights from a cultural economy of car reliance
JO  - Transportation Research Part D: Transport and Environment
VL  - 10
IS  - 1
SP  - 31
EP  - 53
PY  - 2005/1//
T2  - 
AU  - Hinde, Sarah
AU  - Dixon, Jane
SN  - 1361-9209
DO  - http://dx.doi.org/10.1016/j.trd.2004.09.003
UR  - http://www.sciencedirect.com/science/article/pii/S1361920904000616
KW  - Environment
KW  - Obesity
KW  - Cultural economy
KW  - Cars
KW  - Interventions
AB  - The rising rate of obesity is a major public health problem in Australia and the ‘obesogenic environment’ is increasingly acknowledged as the most appropriate target for interventions addressing the problem. Recent research has identified car use as a potential contributor to the obesogenic environment; however, there has been little discussion of the social processes that underpin this trend. This article has a dual purpose: first, to describe a research approach to the study of obesogenic environments that improves on previous attempts by reviewing the cultural and economic dimensions of a social trend; and second, to report on the results of applying the approach to car reliance in Australia. The results provide an explanation for how and why car use has become entrenched in the daily lives of the vast majority of Australians to the point that Australia is now a car-reliant society. Moreover, the theoretically informed audit allows us to describe potential pathways linking features of the environment, such as car reliance, to health promoting or damaging practices. Our emphasis on social processes provides a useful approach for studying the social trends that make up the obesogenic environment, and should stimulate further debate, research and alternative ways of thinking about public health policy.
ER  - 

TY  - JOUR
T1  - Towards a pattern language for information-centred business change
JO  - International Journal of Information Management
VL  - 22
IS  - 5
SP  - 325
EP  - 341
PY  - 2002/10//
T2  - 
AU  - Hinton, C.Matthew
SN  - 0268-4012
DO  - http://dx.doi.org/10.1016/S0268-4012(02)00028-2
UR  - http://www.sciencedirect.com/science/article/pii/S0268401202000282
KW  - Process modelling
KW  - Business value
KW  - Pattern languages
KW  - Knowledge management
AB  - Business change designates one of the most conspicuous and most pervasive features of organisational life. However, there has been very little consideration of business change in itself, rather the emphasis has been on studying the outcomes of this change. This paper focuses on a subset of business change that is centred on the information flows of the organisation and is stimulated by catalysts and enablers which induce such changes. Furthermore, change is recognised in a generic sense as either internal or external to an organisation. A conceptual framework is offered which expresses the relationship between the various elements of information-centred business change (ICBC). In order to capture this model of change a language of patterns is suggested which makes it possible to identify change in different contexts and fashion an appropriate organizational response. Patterns are advantageous as they have the potential to identify areas of change which are repetitious, and therefore, lend themselves to the communication of best practice. This research offers a template for such patterns and applies this concept to four case study organizations. The results of this application suggest that patterns offer a way of recognizing under which circumstances different interventions are most appropriate. However, the study suggests that their application is limited. Whilst patterns facilitate the codification and transfer of knowledge, ICBC depends on social interpretation, so much of this meaning is lost when transferred between contexts. The author would like to acknowledge the support of the Environmental and Physical Sciences Research Council in the UK (grant reference L42353).
ER  - 

TY  - JOUR
T1  - Information management in distributed collaborative systems: The case of collaboration studio
JO  - European Journal of Operational Research
VL  - 177
IS  - 3
SP  - 1385
EP  - 1399
PY  - 2007/3/16/
T2  - 
AU  - Antunes, Francisco
AU  - Melo, Paulo
AU  - Costa, João Paulo
SN  - 0377-2217
DO  - http://dx.doi.org/10.1016/j.ejor.2005.04.010
UR  - http://www.sciencedirect.com/science/article/pii/S0377221705003619
KW  - Collaborative systems
KW  - Groupware
KW  - Divergence management
KW  - Knowledge management
AB  - This paper presents the Collaboration Studio (CS) system, its argumentation and data-structuring models and gives some insights for dealing with information divergence. The system allows discussions among a group of participants that includes a coordinator. The working mechanisms implemented within CS are perfectly transparent to the user, hiding implementation details, giving an appealing and user-friendly environment, and so users do not have to worry about patterns of data distribution, or the details of distribution management. CS shares characteristics with other collaboration computational tools, such as synchronous and asynchronous support and both group working spaces and a local working space. However, its main purpose differs in that, instead of trying to achieve a single document as the outcome of the joint work of several users, CS aims to achieve a broader objective, which is to register (and to demonstrate) the “path” used to obtain certain knowledge.
ER  - 

TY  - JOUR
T1  - Integrated expressional analysis: Application to the drug discovery process
JO  - Methods
VL  - 37
IS  - 3
SP  - 280
EP  - 288
PY  - 2005/11//
T2  - Chip Technology in Neuroscience
AU  - Ilyin, Sergey E.
AU  - Horowitz, Daniel
AU  - Belkowski, Stanley M.
AU  - Xin, Hong
AU  - Eckardt, Annette J.
AU  - Darrow, Andrew L.
AU  - Chen, Cailin
AU  - Maley, Derrick
AU  - D’Andrea, Michael
AU  - Plata-Salamán, Carlos R.
AU  - Derian, Claudia K.
SN  - 1046-2023
DO  - http://dx.doi.org/10.1016/j.ymeth.2005.03.013
UR  - http://www.sciencedirect.com/science/article/pii/S1046202305001453
KW  - High content
KW  - Multiplex
KW  - TaqMan
KW  - RT-PCR
KW  - Gene expression
KW  - Target validation
KW  - Biomarkers
KW  - siRNA
KW  - Toxicity
KW  - Functional informatics
AB  - Microarray technology enables high-throughput testing of gene expression to investigate various neuroscience related questions. This in turn creates a demand for scalable methods to confirm microarray results and the opportunity to use this information to discover and test novel pathways and therapeutic applications. Discovery of new central nervous system (CNS) treatments requires a comprehensive understanding of multiple aspects including the biology of a target, the pathophysiology of a disease/disorder, and the selection of successful lead compounds as well as efficient biomarker and drug disposition strategies such as absorption (how a drug is absorbed), distribution (how a drug spreads through an organism), metabolism (chemical conversion of a drug, if any, and into which substances), and elimination (how is a drug eliminated) (ADME). Understanding of the toxicity is also of paramount importance. These approaches, in turn, require novel high-content integrative assay technologies that provide thorough information about changes in cell biology. To increase efficiency of profiling, characterization, and validation, we established a new screening strategy that combines high-content image-based testing on Array Scan (Cellomics) with a confocal system and the multiplexed TaqMan RT-PCR method for quantitative mRNA expression analysis. This approach could serve as an interface between high-throughput microarray testing and specific application of markers discovered in the course of a microarray experiment. Markers could pinpoint activation or inhibition of a molecular pathway related, for instance, to neuronal viability. We demonstrate the successful testing of the same cell population in an image-based translocational assay followed by poly(A) mRNA capture and multiplexed single tube RT-PCR. In addition, Ciphergen ProteinChip analysis can be performed on the supernatant, thus allowing significant complementarity in the data output and interpretation by also including the capture and initial analysis of proteins in the integrative approach presented. We have determined various conditions including the number of cells, RT and PCR optimization, which are necessary for successful detection and consequent assay integration. We also show the successful convergence of various different approaches and multiplexing of different targets within a single real-time PCR tube. This novel integrative technological approach has utility for CNS drug discovery, target and biomarker identification, selection and characterization as well as for the study of toxicity- and adverse event-associated molecular mechanisms.
ER  - 

TY  - JOUR
T1  - MACS: Multi-Agent COTR System for defense contracting
JO  - Knowledge-Based Systems
VL  - 13
IS  - 5
SP  - 241
EP  - 250
PY  - 2000/10//
T2  - 
AU  - Liebowitz, J
AU  - Adya, M
AU  - Rubenstein-Montano, B
AU  - Yoon, V
AU  - Buchwalter, J
AU  - Imhoff, M
AU  - Baek, S
AU  - Suen, C
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/S0950-7051(00)00084-8
UR  - http://www.sciencedirect.com/science/article/pii/S0950705100000848
KW  - Multi-agents
KW  - Intelligent agents
KW  - Acquisition
AB  - The field of intelligent multi-agent systems has expanded rapidly in the recent past. Multi-agent architectures and systems are being investigated and continue to develop. To date, little has been accomplished in applying multi-agent systems to the defense acquisition domain. This paper describes the design, development, and related considerations of a multi-agent system in the area of procurement and contracting for the defense acquisition community.
ER  - 

TY  - JOUR
T1  - A set of frameworks to aid the project manager in conceptualizing and implementing knowledge management initiatives
JO  - International Journal of Project Management
VL  - 21
IS  - 3
SP  - 189
EP  - 198
PY  - 2003/4//
T2  - 
AU  - Liebowitz, Jay
AU  - Megbolugbe, Isaac
SN  - 0263-7863
DO  - http://dx.doi.org/10.1016/S0263-7863(02)00093-5
UR  - http://www.sciencedirect.com/science/article/pii/S0263786302000935
KW  - Knowledge management
KW  - Knowledge sharing
KW  - Project manager
KW  - Frameworks
AB  - Over the years, researchers and practitioners have been concerned about the “collection” of information and knowledge. Now with Web-based and Intranet technologies, we have the “connectivity” to allow information and knowledge sharing to take place. In recent years, the term “knowledge management” has been proposed, and numerous individuals and organizations are trying to put more “science” behind the “art” of knowledge management. To help in this direction, this paper addresses some useful frameworks to help project managers and others in conceptualizing and implementing knowledge management initiatives. A generic knowledge management implementation framework is proposed. This paper should provide the building blocks necessary to further understand and develop knowledge management initiatives.
ER  - 

TY  - JOUR
T1  - Developing construction assistant experience management system using people-based maps
JO  - Automation in Construction
VL  - 17
IS  - 8
SP  - 975
EP  - 982
PY  - 2008/11//
T2  - 
AU  - Lin, Yu-Cheng
SN  - 0926-5805
DO  - http://dx.doi.org/10.1016/j.autcon.2008.04.004
UR  - http://www.sciencedirect.com/science/article/pii/S0926580508000630
KW  - Experience management
KW  - People-based maps
KW  - Information system
KW  - Web-based application
KW  - Construction
AB  - Experience management encompasses the processes governing creation, storage, reuse, maintenance, dissemination and evaluation of experience relevant to a particular situation or problem-solving context. In the construction industry, experience can be reapplied and shared among engineers and participants to enhance construction processes and minimize costs and problem-solving time. This study presents a novel people-based maps (PBMs) approach that captures and represents engineer experience and project knowledge. This approach enables users to survey and access engineer and expert experience from similar projects and assess their tacit and explicit experience. This study applies experience management principles to the construction phase of construction projects and develops a construction assistant people-based map experience management (APMEM) system for contractors. The APMEM system is then applied to a Taiwan high-tech construction project to verify the efficacy of the proposed methodology and demonstrate the effectiveness of sharing experience during the construction phase. Experience can be captured and reused to benefit future projects by effectively utilizing PBMs and web technology during the construction phase of a project. Combined experimental results of this study indicate that an APMEM system provides an effective experience management platform for other construction projects by adopting a PBMs approach.
ER  - 

TY  - JOUR
T1  - Web-based conceptual cost estimates for construction projects using Evolutionary Fuzzy Neural Inference Model
JO  - Automation in Construction
VL  - 18
IS  - 2
SP  - 164
EP  - 172
PY  - 2009/3//
T2  - 
AU  - Cheng, Min-Yuan
AU  - Tsai, Hsing-Chih
AU  - Hsieh, Wen-Shan
SN  - 0926-5805
DO  - http://dx.doi.org/10.1016/j.autcon.2008.07.001
UR  - http://www.sciencedirect.com/science/article/pii/S0926580508001076
KW  - Construction cost
KW  - Conceptual estimates
KW  - Genetic Algorithms
KW  - Fuzzy Logic
KW  - Neural Networks
AB  - Conceptual cost estimates, the basis of project evaluation, engineering design, cost budgeting, and cost management, not only play an essential role in construction project feasibility studies, but are fundamental to a project's ultimate success. As practiced today, construction cost estimates generally rely on experts' intuitive experience. Scientific methods should be developed and employed during project planning and design stages in order to raise conceptual cost estimate accuracy. This study proposes the use of an artificial intelligence approach, the Evolutionary Fuzzy Neural Inference Model (EFNIM), to improve cost estimation accuracy. The advantages inherent in Genetic Algorithms, Fuzzy Logic and Neural Networks are incorporated into the EFNIM, making this model highly applicable to identifying optimal solutions for complex problems. Furthermore, this paper presents Evolutionary Web-based Conceptual Cost Estimators (EWCCE) obtained by integrating EFNIM, WWW, and historical construction data to assist in project management. The developed EWCCE provides two kinds of estimators that can be deployed to estimate conceptual construction cost more precisely during the early stages of projects.
ER  - 

TY  - JOUR
T1  - Knowledge management and its link to artificial intelligence
JO  - Expert Systems with Applications
VL  - 20
IS  - 1
SP  - 1
EP  - 6
PY  - 2001/1//
T2  - 
AU  - Liebowitz, J
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/S0957-4174(00)00044-0
UR  - http://www.sciencedirect.com/science/article/pii/S0957417400000440
KW  - Knowledge management
KW  - Artificial intelligence
KW  - Expert systems
AB  - Knowledge management is an emerging area which is gaining interest by both industry and government. As we move toward building knowledge organizations, knowledge management will play a fundamental role towards the success of transforming individual knowledge into organizational knowledge. One of the key building blocks for developing and advancing this field of knowledge management is artificial intelligence, which many knowledge management practitioners and theorists are overlooking. This paper will discuss the emergence and future of knowledge management, and its link to artificial intelligence.
ER  - 

TY  - JOUR
T1  - Graph clustering
JO  - Computer Science Review
VL  - 1
IS  - 1
SP  - 27
EP  - 64
PY  - 2007/8//
T2  - 
AU  - Schaeffer, Satu Elisa
SN  - 1574-0137
DO  - http://dx.doi.org/10.1016/j.cosrev.2007.05.001
UR  - http://www.sciencedirect.com/science/article/pii/S1574013707000020
AB  - In this survey we overview the definitions and methods for graph clustering, that is, finding sets of “related” vertices in graphs. We review the many definitions for what is a cluster in a graph and measures of cluster quality. Then we present global algorithms for producing a clustering for the entire vertex set of an input graph, after which we discuss the task of identifying a cluster for a specific seed vertex by local computation. Some ideas on the application areas of graph clustering algorithms are given. We also address the problematics of evaluating clusterings and benchmarking cluster algorithms.
ER  - 

TY  - JOUR
T1  - A case study of automatic authoring: From a textbook to a hyper-textbook
JO  - Data & Knowledge Engineering
VL  - 27
IS  - 1
SP  - 1
EP  - 30
PY  - 1998/8//
T2  - 
AU  - Crestani, Fabio
AU  - Melucci, Massimo
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/S0169-023X(97)00043-8
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X97000438
KW  - Automatic authoring
KW  - Hypertext
KW  - Information Retrieval
KW  - Hyperbook
KW  - Hyper-Textbook
AB  - This paper presents a case-study of automatic construction of a hypertext from a large full-text document. The document we used as the input of the automatic authoring process is a well known textbook of Information Retrieval (IR). We explain in detail the steps performed to transform the textbook into a hyper-textbook. A hyper-textbook is the hypertextual equivalent of a textbook, in the same way as a hyperbook is the hypertextual equivalent of a book. A hyper-textbook is designed to be used both as a self-instruction manual and as a reference source. Moreover, it can be printed out into its textual form in total or only partially for easy consultation without a computer. The hyper-textbook is written in HTML and can be accessed and navigated using a common WWW browser.
ER  - 

TY  - JOUR
T1  - Combined mining of Web server logs and web contents for classifying user navigation patterns and predicting users’ future requests
JO  - Data & Knowledge Engineering
VL  - 61
IS  - 2
SP  - 304
EP  - 330
PY  - 2007/5//
T2  - 
AU  - Liu, Haibin
AU  - Kešelj, Vlado
SN  - 0169-023X
DO  - http://dx.doi.org/10.1016/j.datak.2006.06.001
UR  - http://www.sciencedirect.com/science/article/pii/S0169023X06000954
KW  - Web usage mining
KW  - Web content mining
KW  - User navigation profiles
KW  - Classification
KW  - Prediction
AB  - We present a study of the automatic classification of web user navigation patterns and propose a novel approach to classifying user navigation patterns and predicting users’ future requests. The approach is based on the combined mining of Web server logs and the contents of the retrieved web pages. The textual content of web pages is captured through extraction of character N-grams, which are combined with Web server log files to derive user navigation profiles. The approach is implemented as an experimental system, and its performance is evaluated based on two tasks: classification and prediction. The system achieves the classification accuracy of nearly 70% and the prediction accuracy of about 65%, which is about 20% higher than the classification accuracy by mining Web server logs alone. This approach may be used to facilitate better web personalization and website organization.
ER  - 

TY  - JOUR
T1  - Competitive collaborative learning
JO  - Journal of Computer and System Sciences
VL  - 74
IS  - 8
SP  - 1271
EP  - 1288
PY  - 2008/12//
T2  - Learning Theory 2005
AU  - Awerbuch, Baruch
AU  - Kleinberg, Robert
SN  - 0022-0000
DO  - http://dx.doi.org/10.1016/j.jcss.2007.08.004
UR  - http://www.sciencedirect.com/science/article/pii/S0022000007001250
KW  - Online learning
KW  - Bandit problems
KW  - Regret minimization
KW  - Recommendation systems
KW  - Reputation systems
KW  - Collaborative filtering
KW  - Byzantine fault-tolerance
AB  - Intuitively, it is clear that trust or shared taste enables a community of users to make better decisions over time, by learning cooperatively and avoiding one another's mistakes. However, it is also clear that the presence of malicious, dishonest users in the community threatens the usefulness of such collaborative learning processes. We investigate this issue by developing algorithms for a multi-user online learning problem in which each user makes a sequence of decisions about selecting products or resources. Our model, which generalizes the adversarial multi-armed bandit problem, is characterized by two key features:(1)
The quality of the products or resources may vary over time.
(2)
Some of the users in the system may be dishonest, Byzantine agents.
 Decision problems with these features underlie applications such as reputation and recommendation systems in e-commerce, and resource location systems in peer-to-peer networks. Assuming the number of honest users is at least a constant fraction of the number of resources, and that the honest users can be partitioned into groups such that individuals in a group make identical assessments of resources, we present an algorithm whose expected regret per user is linear in the number of groups and only logarithmic in the number of resources. This bound compares favorably with the naïve approach in which each user ignores feedback from peers and chooses resources using a multi-armed bandit algorithm; in this case the expected regret per user would be polynomial in the number of resources.
ER  - 

TY  - JOUR
T1  - Evolutionary document management and retrieval for specialized domains on the web
JO  - International Journal of Human-Computer Studies
VL  - 60
IS  - 2
SP  - 201
EP  - 241
PY  - 2004/2//
T2  - 
AU  - Kim, Mihye
AU  - Compton, Paul
SN  - 1071-5819
DO  - http://dx.doi.org/10.1016/j.ijhcs.2003.10.004
UR  - http://www.sciencedirect.com/science/article/pii/S1071581903001770
AB  - Domain-specific information retrieval normally depends on general search engines, which make no use of domain knowledge and require a user to look at a linear display of loosely organized search results or handcrafted specialized systems with a better browsing interface but which are costly to build and maintain. As an alternative, a Web-based document management and retrieval system has been developed aimed at small communities in specialized domains. The system is based on the free annotation of documents by users and is browsed using the concept lattice of formal concept analysis (FCA). A number of knowledge acquisition techniques were developed to aid the annotation process. Experiments were conducted using the system to assist in finding staff and student home pages at the School of Computer Science and Engineering, University of New South Wales. Results indicated that the annotation tools provided a good level of assistance so that documents were easily organized and a lattice-based browsing structure that evolves in an ad hoc fashion provided good efficiency in retrieval performance. Results also indicated that the concept lattice helped take users beyond a narrow search to find other useful documents. These findings suggest that the concept lattice of FCA, supported by annotation techniques is a useful way of supporting the flexible open management of documents required by individuals, small communities and in specialized domains.
ER  - 

TY  - JOUR
T1  - Rock: A robust clustering algorithm for categorical attributes
JO  - Information Systems
VL  - 25
IS  - 5
SP  - 345
EP  - 366
PY  - 2000/7//
T2  - 
AU  - Guha, Sudipto
AU  - Rastogi, Rajeev
AU  - Shim, Kyuseok
SN  - 0306-4379
DO  - http://dx.doi.org/10.1016/S0306-4379(00)00022-3
UR  - http://www.sciencedirect.com/science/article/pii/S0306437900000223
KW  - Data Mining
KW  - Knowledge Discovery
KW  - Clustering Algorithms
AB  - Clustering, in data mining, is useful to discover distribution patterns in the underlying data. Clustering algorithms usually employ a distance metric based (e.g., euclidean) similarity measure in order to partition the database such that data points in the same partition are more similar than points in different partitions. In this paper, we study clustering algorithms for data with boolean and categorical attributes. We show that traditional clustering algorithms that use distances between points for clustering are not appropriate for boolean and categorical attributes. Instead, we propose a novel concept of links to measure the similarity/proximity between a pair of data points. We develop a robust hierarchical clustering algorithm ROCK that employs links and not distances when merging clusters. Our methods naturally extend to non-metric similarity measures that are relevant in situations where a domain expert/similarity table is the only source of knowledge. In addition to presenting detailed complexity results for ROCK, we also conduct an experimental study with real-life as well as synthetic data sets to demonstrate the effectiveness of our techniques. For data with categorical attributes, our findings indicate that ROCK not only generates better quality clusters than traditional algorithms, but it also exhibits good scalability properties.
ER  - 

TY  - JOUR
T1  - Cloning and chromosomal localization of a paralog and a mouse homolog of the human transaldolase gene
JO  - Gene
VL  - 209
IS  - 1–2
SP  - 13
EP  - 21
PY  - 1998/3/16/
T2  - 
AU  - Kusuda, Jun
AU  - Hirai, Momoki
AU  - Toyoda, Atsushi
AU  - Tanuma, Reiko
AU  - Nomura-Kitabayashi, Aya
AU  - Hashimoto, Katsuyuki
SN  - 0378-1119
DO  - http://dx.doi.org/10.1016/S0378-1119(97)00639-2
UR  - http://www.sciencedirect.com/science/article/pii/S0378111997006392
KW  - Human transaldolase gene
KW  - Paralog
KW  - Mouse homolog
KW  - Gene duplication
KW  - Multiple sclerosis
AB  - A sequence homologous to the transaldolase gene (TALDO) was identified in a polymorphic cosmid DNA mapped on human chromosome 11p15 by exon trapping with pSPL3. Analysis of lambda clones contiguous to the cosmid clone showed that the related gene (TALDOR) consists of 8 exons spanning approximately 19 kb from the translation start site to the polyadenylation signal. The exon sequence of TALDOR was almost identical with that of TALDO localized on 1p33-34.1, but its exons corresponding to exons 4 and 5 of TALDO were found to be split by 4 introns in TALDOR. To examine the evolutionary conservation of two genes for transaldolase, we have isolated the cDNA for its mouse homolog and determined the nucleotide sequence covering the complete coding region. Fluorescence in situ hybridization using the cDNA as a probe showed that the mouse transaldolase gene (Taldo) is localized on chromosome 7 F3-F4 as a single copy gene. This chromosomal region is known to be syntenic to human chromosome 11p15 rather than to 1p33-p34.1, suggesting that TALDOR is the ancestral form. The existence of TALDOR implies a duplication of the mammalian transaldolase gene after divergence of rodent and primate.
ER  - 

TY  - JOUR
T1  - Shuffle on trajectories: Syntactic constraints
JO  - Theoretical Computer Science
VL  - 197
IS  - 1–2
SP  - 1
EP  - 56
PY  - 1998/5/15/
T2  - 
AU  - Mateescu, Alexandru
AU  - Rozenberg, Grzegorz
AU  - Salomaa, Arto
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/S0304-3975(97)00163-1
UR  - http://www.sciencedirect.com/science/article/pii/S0304397597001631
KW  - Shuffle
KW  - Concurrency
KW  - Parallel computation
KW  - Formal languages
AB  - We introduce and investigate new methods to define parallel composition of words and languages as well as of ω-words and ω-languages. The operation of parallel composition leads to new shuffle-like operations defined by syntactic constraints on the usual shuffle operation. The approach is applicable to concurrency, providing a method to define parallel composition of processes. It is also applicable to parallel computation.

The operations are introduced using a uniform method based on the notion of trajectory. As a consequence, we obtain a very intuitive geometrical interpretation of the parallel composition operation. These operations lead in a natural way to a large class of semirings.

The approach is amazingly flexible, diverse concepts from the theory of concurrency can be introduced and studied in this framework. For instance, we provide examples of applications to fairness property and to parallelization of non-context-free languages in terms of context-free and even regular languages.

This paper concentrates on syntactic constraints. Semantic constraints will be dealt with in a forthcoming contribution.
ER  - 

TY  - JOUR
T1  - Designing as disclosure
JO  - Design Studies
VL  - 25
IS  - 1
SP  - 93
EP  - 109
PY  - 2004/1//
T2  - 
AU  - Newton, Sidney
SN  - 0142-694X
DO  - http://dx.doi.org/10.1016/S0142-694X(03)00035-8
UR  - http://www.sciencedirect.com/science/article/pii/S0142694X03000358
KW  - design process
KW  - design model
KW  - design education
KW  - design philosophy
KW  - reflective conversation
AB  - A notion of designing as disclosure is developed and examined. The conception is developed around elements of impulsion, signification, metaphor, structure, connections and understanding. These elements play together in a reflective process (conversation) of signification and experimentation. Designing as disclosure is then examined relative to non-disclosure-based and alternative disclosure-based conceptions of design. This particular conception highlights the need for a move in design education to a greater focus on experience, discourse and ethics; the potential to apply the design process as an analytical tool in business; and supports the development of visual design devices as new forms of knowledge representation.
ER  - 

TY  - JOUR
T1  - Characteristics of modern landscape architecture and its education
JO  - Landscape and Urban Planning
VL  - 60
IS  - 2
SP  - 117
EP  - 133
PY  - 2002/7/30/
T2  - Landscape of the future, The future of Landscape Architecture Education
AU  - Gazvoda, Davorin
SN  - 0169-2046
DO  - http://dx.doi.org/10.1016/S0169-2046(02)00064-6
UR  - http://www.sciencedirect.com/science/article/pii/S0169204602000646
KW  - Landscape planning methods
KW  - Landscape design
KW  - Design process
KW  - Education
AB  - Landscape architecture must keep the advantage it has gained because of its wide use of the knowledge of landscape which no other related disciplines have. Detailed landscape design, creation of new spaces—new landscapes, and use of characteristic, alive landscape material as well as nature protection, landscape ecology and regional landscape planning require both a creative and a scientific approach. The essential ability that landscape architects have, i.e. the capability of switching between concrete details and even global landscape interactions—enables them to achieve different and often better results than might be developed by architects, artists, urban planners, biologists, ecologists and other colleagues when dealing with similar landscape problems. Examples of our work, deriving from “the layer-cake method” and applied to recent studio projects, are used to illustrate key statements in the paper. A link to the teaching process is made in order to offer small but important solutions on how to teach landscape students the most characteristic and useful landscape basics.
ER  - 

TY  - JOUR
T1  - Evaluation of knowledge management tools using AHP
JO  - Expert Systems with Applications
VL  - 29
IS  - 4
SP  - 889
EP  - 899
PY  - 2005/11//
T2  - 
AU  - Ngai, E.W.T.
AU  - Chan, E.W.C.
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2005.06.025
UR  - http://www.sciencedirect.com/science/article/pii/S0957417405001120
KW  - Analytic hierarchy process
KW  - Knowledge management, knowledge management tools
AB  - This paper presents an application of the analytic hierarchy process (AHP) used to select the most appropriate tool to support knowledge management (KM). This method adopts a multi-criteria approach that can be used to analyse and compare KM tools in the software market. The method is based on pairwise comparisons between several factors that affect the selection of the most appropriate KM tool. An AHP model is formulated and applied to a real case of assisting decision-makers in a leading communications company in Hong Kong to evaluate a suitable KM tool. We believe that the application shown can be of use to managers and that, because of its ease of implementation, others can benefit from this approach.
ER  - 

TY  - JOUR
T1  - Process systems knowledge sharing between higher education and industrial practice
JO  - Computers & Chemical Engineering
VL  - 24
IS  - 2–7
SP  - 1467
EP  - 1472
PY  - 2000/7/15/
T2  - 
AU  - Weijnen, M.P.C.
AU  - Herder, P.M.
SN  - 0098-1354
DO  - http://dx.doi.org/10.1016/S0098-1354(00)00537-8
UR  - http://www.sciencedirect.com/science/article/pii/S0098135400005378
KW  - Knowledge management
KW  - Design process
KW  - Education
KW  - Management
AB  - Five students from the TU Delft and TU Eindhoven were assigned with an M.Sc. research project on implementing knowledge management in different chemical processing companies. The student research projects were set up as a knowledge transfer experiment in itself, encouraging knowledge sharing between the students, between the universities and between the companies involved. In addition, the student projects provided the authors with an excellent opportunity to test the curriculum contents of the process systems engineering specialization in the Department of Technology, Policy and Management in a ‘hard core’ chemical engineering environment. The multidisciplinary TPM graduates proved to fulfill a need, or at least a niche, in the process industry. This has triggered the development of integrated courses, combining education in process design and operation with organization and (knowledge) management in the department of TPM.
ER  - 

TY  - JOUR
T1  - Knowledge guided analysis of microarray data
JO  - Journal of Biomedical Informatics
VL  - 39
IS  - 4
SP  - 401
EP  - 411
PY  - 2006/8//
T2  - 
AU  - Fang, Zhuo
AU  - Yang, Jiong
AU  - Li, Yixue
AU  - Luo, Qingming
AU  - Liu, Lei
SN  - 1532-0464
DO  - http://dx.doi.org/10.1016/j.jbi.2005.08.004
UR  - http://www.sciencedirect.com/science/article/pii/S1532046405000778
KW  - Expression data
KW  - Gene ontology
KW  - Clustering
AB  - To microarray expression data analysis, it is well accepted that biological knowledge-guided clustering techniques show more advantages than pure mathematical techniques. In this paper, Gene Ontology is introduced to guide the clustering process, and thus a new algorithm capturing both expression pattern similarities and biological function similarities is developed. Our algorithm was validated on two well-known public data sets and the results were compared with some previous works. It is shown that our method has advantages in both the quality of clusters and the precision of biological annotations. Furthermore, the clustering results can be adjusted according to different stringency requirements. It is expected that our algorithm can be extended to other biological knowledge, for example, metabolic networks.
ER  - 

TY  - JOUR
T1  - WWW-enabled knowledge management for distributed engineering projects
JO  - Computers in Industry
VL  - 50
IS  - 2
SP  - 165
EP  - 177
PY  - 2003/2//
T2  - Advanced Web Technologies for Industrial Applications
AU  - Hameri, Ari-Pekka
AU  - Puittinen, Rainer
SN  - 0166-3615
DO  - http://dx.doi.org/10.1016/S0166-3615(02)00118-5
UR  - http://www.sciencedirect.com/science/article/pii/S0166361502001185
KW  - Distributed project business
KW  - WWW-technologies
KW  - Networking
KW  - Project and operations management
AB  - This paper address problems related to distributed engineering projects (DEP) and how World Wide Web (WWW)-based technologies can improve projects’ efficiency and success rate. The focus is on how WWW can improve project organisations to manage their knowledge, be it in the form of documents, formal communication or the tacit aspect of human interaction. In order to study the research hypotheses related to improved efficiency and leaner organisations resulting from networked operations, a layered framework is presented on organisational processes taking place in the distributed project business. This framework is applied to two industrial cases harnessing advanced networking technologies in their distributed operations. The cases have been picked to show diversity, the other one describes a global delivery process of complex investment goods and the other a smaller scale knowledge intensive company with rapid product release cycles. Basing on these cases the paper concludes that deploying advanced WWW-technologies to distributed engineering processes their punctuality, cost control and workflow can be improved. The cases indicate also, that the new tools enable the initiation of learning processes based on the quantitative information that accumulates in the network servers during the execution of the project. This information can be used to refine the organisation and focus the processes on the truly value-adding activities, which all support the research hypotheses set for the study.
ER  - 

TY  - JOUR
T1  - Enhancing knowledge exchange through web map-based knowledge management system in construction: Lessons learned in Taiwan
JO  - Automation in Construction
VL  - 15
IS  - 6
SP  - 693
EP  - 705
PY  - 2006/11//
T2  - Knowledge Enabled Information System Applications in Construction
AU  - Lin, Yu-Cheng
AU  - Wang, Lung-Chuang
AU  - Tserng, H. Ping
SN  - 0926-5805
DO  - http://dx.doi.org/10.1016/j.autcon.2005.09.006
UR  - http://www.sciencedirect.com/science/article/pii/S0926580505001317
KW  - Knowledge management
KW  - Knowledge map
KW  - Web-based application
KW  - Construction projects
AB  - Knowledge management involves creating, securing, coordinating, combining, retrieving and distributing knowledge. Knowledge can be reused and shared among engineers and experts to enhance construction processes and decrease the time and cost of solving problems. This study presents a novel and practical method to capture and represent construction project knowledge by using network knowledge maps. Network Knowledge Maps (NKM) gives users an overview of available and missing knowledge in core project areas, enabling tacit and explicit knowledge to be managed appropriately. This study addresses application of knowledge management in the construction phase of construction projects, and presents a construction Map-based Knowledge Management (MBKM) concept and system for contractors. The MBKM system is then utilized in selected case studies involving a High-Tech factory building enterprise in Taiwan to verify the proposed methodology and indicate the effectiveness of sharing knowledge, particularly in the construction phase. Knowledge can be captured and managed to benefit future projects by effectively utilizing information and web technologies during the construction phase of a project. The results of this study demonstrate that an MBKM-like system can be applied effectively in knowledge management systems in the construction industry by using map-based knowledge management and web technology.
ER  - 

TY  - JOUR
T1  - Identifying knowledge agents in a KM strategy: the use of the structural influence index
JO  - Information & Management
VL  - 42
IS  - 7
SP  - 935
EP  - 945
PY  - 2005/10//
T2  - 
AU  - Wakefield, Robin L.
SN  - 0378-7206
DO  - http://dx.doi.org/10.1016/j.im.2004.10.002
UR  - http://www.sciencedirect.com/science/article/pii/S037872060400134X
KW  - Knowledge management
KW  - Knowledge management systems
KW  - Knowledge transfer
KW  - Structural influence index
KW  - Knowledge agents
KW  - Knowledge sharing
AB  - Knowledge transfer is a complex KM activity that integrates communication technologies with challenging social, cultural, and organizational issues. It is critical to effective KM systems (KMS) and the development of effective transfer strategies enhances competitive advantage. This study incorporated the theory of organizational influence to demonstrate the structural influence index within a network KMS. Using the research process in the pharmaceutical industry as a basis for knowledge transfer events, this study demonstrated the benefits of structural indexing, which identifies knowledge agents, evaluates knowledge sharing among organizational members, and objectively assesses the contribution of knowledge agents. Subgrouping knowledge agents gave insight into knowledge sharing among members and provided a basis for the coordination of knowledge resources in new and unique ways.
ER  - 

TY  - JOUR
T1  - Knowledge transfer between marketing functions in multinational companies: a conceptual model
JO  - International Business Review
VL  - 12
IS  - 2
SP  - 215
EP  - 232
PY  - 2003/4//
T2  - 
AU  - Schlegelmilch, Bodo B.
AU  - Chini, Tina Claudia
SN  - 0969-5931
DO  - http://dx.doi.org/10.1016/S0969-5931(02)00097-5
UR  - http://www.sciencedirect.com/science/article/pii/S0969593102000975
KW  - Knowledge transfer
KW  - MNC
KW  - Marketing knowledge
AB  - A key competitive advantage of multinational companies lies in their ability to exploit locally created knowledge worldwide. This implies that such companies have to be able to transfer knowledge within organizational networks characterized by separation through time, space, culture and language. Given the pivotal importance of knowledge transfer for the competitiveness of multinationals, it is remarkable that the process of transferring knowledge effectively across dispersed units of multinational corporations has only attracted little and rather fragmented research interest. What appears to be missing is a unifying framework that serves as a basis for a research agenda. Our paper aims to develop such a framework. Specifically, we propose a conceptual model of knowledge transfer between marketing functions within multinationals and advance research propositions for future empirical testing.
ER  - 

TY  - JOUR
T1  - Retrospective evaluation (1971–1999)
JO  - Research Policy
VL  - 28
IS  - 9
SP  - 911
EP  - 919
PY  - 1999/12//
T2  - 

SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/S0048-7333(99)90003-3
UR  - http://www.sciencedirect.com/science/article/pii/S0048733399900033
ER  - 

TY  - JOUR
T1  - TOFIR: A tool of facilitating information retrieval – introduce a visual retrieval model
JO  - Information Processing & Management
VL  - 37
IS  - 4
SP  - 639
EP  - 657
PY  - 2001/7//
T2  - 
AU  - Zhang, Jin
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(00)00042-X
UR  - http://www.sciencedirect.com/science/article/pii/S030645730000042X
KW  - Visualization model
KW  - Information retrieval
KW  - Angle-based similarity measure
KW  - Information retrieval system
AB  - The paper introduces a new method for the visualization of information retrieval. Angle attributes of a document are used to construct the angle–angle-based visual space. The retrieved documents are perceived, several traditional information retrieval evaluation models are visualized and interpreted, and new non-traditional retrieval control means based on the model are explored in the two-dimensional angle display space. The impacts of different metrics on the visualization of information retrieval are discussed. Ambiguity, future research directions and other relevant issues are also addressed.
ER  - 

TY  - JOUR
T1  - Relay communications strategies for Mars exploration through 2020
JO  - Acta Astronautica
VL  - 59
IS  - 1–5
SP  - 310
EP  - 318
PY  - 2006/7//
Y2  - 2006/9//
T2  - Space for Inspiration of Humankind,  Selected Proceedings of the 56th International Astronautical Federation Congress, Fukuoka, Japan, 17-21 October 2005Space for Inspiration of Humankind, Selected Proceedings of the 56th International Astronautical Federation Congress, Fukuoka, Japan, 17-21 October 2005
AU  - Edwards, Jr., C.D.
AU  - Arnold, B.
AU  - DePaula, R.
AU  - Kazz, G.
AU  - Lee, C.
AU  - Noreen, G.
SN  - 0094-5765
DO  - http://dx.doi.org/10.1016/j.actaastro.2006.02.038
UR  - http://www.sciencedirect.com/science/article/pii/S0094576506000816
AB  - Mars exploration poses significant telecommunications challenges, including the return of large data volumes from high-resolution surface instruments, highly constrained mass, power, and energy for surface spacecraft, frequent telemetry and command sessions for supporting complex surface operations, and high-risk mission events such as entry, descent, and landing for which the capture of engineering telemetry is deemed critical. Relay telecommunication via Mars-orbiting spacecraft offers significant advantages in meeting these challenges, relative to conventional direct-to-Earth communications. NASA's Mars Global Surveyor and Mars Odyssey orbiters, along with ESA's Mars Express orbiter, represent an initial relay telecommunications infrastructure that has successfully supported the Spirit and Opportunity rovers. With the arrival of the Mars Reconnaissance Orbiter in 2006, this expanded relay network will provide key support to the 2007 Phoenix Lander and 2009 Mars Science Laboratory missions later this decade. Second-decade mission concepts will introduce new communications challenges; the provision of relay payloads on science orbiters provides a cost-effective means to sustain and evolve the Mars relay network.
ER  - 

TY  - JOUR
T1  - Reconstruction, regeneration and re-imaging: The case of Rotterdam
JO  - Cities
VL  - 15
IS  - 5
SP  - 337
EP  - 344
PY  - 1998/10//
T2  - 
AU  - McCarthy, John
SN  - 0264-2751
DO  - http://dx.doi.org/10.1016/S0264-2751(98)00029-8
UR  - http://www.sciencedirect.com/science/article/pii/S0264275198000298
KW  - Rotterdam
KW  - reconstruction
KW  - regeneration
KW  - re-imaging
AB  - The city of Rotterdam would seem to have succeeded in adapting to new conditions of urban competition by means of the physical reconstruction of its central area and the re-imaging of its cultural identity on an international level, while also achieving social objectives for regeneration. Moreover, these achievements have been brought about largely in the absence of overt conflict. This has been largely the result of both specific conditions of governance in the city itself, and the wider policy context of the Netherlands.
ER  - 

TY  - JOUR
T1  - Subject index volumes 1–28
JO  - Research Policy
VL  - 28
IS  - 9
SP  - 953
EP  - 1027
PY  - 1999/12//
T2  - 

SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/S0048-7333(99)00108-0
UR  - http://www.sciencedirect.com/science/article/pii/S0048733399001080
ER  - 

TY  - JOUR
T1  - Mapping training: the transfer of a cognitive technology for improving counseling
JO  - Journal of Substance Abuse Treatment
VL  - 22
IS  - 4
SP  - 219
EP  - 230
PY  - 2002/6//
T2  - 
AU  - Dansereau, Donald F.
AU  - Dees, Sandra M.
SN  - 0740-5472
DO  - http://dx.doi.org/10.1016/S0740-5472(02)00235-0
UR  - http://www.sciencedirect.com/science/article/pii/S0740547202002350
KW  - Mapping
KW  - Cognitive tools
KW  - Counselor training
KW  - Drug abuse treatment
AB  - To provide information that will reduce the gap between research and practice, the transfer of a complex drug abuse counseling technology is examined. This technology, cognitive mapping, is a graphic tool shown to effectively facilitate communication and problem solving in group and individual counseling sessions. Unlike some techniques, mapping requires substantial counselor time, effort, and expertise to learn and to use. This article briefly describes the development and evolution of mapping and supporting research. It then focuses on our efforts to develop mapping training that will facilitate use of this evidence-based technique in drug abuse treatment. Major training and transfer pitfalls are noted, and strategies for successful training are recommended.
ER  - 

TY  - JOUR
T1  - From plant and logistics control to multi-enterprise collaboration
JO  - Annual Reviews in Control
VL  - 30
IS  - 1
SP  - 55
EP  - 68
PY  - 2006///
T2  - 2005 IFAC Milestone Reports
AU  - Nof, S.Y.
AU  - Morel, G.
AU  - Monostori, L.
AU  - Molina, A.
AU  - Filip, F.
SN  - 1367-5788
DO  - http://dx.doi.org/10.1016/j.arcontrol.2006.01.005
UR  - http://www.sciencedirect.com/science/article/pii/S136757880600006X
KW  - Agents
KW  - Bio-inspired control
KW  - Collaborative control
KW  - Complex systems
KW  - Coordination
KW  - Digital enterprise
KW  - Distributed manufacturing
KW  - Enterprise networks
KW  - Integration
KW  - Large-scale systems
KW  - Multi-agent control
AB  - Current and emerging manufacturing and logistics systems are posing new challenges and opportunities for the automation and control community. This milestone report describes the main problems, such as management of complexity, scalability, increasing costs, coordination, market-based resource allocation, and more. Recent accomplishments and trends are discussed: control and automation techniques, manufacturing plant automation, collaborative control through integration and networking, and control methods applied to extended enterprises and large-scale critical infrastructure. Finally, forecasts are presented for the next generation manufacturing system; e-work; integration, coordination and collaboration; networked, distributed decision support (NDSS); and active middleware.
ER  - 

TY  - JOUR
T1  - Enterprise modeling and integration (EMI): Current status and research perspectives
JO  - Annual Reviews in Control
VL  - 26
IS  - 1
SP  - 15
EP  - 25
PY  - 2002///
T2  - 
AU  - Vernadat, F.B.
SN  - 1367-5788
DO  - http://dx.doi.org/10.1016/S1367-5788(02)80006-2
UR  - http://www.sciencedirect.com/science/article/pii/S1367578802800062
KW  - Enterprise Integration
KW  - Enterprise Modeling
KW  - Manufacturing enterprises
AB  - Much has been written and high expectations have been placed over the last decade on enterprise modeling and integration. Applicable results are more modest. This paper first recalls challenges and rationale for enterprise modeling and integration. It then points out substantial results achieved so far as well as potential difficulties and pitfalls to make them a reality.
ER  - 

TY  - JOUR
T1  - A new strategy for harnessing knowledge management in e-commerce
JO  - Technology in Society
VL  - 27
IS  - 3
SP  - 413
EP  - 435
PY  - 2005/8//
T2  - 
AU  - Oppong, Stephen A.
AU  - Yen, David C.
AU  - Merhout, Jeffrey W.
SN  - 0160-791X
DO  - http://dx.doi.org/10.1016/j.techsoc.2005.04.009
UR  - http://www.sciencedirect.com/science/article/pii/S0160791X05000321
KW  - Business to business (B2B)
KW  - Business to consumer (B2C)
KW  - Business intelligence (BI)
KW  - Customer relationship management (CRM)
KW  - Electronic commerce (E-commerce)
KW  - Electronic data interchange (EDI)
KW  - Enterprise information portal (EIP)
KW  - Enterprise resource planning (ERP)
KW  - Knowledge management (KM)
KW  - Supply chain management (SCM)
AB  - Knowledge management has become increasingly critical for the success of companies in this emerging era of e-commerce. As business activities increasingly shift to the web, the challenge facing corporate management is maintaining competitive advantage by building strong relations with employees, customers, and upstream/downstream suppliers and partners. A good knowledge management strategy can help achieve this goal. Unfortunately, many companies use knowledge management technologies that do not suit today's new information era. Therefore, it is important to understand how companies can successfully implement knowledge management programs that will help them to gain competitive advantage. Most experts agree that the biggest challenges of knowledge management are not technological but human-based or behavioral challenges.

This paper addresses these problems by tracing the evolution of knowledge management in e-commerce and identifying strategies that are currently in use. We will demonstrate how companies can benefit by adopting strategies that harness the potential of knowledge management technologies to transform their e-business activities. We define knowledge management; then provide an overview of the driving and impeding forces that help and hinder proper deployment of knowledge management strategies in e-commerce. Then we describe approaches and implementation architectures currently in use by companies who are integrating knowledge management into their e-commerce activities. Finally, we suggest a strategic approach that can overcome the limitations in systems presently in use as well as implications for future knowledge management development.
ER  - 

TY  - JOUR
T1  - Comparing approaches to systems of innovation: the knowledge perspective
JO  - Technology in Society
VL  - 26
IS  - 1
SP  - 17
EP  - 37
PY  - 2004/1//
T2  - 
AU  - Chang, Yuan-Chieh
AU  - Chen, Ming-Huei
SN  - 0160-791X
DO  - http://dx.doi.org/10.1016/j.techsoc.2003.10.002
UR  - http://www.sciencedirect.com/science/article/pii/S0160791X03000964
KW  - Systems of innovation
KW  - knowledge perspective
AB  - This paper identifies and compares three existing systems of innovation approaches, namely, the national system of innovation approach, the technological/sectoral system of innovation approach, and the regional system of innovation approach. By focusing the analysis on knowledge, the research scope, unit of analysis, and analytical frameworks applied by each approach are analyzed and synthesized. The paper reveals that the three approaches claim their major knowledge links, facilitating factors, and boundaries differently. Although three methods have emerged in mapping systems of innovation, these methods provide complementary views, rather than substitutive ones, for constructing a complete configuration of an innovation system. Four methodological problems exist: inconsistent definition of innovation, top-down orientation, independence among innovation systems, and ex-post qualitative analysis. Finally, further methodological issues regarding systems of innovation studies are suggested.
ER  - 

TY  - JOUR
T1  - Knowledge based decision making on higher level strategic concerns: system dynamics approach
JO  - Expert Systems with Applications
VL  - 27
IS  - 1
SP  - 143
EP  - 158
PY  - 2004/7//
T2  - 
AU  - Yim, Nam-Hong
AU  - Kim, Soung-Hie
AU  - Kim, Hee-Woong
AU  - Kwahk, Kee-Young
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2003.12.019
UR  - http://www.sciencedirect.com/science/article/pii/S095741740300232X
KW  - Knowledge management
KW  - Naturalistic decision making
KW  - System dynamics
AB  - In recognizing knowledge as a new resource in gaining organizational competitiveness, knowledge management suggests a method in managing and applying knowledge for improving organizational performance. Much knowledge management research has focused on identifying, storing, and disseminating process related knowledge in an organized manner. Applying knowledge to decision making has a significant impact on organizational performance than solely processing transactions for knowledge management. In this research, we suggest a method of knowledge-based decision-making using system dynamics, with an emphasis to strategic concerns. The proposed method transforms individual mental models into explicit knowledge by translating partial and implicit knowledge into an integrated knowledge model. The scenario-based test of the organized knowledge model enables decision-makers to understand the structure of the target problem and identify its basic cause, which facilitates effective decision-making. This method facilitates the linkage between knowledge management initiatives and achieving strategic goals and objectives of an organization.
ER  - 

TY  - JOUR
T1  - MEK: Using spatial–temporal information to improve social networks and knowledge dissemination
JO  - Information Sciences
VL  - 179
IS  - 15
SP  - 2524
EP  - 2537
PY  - 2009/7/4/
T2  - Including Special Issue on Computer-Supported Cooperative WorkTechniques and ApplicationsThe 11th Edition of the International Conference on CSCW in Design
AU  - Monclar, Rafael
AU  - Tecla, Alessandro
AU  - Oliveira, Jonice
AU  - de Souza, Jano M.
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/j.ins.2009.01.032
UR  - http://www.sciencedirect.com/science/article/pii/S0020025509000607
KW  - CSCW
KW  - Knowledge management
KW  - Mobile computing
KW  - Distributed collaboration
KW  - Social networks
AB  - Most of the projects which envision knowledge dissemination create and use a unique knowledge base, where all items acquired are organized according to a simple classification. This kind of ‘centralized’ approach shows some inconsistencies in relation to many of the theories about the creation of knowledge and its dissemination. Due to them, distribution and sociability are essential characteristics for the creation and sharing of knowledge. This incoherence partially explains the reason which leads many users into abandoning this kind of system because they have to adapt themselves to a classification and a rigid structure to represent pieces of knowledge. On the other hand, a lot of tacit knowledge and interaction possibilities are lost in this centralized vision. So, based on the advantages of a distributed approach for knowledge dissemination and the improvement of interaction, we designed and constructed the Mobile Exchange of Knowledge (MEK). This approach involves, in a mobile way, the exchanging of knowledge among people who share the same interests. Some issues like ad-hoc networks, social networks, location prediction and distributed knowledge management are also related to the MEK concept. However, to verify how effective our idea is, we conducted an experiment in the geographical space of a university in Brazil where we analyzed the movements of students and also their interest and willingness to share knowledge items.
ER  - 

TY  - JOUR
T1  - Managing uncertainty and ambiguity in frontier R&amp;D projects: A Korean case study
JO  - Journal of Engineering and Technology Management
VL  - 24
IS  - 3
SP  - 231
EP  - 250
PY  - 2007/9//
T2  - 
AU  - Song, Yong-Il
AU  - Lee, Dae-Hee
AU  - Lee, Yong-Gil
AU  - Chung, Yun-Chul
SN  - 0923-4748
DO  - http://dx.doi.org/10.1016/j.jengtecman.2007.05.001
UR  - http://www.sciencedirect.com/science/article/pii/S0923474807000240
KW  - Technology management
KW  - R&amp;D planning
KW  - Fuzzy front-end
KW  - Knowledge management
AB  - One of the important tasks in planning large, frontier R&amp;D projects is to minimize innate uncertainties and ambiguities in the early stages of the project. This case study is an attempt to provide a framework to handle such problems in R&amp;D planning. In it we analyze various elements that define planning conditions, classify them into basic constructs, and suggest tools and methods to deal with uncertainty and ambiguity. We utilize two case studies to approach the research questions. Our findings suggest that both initial planning conditions and the effectiveness of front-end planning management affect the performance of R&amp;D planning and the later R&amp;D process.
ER  - 

TY  - JOUR
T1  - Assessing knowledge-based resources in a utility company: Identify and prioritise the balancing factors
JO  - Energy
VL  - 33
IS  - 7
SP  - 1027
EP  - 1037
PY  - 2008/7//
T2  - 
AU  - Kayakutlu, Gülgün
AU  - Büyüközkan, Gülçin
SN  - 0360-5442
DO  - http://dx.doi.org/10.1016/j.energy.2008.01.006
UR  - http://www.sciencedirect.com/science/article/pii/S0360544208000285
KW  - Knowledge management
KW  - Business role players
KW  - Utility sector
KW  - Delphi method
KW  - Fuzzy AHP
AB  - Confidence in the future of an enterprise success is only possible by balancing the resources and the expectations. The increase in knowledge-based resources request new assessment models. This study aims to demonstrate the divergence in value of the knowledge resources for different role players. Thus, knowledge management strategies can be reviewed as to support the future of the company. The case study is performed in a Turkish utility company, where, the role players have comparable influences on the future of the business. An integrated Delphi and fuzzy Analytic Hierarchy Process (AHP) based framework is used in analysis which also helps prioritising the balancing factors according to the different role players. Achievements in the case study led for a mind-shift of considering the accordance of the sustainability and the resource balancing goals for the utility sector.
ER  - 

TY  - JOUR
T1  - Abstracts
JO  - Journal of Product Innovation Management
VL  - 17
IS  - 5
SP  - 393
EP  - 404
PY  - 2000/9//
T2  - 
AU  - Di Benedetto, C.Anthony
SN  - 0737-6782
DO  - http://dx.doi.org/10.1016/S0737-6782(00)00051-5
UR  - http://www.sciencedirect.com/science/article/pii/S0737678200000515
ER  - 

TY  - JOUR
T1  - Agent-based support of mass customization for corporate knowledge management
JO  - Engineering Applications of Artificial Intelligence
VL  - 16
IS  - 4
SP  - 349
EP  - 364
PY  - 2003/6//
T2  - Intelligent Manufacturing
AU  - Smirnov, A.V.
AU  - Pashkin, M.
AU  - Chilov, N.
AU  - Levashova, T.
SN  - 0952-1976
DO  - http://dx.doi.org/10.1016/S0952-1976(03)00074-5
UR  - http://www.sciencedirect.com/science/article/pii/S0952197603000745
KW  - Agents
KW  - Data processing
KW  - Constraints
KW  - Configuration management
AB  - The paper describes an agent-based architecture developed as a part of the KSNet-approach to the knowledge logistics. This approach is targeted to timely provide an appropriate personalized knowledge for an intelligent support of decision-makers. In the KSNet-approach the problem of knowledge logistics is considered as a configuration of a network of end-users/customers, loosely coupled knowledge sources/resources, and set of tools and methods for information processing. Such network located in the information environment has been referred to as knowledge source network or “KSNet”. The paper presents this approach from the perspective of application of the mass customization idea to corporate knowledge management as a major information kernel technology of intelligent enterprises. As an example of intelligent enterprise the paper considers virtual supply network. Main ideas of the KSNet-approach are presented and the structure of the developed agents’ society is described in more detail. Main results are illustrated via a configuration case study and discussed in conclusions.
ER  - 

TY  - JOUR
T1  - Knowledge logistics in information grid environment
JO  - Future Generation Computer Systems
VL  - 20
IS  - 1
SP  - 61
EP  - 79
PY  - 2004/1/15/
T2  - Semantic Grid and Knowledge Grid the Next Generation Web
AU  - Smirnov, Alexander
AU  - Pashkin, Mikhail
AU  - Chilov, Nikolai
AU  - Levashova, Tatiana
SN  - 0167-739X
DO  - http://dx.doi.org/10.1016/S0167-739X(03)00165-1
UR  - http://www.sciencedirect.com/science/article/pii/S0167739X03001651
KW  - Knowledge logistics
KW  - Intelligent systems
KW  - Ontologies
KW  - Multi-agent systems
KW  - Information grid
AB  - Rapidity of decision making process is an important factor for different areas of human life (business, healthcare, industry, military applications, etc.). Since responsible persons make decisions using available knowledge a delivery of necessary and timely information for knowledge management systems is important. Knowledge logistics is a new direction of knowledge management addressing this issue. It provides a set of activities for knowledge search, acquisition and integration from distributed sources located in information grid environment. The paper proposes a developed Knowledge Source Network approach (KSNet-approach) to knowledge logistics and its multi-agent architecture, and describes a research prototype of the system “KSNet” based on this approach.
ER  - 

TY  - JOUR
T1  - A Framework for Practising Knowledge Management
JO  - Long Range Planning
VL  - 35
IS  - 1
SP  - 49
EP  - 71
PY  - 2002/2//
T2  - 
AU  - Armistead, Colin
AU  - Meakins, Magda
SN  - 0024-6301
DO  - http://dx.doi.org/10.1016/S0024-6301(02)00017-1
UR  - http://www.sciencedirect.com/science/article/pii/S0024630102000171
AB  - The management of an intangible asset such as knowledge is beset with complex and theoretical concepts. This paper sets out a matrix that describes four approaches to Knowledge Management based on whether it is in an organisational or an individual context, and whether knowledge management is imposed or empowered by managerial approaches. It explores the validity of the framework through an analysis of ongoing management projects at seven organisations.
ER  - 

TY  - JOUR
T1  - On analysis of collaborative problem solving: an object-oriented approach
JO  - Computers in Human Behavior
VL  - 19
IS  - 2
SP  - 147
EP  - 167
PY  - 2003/3//
T2  - 
AU  - Avouris, Nikolaos
AU  - Dimitracopoulou, Angelique
AU  - Komis, Vassilis
SN  - 0747-5632
DO  - http://dx.doi.org/10.1016/S0747-5632(02)00056-0
UR  - http://www.sciencedirect.com/science/article/pii/S0747563202000560
KW  - Collaborative problem solving
KW  - Object-oriented approach
KW  - Educational software
AB  - During the last decade an increased interest has been observed on computer-supported collaborative problem solving. This relatively new area of research requires new methodological approaches of interaction and problem solving analysis. Usually analysis of collaborative problem solving situations is done through discourse analysis or interaction analysis, where in the center of attention are the actors involved (students, tutors etc.). An alternative framework, called “Object-oriented Collaboration Analysis Framework (OCAF)” is presented here, according to which the objects of the collaboratively developed solution become the center of attention and are studied as entities that carry their own history. This approach produces a reversed view of the process, according to which the solution is made of structural components that are ‘owned’ by actors who have contributed in various degrees to their development. OCAF provides both qualitative and quantitative measures of collaboration. It is shown that this framework can be applied effectively both in synchronous computer supported collaborative environments of distance groups and in face-to-face collaborative activities.
ER  - 

TY  - JOUR
T1  - Literature listing
JO  - World Patent Information
VL  - 31
IS  - 3
SP  - 258
EP  - 266
PY  - 2009/9//
T2  - 

SN  - 0172-2190
DO  - http://dx.doi.org/10.1016/j.wpi.2009.03.007
UR  - http://www.sciencedirect.com/science/article/pii/S0172219009000349
ER  - 

TY  - JOUR
T1  - How knowledge map fit and personalization affect success of KMS in high-tech firms
JO  - Technovation
VL  - 29
IS  - 4
SP  - 313
EP  - 324
PY  - 2009/4//
T2  - 
AU  - Lai, Jung-Yu
AU  - Wang, Chao-Te
AU  - Chou, Chun-Yi
SN  - 0166-4972
DO  - http://dx.doi.org/10.1016/j.technovation.2008.10.007
UR  - http://www.sciencedirect.com/science/article/pii/S0166497208001387
KW  - Effectiveness
KW  - IS success
KW  - Knowledge management systems (KMS)
KW  - Knowledge map fit
KW  - Personalization
KW  - User satisfaction
AB  - The shift from a product-based to a knowledge-based economy has resulted in an increasing demand for organizations to implement knowledge management systems (KMS) at an accelerating pace. However, factors influencing success of KMS have seldom been empirically examined by prior research, particularly how knowledge map fit and personalization influence employee satisfaction with KMS, which is a surrogate measure of the success/effectiveness of information systems (IS). Results from a sample of 133 employees, mostly from four international high-tech companies in the Hsin-Chu Science-based Industrial Park in Taiwan, help us better understand what factors affect employee satisfaction with KMS. The result shows that KMS with a higher level of knowledge map fit and personalization will satisfy employees directly or indirectly through the mediation effects of increased perceptions of ease of use and usefulness of KMS. Our findings could serve as useful references for researchers and practitioners interested in investigating issues related to the successful implementation of KMS.
ER  - 

TY  - JOUR
T1  - Development of a mechanism for ontology-based product lifecycle knowledge integration
JO  - Expert Systems with Applications
VL  - 36
IS  - 2, Part 2
SP  - 2759
EP  - 2779
PY  - 2009/3//
T2  - 
AU  - Chen, Yuh-Jen
AU  - Chen, Yuh-Min
AU  - Chu, Hui-Chuan
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2008.01.049
UR  - http://www.sciencedirect.com/science/article/pii/S0957417408000742
KW  - Product lifecycle
KW  - Collaboration
KW  - Knowledge integration
KW  - Knowledge sharing
KW  - Ontology-based
AB  - Compared with relying on the efforts of various enterprises collaborating on product lifecycle activities, such as coordination, communication and control, the ability to effectively share product information and knowledge is more important. Therefore, how to best integrate such heterogeneous product knowledge distributed among various cooperating enterprises has become an extremely important knowledge management subjects associated with collaborative product lifecycle.

This study develops a novel mechanism for integrating ontology-based product lifecycle knowledge to effectively integrate the heterogeneous product knowledge distributed among different enterprises during a product’s lifecycle, thereby facilitating sharing of this product knowledge. This study: (i) designed an integration and sharing process for collaborative product lifecycle knowledge, (ii) developed techniques associated with integration of ontology-based product lifecycle knowledge, and (iii) implemented an integration and sharing mechanism for ontology-based product lifecycle knowledge. In developing techniques associated with integration of ontology-based product lifecycle knowledge, which involves establishing a product lifecycle ontology, designing local ontology schema, designing an integration algorithm for ontology-based product lifecycle knowledge, and designing a searching method for ontology-based product lifecycle knowledge.
ER  - 

TY  - JOUR
T1  - Semantic Enrichment of Standard-based Electronic Catalogues
JO  - IFAC Proceedings Volumes
VL  - 42
IS  - 4
SP  - 163
EP  - 168
PY  - 2009///
T2  - 13th IFAC Symposium on Information Control Problems in Manufacturing
AU  - Sarraipa, João
AU  - Agostinho, Carlos
AU  - Panetto, Hervé
AU  - Jardim-Goncalves, Ricardo
SN  - 1474-6670
DO  - http://dx.doi.org/10.3182/20090603-3-RU-2001.0329
UR  - http://www.sciencedirect.com/science/article/pii/S1474667016337855
KW  - Semantic Interoperability
KW  - Knowledge Representation
KW  - Knowledge-based systems
KW  - Standards
AB  - Abstract
Today, enterprises are facing serious interoperability problems concerning the exchange of electronic data. Due to the proliferation of terminology, organizations from similar business environments have trouble cooperating, and supply chains are experiencing difficulties exchanging electronically vital information, such as catalogue data. In order to solve this problem, standardization communities are working to define formalized structures for catalogue and product data. However, standards by themselves do not solve semantic interoperability issues. For instance, a group of enterprises which share catalogue information in their business activities need to have a common semantics to understand each other. Otherwise their systems might understand the data structure but not its meaning. This is today a major challenge in modern enterprise integration. This paper contributes to achieving seamless product oriented enterprise interoperability by proposing a framework based on knowledge representation elements to support the semantic enrichment of standard-based electronic catalogues.
ER  - 

TY  - JOUR
T1  - Geographical information system (GIS) application to construction and geotechnical data management on MRT construction projects in Singapore
JO  - Tunnelling and Underground Space Technology
VL  - 14
IS  - 4
SP  - 469
EP  - 479
PY  - 1999/10//
Y2  - 1999/12//
T2  - Tunneling in Singapore
AU  - Kimmance, J.P.
AU  - Bradshaw, M.P.
AU  - Seetoh, H.H.
SN  - 0886-7798
DO  - http://dx.doi.org/10.1016/S0886-7798(00)00009-2
UR  - http://www.sciencedirect.com/science/article/pii/S0886779800000092
AB  - Major construction projects, such as the North East Line (NEL) and Changi Airport Line (CAL), being undertaken by the Land Transport Authority in Singapore, produce vast quantities of construction related data which require management and interpretation. The management information system developed and deployed by the Land Transport Authority to handles such data is a client-web server based Geographical Information System (GIS) termed the Land Transport Authority (LTA) Geotechnical Database (GDB). This paper briefly discusses the design and architecture of the GDB. Then the user interface and the varied data management and presentation capabilities of the system are described in detail. Finally, the performance of the system is assessed in terms of the quantity of data handled, the user profile and numbers. It is concluded that the system performs well in its role of managing large volumes of instrumentation and construction data, and providing this to clients in user-friendly graphical formats that makes interpretation faster and easier. This has resulted in the GDB being widely used and providing tangible benefits to the organisation.
ER  - 

TY  - JOUR
T1  - Scientific space mission news
JO  - COSPAR Information Bulletin
VL  - 2002
IS  - 153
SP  - 17
EP  - 29
PY  - 2002/4//
T2  - 

SN  - 0045-8732
DO  - http://dx.doi.org/10.1016/S0045-8732(02)80004-3
UR  - http://www.sciencedirect.com/science/article/pii/S0045873202800043
ER  - 

TY  - JOUR
T1  - Author index volumes 1–28
JO  - Research Policy
VL  - 28
IS  - 9
SP  - 921
EP  - 951
PY  - 1999/12//
T2  - 

SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/S0048-7333(99)00107-9
UR  - http://www.sciencedirect.com/science/article/pii/S0048733399001079
ER  - 

TY  - JOUR
T1  - Fine hierarchy of regular ω-languages
JO  - Theoretical Computer Science
VL  - 191
IS  - 1–2
SP  - 37
EP  - 59
PY  - 1998/1/30/
T2  - 
AU  - Selivanov, Victor
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/S0304-3975(97)00301-0
UR  - http://www.sciencedirect.com/science/article/pii/S0304397597003010
AB  - By applying descriptive set theory to the Wagner's fine structure of regular ω-languages we get quite different proofs of his results and obtain new results. We give an automata-free description of the fine structure. We present also a simple property of a deterministic Muller automaton equivalent to the condition that the corresponding regular ω-language belongs to any given level of the fine structure. Our results and proofs demonstrate deep interconnections between descriptive set theory and the theory of ω-languages.
ER  - 

TY  - JOUR
T1  - A knowledge management approach to organizational competitive advantage: Evidence from the food sector
JO  - European Management Journal
VL  - 27
IS  - 2
SP  - 129
EP  - 141
PY  - 2009/4//
T2  - 
AU  - Massa, Silvia
AU  - Testa, Stefania
SN  - 0263-2373
DO  - http://dx.doi.org/10.1016/j.emj.2008.06.005
UR  - http://www.sciencedirect.com/science/article/pii/S0263237308000856
KW  - Knowledge management system (KMS)
KW  - Food sector
KW  - Case study
AB  - Summary
This paper uses a comparative case study approach to investigate how two small Italian food producers manage their knowledge. The first company under consideration is mainly focused on marketing, while the second on the technology knowledge domain. This paper enriches the existing literature by documenting examples of how companies can successfully manage organizational knowledge on the basis of their relative knowledge domain. This research claims that not only knowledge domain but also innovation behavior seem to be the contingencies that mostly impact on knowledge management system features. In fact, the different combinations of the two variables have deeply different requirements in terms of knowledge management.
ER  - 

TY  - JOUR
T1  - The construction and application of knowledge navigator model (KNM™): An evaluation of knowledge management maturity
JO  - Expert Systems with Applications
VL  - 36
IS  - 2, Part 2
SP  - 4087
EP  - 4100
PY  - 2009/3//
T2  - 
AU  - Hsieh, Ping Jung
AU  - Lin, Binshan
AU  - Lin, Chinho
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/j.eswa.2008.03.005
UR  - http://www.sciencedirect.com/science/article/pii/S0957417408001942
KW  - Knowledge management
KW  - Knowledge navigator model (KNM™)
KW  - Inter-rater reliability analysis
AB  - This study develops a knowledge navigator model (KNM™) to navigate knowledge management (KM) implementation journey. The KNM comprises two frameworks: evaluation and calculation framework. Qualitative research methods, including a literature review, in-depth interviews, focus groups and content analysis, are conducted to construct the evaluation framework of KNM. An algorithm model is proposed in the calculation framework and a 30 cases survey was employed to obtain the initial version of the score ranges used to differentiate maturity levels. Several propositions and the corresponding KNM were constructed. We define the KM maturity level into five stages: knowledge chaotic stage, knowledge conscientious stage, KM stage, KM advanced stage, and KM integration stage. The evaluation framework of KNM consists of three aspects: three target management objects (culture, KM process, and information technology), 68 KM activities, and 16 key areas (KAs). The initial version of the score ranges was identified. The study results can be referenced and the methodology can be applied to other countries, although the sample is confined to industries in Taiwan.
ER  - 

TY  - JOUR
T1  - H. sapiens as ecologically special: what does language contribute?
JO  - Language Sciences
VL  - 29
IS  - 5
SP  - 710
EP  - 731
PY  - 2007/9//
T2  - Cognitive Dynamics in Language
AU  - Ross, Don
SN  - 0388-0001
DO  - http://dx.doi.org/10.1016/j.langsci.2006.12.008
UR  - http://www.sciencedirect.com/science/article/pii/S0388000106000763
KW  - Human distinctiveness
KW  - Human language
KW  - Cultural evolution
KW  - Strategic signaling
AB  - This paper inquires into the extent to which humans are specially constituted relative to other animals by their language. First a principled concept of evolutionary specialness is operationalized. Then it is agreed that humans satisfy the criteria for this sort of specialness in consequence of the kind of cultural evolution in which they have participated. However, it is argued that although certain representational capacities limited to highly social and intelligent animals are necessary for such cultural evolution, the representational capacities in themselves are not special. Instead, the special property of humans that leads them to explosive niche-construction is the propensity to stabilize coordination through socially controlled self-narration. This propensity indeed depends on special aspects of human language, though syntactical structure is not necessarily among them.
ER  - 

TY  - JOUR
T1  - The critical geopolitics of the Uzbekistan–Kyrgyzstan Ferghana Valley boundary dispute, 1999–2000
JO  - Political Geography
VL  - 23
IS  - 6
SP  - 731
EP  - 764
PY  - 2004/8//
T2  - 
AU  - Megoran, Nick
SN  - 0962-6298
DO  - http://dx.doi.org/10.1016/j.polgeo.2004.03.004
UR  - http://www.sciencedirect.com/science/article/pii/S0962629804000320
KW  - Uzbekistan
KW  - Kyrgyzstan
KW  - Border
KW  - Nationalism
KW  - Geopolitics
KW  - Gender
AB  - In 1999 the Uzbekistan–Kyrgyzstan Ferghana Valley boundary became a brutal reality in the lives of borderland inhabitants, when it became the key issue in a crisis of inter-state relations. Mainstream explanations have suggested that the Soviet boundary legacy and convergent post-Soviet macro-economic policies made conflict inevitable. Drawing on critical geopolitics theory, this paper questions the implicit determinism in these accounts, and seeks to augment them by a political analysis. It suggests that ‘the border crisis’ was the product of the interaction of complex domestic power struggles in both countries, the boundary itself acting as a material and discursive site where elites struggled for the power to inscribe conflicting gendered, nationalistic visions of geopolitical identity. It concludes by insisting upon a moral imperative to expose and challenge the geographical underpinnings of state violence.
ER  - 

TY  - JOUR
T1  - Knowledge management in virtual enterprises: A systemic multi-methodology towards the strategic use of information
JO  - International Journal of Information Management
VL  - 28
IS  - 4
SP  - 305
EP  - 321
PY  - 2008/8//
T2  - 
AU  - Pollalis, Yannis A.
AU  - Dimitriou, Nikolaos K.
SN  - 0268-4012
DO  - http://dx.doi.org/10.1016/j.ijinfomgt.2008.02.005
UR  - http://www.sciencedirect.com/science/article/pii/S0268401208000376
KW  - Virtual enterprises
KW  - Information management
KW  - Knowledge management
KW  - Strategic information systems
KW  - Systemic methodologies
AB  - This paper examines the development of a systemic multi-methodology for knowledge management in virtual enterprises. The main objective is the strategic management of information for the acquisition of competitive advantage and the advance of networked corporate agreements (i.e., Virtual Enterprise Projects) in order to maintain business flexibility and innovation. Making use of systemic methodologies, emphasis is given on the creation and the sustenance of knowledge coming from both the internal and the external business environment, instead of directly intervening to the operational characteristics of the modern enterprise. We present an approach to knowledge management supported by four systemic methodologies namely the total systems intervention (TSI), the strategic assumption surfacing and testing (SAST), the viable systems model (VSM) and the problem structuring methodology (PSM). The composition of systemic methodologies can result in powerful multi-methodologies that effectively compensate complexity, combine different mental pictures and perspectives and handle diversity in a creative and innovative manner. Information systems, especially those involving multiple stakeholders, profoundly limit the capability of traditional generic methods of analysis to develop and utilize interventions. In this paper, we demonstrate the effectiveness of a multi-methodology designed to facilitate the creation of a knowledge exchange business network in the field of consulting companies that provide an ideal practice field for the verification and testing of the results of our study.
ER  - 

TY  - JOUR
T1  - Categorizing art: Comparing humans and computers
JO  - Computers & Graphics
VL  - 33
IS  - 4
SP  - 484
EP  - 495
PY  - 2009/8//
T2  - 
AU  - Wallraven, Christian
AU  - Fleming, Roland
AU  - Cunningham, Douglas
AU  - Rigau, Jaume
AU  - Feixas, Miquel
AU  - Sbert, Mateu
SN  - 0097-8493
DO  - http://dx.doi.org/10.1016/j.cag.2009.04.003
UR  - http://www.sciencedirect.com/science/article/pii/S0097849309000612
KW  - Computational aesthetics
KW  - Multi-dimensional scaling
KW  - Computer vision
KW  - Human studies
AB  - The categorization of art (paintings, literature) into distinct styles such as Expressionism, or Surrealism has had a profound influence on how art is presented, marketed, analyzed, and historicized. Here, we present results from human and computational experiments with the goal of determining to which degree such categories can be explained by simple, low-level appearance information in the image. Following experimental methods from perceptual psychology on category formation, naive, non-expert participants were first asked to sort printouts of artworks from different art periods into categories. Converting these data into similarity data and running a multi-dimensional scaling (MDS) analysis, we found distinct categories which corresponded sometimes surprisingly well to canonical art periods. The result was cross-validated on two complementary sets of artworks for two different groups of participants showing the stability of art interpretation. The second focus of this paper was on determining how far computational algorithms would be able to capture human performance or would be able in general to separate different art categories. Using several state-of-the-art algorithms from computer vision, we found that whereas low-level appearance information can give some clues about category membership, human grouping strategies included also much higher-level concepts.
ER  - 

TY  - JOUR
T1  - Fuzzy situational tree-networks for intelligent flight support
JO  - Engineering Applications of Artificial Intelligence
VL  - 12
IS  - 4
SP  - 523
EP  - 541
PY  - 1999/8//
T2  - 
AU  - Burdun, Ivan Y.
AU  - Parfentyev, Oleg M.
SN  - 0952-1976
DO  - http://dx.doi.org/10.1016/S0952-1976(99)00012-3
UR  - http://www.sciencedirect.com/science/article/pii/S0952197699000123
KW  - Flight safety
KW  - Complex operational domains
KW  - Fuzzy situational trees
KW  - Intelligent technologies
AB  - The problem of intelligent flight support under complex operational conditions is studied. A ‘chain reaction’ mechanism of a flight accident is described. An affordable method of flight safety enhancement in advanced aircraft is suggested. This method employs the concept of a hybrid intelligent pilot model, which combines positive anthropomorphic and mathematical properties. A central component of this AI model is a comprehensive knowledge base in the form of fuzzy situational tree-network (FSTN) of flight. A conceptual framework and some algorithmic issues of the method are discussed. Examples of FSTN prototyping are demonstrated. Potential applications include an intelligent pilot-vehicle interface, automatic flight-envelope protection, autonomous (robotic) flight including multiple vehicle systems, resolution of conflicts in close free-flight air space, and others. This paper is addressed to specialists and managers in the sector of applied research into intelligent flight control and flight safety.
ER  - 

TY  - JOUR
T1  - Nanonetworks: A new communication paradigm
JO  - Computer Networks
VL  - 52
IS  - 12
SP  - 2260
EP  - 2279
PY  - 2008/8/22/
T2  - 
AU  - Akyildiz, Ian F.
AU  - Brunetti, Fernando
AU  - Blázquez, Cristina
SN  - 1389-1286
DO  - http://dx.doi.org/10.1016/j.comnet.2008.04.001
UR  - http://www.sciencedirect.com/science/article/pii/S1389128608001151
KW  - Nanonetworks
KW  - Nanocommunication
KW  - Molecular communication
AB  - Nanotechnologies promise new solutions for several applications in biomedical, industrial and military fields. At nano-scale, a nano-machine can be considered as the most basic functional unit. Nano-machines are tiny components consisting of an arranged set of molecules, which are able to perform very simple tasks. Nanonetworks. i.e., the interconnection of nano-machines are expected to expand the capabilities of single nano-machines by allowing them to cooperate and share information. Traditional communication technologies are not suitable for nanonetworks mainly due to the size and power consumption of transceivers, receivers and other components. The use of molecules, instead of electromagnetic or acoustic waves, to encode and transmit the information represents a new communication paradigm that demands novel solutions such as molecular transceivers, channel models or protocols for nanonetworks. In this paper, first the state-of-the-art in nano-machines, including architectural aspects, expected features of future nano-machines, and current developments are presented for a better understanding of nanonetwork scenarios. Moreover, nanonetworks features and components are explained and compared with traditional communication networks. Also some interesting and important applications for nanonetworks are highlighted to motivate the communication needs between the nano-machines. Furthermore, nanonetworks for short-range communication based on calcium signaling and molecular motors as well as for long-range communication based on pheromones are explained in detail. Finally, open research challenges, such as the development of network components, molecular communication theory, and the development of new architectures and protocols, are presented which need to be solved in order to pave the way for the development and deployment of nanonetworks within the next couple of decades.
ER  - 

TY  - JOUR
T1  - Towards autonomous robotic servicing: Using an integrated hand-arm-eye system for manipulating unknown objects
JO  - Robotics and Autonomous Systems
VL  - 26
IS  - 1
SP  - 23
EP  - 42
PY  - 1999/1/31/
T2  - 
AU  - Seitz, Matthias
SN  - 0921-8890
DO  - http://dx.doi.org/10.1016/S0921-8890(98)00038-4
UR  - http://www.sciencedirect.com/science/article/pii/S0921889098000384
KW  - 3D active vision
KW  - Power grasp planning
KW  - Closed-loop visual manipulation
KW  - Hand-arm-eye coordination
KW  - System integration
AB  - Executing complex robotic tasks including dexterous grasping and manipulation requires a combination of dexterous robots, intelligent sensors and adequate object information processing. In this paper, vision has been integrated into a highly redundant robotic system consisting of a tiltable camera and a three-fingered dexterous gripper both mounted on a puma-type robot arm. In order to condense the image data of the robot working space acquired from the mobile camera, contour image processing is used for offline grasp and motion planning as well as for online supervision of manipulation tasks. The performance of the desired robot and object motions is controlled by a visual feedback system coordinating motions of hand, arm and eye according to the specific requirements of the respective situation. Experiences and results based on several experiments in the field of service robotics show the possibilities and limits of integrating vision and tactile sensors into a dexterous hand-arm-eye system being able to assist humans in industrial or servicing environments.
ER  - 

TY  - JOUR
T1  - Visual Strategizing: The Systematic Use of Visualization in the Strategic-Planning Process
JO  - Long Range Planning
VL  - 42
IS  - 1
SP  - 42
EP  - 74
PY  - 2009/2//
T2  - 
AU  - Eppler, Martin J.
AU  - Platts, Ken W.
SN  - 0024-6301
DO  - http://dx.doi.org/10.1016/j.lrp.2008.11.005
UR  - http://www.sciencedirect.com/science/article/pii/S0024630108001180
AB  - This article shows how visualization can be used in the strategic-planning process, by examining the use of real-time, interactive visual representations in the business strategy process. Starting with a concise review of literature, we postulate that visualization can improve the quality of the strategic planning process by addressing many of its cognitive, social, and emotional challenges. We develop a conceptual framework for strategy visualization, and use this structure to group and position interactive visual representations of information along the strategic-planning process. We highlight the benefits of visual methods for strategizing, and illustrate them with five case studies covering the entire strategizing process from analysis to implementation. The cases also highlight the use of visualization at different organizational levels, and we consider some of the challenges involved in employing graphic means in strategy work, and how to address them. We highlight resulting risks and practices for visual strategizing and articulate a research agenda for this emergent domain. The key lesson for executives is that visualization should not just be seen as an attractive way to communicate strategic planning process outcomes and monitor its progress, but as a powerful process enabler that can enable strategizing as a joint managerial practice – if facilitated properly. Visualization is, however, a double edged sword and we present several caveats that need to be considered in its application in the strategy context.
ER  - 

TY  - JOUR
T1  - Knowledge transfer and management in tourism organisations: An emerging research agenda
JO  - Tourism Management
VL  - 30
IS  - 3
SP  - 325
EP  - 335
PY  - 2009/6//
T2  - 
AU  - Shaw, Gareth
AU  - Williams, Allan
SN  - 0261-5177
DO  - http://dx.doi.org/10.1016/j.tourman.2008.02.023
UR  - http://www.sciencedirect.com/science/article/pii/S0261517708000836
KW  - Knowledge management
KW  - Knowledge transfer
KW  - Innovations
AB  - This paper reviews current research on knowledge management and knowledge transfer in the context of innovations. Specific attention is focussed on the integration of management perspectives into tourism research. The paper explores some of the key mechanisms and conduits of knowledge transfer within tourism. In doing so it explores such concepts as interlocking directorships, communities of practice, learning regions and labour mobility. There is also an emerging research agenda on knowledge management within tourism but progress is variable with most research being within the hotel sector, where a range of recent studies have examined aspects of knowledge transfer. The paper also draws attention to the need to give closer attention to the nature of innovations within tourism and to consider these in a knowledge management framework.
ER  - 

TY  - JOUR
T1  - Information landscaping: information mapping, charting, querying and reporting techniques for total quality knowledge management
JO  - Information Processing & Management
VL  - 39
IS  - 4
SP  - 639
EP  - 664
PY  - 2003/7//
T2  - 
AU  - Tsai, Bor-sheng
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(02)00098-5
UR  - http://www.sciencedirect.com/science/article/pii/S0306457302000985
KW  - Bibliometrics and informetrics
KW  - Citation mining
KW  - Information landscaping
KW  - Information mapping
KW  - Knowledge management
AB  - Information landscaping––an integration of information mapping, charting, querying and reporting techniques––has been developed to enable the construction of a total quality knowledge management system focusing on a particular subject information field. The techniques apply five major parameters of the Fuzzy commonality model (FCM) including unionization, quantity, continuity or stability, changeability, and critical probability, to construct a series of information maps (infomaps) and a set of chronological-statistical charts (infocharts). The infomaps and infocharts are used as the blueprints and navigation agents for building and developing a web-based subject experts depository and query–report system. Focusing on the subject experts/expertise, this system enables a researcher to expedite a query search through infomaps (qualitative reference) and infocharts (quantitative reference). The entropy measurement and the entropy constant (the square root of the average entropy measure) are calculated to compare with the critical probability of the FCM. This leads to the finding of a set of regression straight lines and the establishment of an information oscillogram. The tropics (upper limit, middle range, lower limit), and the potential/solstitial population and its growth rate within a subject information domain during a particular time period can be determined. They can effectively and efficiently guide librarians and information professionals towards the construction and the continuous development of an electronic collection. The cultivation of a virtual learning and referencing environment can also be created by utilizing this data.
ER  - 

TY  - JOUR
T1  - The functioning of co-opetition in the health-care sector: An explorative analysis
JO  - Scandinavian Journal of Management
VL  - 24
IS  - 3
SP  - 209
EP  - 220
PY  - 2008/9//
T2  - 
AU  - Barretta, Antonio
SN  - 0956-5221
DO  - http://dx.doi.org/10.1016/j.scaman.2008.03.005
UR  - http://www.sciencedirect.com/science/article/pii/S0956522108000274
KW  - Co-opetition
KW  - Health-care trust networks
KW  - Italian health-care service
AB  - The doctrine on the management of the health-care sector has mainly considered cooperation and competition to be opposite models. However, several recent studies of the private sector have stressed the positive effects of balancing competitive and cooperative stimuli in inter-firm relationships. Since many public health-care sectors are often characterized by the presence of both cooperative and competitive forces, this explorative analysis is aimed at identifying the possible determinants of these stimuli and analyzing the likely results of the interaction between these forces within a network of health-care trusts. A better understanding of how simultaneous cooperation and competition impact one another could help regulatory bodies to avoid implementing policies that could produce inconsistent results.
ER  - 

TY  - JOUR
T1  - Detecting emerging research fronts based on topological measures in citation networks of scientific publications
JO  - Technovation
VL  - 28
IS  - 11
SP  - 758
EP  - 775
PY  - 2008/11//
T2  - 
AU  - Shibata, Naoki
AU  - Kajikawa, Yuya
AU  - Takeda, Yoshiyuki
AU  - Matsushima, Katsumori
SN  - 0166-4972
DO  - http://dx.doi.org/10.1016/j.technovation.2008.03.009
UR  - http://www.sciencedirect.com/science/article/pii/S0166497208000436
KW  - R&amp;D management
KW  - Research front
KW  - Bibliometrics
KW  - Citation network
KW  - Topological clustering
AB  - In this paper, we performed a comparative study in two research domains in order to develop a method of detecting emerging knowledge domains. The selected domains are research on gallium nitride (GaN) and research on complex networks, which represent recent examples of innovative research. We divided citation networks into clusters using the topological clustering method, tracked the positions of papers in each cluster, and visualized citation networks with characteristic terms for each cluster. Analyzing the clustering results with the average age and parent–children relationship of each cluster may be helpful in detecting emergence. In addition, topological measures, within-cluster degree z and participation coefficient P, succeeded in determining whether there are emerging knowledge clusters. There were at least two types of development of knowledge domains. One is incremental innovation as in GaN and the other is branching innovation as in complex networks. In the domains where incremental innovation occurs, papers changed their position to large z and large P. On the other hand, in the case of branching innovation, they moved to a position with large z and small P, because there is a new emerging cluster, and active research centers shift rapidly. Our results showed that topological measures are beneficial in detecting branching innovation in the citation network of scientific publications.
ER  - 

TY  - JOUR
T1  - FROM PLANT AND LOGISTICS CONTROL TO MULTI-ENTERPRISE COLLABORATION: Status report prepared by the IFAC Coordinating Committee on Manufacturing Systems
JO  - IFAC Proceedings Volumes
VL  - 38
IS  - 1
SP  - 218
EP  - 231
PY  - 2005///
T2  - 16th IFAC World Congress
AU  - Nof, S.Y.
AU  - Morel, G.
AU  - Monostori, L.
AU  - Molina, A.
AU  - Filip, F.
SN  - 1474-6670
DO  - http://dx.doi.org/10.3182/20050703-6-CZ-1902.01461
UR  - http://www.sciencedirect.com/science/article/pii/S1474667016374730
KW  - Agents
KW  - Bio-Inspired Control
KW  - Collaborative Control
KW  - Complex Systems
KW  - Coordination
KW  - Digital Enterprise
KW  - Distributed Manufacturing
KW  - Enterprise Networks
KW  - Integration
KW  - Large-Scale Systems
KW  - Multi-Agent Control
AB  - Abstract
Current and emerging manufacturing and logistics systems are posing new challenges and opportunities for the automation and control community. This milestone report describes the main problems, such as management of complexity, scalability, increasing costs, coordination, market-based resource allocation, and more. Recent accomplishments and trends are discussed: Control and automation techniques, manufacturing plant automation, collaborative control through integration and networking, and control methods applied to extended enterprises and large-scale critical infrastructure. Finally, forecasts are presented for the next generation manufacturing system; e-work; integration, coordination and collaboration; networked, distributed decision support (NDSS); and active middleware.
ER  - 

TY  - JOUR
T1  - Stakeholder participation for environmental management: A literature review
JO  - Biological Conservation
VL  - 141
IS  - 10
SP  - 2417
EP  - 2431
PY  - 2008/10//
T2  - 
AU  - Reed, Mark S.
SN  - 0006-3207
DO  - http://dx.doi.org/10.1016/j.biocon.2008.07.014
UR  - http://www.sciencedirect.com/science/article/pii/S0006320708002693
KW  - Stakeholder participation
KW  - Environmental management
KW  - Knowledge
KW  - Decision-making
KW  - Best practice
KW  - Typology
AB  - The complex and dynamic nature of environmental problems requires flexible and transparent decision-making that embraces a diversity of knowledges and values. For this reason, stakeholder participation in environmental decision-making has been increasingly sought and embedded into national and international policy. Although many benefits have been claimed for participation, disillusionment has grown amongst practitioners and stakeholders who have felt let down when these claims are not realised. This review first traces the development of participatory approaches in different disciplinary and geographical contexts, and reviews typologies that can be used to categorise and select participatory methods. It then reviews evidence for normative and pragmatic benefits of participation, and evaluates limitations and drawbacks. Although few of the claims that are made have been tested, there is evidence that stakeholder participation can enhance the quality of environmental decisions by considering more comprehensive information inputs. However, the quality of decisions made through stakeholder participation is strongly dependant on the nature of the process leading to them. Eight features of best practice participation are then identified from a Grounded Theory Analysis of the literature. These features emphasise the need to replace a “tool-kit” approach, which emphasises selecting the relevant tools for the job, with an approach that emphasises participation as a process. It is argued that stakeholder participation needs to be underpinned by a philosophy that emphasises empowerment, equity, trust and learning. Where relevant, participation should be considered as early as possible and throughout the process, representing relevant stakeholders systematically. The process needs to have clear objectives from the outset, and should not overlook the need for highly skilled facilitation. Local and scientific knowledges can be integrated to provide a more comprehensive understanding of complex and dynamic socio-ecological systems and processes. Such knowledge can also be used to evaluate the appropriateness of potential technical and local solutions to environmental problems. Finally, it is argued that to overcome many of its limitations, stakeholder participation must be institutionalised, creating organisational cultures that can facilitate processes where goals are negotiated and outcomes are necessarily uncertain. In this light, participatory processes may seem very risky, but there is growing evidence that if well designed, these perceived risks may be well worth taking. The review concludes by identifying future research needs.
ER  - 

TY  - JOUR
T1  - Progress of space research
JO  - COSPAR Information Bulletin
VL  - 2003
IS  - 158
SP  - 30
EP  - 43
PY  - 2003/12//
T2  - 

SN  - 0045-8732
DO  - http://dx.doi.org/10.1016/S0045-8732(03)90063-5
UR  - http://www.sciencedirect.com/science/article/pii/S0045873203900635
ER  - 

TY  - JOUR
T1  - Combining full text and bibliometric information in mapping scientific disciplines
JO  - Information Processing & Management
VL  - 41
IS  - 6
SP  - 1548
EP  - 1572
PY  - 2005/12//
T2  - Special Issue on Infometrics
AU  - Glenisson, Patrick
AU  - Glänzel, Wolfgang
AU  - Janssens, Frizo
AU  - De Moor, Bart
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/j.ipm.2005.03.021
UR  - http://www.sciencedirect.com/science/article/pii/S0306457305000178
KW  - Automatic indexing
KW  - Full text analysis
KW  - Text-based clustering
KW  - Mapping of science
KW  - Bibliometrics
AB  - In the present study results of an earlier pilot study by Glenisson, Glänzel and Persson are extended on the basis of larger sets of papers. Full text analysis and traditional bibliometric methods are serially combined to improve the efficiency of the two individual methods. The text mining methodology already introduced in the pilot study is applied to the complete publication year 2003 of the journal Scientometrics. Altogether 85 documents that can be considered research articles or notes have been selected for this exercise. The outcomes confirm the main results of the pilot study, namely, that such hybrid methodology can be applied to both research evaluation and information retrieval. Nevertheless, Scientometrics documents published in 2003 cover a much broader and more heterogeneous spectrum of bibliometrics and related research than those analysed in the pilot study. A modified subject classification based on the scheme used in an earlier study by Schoepflin and Glänzel has been applied for validation purposes.
ER  - 

TY  - JOUR
T1  - Database tomography for technical intelligence: A roadmap of the near-earth space science and technology literature
JO  - Information Processing & Management
VL  - 34
IS  - 1
SP  - 69
EP  - 85
PY  - 1998/1//
T2  - 
AU  - Kostoff, Ronald N.
AU  - Eberhart, Henry J.
AU  - Toothman, Darrell Ray
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(97)00066-6
UR  - http://www.sciencedirect.com/science/article/pii/S0306457397000666
AB  - Database Tomography (DT) is a system which includes algorithms for extracting multi-word phrase frequencies and performing phrase proximity analyses (relating physical closeness of the multi-word technical phrases to thematic relationships) on any type of large textual database. As an illustration of the DT process applied to the published literature, DT was used to derive technical intelligence from a near-earth space (NES) database derived from the Science Citation Index and the Engineering Compendex. Phrase frequency analysis (the occurrence frequency of multi-word technical phrases) provided the pervasive technical themes of the space database, and the phrase proximity analysis provided the relationships among the pervasive technical themes. Bibliometric analysis of the NES literature supplemented the DT results by identifying: the recent most prolific NES authors; the journals which contain numerous NES papers; the institutions which produce numerous NES papers; the keywords most frequently specified by the NES authors; the authors whose works are cited most frequently in the NES papers; and the particular papers and journals cited most frequently in the NES papers.
ER  - 

TY  - JOUR
T1  - On repetition-free binary words of minimal density
JO  - Theoretical Computer Science
VL  - 218
IS  - 1
SP  - 161
EP  - 175
PY  - 1999/4/28/
T2  - 
AU  - Kolpakov, Roman
AU  - Kucherov, Gregory
AU  - Tarannikov, Yuri
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/S0304-3975(98)00257-6
UR  - http://www.sciencedirect.com/science/article/pii/S0304397598002576
KW  - Unavoidable patterns
KW  - Power-free words
KW  - Exponent
KW  - Minimal density
AB  - We study the minimal proportion (density) of one letter in nth power-free binary words. First, we introduce and analyse a general notion of minimal letter density for any infinite set of words which does not contain a specified set of “prohibitedrdquo; subwords. We then prove that for nth power-free binary words the density function is 1n + 1n3 + 1n4 + O(1n5). We also consider a generalization of nth power-free words for fractional powers (exponents): a word is xth power-free for a real x, if it does not contain subwords of exponent x or more. We study the minimal proportion of one letter in xth power-free binary words as a function of x and prove, in particular, that this function is discontinuous at 73 as well as at all integer points n ⩾ 3. Finally, we give an estimate of the size of the jumps.
ER  - 

TY  - JOUR
T1  - Separation of clones of cooperations by cohyperidentities
JO  - Discrete Mathematics
VL  - 309
IS  - 4
SP  - 772
EP  - 783
PY  - 2009/3/6/
T2  - 
AU  - Denecke, K.
AU  - Saengsura, K.
SN  - 0012-365X
DO  - http://dx.doi.org/10.1016/j.disc.2008.01.043
UR  - http://www.sciencedirect.com/science/article/pii/S0012365X08000654
KW  - Cooperations
KW  - Coalgebras
KW  - Clones
KW  - Boolean cooperations
KW  - Coidentities
KW  - Cohyperidentities
AB  - An n -ary cooperation is a mapping from a nonempty set A to the n th copower of A . A clone of cooperations is a set of cooperations which is closed under superposition and contains all injections. Coalgebras are pairs consisting of a set and a set of cooperations defined on this set. We define terms for coalgebras, coidentities and cohyperidentities. These concepts will be applied to give a new solution of the completeness problem for clones of cooperations defined on a two-element set and to separate clones of cooperations by coidentities.
ER  - 

TY  - JOUR
T1  - Country index volumes 1–28
JO  - Research Policy
VL  - 28
IS  - 9
SP  - 1029
EP  - 1059
PY  - 1999/12//
T2  - 

SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/S0048-7333(99)00109-2
UR  - http://www.sciencedirect.com/science/article/pii/S0048733399001092
ER  - 

TY  - JOUR
T1  - Application of formal verification and behaviour abstraction to the service interaction problem in intelligent networks
JO  - Journal of Systems and Software
VL  - 40
IS  - 3
SP  - 227
EP  - 248
PY  - 1998/3//
T2  - Formal Methods Technology Transfer
AU  - Nitsche, Ulrich
SN  - 0164-1212
DO  - http://dx.doi.org/10.1016/S0164-1212(97)00169-6
UR  - http://www.sciencedirect.com/science/article/pii/S0164121297001696
AB  - One of the major drawbacks for the use of formal methods is the excessive size of the state-spaces representing behaviours of industrial-sized specifications of concrete systems. Existing verification algorithms simply are often not applicable to the large systems of practical relevance. One can improve the applicability of verification methods by orders of magnitude by ignoring parts of a behaviour which contain no information with respect to a given verification task. We focus on exactly such an abstraction based way of dealing with large, so called industrial-sized systems and discuss its application in an industrial project aiming at the detection of service interactions in Intelligent Networks on the specification level. The concrete application of the abstraction and verification method is presented mainly by considering an example taken from the service interaction project.
ER  - 

TY  - JOUR
T1  - Dynamic linear time temporal logic
JO  - Annals of Pure and Applied Logic
VL  - 96
IS  - 1–3
SP  - 187
EP  - 207
PY  - 1999/3/1/
T2  - 
AU  - Henriksen, Jesper G.
AU  - Thiagarajan, P.S.
SN  - 0168-0072
DO  - http://dx.doi.org/10.1016/S0168-0072(98)00039-6
UR  - http://www.sciencedirect.com/science/article/pii/S0168007298000396
KW  - Linear time temporal logic
KW  - Dynamic logic
KW  - ω-automata
KW  - Expressive completeness
KW  - Axiomatizations
AB  - A simple extension of the propositional temporal logic of linear time is proposed. The extension consists of strengthening the until operator by indexing it with the regular programs of propositional dynamic logic. It is shown that DLTL, the resulting logic, is expressively equivalent to the monadic second-order theory of ω-sequences. In fact, a sublogic of DLTL which corresponds to propositional dynamic logic with a linear time semantics is already expressively complete. We show that DLTL has an exponential time decision procedure and admits a finitary axiomatization. We also point to a natural extension of the approach presented here to a distributed setting.
ER  - 

TY  - JOUR
T1  - Subject index volumes 1–200
JO  - Theoretical Computer Science
VL  - 213–214
IS  - 
SP  - 5
EP  - 436
PY  - 1999/2/17/
T2  - 

SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/S0304-3975(98)00319-3
UR  - http://www.sciencedirect.com/science/article/pii/S0304397598003193
ER  - 

TY  - JOUR
T1  - A neural algorithm for document clustering
JO  - Information Processing & Management
VL  - 27
IS  - 4
SP  - 337
EP  - 346
PY  - 1991///
T2  - Special Issue: Parallel Processing and Information Retrieval
AU  - Macleod, Kevin J.
AU  - Robertson, W.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(91)90088-4
UR  - http://www.sciencedirect.com/science/article/pii/0306457391900884
AB  - A difficulty in implementing document clustering using algorithms based on sequential architectures is that a computational bottleneck arises eventually in the classification of documents. Neural networks have the potential to alleviate this problem. This paper reviews the fundamentals of a framework for describing neural nets. Next, the MacLeod algorithm, a neural network algorithm designed specifically for document clustering is presented. The features of this algorithm are examined. Experimental results from two small test collections are reported. Based on these results the algorithm exhibits effectiveness comparable to hierarchic (sequential) clustering algorithms. The MacLeod algorithm also appears to require time and space complexities of O(n2) and 0(n), respectively. Experimental results show that the algorithm's performance is order independent.
ER  - 

TY  - JOUR
T1  - Recent trends in hierarchic document clustering: A critical review
JO  - Information Processing & Management
VL  - 24
IS  - 5
SP  - 577
EP  - 597
PY  - 1988///
T2  - 
AU  - Willett, Peter
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(88)90027-1
UR  - http://www.sciencedirect.com/science/article/pii/0306457388900271
AB  - This article reviews recent research into the use of hierarchic agglomerative clustering methods for document retrieval. After an introduction to the calculation of interdocument similarities and to clustering methods that are appropriate for document clustering, the article discusses algorithms that can be used to allow the implementation of these methods on databases of nontrivial size. The validation of document hierarchies is described using tests based on the theory of random graphs and on empirical characteristics of document collections that are to be clustered. A range of search strategies is available for retrieval from document hierarchies and the results are presented of a series of research projects that have used these strategies to search the clusters resulting from several different types of hierarchic agglomerative clustering method. It is suggested that the complete linkage method is probably the most effective method in terms of retrieval performance; however, it is also difficult to implement in an efficient manner. Other applications of document clustering techniques are discussed briefly; experimental evidence suggests that nearest neighbor clusters, possibly represented as a network model, provide a reasonably efficient and effective means of including interdocument similarity information in document retrieval systems.
ER  - 

TY  - JOUR
T1  - Document clustering: An evaluation of some experiments with the cranfield 1400 collection
JO  - Information Processing & Management
VL  - 11
IS  - 5–7
SP  - 171
EP  - 182
PY  - 1975///
T2  - 
AU  - Van Rijsbergen, C.J.
AU  - Croft, W.B.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(75)90006-0
UR  - http://www.sciencedirect.com/science/article/pii/0306457375900060
AB  - The single-link cluster method is used to construct a hierarchic classification for the 1400 documents in the Cranfield test collection. A variety of retrieval strategies applied to this hierarchy are evaluated in terms of effectiveness and efficiency. Comparisons are made between our results and those of similar experiments in document clustering on the Smart project.
ER  - 

TY  - JOUR
T1  - Considerations on the similarity measures between index terms
JO  - Information Processing Letters
VL  - 16
IS  - 5
SP  - 243
EP  - 246
PY  - 1983/6/10/
T2  - 
AU  - Ozawa, Kazumasa
SN  - 0020-0190
DO  - http://dx.doi.org/10.1016/0020-0190(83)90096-0
UR  - http://www.sciencedirect.com/science/article/pii/0020019083900960
KW  - Similarity measures
KW  - index terms
KW  - document clustering
KW  - information retrieval
KW  - metric property
ER  - 

TY  - JOUR
T1  - Knowledge mapping: Psychoeducational tool in relapse prevention training for probationers: Kevin Knight, D. Dwayne Simpson and Donald F. Dansereau. Texas Christian University, Fort Worth, TX
JO  - Pharmacology Biochemistry and Behavior
VL  - 42
IS  - 2
SP  - 373
EP  - 
PY  - 1992/6//
T2  - 

SN  - 0091-3057
DO  - http://dx.doi.org/10.1016/0091-3057(92)90591-3
UR  - http://www.sciencedirect.com/science/article/pii/0091305792905913
ER  - 

TY  - JOUR
T1  - Further experiments with hierarchic clustering in document retrieval
JO  - Information Storage and Retrieval
VL  - 10
IS  - 1
SP  - 1
EP  - 14
PY  - 1974/1//
T2  - 
AU  - van Rijsbergen, C.J.
SN  - 0020-0271
DO  - http://dx.doi.org/10.1016/0020-0271(74)90038-2
UR  - http://www.sciencedirect.com/science/article/pii/0020027174900382
AB  - The purpose of this paper is to report the results of experiments in document clustering using three well known test collections. Automatic classification is briefly introduced. The hypothesis underlying the use of clustering is discussed. A framework for the evaluation of cluster-based retrieval strategies is constructed. These strategies are shown to be dependent on the method of cluster representation (cluster profile) adopted. Finally, a particular cluster-based strategy together with a cluster representation method associated with it is examined and evaluated in detail.
ER  - 

TY  - JOUR
T1  - The importance of rough approximations for information retrieval
JO  - International Journal of Man-Machine Studies
VL  - 34
IS  - 5
SP  - 657
EP  - 671
PY  - 1991/5//
T2  - 
AU  - Srinivasan, Padmini
SN  - 0020-7373
DO  - http://dx.doi.org/10.1016/0020-7373(91)90017-2
UR  - http://www.sciencedirect.com/science/article/pii/0020737391900172
AB  - The objective here is to present the results of our study which show that rough approximations contribute to the improvement of recall in information retrieval (IR). The information retrieval literature provides ample evidence of situations in which less than 40% of the relevant documents are retrieved. A major reason for this is the problem of search vocabulary and the burden it imposes on the user who is expected to specify all possible terms that refer to the subject of interest. The theory of rough sets provides a framework for organizing the vocabulary in such a way that this constraint is reduced. The model also provides a set of search strategies that are flexible and user oriented. These strategies are based on approximate descriptions of objects such as queries and documents. This study concludes that retrieval strategies within the rough set model perform significantly better than retrieval within the vector model using the cosine formula, in document ranking as well as in recall. The paper concludes by demonstrating a methodology for document clustering using rough sets. This work is a continuation of earlier work by the author on the application of rough sets to information retrieval.
ER  - 

TY  - JOUR
T1  - Performance of automatic information systems
JO  - Information Storage and Retrieval
VL  - 4
IS  - 2
SP  - 201
EP  - 218
PY  - 1968/6//
T2  - 
AU  - Lesk, Michael E.
SN  - 0020-0271
DO  - http://dx.doi.org/10.1016/0020-0271(68)90022-3
UR  - http://www.sciencedirect.com/science/article/pii/0020027168900223
AB  - The SMART document retrieval system is used to investigate algorithms for text analysis and request searching. Results from three document collections indicate that word normalization is efficiently performed by automatic thesaurus lookup, while phrase matching procedures, statistical association methods, and concept hierarchies are useful for special applications. Automatic document clustering schemes and user-interactive feedback methods permit rapid searches of large collections. Abstracts are found to be superior to titles as a base for content analysis in a document retrieval system and almost as good as complete texts. Proper procedures for designing dictionaries and searching requests are discussed. The practicality of large scale document centers and their proper design are considered in light of these results.
ER  - 

TY  - JOUR
T1  - A user-adaptive neural network supporting a rule-based relevance feedback
JO  - Fuzzy Sets and Systems
VL  - 82
IS  - 2
SP  - 201
EP  - 211
PY  - 1996/9/9/
T2  - Connectionist and Hybrid Connectionist Systems for Approximate Reasoning
AU  - Bordogna, Gloria
AU  - Pasi, Gabriella
SN  - 0165-0114
DO  - http://dx.doi.org/10.1016/0165-0114(95)00256-1
UR  - http://www.sciencedirect.com/science/article/pii/0165011495002561
KW  - Information storage and retrieval
KW  - Relevance feedback
KW  - Neural networks
KW  - Rule-based systems
AB  - Associative mechanisms, such as those based on the use of thesauri, document clustering and relevance feedback, are widely employed in information retrieval systems to enhance their effectiveness. They make it possible to retrieve also the documents not directly indexed by the search terms. In this paper, a relevance feedback model is defined, based on an associative neural network in which concepts meaningful to the user are accumulated at retrieval time by an iterative process. The network can be regarded as a kind of personal thesaurus of the user. A rule-based superstructure is then defined to expand the query evaluation with the meaningful terms identified in the network. The search terms are expanded by taking into account their associations with the meaningful terms in the network.
ER  - 

TY  - JOUR
T1  - A theoretical framework for defining similarity measures for boolean search request formulations, including some experimental results
JO  - Information Processing & Management
VL  - 21
IS  - 6
SP  - 501
EP  - 524
PY  - 1985///
T2  - 
AU  - Radecki, Tadeusz
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(85)90004-4
UR  - http://www.sciencedirect.com/science/article/pii/0306457385900044
AB  - Clusters of queries submitted to a given information retrieval system can be used as a basis for an effective method of clustering documents. This indirect procedure of document clustering requires the availability of a similarity measure for queries. Research carried out along these lines has resulted in the development of some methodologies for estimating such query similarities, applicable both in the case of queries characterized by sets of weighted or unweighted index terms and in the case of queries represented by Boolean combinations of index terms. This paper reports the results of further research by the author into a methodology of the latter type, i.e. a methodology for determining the similarity between queries characterized by Boolean search request formulations. The novelty of the presented approach, as compared with the methodology introduced in an earlier paper by the author, is that some relations among index terms are now taken into account. A number of similarity measures for Boolean combinations of index terms are discussed here in some detail. The rationale behind these measures is outlined, and the conditions to be met for ensuring their equivalence are identified. Moreover, the results of an experiment concerning two of the similarity measures introduced are given.
ER  - 

TY  - JOUR
T1  - Earth science mapping: edited by J. McCall and B. Marker, Kluwer Academic Publishers (Graham &amp; Trotman), Dordrecht, The Netherlands, 1989, 268 pp. Price: Dfl. 310.00, US$124.00
JO  - Science of The Total Environment
VL  - 104
IS  - 3
SP  - 252
EP  - 
PY  - 1991/5/15/
T2  - 
AU  - Benarie, Michel
SN  - 0048-9697
DO  - http://dx.doi.org/10.1016/0048-9697(91)90081-O
UR  - http://www.sciencedirect.com/science/article/pii/004896979190081O
ER  - 

TY  - JOUR
T1  - Automatically organizing bookmarks per contents
JO  - Computer Networks and ISDN Systems
VL  - 28
IS  - 7–11
SP  - 1321
EP  - 1333
PY  - 1996/5//
T2  - Proceedings of the Fifth International World Wide Web Conference 6-10 May 1996
AU  - Maarek, Yoelle S.
AU  - Ben Shaul, Israel Z.
SN  - 0169-7552
DO  - http://dx.doi.org/10.1016/0169-7552(96)00024-4
UR  - http://www.sciencedirect.com/science/article/pii/0169755296000244
KW  - Bookmark organization
KW  - Document clustering
KW  - Information retrieval
AB  - The explosive growth in the Web leads to the need for personalized client-based local URL repositories often called bookmarks. We present a novel approach to bookmark organization that provides automatic classification together with user adaption.
ER  - 

TY  - JOUR
T1  - Words and co-words as indicators of intellectual organization
JO  - Research Policy
VL  - 18
IS  - 4
SP  - 209
EP  - 223
PY  - 1989/8//
T2  - 
AU  - Leydesdroff, Loet
SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/0048-7333(89)90016-4
UR  - http://www.sciencedirect.com/science/article/pii/0048733389900164
AB  - Co-word linkages among documents have been proposed as an alternative to citations and co-citations to indicate (“map”) how documents are related. From this study, it appears that the co-word structure of citing documents is about the same as that of cited documents for a set of biochemistry articles. This co-word structure reflects the intellectual structure of the document set and the intellectual organization of the work of related groups of authors, as can be validated against the results of an independent document analysis. It will be argued that given the condition of a restricted document set, the document structure, in terms of attributed word-word associations in the titles of scientific articles, provides us with a tool for the description of intellectual organization. Since most science studies and nearly all science policy studies use institutionally defined sets of documents, this instrument could have a wide range of applications.
ER  - 

TY  - JOUR
T1  - VIA-RAD: a blackboard-based system for diagnostic radiology
JO  - Artificial Intelligence in Medicine
VL  - 7
IS  - 4
SP  - 343
EP  - 360
PY  - 1995/8//
T2  - 
AU  - Rogers, Erika
SN  - 0933-3657
DO  - http://dx.doi.org/10.1016/0933-3657(95)00009-U
UR  - http://www.sciencedirect.com/science/article/pii/093336579500009U
KW  - Intelligent systems
KW  - Blackboard architecture
KW  - Diagnostic radiology
KW  - Cooperative decision-making assistance
KW  - Perception and problem-solving
AB  - The work described in this article presents an approach to the integration of computer-displayed radiological images with cooperative computerized assistance for decision-making. The VIA-RAD system (Visual Interaction Assistant for Radiology) is a blackboard-based architecture, founded on extensive data collection and analysis in the domain of diagnostic radiology, together with cognitive modeling of the interaction between perception and problem-solving. The details of this system are presented in terms of domain knowledge representation and domain knowledge mapping. A small prototype of the system has been implemented and tested with radiology subjects, and the results of this study are also described.
ER  - 

TY  - JOUR
T1  - Designer®—Intelligent expert system for intelligent manufacturing systems design
JO  - Robotics and Computer-Integrated Manufacturing
VL  - 11
IS  - 3
SP  - 121
EP  - 136
PY  - 1994/9//
T2  - 
AU  - Milacic, Vladimir R
SN  - 0736-5845
DO  - http://dx.doi.org/10.1016/0736-5845(94)90029-9
UR  - http://www.sciencedirect.com/science/article/pii/0736584594900299
AB  - This survey on expert systems activities and trends in Yugoslavia offers some results already obtained in the domain of manufacturing science and technology. In the scope of a long-term research project “Intelligent Manufacturing Systems (IMS)—Theory and Application” a Designer® Intelligent Expert System for mafacturing engineering has been proposed and partially developed. Designer® IES is based on new developed knowledge automata theory enhanced with cellular automata concept. Induction learning by analogy and Quasimorphism knowledge mapping from real world to model world is used to generate a reasoning structure. The Intelligent Expert System is divided into three main subsystems, with a very large knowledge base: •
Product designer
•
Process Designer, and
•
Production Planning and Control Designer.
 All these segments were developed in pilot versions of expert systems for specific groups of activities inside each of these three domains.
ER  - 

TY  - JOUR
T1  - The knowledge hypermap: An alternative to hypertext
JO  - Computers & Education
VL  - 14
IS  - 5
SP  - 409
EP  - 416
PY  - 1990///
T2  - 
AU  - Reynolds, Sharon B.
AU  - Dansereau, Donald F.
SN  - 0360-1315
DO  - http://dx.doi.org/10.1016/0360-1315(90)90034-5
UR  - http://www.sciencedirect.com/science/article/pii/0360131590900345
AB  - Two types of non-linear, computer-linked text were investigated to determine differences in recall, reference time and accuracy, and satisfaction among students learning statistical material. The two instructional presentation methods studied, hypermaps and hypertext, were implemented on a Macintosh SE-HD20 in HyperCard. Hypermaps were implemented according to the TCU Knowledge Mapping System developed by Dansereau et al. No significant differences were found in recall of material following the hypertext (n = 15) or hypermap (n = 18) instruction. Although not significant, an interesting trend in the data indicated that differences in verbal skills, as measured by the Delta Reading Vocabulary Test, had differential effects in the text and map groups. A significant difference was found in overall satisfaction, with the hypermap group expressing more satisfaction than the hypertext group. The hypertext group expressed significantly more frustration and confusion than the hypermap group. Although not significant, there was a trend toward greater efficiency for hypermaps on measures of reference accuracy and time. The findings indicate a need for further study of the utility of hypermaps for presentation of textual material in conjuction with computer-based instruction.
ER  - 

TY  - JOUR
T1  - Applied earth-science mapping: the planners' requirement
JO  - Engineering Geology
VL  - 29
IS  - 4
SP  - 403
EP  - 411
PY  - 1990/12//
T2  - 
AU  - Marker, B.R.
AU  - McCall, G.J.H.
SN  - 0013-7952
DO  - http://dx.doi.org/10.1016/0013-7952(90)90075-C
UR  - http://www.sciencedirect.com/science/article/pii/001379529090075C
AB  - During the last 20 years earth-scientists have energetically explained the relevance of environmental geology to, and provided advice for, planning and development. Even so, numerous instances of sterilisation of earth-resources and of development on unstable land with insufficient precautions taken still occur. The reasons for this include: (a) limited training in the earth-sciences for many planners and developers; (b) failure to appreciate the benefits of having sound, easily available background information for decision making; and (c) presentation of results in ways that are not readily understood by potential users or do not fit easily into the administrative processes for land-use planning and development control.

Addressing these issues is at least as important as developing techniques and undertaking new studies, since full and proper utilisation of results and appreciation of the need to commission such research depend on their resolution.
ER  - 

TY  - JOUR
T1  - The use of knowledge acquisition in instructional design
JO  - Computers in Human Behavior
VL  - 4
IS  - 3
SP  - 257
EP  - 274
PY  - 1988///
T2  - 
AU  - Wiggs, Cheri L.
AU  - Perez, Ray S.
SN  - 0747-5632
DO  - http://dx.doi.org/10.1016/0747-5632(88)90017-9
UR  - http://www.sciencedirect.com/science/article/pii/0747563288900179
AB  - Expert systems and knowledge based systems have emerged from “esoteric” laboratory research in Artificial Intelligence (AI) to become an important tool for approaching real world problems. Expert systems are distinctive in that they are designed to address problems in a similar manner and with similar results as a human expert. The basic structure of an expert system is comprised of three functionally separate components: (a) knowledge base, which contains a representation of domain related facts; (b) means of knowledge base use to solve a problem, inference mechanism; and (c) working memory, which records the input data and progress for each problem. Given the complexity and cost of expert system construction, it is imperative that system developers and researchers attend to research issues which are critical to knowledge engineering. These questions can be categorized according to the parts of an expert system: (a) knowledge representation; (b) knowledge utilization; and (c) knowledge acquisition. A knowledge acquisition procedure is presented which displays the relationship between subject matter expert expertise consisting of declarative knowledge, procedural knowledge, heuristics, formal rules, and meta-rules. The knowledge engineer uses one or a combination of elicitation methods to gather relevant data to eventually build the components of an expert system. Further explained are the acquisition methods: (a) structured interview; (b) verbal reports; (c) teaching the subject matter; (d) observation; and (e) automated knowledge acquisition tools. The paper concludes with a discussion of the future research issues concerned with using knowledge mapping and task analysis vs. knowledge acquisition techniques.
ER  - 

TY  - JOUR
T1  - An experiment in science mapping for research planning
JO  - Research Policy
VL  - 15
IS  - 5
SP  - 233
EP  - 251
PY  - 1986/10//
T2  - 
AU  - Healey, Peter
AU  - Rothman, Harry
AU  - Hoch, Paul K.
SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/0048-7333(86)90024-7
UR  - http://www.sciencedirect.com/science/article/pii/0048733386900247
AB  - This paper considers the recent attempt of the U.K. Advisory Board for the Research Councils to test the usefulness of various citation, co-citation and co-word bibliographic analysis techniques for evaluating the stale of various scientific disciplines, including potential areas for useful investment; and in general as an aid to research planning by science policy-makers in a period of steady (or even relatively declining) resources. Results of a study involving the examination of five important scientific fields are considered, and discussion focuses on the advantages and disadvantages of each technique.
ER  - 

TY  - JOUR
T1  - Co-word-based science maps of chemical engineering. Part II: Representations by combined clustering and multidimensional scaling
JO  - Research Policy
VL  - 22
IS  - 1
SP  - 47
EP  - 71
PY  - 1993/2//
T2  - 
AU  - Peters, H.P.F.
AU  - van Raan, A.F.J.
SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/0048-7333(93)90032-D
UR  - http://www.sciencedirect.com/science/article/pii/004873339390032D
AB  - In this paper we present the results of the second part of our study on science mapping. We discuss an improvement of co-word analysis based on a combination of a clustering technique applied to the word co-occurrence data matrix and multidimensional scaling of the resulting word-clusters. As in the first of our study, we construct journal-based, author-based, and conference-based co-word maps of chemical engineering. We apply word-similarity analysis to compare these different maps, using the views of the experts (as discussed in part I) as a frame of reference. Next, we apply word-similarity analysis to compare maps from subsequent periods of time, in order to identify developments over time.

An important improvement in the practical applicability of our maps is attained by labelling the co-word clusters with data on journals, classification codes, authors and countries.

Finally, we compare our author-based co-word maps with a “hybrid” author-keyword map and with a co-author map. Important developments in chemical engineering are indeed visualized by our mapping techniques. The usefulness of the various types of maps is strongly related with the questions one wants to answer.
ER  - 

TY  - JOUR
T1  - Co-word-based science maps of chemical engineering. Part I: Representations by direct multidimensional scaling
JO  - Research Policy
VL  - 22
IS  - 1
SP  - 23
EP  - 45
PY  - 1993/2//
T2  - 
AU  - Peters, H.P.F.
AU  - van Raan, A.F.J.
SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/0048-7333(93)90031-C
UR  - http://www.sciencedirect.com/science/article/pii/004873339390031C
AB  - In this paper we present the results of the first part of our study on science mapping. We discuss a new approach to co-word analysis in order to solve or to circumvent some of the problems mentioned in the earlier literature. The mapping technique is based on a “direct” application to the word co-occurrence data matrix of multidimensional scaling. The subject area of our co-word mapping approach is chemical engineering. We have chosen this field of scientific research because we found it tempting to bibliometrically map such a large, rather multidisciplinary and economically important field. Furthermore, it is important to assess bibliometric methods and techniques not only for basic research fields, but also for the more applied and engineering fields.

We discuss maps based on three different datasets (top-journals, top-scientists, and a conference). Furthermore, we discuss the differences between maps based on title- and on abstract-words. Moreover, we experiment with different relational indices to obtain optimal contrasts between interesting and not-interesting features. We explore the possibilities to visualize changes over time in one display. An important part of the work is the evaluation of the maps by an extensive expert judgement.
ER  - 

TY  - JOUR
T1  - Information resource matrix for production and intelligent manufacturing using genetic algorithm techniques
JO  - Computers & Industrial Engineering
VL  - 23
IS  - 1–4
SP  - 483
EP  - 485
PY  - 1992/11//
T2  - 
AU  - Kulkarni, Janardan
AU  - Parsael, Hamid R.
SN  - 0360-8352
DO  - http://dx.doi.org/10.1016/0360-8352(92)90166-H
UR  - http://www.sciencedirect.com/science/article/pii/036083529290166H
AB  - In the field of production and intelligent manufacturing an experiment was conducted to obtain the relevant citations from nine databases in science and technology. A set of keywords or descriptors were used to formulate the search and their effectiveness was tested by using the clustering and genetic algorithm techniques. The results of this research are reported in this paper.
ER  - 

TY  - JOUR
T1  - Information retrieval research: R. N. Oddy et al. (Eds), Butterworths, London, England 1981, 379pp. $49.50, ISBN: 0-408-10775-8
JO  - Information Processing & Management
VL  - 19
IS  - 6
SP  - 399
EP  - 
PY  - 1983///
T2  - 
AU  - Yu, Clement T.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(83)90057-2
UR  - http://www.sciencedirect.com/science/article/pii/0306457383900572
ER  - 

TY  - JOUR
T1  - systolic array exploitation of a neural network inherent parallelism solving the nearest neighbor problem
JO  - Nonlinear Analysis: Theory, Methods & Applications
VL  - 30
IS  - 5
SP  - 2945
EP  - 2952
PY  - 1997/12//
T2  - Proceedings of the Second World Congress of Nonlinear Analysts
AU  - Bekakos, Michael P.
AU  - Pramataris, Katherine C.
SN  - 0362-546X
DO  - http://dx.doi.org/10.1016/S0362-546X(97)00345-3
UR  - http://www.sciencedirect.com/science/article/pii/S0362546X97003453
KW  - and phrasesNeural networks
KW  - Kohonen neural network
KW  - backpropagation neural network
KW  - nearest neighbor problem
KW  - text retrieval
KW  - systolic arrays
KW  - matrix-vector multiplication.
ER  - 

TY  - JOUR
T1  - Current research into chemical and textual information retrieval at the department of information studies, University of Sheffield
JO  - Information Processing & Management
VL  - 23
IS  - 5
SP  - 447
EP  - 463
PY  - 1987///
T2  - 
AU  - Lynch, Michael F.
AU  - Willett, Peter
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(87)90113-0
UR  - http://www.sciencedirect.com/science/article/pii/0306457387901130
AB  - This paper discusses research into chemical information and document retrieval systems at the Department of Information Studies, University of Sheffield. The research includes the use of cluster analysis methods for document retrieval and drug design, the representation and searching of files of generic chemical structures, substructure searching and maximal common substructure identification in files of three-dimensional chemical structures, and the use of novel parallel computer hardware in all of these application areas.
ER  - 

TY  - JOUR
T1  - One approach to classification of users and automatic clustering of documents
JO  - Information Processing & Management
VL  - 29
IS  - 2
SP  - 187
EP  - 195
PY  - 1993/3//
Y2  - 1993/4//
T2  - 
AU  - Frants, Valery I.
AU  - Kamenoff, Nick I.
AU  - Shapiro, Jacob
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(93)90002-U
UR  - http://www.sciencedirect.com/science/article/pii/030645739390002U
AB  - This paper shows how to automatically construct a classification of users and a clustering of documents on the basis of users' information needs, that is, how to create clusters of documents and cross references among clusters using users' search requests. The paper also addresses a question of feedback in the construction of this classification and clustering so that the classification can be changed over time to reflect the changing needs of the users.
ER  - 

TY  - JOUR
T1  - A fast procedure for the calculation of similarity coefficients in automatic classification
JO  - Information Processing & Management
VL  - 17
IS  - 2
SP  - 53
EP  - 60
PY  - 1981///
T2  - 
AU  - Willett, Peter
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(81)90026-1
UR  - http://www.sciencedirect.com/science/article/pii/0306457381900261
AB  - A fast algorithm is described for comparing the lists of terms representing documents in automatic classification experiments. The speed of the procedure arises from the fact that all of the non-zero-valued coefficients for a given document are identified together, using an inverted file to the terms in the document collection. The complexity and running time of the algorithm are compared with previously described procedures.
ER  - 

TY  - JOUR
T1  - The impact of information research: Studies of three research areas
JO  - International Journal of Information Management
VL  - 7
IS  - 2
SP  - 98
EP  - 99
PY  - 1987/6//
T2  - 
AU  - Craghill, D.
SN  - 0268-4012
DO  - http://dx.doi.org/10.1016/0268-4012(87)90049-1
UR  - http://www.sciencedirect.com/science/article/pii/0268401287900491
ER  - 

TY  - JOUR
T1  - List of contents and author index
JO  - Information Processing & Management
VL  - 11
IS  - 
SP  - i
EP  - ii
PY  - 1975///
T2  - 

SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(75)90015-1
UR  - http://www.sciencedirect.com/science/article/pii/0306457375900151
ER  - 

TY  - JOUR
T1  - Subject index
JO  - Research Policy
VL  - 15
IS  - 6
SP  - 349
EP  - 352
PY  - 1986/12//
T2  - 

SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/0048-7333(86)90036-3
UR  - http://www.sciencedirect.com/science/article/pii/0048733386900363
ER  - 

TY  - JOUR
T1  - On the non-random nature of nearest-neighbour document clusters
JO  - Information Processing & Management
VL  - 29
IS  - 4
SP  - 449
EP  - 452
PY  - 1993/7//
Y2  - 1993/8//
T2  - 
AU  - Shaw, Rachel J.
AU  - Willett, Peter
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(93)90040-K
UR  - http://www.sciencedirect.com/science/article/pii/030645739390040K
AB  - It has recently been suggested that the observed values of retrieval effectiveness that are obtained in searches of files of nearest-neighbour clusters can be explained by assuming that the pairwise inter-document similarities used to construct the clusters have been generated randomly. This paper presents evidence to suggest that such similarities are significantly different from those obtained by a random generation procedure.
ER  - 

TY  - JOUR
T1  - Plant stress from air pollution: by M. Treshov and F.K. Anderson, John Wiley &amp; Sons, Chichester, UK, 1989, 283 pp. Price: £39.00
JO  - Science of The Total Environment
VL  - 104
IS  - 3
SP  - 251
EP  - 252
PY  - 1991/5/15/
T2  - 
AU  - Benarie, Michel
SN  - 0048-9697
DO  - http://dx.doi.org/10.1016/0048-9697(91)90080-X
UR  - http://www.sciencedirect.com/science/article/pii/004896979190080X
ER  - 

TY  - JOUR
T1  - The use of hierarchic clustering in information retrieval
JO  - Information Storage and Retrieval
VL  - 7
IS  - 5
SP  - 217
EP  - 240
PY  - 1971/12//
T2  - 
AU  - Jardine, N.
AU  - van Rijsbergen, C.J.
SN  - 0020-0271
DO  - http://dx.doi.org/10.1016/0020-0271(71)90051-9
UR  - http://www.sciencedirect.com/science/article/pii/0020027171900519
AB  - We introduce information retrieval strategies which are based on automatic hierarchic clustering of documents. We discuss the evaluation of retrieval strategies and show, using a subset of the Cranfield Aeronautics document collection, that cluster-based retrieval strategies can be devised which are as effective as linear associative retrieval strategies and much more efficient. Finally, we outline how cluster-based retrieval may be extended to large growing document collections and indicate some ways in which the effectiveness of cluster-based retrieval strategies may be improved.
ER  - 

TY  - JOUR
T1  - The use of vocabulary files for on-line information retrieval
JO  - Information Processing & Management
VL  - 15
IS  - 6
SP  - 281
EP  - 289
PY  - 1979///
T2  - 
AU  - Burket, T.G.
AU  - Emrath, P.
AU  - Kuck, D.J.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(79)90052-9
UR  - http://www.sciencedirect.com/science/article/pii/0306457379900529
AB  - Online information retrieval systems continued to reach wider audiences. The authors discuss a particular text retrieval system and its techniques for helping the common unsophisticated user through both the search for and understanding of information based on the vocabular file concept. In addition methods for easy construction and maintenance of a suuitable data base organization are described.
ER  - 

TY  - JOUR
T1  - Behavioral effects of caffeine and CGS 15943, a novel adenosine antagonist: Leonard L. Howell and Larry D. Byrd. Emory University, Atlanta, GA
JO  - Pharmacology Biochemistry and Behavior
VL  - 42
IS  - 2
SP  - 373
EP  - 
PY  - 1992/6//
T2  - 

SN  - 0091-3057
DO  - http://dx.doi.org/10.1016/0091-3057(92)90588-7
UR  - http://www.sciencedirect.com/science/article/pii/0091305792905887
ER  - 

TY  - JOUR
T1  - Rearing environment influences rat's sensitivity to cocaine and amphetamine: Stephen C. Fowler, Julie S. Johnson and Mary J. Kallman. University of Mississippi, University, MS
JO  - Pharmacology Biochemistry and Behavior
VL  - 42
IS  - 2
SP  - 373
EP  - 
PY  - 1992/6//
T2  - 

SN  - 0091-3057
DO  - http://dx.doi.org/10.1016/0091-3057(92)90589-8
UR  - http://www.sciencedirect.com/science/article/pii/0091305792905898
ER  - 

TY  - JOUR
T1  - The opioid-stress interaction: Examination of the role of conditioning: Yavin Shaham. Uniformed Services University of the Health Sciences, Bethesda, MD
JO  - Pharmacology Biochemistry and Behavior
VL  - 42
IS  - 2
SP  - 373
EP  - 
PY  - 1992/6//
T2  - 

SN  - 0091-3057
DO  - http://dx.doi.org/10.1016/0091-3057(92)90590-C
UR  - http://www.sciencedirect.com/science/article/pii/009130579290590C
ER  - 

TY  - JOUR
T1  - Effects of ethanol on cooperative responding: Ralph Spiga. University of Texas Medical School, Houston, TX
JO  - Pharmacology Biochemistry and Behavior
VL  - 42
IS  - 2
SP  - 373
EP  - 
PY  - 1992/6//
T2  - 

SN  - 0091-3057
DO  - http://dx.doi.org/10.1016/0091-3057(92)90587-6
UR  - http://www.sciencedirect.com/science/article/pii/0091305792905876
ER  - 

TY  - JOUR
T1  - Introduction: Parallel processing and information retrieval
JO  - Information Processing & Management
VL  - 27
IS  - 4
SP  - 255
EP  - 263
PY  - 1991///
T2  - Special Issue: Parallel Processing and Information Retrieval
AU  - Rasmussen, Edie M.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(91)90083-X
UR  - http://www.sciencedirect.com/science/article/pii/030645739190083X
AB  - Recent advances in parallel processing have made powerful computing resources available for information retrieval. This introduction, an overview of trends and work in parallel information retrieval, covers three areas: the development of parallel algorithms for information retrieval, the design of parallel architectures to handle information retrieval tasks, and the distribution of databases over multiple processors. The articles in this issue are introduced in the context of ongoing work.
ER  - 

TY  - JOUR
T1  - Criteria for the selection of search strategies in best-match document-retrieval systems
JO  - International Journal of Man-Machine Studies
VL  - 25
IS  - 3
SP  - 317
EP  - 326
PY  - 1986/9//
T2  - 
AU  - McCall, Fiona M.
AU  - Willett, Peter
SN  - 0020-7373
DO  - http://dx.doi.org/10.1016/S0020-7373(86)80063-3
UR  - http://www.sciencedirect.com/science/article/pii/S0020737386800633
AB  - It has been suggested that document-retrieval systems should have a range of different search strategies available which may be used in response to different types of query. This raises the question of what criteria should be used to select a strategy for use with an individual query. This paper considers statistical characteristics of queries that may be used to choose between clustered and non-clustered searches in best-match retrieval systems. The results suggest that such statistical information is not a good basis for the selection of search strategies.
ER  - 

TY  - JOUR
T1  - A file organization and maintenance procedure for dynamic document collections
JO  - Information Processing & Management
VL  - 11
IS  - 1–2
SP  - 11
EP  - 21
PY  - 1975/6//
T2  - 
AU  - Crouch, Donald B.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(75)90031-X
UR  - http://www.sciencedirect.com/science/article/pii/030645737590031X
AB  - Several techniques have been proposed for clustering document collections. However, these algorithms ignore file maintenance problems which occur whenever the collection is dynamic. This paper describes a clustering algorithm designed for dynamic data bases and presents an update procedure which maintains an effective document classification without reclustering. The effectiveness of the algorithms is demonstrated for a subset of the Cranfield collection.
ER  - 

TY  - JOUR
T1  - Searching and clustering of databases using the ICL Distributed Array Processor
JO  - Parallel Computing
VL  - 8
IS  - 1–3
SP  - 399
EP  - 407
PY  - 1988/10//
T2  - Proceedings of the International Conference on Vector and Parallel Processors in Computational Science III
AU  - Pogue, Christine A.
AU  - Rasmussen, Edie M.
AU  - Willett, Peter
SN  - 0167-8191
DO  - http://dx.doi.org/10.1016/0167-8191(88)90145-7
UR  - http://www.sciencedirect.com/science/article/pii/0167819188901457
KW  - Automatic classification
KW  - cluster analysis
KW  - ICL Distributed Array Processor
KW  - information retrieval
KW  - nearest neighbour searching
KW  - pattern matching
KW  - serial file structure
KW  - text signature
AB  - The ICL Distributed Array Processor (DAP) is an SIMD array processor containing a large, 2-D array of bit serial processing elements. The architecture of the DAP makes it well suited to data processing applications where searching operations must be carried out on large numbers of data records. This paper discusses the use of the DAP for two such applications, these being the scanning of serial text files and the clustering of a range of types of database. The processing efficiency of the DAP, when compared with a serial processor, is greatest when fixed length records are processed.
ER  - 

TY  - JOUR
T1  - On cube-free ω-words generated by binary morphisms
JO  - Discrete Applied Mathematics
VL  - 5
IS  - 3
SP  - 279
EP  - 297
PY  - 1983/3//
T2  - 
AU  - Karhumäki, Juhani
SN  - 0166-218X
DO  - http://dx.doi.org/10.1016/0166-218X(83)90002-1
UR  - http://www.sciencedirect.com/science/article/pii/0166218X83900021
AB  - Let h be a morphism satisfying h(a) = ax for a letter a and a nonempty word x. Then h defines an infinite word (an ω-word) when applied iteratively starting from a. Such ω-words are considered in a binary case. It is shown that only biprefixes can generate cube-free ω-words, i.e. words which do not contain a word υ3, with υ ≠ λ, as a subword. The same does not hold true for fourth power-free ω-words, the counterexample being the ω-word defined by the Fibonaccimorphism: h(a) = ba, h(b) = a.

As the main result it is proved that it is decidable whether a given morphism of the above form generates a cube-free ω-word. Moreover, it is shown that no more than 10 steps of iterations are needed to solve the problem.
ER  - 

TY  - JOUR
T1  - Subject index
JO  - Computer Networks and ISDN Systems
VL  - 28
IS  - 14
SP  - 2011
EP  - 2016
PY  - 1996/11//
T2  - 7th Joint European Networking Conference

SN  - 0169-7552
DO  - http://dx.doi.org/10.1016/S0169-7552(96)90010-0
UR  - http://www.sciencedirect.com/science/article/pii/S0169755296900100
ER  - 

TY  - JOUR
T1  - Reports and theses
JO  - Information Storage and Retrieval
VL  - 6
IS  - 3
SP  - 299
EP  - 303
PY  - 1970/7//
T2  - 

SN  - 0020-0271
DO  - http://dx.doi.org/10.1016/0020-0271(70)90004-5
UR  - http://www.sciencedirect.com/science/article/pii/0020027170900045
ER  - 

TY  - JOUR
T1  - An improved algorithm for the calculation of exact term discrimination values
JO  - Information Processing & Management
VL  - 24
IS  - 1
SP  - 17
EP  - 22
PY  - 1988///
T2  - 
AU  - El-Hamdouchi, Abdelmoula
AU  - Willett, Peter
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(88)90073-8
UR  - http://www.sciencedirect.com/science/article/pii/0306457388900738
AB  - The term discrimination model provides a means of evaluating indexing terms in automatic document retrieval systems. This article describes an efficient algorithm for the calculation of term discrimination values that may be used when the interdocument similarity measure used is the cosine coefficient and when the document representatives have been weighted using one particular term-weighting scheme. The algorithm has an expected running time proportional to Nn2 for a collection of N documents, each of which has been assigned an average of n terms.
ER  - 

TY  - JOUR
T1  - The effect of indexing exhaustivity on retrieval performance
JO  - Information Processing & Management
VL  - 27
IS  - 6
SP  - 623
EP  - 628
PY  - 1991///
T2  - 
AU  - Burgin, Robert
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(91)90003-5
UR  - http://www.sciencedirect.com/science/article/pii/0306457391900035
AB  - The effect of variations in indexing exhaustivity on retrieval performance in a vector space retrieval system was investigated by using a term weight threshold to construct different document representations for a test collection. Retrieval results showed that retrieval performance, as measured by the mean optimal E measure for all queries at a term weight threshold, was highest at the most exhaustive representation, and decreased slightly as terms were eliminated and the indexing representation became less exhaustive. These findings, coupled with those of Shaw for a retrieval system based on single-link clustering, suggest that the vector space model is more robust against variations in indexing exhaustivity than is the single-link clustering model.
ER  - 

TY  - JOUR
T1  - An evaluation of Goffman's indirect retrieval method
JO  - Information Processing & Management
VL  - 12
IS  - 5
SP  - 327
EP  - 331
PY  - 1976///
T2  - 
AU  - Croft, W.B.
AU  - Van Rijsbergen, C.J.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(76)90051-0
UR  - http://www.sciencedirect.com/science/article/pii/0306457376900510
AB  - The indirect retrieval method proposed by Goffman is outlined and some similarities to other retrieval methods are indicated. The method is then evaluated and the results are compared with those obtained on the same document collection with cluster-based retrieval using single-link clustering.

The comparisons show that although the effectiveness of the indirect retrieval method can be comparable to cluster-based retrieval, the efficiency is lower.
ER  - 

TY  - JOUR
T1  - Book announcements
JO  - Discrete Applied Mathematics
VL  - 41
IS  - 3
SP  - 275
EP  - 278
PY  - 1993/2/9/
T2  - 

SN  - 0166-218X
DO  - http://dx.doi.org/10.1016/0166-218X(90)90062-H
UR  - http://www.sciencedirect.com/science/article/pii/0166218X9090062H
ER  - 

TY  - JOUR
T1  - Performance standards and evaluations in IR test collections: Cluster-based retrieval models
JO  - Information Processing & Management
VL  - 33
IS  - 1
SP  - 1
EP  - 14
PY  - 1997/1//
T2  - 
AU  - Shaw Jr, W.M.
AU  - Burgin, Robert
AU  - Howell, Patrick
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(96)00043-X
UR  - http://www.sciencedirect.com/science/article/pii/S030645739600043X
AB  - Low performance standards for the group of queries in 13 retrieval test collections have been computed. Derived from the random graph hypothesis, these standards represent the highest levels of retrieval effectiveness that can be obtained from meaningless clustering structures. Operational levels of cluster-based performance reported in selected sources during the past 20 years have been compared to the standards. Comparisons show that typical levels of operational cluster-based retrieval can be explained on the basis of chance. Indeed, most operational results in retrieval test collections are lower than those predicted by random graph theory. A tentative explanation for the poor performance of cluster-based retrieval reveals weaknesses in both fundamental assumptions and operational implementations. The cluster hypothesis offers no guarantee that relevant documents are naturally grouped together, clustering algorithms may not reveal the inherent structure in a set of documents, and retrieval strategies do not reliably retrieve the most effective cluster or clusters of documents. That most cluster-based retrieval implementations implicitly rely on topical relatedness to be equivalent to a relevance relationship contributes to the poor performance. Clustering strategies capable of adapting to relevance information may succeed where static clustering techniques have failed.
ER  - 

TY  - JOUR
T1  - Author index
JO  - Research Policy
VL  - 15
IS  - 6
SP  - 347
EP  - 
PY  - 1986/12//
T2  - 

SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/0048-7333(86)90035-1
UR  - http://www.sciencedirect.com/science/article/pii/0048733386900351
ER  - 

TY  - JOUR
T1  - Author index
JO  - Research Policy
VL  - 18
IS  - 6
SP  - 389
EP  - 390
PY  - 1989/12//
T2  - Special Issue on Evaluation of Government Innovation Programs

SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/0048-7333(89)90025-5
UR  - http://www.sciencedirect.com/science/article/pii/0048733389900255
ER  - 

TY  - JOUR
T1  - Periodic D0L languages
JO  - Theoretical Computer Science
VL  - 46
IS  - 
SP  - 83
EP  - 89
PY  - 1986///
T2  - 
AU  - Head, Tom
AU  - Lando, Barbara
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/0304-3975(86)90023-X
UR  - http://www.sciencedirect.com/science/article/pii/030439758690023X
AB  - Periodic D0L systems and languages are defined, and periodicity is shown to be a decidable property of D0L systems. The fundamental tools used are recent results on the representation of stationary ω-words (Head and Lando, 1986) and the decidability of ultimate periodicity of ω-words (Harju and Linna, 1986; Pansiot, 1986). The relation of D0L periodicity to local catenativity and to n-codes is examined.
ER  - 

TY  - JOUR
T1  - Retrieval strategies for hypertext
JO  - Information Processing & Management
VL  - 29
IS  - 3
SP  - 313
EP  - 324
PY  - 1993/5//
Y2  - 1993/6//
T2  - 
AU  - Croft, W.Bruce
AU  - Turtle, Howard R.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(93)90058-L
UR  - http://www.sciencedirect.com/science/article/pii/030645739390058L
AB  - The links in a hypertext database distinguish it from a typical document database used in information retrieval applications. We show how these links can be incorporated into a probabilistic retrieval model based on inference nets. Retrieval experiments using a strategy based on this model show that it produces results at least as good as a spreading activation strategy. The results also show that citations can be a better source of links for a hypertext database than nearest neighbors, even though the latter appear to connect related documents. For this test collection, the overall improvement obtained by including hypertext links in the retrieval model was low. The hypertext model may, however, have additional benefits in multimedia environments.
ER  - 

TY  - JOUR
T1  - Reports and theses
JO  - Information Storage and Retrieval
VL  - 9
IS  - 9
SP  - 515
EP  - 521
PY  - 1973/9//
T2  - 

SN  - 0020-0271
DO  - http://dx.doi.org/10.1016/0020-0271(73)90037-5
UR  - http://www.sciencedirect.com/science/article/pii/0020027173900375
ER  - 

TY  - JOUR
T1  - List of contents and author index volume 27 (1991)
JO  - Information Processing & Management
VL  - 27
IS  - 6
SP  - I
EP  - X
PY  - 1991///
T2  - 

SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(91)90024-G
UR  - http://www.sciencedirect.com/science/article/pii/030645739190024G
ER  - 

TY  - JOUR
T1  - List of contents and author index volume 24 (1988)
JO  - Information Processing & Management
VL  - 24
IS  - 6
SP  - I
EP  - XI
PY  - 1988///
T2  - 

SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(88)90019-2
UR  - http://www.sciencedirect.com/science/article/pii/0306457388900192
ER  - 

TY  - JOUR
T1  - Dynamic cluster maintenance
JO  - Information Processing & Management
VL  - 25
IS  - 3
SP  - 275
EP  - 291
PY  - 1989///
T2  - 
AU  - Can, Fazli
AU  - Ozkarahan, Esen A.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(89)90045-9
UR  - http://www.sciencedirect.com/science/article/pii/0306457389900459
AB  - Partitioning of very large document databases is a necessity to reduce the space/time complexity of retrieval operations. Modern information retrieval (IR) environments demand dynamic clustering to constantly achieve this goal. In this article, a new strategy is proposed for dynamic cluster maintenance. The strategy is based on the cover coefficient (CC) concept. The maintenance performance and behavior are tested on a database consisting of 214 ACM Transactions on Database Systems abstracts, titles, and keywords. The similarity/stability characteristics, cost analysis, and retrieval effectiveness of both unclustered and reclustered documents are among the problems studied.
ER  - 

TY  - JOUR
T1  - System architecture for information processing
JO  - Information Processing & Management
VL  - 27
IS  - 4
SP  - 347
EP  - 369
PY  - 1991///
T2  - Special Issue: Parallel Processing and Information Retrieval
AU  - Ozkarahan, Esen
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(91)90089-5
UR  - http://www.sciencedirect.com/science/article/pii/0306457391900895
KW  - Computer system architecture
KW  - Parallel computers
KW  - Database machines
KW  - Multiprocessing
KW  - Intelligent I/O architectures
KW  - File partitioning
KW  - Query
KW  - Integrity constraint filtering
KW  - Information retrieval
KW  - Multimedia databases
KW  - Conceptual modeling
KW  - Object-oriented databases
AB  - Text and fact retrieval efficiency can be achieved only within the framework of a computer system architecture embodying parallel search hardware, intelligent I/O architecture, and effective data partitioning and search strategies. Parallelism by itself is not a panacea. This paper presents the framework of the system architecture and the details of our intelligent I/O architecture called IMSA, data partitioning, and the RAP.3 integrated retrieval system. The RAP.3 system is driven by cluster searching for narrowing the search space. All media documents are converted to special relational formats and searched by relational database and text search commands. An integrated multimedia information system supported by object-oriented database methodology within the RAP.3 system architecture is included as a demonstration.
ER  - 

TY  - JOUR
T1  - Knowledge hypermaps and cooperative learning
JO  - Computers & Education
VL  - 16
IS  - 2
SP  - 167
EP  - 173
PY  - 1991///
T2  - 
AU  - Reynolds, Sharon B.
AU  - Patterson, Michael E.
AU  - Skaggs, Lisa P.
AU  - Dansereau, Donald F.
SN  - 0360-1315
DO  - http://dx.doi.org/10.1016/0360-1315(91)90023-K
UR  - http://www.sciencedirect.com/science/article/pii/036013159190023K
AB  - The effects of scripted cooperation in two types of non-linear, computer-linked presentations (hypermap and hypertext) were investigated to determine differences in recall, reference accuracy and satisfaction among students learning the material. Cooperative scripts with pilot and navigator roles were developed for both environments, with the pilot using the computer presentation (hypermap and hypertext) and the navigator using large sheets of paper on which printouts of the screens (map or text) had been reproduced. No significant overall differences were found in performance on recall and reference tests. Significant differences among navigators were found in favor of the map group, indicating that maps may increase comprehension. Greater satisfaction and lower frustration was expressed by pilots than by navigators. Students using the map format expressed less frustration than those using the text format. The findings suggest a need for further study of the differential effects of hypermap and hypertext on comprehension, and of other forms of scripted cooperation in hypertext and hypermap environments.
ER  - 

TY  - JOUR
T1  - An investigation of document structures
JO  - Information Processing & Management
VL  - 26
IS  - 3
SP  - 339
EP  - 348
PY  - 1990///
T2  - 
AU  - Shaw Jr., W.M.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(90)90095-J
UR  - http://www.sciencedirect.com/science/article/pii/030645739090095J
AB  - The presence of clustering structure in a document collection and the influence of the presence of clustering structure on the success of cluster-based retrieval are investigated as a function of term-weight and similarity thresholds. The term-weight threshold selects a particular level of indexing exhaustivity for the document representation, and the similarity threshold selects a specific level of the associated single-link hierarchy. Results show clear evidence for clustering structure in the most exhaustive and the least exhaustive subject representations. Results also show that observed values of cluster-based retrieval effectiveness at all exhaustivity levels can be explained by assuming that the pairwise associations responsible for the structure imposed on the document collection are generated randomly. The results suggest that the structure imposed on a small document collection by an automatically produced subject representation is unrelated to the structure imposed on the documents by relevance relationships.
ER  - 

TY  - JOUR
T1  - ‘Citation profiles’ to improve relevance in a two-stage retrieval system: A proposal
JO  - Information Processing & Management
VL  - 29
IS  - 4
SP  - 463
EP  - 470
PY  - 1993/7//
Y2  - 1993/8//
T2  - 
AU  - Shalini, R.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(93)90042-C
UR  - http://www.sciencedirect.com/science/article/pii/030645739390042C
AB  - Individual differences in relevance judgements are not entirely erratic, and it is productive to consider citation profiles as a simple, convenient, and automatic method of reflecting the knowledge structure/past experience/viewpoints of the authors of papers. A citation profile is nothing but the list of citations appended to the paper. The list of references normally reflects a good sample of the complete or partial survey of that literature considered relevant by the author. Therefore, the source paper, together with its list of references, are to be kept together to provide a more complete picture of the ‘content’ and ‘structure’ of the document. The citation profile is believed to reflect the ‘state of knowing’ of the author, and higher commonality between the citation profile and the mental profile of a user would help improve a relevance decision. A mental profile is the state of knowing of the user, in terms of a set of documents known to the user as relevant. A step in the direction of designing and developing interactive, user-oriented, user-driven systems would be a two-stage information retrieval system where, in the first stage, a topical set of document representations would be produced by a Boolean search, and in the second stage, the citation profile of each document would be provided to the user, either in addition to or in lieu of abstracts.
ER  - 

TY  - JOUR
T1  - An investigation of document partitions
JO  - Information Processing & Management
VL  - 22
IS  - 1
SP  - 19
EP  - 28
PY  - 1986///
T2  - 
AU  - Shaw Jr., W.M.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(86)90006-3
UR  - http://www.sciencedirect.com/science/article/pii/0306457386900063
AB  - In this paper, the empirical significance of document partitions is investigated as a function of term-weight and similarity thresholds. The term-weight threshold selects a particular level of indexing exhaustivity and specificity for the document representation and the similarity threshold selects a specific level of the associated single-link hierarchy. The results show that the same empirically “preferred” partitions can be detected by two independent strategies; an analysis of cluster-based retrieval effectiveness and an analysis of regularities in the underlying structure of the document graph. These results represent the first step in an investigation designed to determine if the statistical significance of document partitions can explain the empirical significance of the same partitions.
ER  - 

TY  - JOUR
T1  - Enhancement of text representations using related document titles
JO  - Information Processing & Management
VL  - 22
IS  - 5
SP  - 385
EP  - 394
PY  - 1986///
T2  - 
AU  - Salton, G.
AU  - Zhang, Y.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(86)90073-7
UR  - http://www.sciencedirect.com/science/article/pii/0306457386900737
AB  - Various attempts have been made over the years to construct enhanced document representations by using thesauruses of related terms, term association maps, or knowledge frameworks that can be used to extract appropriate terms and concepts. None of the proposed methods for the improvement of document representation has proved to be generally useful when applied to a variety of different retrieval environments. Some recent work by Kwok suggests that document indexing may be enhanced by using title words taken from bibliographically related items. An evaluation of the process shows that many useful content words can be extracted from related document titles, as well as many terms of doubtful value. Overall, the procedure is not sufficiently reliable to warrant incorporation into operational automatic retrieval systems.
ER  - 

TY  - JOUR
T1  - Subject index
JO  - Research Policy
VL  - 18
IS  - 6
SP  - 391
EP  - 393
PY  - 1989/12//
T2  - Special Issue on Evaluation of Government Innovation Programs

SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/0048-7333(89)90026-7
UR  - http://www.sciencedirect.com/science/article/pii/0048733389900267
ER  - 

TY  - JOUR
T1  - Effects of knowledge map characteristics on information processing
JO  - Contemporary Educational Psychology
VL  - 17
IS  - 2
SP  - 136
EP  - 155
PY  - 1992/4//
T2  - 
AU  - Wiegmann, Douglas A.
AU  - Dansereau, Donald F.
AU  - McCagg, Edward C.
AU  - Rewey, Kirsten L.
AU  - Pitre, Urvashi
SN  - 0361-476X
DO  - http://dx.doi.org/10.1016/0361-476X(92)90055-4
UR  - http://www.sciencedirect.com/science/article/pii/0361476X92900554
AB  - The majority of research on knowledge maps has focused on demonstrating their effectiveness in educational settings. However, very little work has attempted to xamine the parameters of map construction that mediate their impact on performance. The present set of experiments represents an attempt to remedy this situation by examining the impact of three parameters of map construction on knowledge acquisition. Experiment 1 investigated spatial configuration, Experiment 2 investigated map format, and Experiment 3 investigated link structure. Results of these examinations revealed that the way the maps were constructed influenced both the encoding and the retrieval of the information in the maps and that these effects were mediated by the users' spatial and verbal abilities.
ER  - 

TY  - JOUR
T1  - A comparison of a network structure and a database system used for document retrieval
JO  - Information Systems
VL  - 10
IS  - 4
SP  - 377
EP  - 390
PY  - 1985///
T2  - 
AU  - Croft, W.Bruce
AU  - Parenty, Thomas J
SN  - 0306-4379
DO  - http://dx.doi.org/10.1016/0306-4379(85)90042-0
UR  - http://www.sciencedirect.com/science/article/pii/0306437985900420
AB  - Database systems have many advantages for implementing document retrieval systems. One of the main advantages would be the integration of data and text handling in a single information system. However, it has not been clear how much a database implementation would cost in terms of efficiency. In this paper, we compare a database implementation and a stand-alone implementation of a flexible representation of the content of documents and the associated search strategies. The representation used is a network of document and index term nodes. The comparison shows that certain features of a database system can have a significant effect on the efficiency of the implementation. Despite this, it appears that a database implementation of a sophisticated document retrieval system can be competitive with a stand-alone implementation.
ER  - 

TY  - JOUR
T1  - Knowledge-sparse and knowledge-rich learning in information retrieval
JO  - Information Processing & Management
VL  - 23
IS  - 3
SP  - 195
EP  - 210
PY  - 1987///
T2  - 
AU  - Rada, Roy
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(87)90004-5
UR  - http://www.sciencedirect.com/science/article/pii/0306457387900045
AB  - This paper reviews some aspects of the relationship between the large and growing fields of machine learning (ML) and information retrieval (IR). Learning programs are described along several dimensions. One dimension refers to the degree of dependence of an ML + IR program on users, thesauri, or documents. This paper emphasizes the role of the thesaurus in ML + IR work. ML + IR programs are also classified in a dimension that extends from knowledge-sparse learning at one end to knowledge-rich learning at the other. Knowledge-sparse learning depends largely on user yes-no feedback or on word frequencies across documents to guide adjustments in the IR system. Knowledge-rich learning depends on more complex sources of feedback, such as the structure within a document or thesaurus, to direct changes in the knowledge bases on which an intelligent IR system depends. New advances in computer hardware make the knowledge-sparse learning programs that depend on word occurrences in documents more practical. Advances in artificial intelligence bode well for knowledge-rich learning.
ER  - 

TY  - JOUR
T1  - Thesaurus construction: Problems and their roots
JO  - Information Processing & Management
VL  - 33
IS  - 4
SP  - 481
EP  - 493
PY  - 1997/7//
T2  - 
AU  - Miller, Uri
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(97)00009-5
UR  - http://www.sciencedirect.com/science/article/pii/S0306457397000095
AB  - Some general problems of thesaurus construction theory and practice are analyzed and discussed. The analysis is based on research and experience already accumulated in librarianship and information science as well as some other sciences and general scientific methods (linguistics, systems analysis, etc.). Some methodological and methodical ways of solving problems existing in thesaurus construction are recommended.
ER  - 

TY  - JOUR
T1  - Concept Mapping: An Effective Instructional Strategy for Diet Therapy
JO  - Journal of the American Dietetic Association
VL  - 95
IS  - 8
SP  - 908
EP  - 911
PY  - 1995/8//
T2  - 
AU  - ROBERTS, CANDYCE M
AU  - SUCHER, KATHRYN
AU  - PERRIN, DONALD G
AU  - RODRIGUEZ, STEPHEN
SN  - 0002-8223
DO  - http://dx.doi.org/10.1016/S0002-8223(95)00250-2
UR  - http://www.sciencedirect.com/science/article/pii/S0002822395002502
AB  - Concept mapping is an instructional strategy that requires learners to identify, graphically display, and link key concepts in instructional reading material. Although proven effective in numerous disciplines as a means to promote critical thinking and self-directed learning, concept mapping has not been tested in diet therapy. The objective of this study was to implement concept mapping as a small-group, cooperative learning strategy in an upper-division diet therapy course and to evaluate student attitudes about the effect of concept mapping on knowledge, self-directed learning, problem-solving, and collaborative skills. Students in the first semester (n=27) initially learned course material by lecture (4 weeks) followed by an integrated mapping/lecture format (12 weeks); the second semester (n=25) used an integrated mapping lecture format for the full 16 weeks. At the end of both semesters, students completed a 10-item original survey questionnaire. Responses for first (n=25) and second (n=21) semesters were analyzed independently. Results indicated that a majority of students thought participation in concept mapping enhanced knowledge of diet therapy principles (n=19 of 25; 18 of 21), self-directed learning (n=14 of 25; 18 of 21), critical thinking (n=21 of 25; 14 of 21), problem-solving (n=22 of 25; 16 of 21), and collaboration (n=24 of 25; 20 of 21) skills. When noncooperation of teammates was a factor, concept mapping was viewed as more frustrating and time consuming than lecture. This study demonstrated concept mapping as an effective learning strategy for diet therapy; it improves students’ ability to engage in self-directed learning, critical thinking, collaboration, and creative problem solving. Results suggest that concept mapping is most effective when accompanied with comprehensive training, coordinated lectures, instructor guidance, and long-term practice. J Am Diet Assoc. 1995; 95:908–911.
ER  - 

TY  - JOUR
T1  - Incremental clustering for very large document databases: Initial MARIAN Experience
JO  - Information Sciences
VL  - 84
IS  - 1–2
SP  - 101
EP  - 114
PY  - 1995/5//
T2  - 
AU  - Can, Fazli
AU  - Fox, Edward A.
AU  - Snavely, Cory D.
AU  - France, Robert K.
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/0020-0255(94)00111-N
UR  - http://www.sciencedirect.com/science/article/pii/002002559400111N
AB  - Clustering of document databases is useful for both browsing and searching purposes; however, this can be a prohibitively expensive computational process for large collections. This problem is compounded when the clustering structure must reflect a constantly changing database. Therefore, efficient algorithms which maintain an existing clustering structure are desirable. This study provides the details of a large-scale implementation of the Cover-Coefficient-based Incremental Clustering Methodology (C2ICM). The experiments performed on a sample of the MARIAN database show that its resource requirements are within practical bounds for most platforms. Furthermore, C2ICM) offers considerable savings over reclustering. The results of this study will lead to an additional type of browsing and/or searching facility on the Virginia Tech-based MARIAN large online public access library catalog (OPAC) project.
ER  - 

TY  - JOUR
T1  - Information retrieval based on fuzzy associations
JO  - Fuzzy Sets and Systems
VL  - 38
IS  - 2
SP  - 191
EP  - 205
PY  - 1990/11/20/
T2  - Fuzzy Information and Database Systems
AU  - Miyamoto, S.
SN  - 0165-0114
DO  - http://dx.doi.org/10.1016/0165-0114(90)90149-Z
UR  - http://www.sciencedirect.com/science/article/pii/016501149090149Z
KW  - Information storage and retrieval
KW  - fuzzy associations
KW  - algorithms
AB  - The aim of the present paper is to propose a fuzzy set model for information retrieval and to develop methods and algorithms for fuzzy information retrieval based on the fuzzy set model. A process of information retrieval is represented as a diagram that consists of three components. Each component has its inherent fuzziness. As typical examples for describing the three components, we consider a fuzzy association as a generalization of a fuzzy thesaurus for the first component, a fuzzy inverted index for the second component, and a fuzzy filter for the third component. Efficient algorithms for fuzzy retrieval on large scale bibliographic databases are developed. The significance of the present method is that current techniques in researches of bibliographic databases without fuzzy sets are studied in the framework of fuzzy sets and their implications are made clear using the model herein.
ER  - 

TY  - JOUR
T1  - Learned vector-space models for document retrieval
JO  - Information Processing & Management
VL  - 31
IS  - 3
SP  - 419
EP  - 429
PY  - 1995/5//
Y2  - 1995/6//
T2  - The Second Text Retrieval Conference (TREC-2)
AU  - Caid, William R.
AU  - Dumais, Susan T.
AU  - Gallant, Stephen I.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(94)00056-9
UR  - http://www.sciencedirect.com/science/article/pii/0306457394000569
ER  - 

TY  - JOUR
T1  - Implementing agglomerative hierarchic clustering algorithms for use in document retrieval
JO  - Information Processing & Management
VL  - 22
IS  - 6
SP  - 465
EP  - 476
PY  - 1986///
T2  - 
AU  - Voorhees, Ellen M.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(86)90097-X
UR  - http://www.sciencedirect.com/science/article/pii/030645738690097X
AB  - Searching hierarchically clustered document collections can be effective[6], but creating the cluster hierarchies is expensive, since there are both many documents and many terms. However, the information in the document-term matrix is sparse: Documents are usually indexed by relatively few terms. This paper describes the implementations of three agglomerative hierarchic clustering algorithms that exploit this sparsity so that collections much larger than the algorithms' worst case running times would suggest can be clustered. The implementations described in the paper have been used to cluster a collection of 12,000 documents.
ER  - 

TY  - JOUR
T1  - Experiments with a very efficient heuristic for clustering problems
JO  - Information Systems
VL  - 4
IS  - 4
SP  - 285
EP  - 292
PY  - 1979///
T2  - 
AU  - Stanfel, Larry E.
SN  - 0306-4379
DO  - http://dx.doi.org/10.1016/0306-4379(79)90022-X
UR  - http://www.sciencedirect.com/science/article/pii/030643797990022X
AB  - A method is described for solving certain nonlinear clustering problems. While operating in polynomial time the method is not an algorithm and counter examples are cited, along with a linear programming methodology for constructing them. The success of the procedure when applied to real problems is discussed and some theoretical lines of investigation suggested for establishing circumstances under which convergence may be guaranteed. Finally, applications to important problems in the information sciences are reviewed, and the case of large sets of objects discussed.
ER  - 

TY  - JOUR
T1  - A model of cluster searching based on classification
JO  - Information Systems
VL  - 5
IS  - 3
SP  - 189
EP  - 195
PY  - 1980///
T2  - 
AU  - Croft, W.Bruce
SN  - 0306-4379
DO  - http://dx.doi.org/10.1016/0306-4379(80)90010-1
UR  - http://www.sciencedirect.com/science/article/pii/0306437980900101
AB  - The use of document clusters has been suggested as an efficient file organization for a document retrieval system. It is possible that by using this information about the relationships between documents that the effectiveness of the system (i.e. its ability to distinguish relevant from non-relevant documents) may also be improved. In this paper a probabilistic model of cluster searching based on query classification is described. This model is tested with retrieval experiments which indicate that it can be more effective than heuristic cluster searches and cluster searches based on other models. It can also be more effective than a full search in which every document is compared to the query. The efficiency aspects of the implementation of the model are discussed.
ER  - 

TY  - JOUR
T1  - The selection of good search terms
JO  - Information Processing & Management
VL  - 17
IS  - 2
SP  - 77
EP  - 91
PY  - 1981///
T2  - 
AU  - van Rijsbergen, C.J.
AU  - Harper, D.J.
AU  - Porter, M.F.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(81)90029-7
UR  - http://www.sciencedirect.com/science/article/pii/0306457381900297
AB  - This paper tackles the problem of how one might select further search terms, using relevance feedback, given the search terms in the query. These search terms are extracted from a maximum spanning tree connecting all the terms in the index term vocabulary. A number of different spanning trees are generated from a variety of association measures. The retrieval effectiveness for the different spanning trees is shown to be approximately the same. Effectiveness is measured in terms of precision and recall, and the retrieval tests are done on three different test collections.
ER  - 

TY  - JOUR
T1  - A theoretical background for applying fuzzy set theory in information retrieval
JO  - Fuzzy Sets and Systems
VL  - 10
IS  - 1–3
SP  - 169
EP  - 183
PY  - 1983///
T2  - 
AU  - Radecki, Tadeusz
SN  - 0165-0114
DO  - http://dx.doi.org/10.1016/S0165-0114(83)80113-4
UR  - http://www.sciencedirect.com/science/article/pii/S0165011483801134
KW  - Information retrieval
KW  - Document retrieval models
KW  - Fuzzy set theory
AB  - The paper deals with information retrieval systems, and especially with document retrieval systems. Some of the postulates most desired to be met by possible approaches to document retrieval are given, and the extent to which they are fulfilled by the established retrieval methodologies is discussed. In particular, a considerable place is devoted to the probabilistic approach and the document retrieval methodologies based on vector space theory and cluster analysis. The examination of the widely known theoretical approaches to document retrieval has resulted in the conclusion that fuzzy set theory and fuzzy logic provide a basis for fulfilling most of those postulates in a direct manner and with sufficient consistency and rigorousness. Since the concept of a fuzzy set is a generalization of the conventional notion of a set, the generalization of the document retrieval methods based on set theory and binary logic can be derived in a natural way. At the end of the paper the main advantages of the document retrieval approach based on fuzzy set theory and fuzzy logic are specified and briefly discussed.
ER  - 

TY  - JOUR
T1  - Relevance judgements for assessing recall
JO  - Information Processing & Management
VL  - 32
IS  - 3
SP  - 273
EP  - 286
PY  - 1996/5//
T2  - 
AU  - Wallis, Peter
AU  - Thom, James A.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(95)00061-5
UR  - http://www.sciencedirect.com/science/article/pii/0306457395000615
AB  - Recall and Precision have become the principle measures of the effectiveness of information retrieval systems. Inherent in these measures of performance is the idea of a relevant document. Although recall and precision are easily and unambiguously defined, selecting the documents relevant to a query has long been recognized as problematic. To compare performance of different systems, standard collections of documents, queries, and relevance judgments have been used. Unfortunately the standard collections, such as SMART and TREC, have locked in a particular approach to relevance that is suitable for assessing precision but not recall. The problem is demonstrated by comparing two information retrieval methods over several queries, and showing how a new method of forming relevance judgments that a suitable for assessing recall gives different results. Recall is an interesting and practical issue, but current test procedures are inadequate for measuring it.
ER  - 

TY  - JOUR
T1  - Financial decision support with hybrid genetic and neural based modeling tools
JO  - European Journal of Operational Research
VL  - 103
IS  - 2
SP  - 339
EP  - 349
PY  - 1997/12/1/
T2  - 
AU  - Kumar, Ned
AU  - Krovi, Ravindra
AU  - Rajagopalan, Balaji
SN  - 0377-2217
DO  - http://dx.doi.org/10.1016/S0377-2217(97)00124-0
UR  - http://www.sciencedirect.com/science/article/pii/S0377221797001240
KW  - Decision support systems
KW  - Artificial intelligence
KW  - Genetic algorithms
KW  - Neural networks
AB  - This paper presents a comparative investigation of hybrid genetic classifiers vis-a-vis neural classifiers and statistical models in the financial domain. It is hypothesized that the proposed hybrid genetic classifier will perform better than the statistical counterpart. We provide a brief overview of the hybrid genetic classifier and discuss the design issues when applied to developing classification models for financial decision support. Further, the models are tested on a liquidation-merger problem. Results are consistent with the hypothesized premise. The proposed genetic classifiers outperform the statistical model. Implications of the comparison and issues for future research are addressed.
ER  - 

TY  - JOUR
T1  - Approximate algorithms for marketing management problems
JO  - Journal of Retailing and Consumer Services
VL  - 3
IS  - 3
SP  - 145
EP  - 154
PY  - 1996/7//
T2  - 
AU  - Hurley, S.
AU  - Moutinho, L.
SN  - 0969-6989
DO  - http://dx.doi.org/10.1016/0969-6989(95)00067-4
UR  - http://www.sciencedirect.com/science/article/pii/0969698995000674
KW  - site location
KW  - sales territory design
KW  - segmentation
KW  - new generation optimization techniques
AB  - In this paper we show how three relatively unknown optimization techniques could be used to solve important marketing management problems. In particular, we consider genetic algorithms for site location analysis, tabu search for market segmentation, and finally simulated annealing for designing sales territories.
ER  - 

TY  - JOUR
T1  - A cooccurrence-based thesaurus and two applications to information retrieval
JO  - Information Processing & Management
VL  - 33
IS  - 3
SP  - 307
EP  - 318
PY  - 1997/5//
T2  - 
AU  - Schütze, Hinrich
AU  - Pedersen, Jan O.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/S0306-4573(96)00068-4
UR  - http://www.sciencedirect.com/science/article/pii/S0306457396000684
AB  - This paper presents a new method for computing a thesaurus from a text corpus. Each word is represented as a vector in a multi-dimensional space that captures cooccurrence information. Words are defined to be similar if they have similar cooccurrence patterns. Two different methods for using these thesaurus vectors in information retrieval are shown to significantly improve performance over the Tipster reference corpus as compared to a term vector space baseline.
ER  - 

TY  - JOUR
T1  - Mapping the Fermi surface of Cu using ARUPS
JO  - Surface Science
VL  - 331–333, Part B
IS  - 
SP  - 1272
EP  - 1276
PY  - 1995/7/1/
T2  - Proceedings of the 14th European Conference on Surface Science
AU  - Stampfl, A.P.J.
AU  - Foo, J.A.Con
AU  - Leckey, R.C.G.
AU  - Riley, J.D.
AU  - Denecke, R.
AU  - Ley, L.
SN  - 0039-6028
DO  - http://dx.doi.org/10.1016/0039-6028(95)00340-1
UR  - http://www.sciencedirect.com/science/article/pii/0039602895003401
KW  - Angle resolved photoemission
KW  - Copper
KW  - Low index single crystal surfaces
KW  - Photoelectron emission
AB  - The topology of the Fermi surface of copper has been illuminated in a direct fashion using the technique of photoelectron spectroscopy. Full emission hemisphere intensity distributions of photoelectrons excited from the Fermi energy by photons of various energies have been compared with the theoretically expected loci of such transitions and good agreement was found. An alternative method of determining the shape of a slice through the bulk Fermi surface involving the use of constant initial state spectroscopy has also been used for the first time. In particular, part of the Fermi surface of Cu in the ΓL[1&amp;#x0304;1&amp;#x0304;2] plane has been mapped in this way by following the k-space dispersion of transitions originating at the Fermi level as a function of photon energy.
ER  - 

TY  - JOUR
T1  - Science and technology policy in the 1980s and beyond : Edited by M. Gibbons, P. Gummet, B. Udgaonkar 346 pages, £15.95 (London and New York, Longman Group Ltd, 1984)
JO  - Futures
VL  - 16
IS  - 6
SP  - 659
EP  - 661
PY  - 1984/12//
T2  - 
AU  - Brookman, Henry
SN  - 0016-3287
DO  - http://dx.doi.org/10.1016/0016-3287(84)90133-2
UR  - http://www.sciencedirect.com/science/article/pii/0016328784901332
ER  - 

TY  - JOUR
T1  - Neural network applications in business: A review and analysis of the literature (1988–1995)
JO  - Decision Support Systems
VL  - 19
IS  - 4
SP  - 301
EP  - 320
PY  - 1997/4//
T2  - 
AU  - Wong, Bo K
AU  - Bodnovich, Thomas A
AU  - Selvi, Yakup
SN  - 0167-9236
DO  - http://dx.doi.org/10.1016/S0167-9236(96)00070-X
UR  - http://www.sciencedirect.com/science/article/pii/S016792369600070X
KW  - Neural networks
KW  - Research
AB  - A survey of journal articles on neural network business applications published between 1988 and 1995 indicates that an increasing amount of neural network research is being conducted for a diverse range of business activities. The classification of literature by (1) year of publication, (2) application area, (3) problem domain, (4) decision process phase, (5) level of management, (6) level of task interdependence, (7) means of development, (8) corporate/academic interaction in development, (9) technology integration, (10) comparative study, (11) major contribution, and (12) journal provides some insights into the trends in neural networks research. The implications for neural networks developers/researchers and suggestions on future research areas are discussed.
ER  - 

TY  - JOUR
T1  - Infinite trees and automaton- definable relations over ω-words
JO  - Theoretical Computer Science
VL  - 103
IS  - 1
SP  - 143
EP  - 159
PY  - 1992/8/24/
T2  - 
AU  - Thomas, Wolfgang
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/0304-3975(92)90090-3
UR  - http://www.sciencedirect.com/science/article/pii/0304397592900903
AB  - We study relations over ω-words using a representation by tree languages. An ω-word over an alphabet with k letters is considered as a path through the k-ary tree, an n-tuple of ω-words as an n-tuple of paths (coded by an appropriate valuation of the k-ary tree using values in {0,1}n), and a relation over ω-words as a tree language. In the first part of the paper we give a logical characterization of the “Rabin-recognizable relations” (whose associated tree languages are recognized by Rabin tree automata) in terms of “weak chain logic”, a restriction of monadic second-order logic over trees. In the second part of the paper an extended logic is considered, obtained by adjoining the “equal-level predicate” over trees. We describe the class of relations over ω-words which (in the tree language representation) are definable in this logic, and show that the theory of the k-ary tree in this logic is decidable. It covers tree properties which are not expressible in the monadic second-order logic SkS.
ER  - 

TY  - JOUR
T1  - Leveraging collective intellect by building organizational capabilities
JO  - Expert Systems with Applications
VL  - 13
IS  - 1
SP  - 29
EP  - 40
PY  - 1997/7//
T2  - Knowledge management
AU  - Junnarkar, Bipin
SN  - 0957-4174
DO  - http://dx.doi.org/10.1016/S0957-4174(97)00020-1
UR  - http://www.sciencedirect.com/science/article/pii/S0957417497000201
AB  - This paper approaches knowledge management from a definitely practical angle. Based on experiences in Monsanto, several important aspects are addressed. The notion of value creation through insight generation is seen as crucial. Leveraging collective intellect heavily relies on learning. By using the completeness-of-information and clarity-of-understanding dimension more light is shed on adding value through learning. A knowledge management methodology consisting of six components (‘maps’) is presented that has been used in Monsanto to deal with knowledge management problems. The enabling role of information technology is highlighted. In the concluding section some guidelines for knowledge management actions are stated, which will help users to avoid the many traps that can occur when dealing with knowledge in organizations.
ER  - 

TY  - JOUR
T1  - The effect of knowledge-map and underlining training on the reading comprehension of scientific texts
JO  - English for Specific Purposes
VL  - 13
IS  - 1
SP  - 35
EP  - 45
PY  - 1994///
T2  - 
AU  - Amer, Aly Anwar
SN  - 0889-4906
DO  - http://dx.doi.org/10.1016/0889-4906(94)90023-X
UR  - http://www.sciencedirect.com/science/article/pii/088949069490023X
AB  - This study was prompted by awareness of college students' difficulties understanding scientific texts in English. To help students overcome these difficulties, the present researcher investigated the effect of using two reading study strategies (i.e., knowledge-map and underlining) on the students' reading comprehension of scientific English. Students participating in the study were randomly assigned to “knowledge map” treatment, “underlining” treatment, or “control” group. Two measures of reading comprehension were used: open-ended questioning and summarizing. Results showed that although both treatment groups outperformed the control group on open-ended questioning, the difference between the two treatment groups on this measure was not statistically significant. Both treatment groups outperformed the control group on summarization, with the knowledge map group performing significantly better.
ER  - 

TY  - JOUR
T1  - Towards the “cognitive management” of a research institute
JO  - Research Policy
VL  - 17
IS  - 4
SP  - 225
EP  - 233
PY  - 1988///
T2  - 
AU  - Courtial, J.-P.
AU  - Remy, J.C.
SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/0048-7333(88)90051-0
UR  - http://www.sciencedirect.com/science/article/pii/0048733388900510
AB  - The purpose of this article is to describe a method for classifying the activity of large general-interest research centres. The system of classification should permit an evaluation of the interface between any given research project and any given economic goal. It should thus become a management tool.

Working from a description of research activity in terms of elementary tasks, the method - called co-word analysis - consists in aggregating key words describing these tasks into larger “themes” of about 10 words. It is then possible to compare the research efforts of particular laboratories within the research centre in terms of a short, “natural”, variable list of themes. This classification can be compared with the current administrative structure, and can be used as a basis for the negotiation of change.

It is then suggested that the themes attached to a specific subfile of research operations can be displayed on a two-dimensional diagram, with one axis being the “centrality” (the weight of external links) and the other being the “density” (the weight of internal links) of each theme. This diagram structures the file into core research activity (central and developed), general research context (central but not developed) and subfields (peripheral, developed or undeveloped). Being a representation of implicit strategies, this diagram can be used at many levels - from that of the choice of key words to the determination of research goals. It can be used for the negotiation of policy both within and outside of the research centre.
ER  - 

TY  - JOUR
T1  - X-automata on ω-words
JO  - Theoretical Computer Science
VL  - 110
IS  - 1
SP  - 1
EP  - 51
PY  - 1993/3/15/
T2  - 
AU  - Engelfriet, Joost
AU  - Jan Hoogeboom, Hendrik
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/0304-3975(93)90349-X
UR  - http://www.sciencedirect.com/science/article/pii/030439759390349X
AB  - For any storage type X, the ω-languages accepted by X-automata are investigated. Six accepting conditions (including those introduced by Landweber) are compared for X-automata. The inclusions between the corresponding six families of ω-languages are essentially the same as for finite-state automata. Apart from unrestricted automata, also real-time and deterministic automata are considered. The main tools for this investigation are: (1) a characterization of the ω-languages accepted by X-automata in terms of inverse X-transductions of finite-state ω-languages; and (2) the existence of topological upper bounds on some of the families of accepted ω-languages (independent of the storage type X).
ER  - 

TY  - JOUR
T1  - Retrieving documents by plausible inference: An experimental study
JO  - Information Processing & Management
VL  - 25
IS  - 6
SP  - 599
EP  - 614
PY  - 1989///
T2  - 
AU  - Croft, W.B.
AU  - Lucia, T.J.
AU  - Cringean, J.
AU  - Willett, P.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(89)90095-2
UR  - http://www.sciencedirect.com/science/article/pii/0306457389900952
AB  - Choosing an appropriate document representation and search strategy for document retrieval has been largely guided by achieving good average performance instead of optimizing the results for each individual query. A model of retrieval based on plausible inference gives us a different perspective and suggests that techniques should be found for combining multiple sources of evidence (or search strategies) into an overall assessment of a document's relevance, rather than attempting to pick a single strategy. In this paper, we outline our approach to plausible inference for retrieval and describe some experiments designed to test this approach. The experiments use a simple spreading activation search to implement the plausible inference process. The results show that combining term-based, nearest-neighbor, and citation evidence can give significant effectiveness improvements.
ER  - 

TY  - JOUR
T1  - Bayesian inference networks and spreading activation in hypertext systems
JO  - Information Processing & Management
VL  - 28
IS  - 3
SP  - 389
EP  - 406
PY  - 1992///
T2  - 
AU  - Savoy, Jacques
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(92)90082-B
UR  - http://www.sciencedirect.com/science/article/pii/030645739290082B
KW  - Hypertext
KW  - Information retrieval
KW  - Information retrieval in hypertext
KW  - Bayesian network
KW  - Inference network
KW  - Probabilistic inference
KW  - Spreading activation
KW  - Hypertext link semantics
AB  - Browsing is the foremost method in searching through information in a hypertext or hypermedia system. However, as the number of nodes and links increases, this technique is far from satisfactory, and other search mechanisms must be provided. Classical search techniques such as menu selection hierarchies, string matching, Boolean query, etc., are already available, but they treat nodes as independent entities rather than considering the link semantics between nodes. Moreover, in order to write a query the users often encounter many problems such as how to find the appropriate terms that describe the information needs, how to correctly write a query in a language using artificial syntax, etc. This paper describes an alternative based on a Bayesian network that structures the indexing terms and stores the user's information needs. In our approach, the user does not have to write a formal query because the computation required is accomplished automatically and without any prior information or constraint. Moreover, using a constrained spreading activation, our solution uses link semantics to search relevant starting points for browsing.
ER  - 

TY  - JOUR
T1  - An essay on the past and future (?) of information science education—I: Historical overview
JO  - Information Processing & Management
VL  - 15
IS  - 1
SP  - 1
EP  - 15
PY  - 1979///
T2  - 
AU  - Saracevic, Tefko
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(79)90002-5
UR  - http://www.sciencedirect.com/science/article/pii/0306457379900025
AB  - The rapid and rather chaotic evolution of information science has left the field's academic sector in a largely disorganized state. This essay examines the basic issues confronting information science education, issues that must be resolved if information science education and thus information science itself are to evolve in an orderly fashion. For the quality of a field's professional services and research activities depends upon the quality of its formal academic programs. The essay is organized in three parts. In this first part are considered definitions and in a historic context the emergence, evolution and current state of information science and its education. The second part considers the “externalities” of education—problems and unresolved questions in information science education that deal with: (i) academic affiliations, (ii) degree levels, (iii) admission requirements, (iv) jurisdiction and (v) financing. The third part considers the problems and unresolved questions in respect to internal aspects (“internalities”) of information science education: (i) objectives, (ii) content, (iii) teachers and (iv) teaching. It is suggested that information science cannot prosper; possibly even survive in the next decade if serious, concentrated action is not undertaken in the “externalities” and “internalities” of its education. Recommendations about the areas that need action are made.
ER  - 

TY  - JOUR
T1  - Utilizing the age of references to control the exhaustivity of the reference representation in information retrieval
JO  - Information Processing & Management
VL  - 31
IS  - 1
SP  - 29
EP  - 45
PY  - 1995/1//
Y2  - 1995/2//
T2  - 
AU  - Sumner Jr., Robert G.
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(95)80004-D
UR  - http://www.sciencedirect.com/science/article/pii/030645739580004D
AB  - The effectiveness of using the age of references to control the exhaustivity of the reference representation in information retrieval was investigated through analysis of optimal cluster-based retrieval results. The CF310 database, a subset of the CF database, was used. The two types of reference representations studied were the “foreground” representation, restricted to references with ages less than or equal to a specific age threshold, and the “background” representation, restricted to references with ages greater than this age threshold. It was assumed that the optimal level of exhaustivity for the foreground representation would be that age threshold at which the representation was restricted to references in the research front. It was also assumed that this representation would produced significantly better results than the exhaustive representation. The results show, as expected, that the foreground representation at its optimal level of exhaustivity is restricted to references of a relatively recent vintage—with ages less than or equal to seven. However, this representation does not produce significantly better results than the exhaustive representation. The background representation at its optimal level of exhaustivity is the exhaustive representation. Interestingly, the optimization of results for individual queries yields significantly better retrieval performance than the foreground representation at its optimal level of exhaustivity. Twenty-one out of 44 queries have optimal results with either the foreground or background representations, 15 have optimal results with just the foreground representation, and 8 have optimal results with just the background representation. The levels of exhaustivity for the optimal results vary considerably among the queries and, when the foreground representation is the optimal representation, span the complete range of age threshold values.
ER  - 

TY  - JOUR
T1  - On the efficiency of best-match cluster searches
JO  - Information Processing & Management
VL  - 30
IS  - 3
SP  - 343
EP  - 361
PY  - 1994/5//
Y2  - 1994/6//
T2  - 
AU  - Can, Fazli
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(94)90049-3
UR  - http://www.sciencedirect.com/science/article/pii/0306457394900493
AB  - The efficiency of various cluster-based retrieval (CBR) strategies is analyzed. The possibility of combining CBR and inverted index search (IIS) is investigated. A method for combining the two approaches is proposed and shown to be cost effective in terms of paging and CPU time. In the new method, the selection of documents from the best-matching clusters is done using the inverted index for all documents. Although this is counterintuitive to the concept of best-match CBR, the observations prove that it is much more efficient than conventional approaches. In the experiments, the effects of the number of selected clusters, page size, centroid length, and matching function are considered. The experiments show that the storage overhead of the new method would be moderately higher than that of IIS.
ER  - 

TY  - JOUR
T1  - Compound key word generation from document databases using a hierarchical clustering ART model
JO  - Intelligent Data Analysis
VL  - 1
IS  - 1–4
SP  - 25
EP  - 48
PY  - 1997///
T2  - 
AU  - Muñoz, Alberto
SN  - 1088-467X
DO  - http://dx.doi.org/10.1016/S1088-467X(98)00008-0
UR  - http://www.sciencedirect.com/science/article/pii/S1088467X98000080
KW  - Automatic indexing
KW  - Knowledge extraction
KW  - Information retrieval
KW  - Neural fuzzy ART models
KW  - Information retrieval
AB  - The growing availability of databases on the information highways motivates the development of new processing tools able to deal with a heterogeneous and changing information environment. A highly desirable feature of data processing systems handling this type of information is the ability to automatically extract its own key words. In this paper we address the specific problem of creating semantic term associations from a text database. The proposed method uses a hierarchical model made up of Fuzzy Adaptive Resonance Theory (ART) neural networks. First, the system uses several Fuzzy ART modules to cluster isolated words into semantic classes, starting from the database raw text. Next, this knowledge is used together with coocurrence information to extract semantically meaningful term associations. These associations are asymmetric and one-to-many due to the polisemy phenomenon. The strength of the associations between words can be measured numerically. Besides this, they implicitly define a hierarchy between descriptors. The underlying algorithm is appropriate for employment on large databases. The operation of the system is illustrated on several real databases.
ER  - 

TY  - JOUR
T1  - Mapping of the local minority carrier diffusion length in silicon wafers
JO  - Applied Surface Science
VL  - 63
IS  - 1–4
SP  - 213
EP  - 217
PY  - 1993/1//
T2  - 
AU  - Stemmer, Michael
SN  - 0169-4332
DO  - http://dx.doi.org/10.1016/0169-4332(93)90092-P
UR  - http://www.sciencedirect.com/science/article/pii/016943329390092P
AB  - A new instrument based on the light beam induced current (LBIC) technique for the determination of the local minority carrier diffusion length L in silicon samples is presented. The evaluation of L is done by measuring the spectral variation of the normalized photocurrent as collected by a diode structure under local excitation by a light spot for wavelength λ in the near infrared range. Mappings of L(x,y) are obtained by scanning the sample under the spot in x–y direction. White light bias applied during the measurement gives informations about saturation effects at recombination centers. Applications of this technique are given for multicrystalline wafers treated by phosphorus diffusion for a differing time, and for silicon bicrystals prior and after heat treatments. The evolution of L(x,y) in the grains and at extended defects is discussed in relation to the sample processing.
ER  - 

TY  - JOUR
T1  - Master author index, volumes 1–20
JO  - Research Policy
VL  - 22
IS  - 2
SP  - 117
EP  - 136
PY  - 1993/4//
T2  - 

SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/0048-7333(93)90069-T
UR  - http://www.sciencedirect.com/science/article/pii/004873339390069T
ER  - 

TY  - JOUR
T1  - THE LANCET.: London, Saturday, Nov. 22, 1834
JO  - The Lancet
VL  - 23
IS  - 586
SP  - 324
EP  - 328
PY  - 1834/11/22/
T2  - Originally published as Volume 1, Issue 586

SN  - 0140-6736
DO  - http://dx.doi.org/10.1016/S0140-6736(02)96540-2
UR  - http://www.sciencedirect.com/science/article/pii/S0140673602965402
ER  - 

TY  - JOUR
T1  - Shpol'skii fluorimetry: The anatomy of an eponym
JO  - TrAC Trends in Analytical Chemistry
VL  - 11
IS  - 6
SP  - 200
EP  - 202
PY  - 1992/6//
Y2  - 1992/7//
T2  - 
AU  - Braun, T.
AU  - Klein, Agnes
SN  - 0165-9936
DO  - http://dx.doi.org/10.1016/0165-9936(92)80042-5
UR  - http://www.sciencedirect.com/science/article/pii/0165993692800425
ER  - 

TY  - JOUR
T1  - Master subject index, volumes 1–20
JO  - Research Policy
VL  - 22
IS  - 2
SP  - 137
EP  - 179
PY  - 1993/4//
T2  - 

SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/0048-7333(93)90070-X
UR  - http://www.sciencedirect.com/science/article/pii/004873339390070X
ER  - 

TY  - JOUR
T1  - Intelligent information systems: The concept of an intelligent document
JO  - Information Systems
VL  - 14
IS  - 4
SP  - 351
EP  - 358
PY  - 1989///
T2  - 
AU  - Goyal, Pankaj
SN  - 0306-4379
DO  - http://dx.doi.org/10.1016/0306-4379(89)90054-9
UR  - http://www.sciencedirect.com/science/article/pii/0306437989900549
KW  - Information retrieval
KW  - document systems
AB  - This paper presents certain ideas on the concept of an intelligent information system (IIS). An IIS allows the simultaneous presentation of different parts of the same or different referenced or related documents. The documents are organized such that they permit a non-linear traversal, and may be classed as being Hypertext documents. The ideas are a continuation of the Intelligent Document System (IDS) presented in [1].
ER  - 

TY  - JOUR
T1  - Maintaining the cohesive collection: The case for the local cataloger
JO  - The Journal of Academic Librarianship
VL  - 22
IS  - 6
SP  - 462
EP  - 465
PY  - 1996/11//
T2  - 
AU  - Sheeran, Ruth
SN  - 0099-1333
DO  - http://dx.doi.org/10.1016/S0099-1333(96)90009-9
UR  - http://www.sciencedirect.com/science/article/pii/S0099133396900099
ER  - 

TY  - JOUR
T1  - The pragmatics of information retrieval experimentation, revisited
JO  - Information Processing & Management
VL  - 28
IS  - 4
SP  - 467
EP  - 490
PY  - 1992/7//
Y2  - 1992/8//
T2  - Special Issue: Evaluation Issues in Information Retrieval
AU  - Tague-Sutcliffe, Jean
SN  - 0306-4573
DO  - http://dx.doi.org/10.1016/0306-4573(92)90005-K
UR  - http://www.sciencedirect.com/science/article/pii/030645739290005K
AB  - The decisions that must be made by an investigator in carrying out an information retrieval experiment are described. Guidance is provided on a number of issues, specifically determining the need for testing, choosing the type of test (laboratory or operational), defining the variables, developing or using databases, finding queries, processing queries, assigning treatments to experimental units, collecting the data, analyzing the data, and presenting the results.
ER  - 

TY  - JOUR
T1  - Contents volume 29, 1990
JO  - Engineering Geology
VL  - 29
IS  - 4
SP  - 441
EP  - 443
PY  - 1990/12//
T2  - 

SN  - 0013-7952
DO  - http://dx.doi.org/10.1016/0013-7952(90)90077-E
UR  - http://www.sciencedirect.com/science/article/pii/001379529090077E
ER  - 

TY  - JOUR
T1  - Language-theoretic complexity of disjunctive sequences
JO  - Discrete Applied Mathematics
VL  - 80
IS  - 2–3
SP  - 203
EP  - 209
PY  - 1997/12/11/
T2  - 
AU  - Calude, Cristian
AU  - Sheng, Yu
SN  - 0166-218X
DO  - http://dx.doi.org/10.1016/S0166-218X(97)00061-9
UR  - http://www.sciencedirect.com/science/article/pii/S0166218X97000619
AB  - A sequence over an alphabet ∑ is called disjunctive if it contains all possible finite strings over ∑ as its substrings. Disjunctive sequences have been recently studied in various contexts. They abound in both category and measure senses. In this paper we measure the complexity of a sequence x by the complexity of the language P(x) consisting of all prefixes of x. The languages P(x) associated to disjunctive sequences can be arbitrarily complex. We show that for some disjunctive numbers x the language P(x) is context-sensitive, but no language P(x) associated to a disjunctive number can be context-free. We also show that computing a disjunctive number x by rationals corresponding to an infinite subset of P(x) does not decrease the complexity of the procedure, i.e. if x is disjunctive, then P(x) does not have an infinite context-free subset. This result reinforces, in a way, Chaitin's thesis (1969) according to which perfect sets, i.e. sets for which there is no way to compute infinitely many of its members essentially better (simpler/quicker) than computing the whole set, do exist. Finally we prove the existence of the following language-theoretic complexity gap: There is no x ϵ ∑w such that P(x) is context-free but not regular. If S(x), the set of all finite substrings of a sequence x ϵ ∑w, is slender, then the set of all prefixes of x is regular, that is P(x) is regular if and only if S(x) is slender.
ER  - 

TY  - JOUR
T1  - On alternating ω-automata
JO  - Journal of Computer and System Sciences
VL  - 36
IS  - 1
SP  - 16
EP  - 24
PY  - 1988/2//
T2  - 
AU  - Lindsay, Peter A.
SN  - 0022-0000
DO  - http://dx.doi.org/10.1016/0022-0000(88)90018-9
UR  - http://www.sciencedirect.com/science/article/pii/0022000088900189
AB  - Deterministic and nondeterministic automata on ω-strings have been studied extensively under six different acceptance conditions. Miyano and Hayashi extended the study to alternating automata, but two of the conditions were not considered; the present paper completes the gap by showing that alternating ω-automata accept precisely the ω-regular languages under these conditions.
ER  - 

TY  - JOUR
T1  - On ω-sets associated with context-free languages
JO  - Information and Control
VL  - 31
IS  - 3
SP  - 272
EP  - 293
PY  - 1976/7//
T2  - 
AU  - Linna, M.
SN  - 0019-9958
DO  - http://dx.doi.org/10.1016/S0019-9958(76)90415-0
UR  - http://www.sciencedirect.com/science/article/pii/S0019995876904150
AB  - New families of ω-languages (sets of infinite sequences) associated with context-free languages and pushdown automata are introduced. Their basic properties, such as inclusion relations, closure under the Boolean operations and periodicity, are studied and compared with the corresponding properties of the families of ω-languages accepted by finite automata. Moreover, a number of solvability and unsolvability results are proved. The results obtained imply that there is a definite difference between the family of ω-languages accepted by pushdown automata and the family associated with context-free languages.
ER  - 

TY  - JOUR
T1  - Kafka criticism and empirical studies of literature
JO  - Poetics
VL  - 21
IS  - 1–2
SP  - 45
EP  - 56
PY  - 1992/4//
T2  - 
AU  - Petr, Pavel
SN  - 0304-422X
DO  - http://dx.doi.org/10.1016/0304-422X(92)90021-T
UR  - http://www.sciencedirect.com/science/article/pii/0304422X9290021T
AB  - Two ESL concepts, ‘construction of meaning’ and ‘literary system’, are used in order to establish a plausible methodological framework for dealing with the complex and vastly divergent Kafka reception phenomenon. The essential categorial groups of Kafka criticism (here somewhat re-classified in comparison with existing summaries) are thus identified as constructs linked with typical forms of group consensus, and divergent assessments of Kafka's life are seen as based on the divergence in the profile of those who receive them in different cultural circumstances, rather than on ‘objective truth’. In the second part of the article, the contradictions and complexities of Marxist Kafka criticism are defined and categorized with the help of the concept ‘literary system’, also focussing on the pressures concerning its demarcation in our century.
ER  - 

TY  - JOUR
T1  - Application of an expert system to monitoring and control in aquaculture
JO  - Knowledge-Based Systems
VL  - 4
IS  - 3
SP  - 165
EP  - 171
PY  - 1991/9//
T2  - 
AU  - Harris, D.D.
AU  - Zhang, Feng
AU  - Sydenham, P.H.
SN  - 0950-7051
DO  - http://dx.doi.org/10.1016/0950-7051(91)90005-M
UR  - http://www.sciencedirect.com/science/article/pii/095070519190005M
KW  - expert systems
KW  - monitoring and control
KW  - knowledge base
KW  - user interaction
AB  - When any measurement task is approached from the point of view of the knowledge which is needed, it is found that this knowledge often comprises a range of data, interpreted in terms of a set of rules. In the current explanatory application, measurement and control of water quality is fundamental to the breeding of healthy fish in aquaculture installations. It is the rule base, fed with real-time measured data, which is of primary importance in ensuring the health of the fish.

Computer based expert systems simplify the application of rules and heuristics to real-time monitoring and control. This paper discusses the development of a computer-based, distributed monitoring and control system built around the “Crystal” expert system. The system enables both heuristic and real-time varying knowledge to be integrated into the rule base on which control decisions are automatically made.

An important feature is that, by directly accessing the expert system's rule builder, the application domain user can change the configuration and operating rules of the system using only low-level computing skills. By also building ‘sensor knowledge’ into the expert system, the sensor design and operating requirements are simplified, allowing the inexpert user to specify the needed sensors, or build them to drawings supplied by the system.
ER  - 

TY  - JOUR
T1  - Cal as a trojan horse for educational change: The case of psychology
JO  - Computers & Education
VL  - 19
IS  - 1–2
SP  - 87
EP  - 95
PY  - 1992/7//
Y2  - 1992/8//
T2  - 
AU  - Hammond, Nick
AU  - Trapp, Annie
SN  - 0360-1315
DO  - http://dx.doi.org/10.1016/0360-1315(92)90014-V
UR  - http://www.sciencedirect.com/science/article/pii/036013159290014V
AB  - The use of CAL in psychology teaching in higher education in the U.K. is reviewed from a perspective of educational change. Approaches vary in how they challenge the traditional educational and organization assumptions of university teaching, though virtually all require some re-thinking of educational objectives and context of use.
ER  - 

TY  - JOUR
T1  - The effects of HyperCard authoring on computer-related attitudes and Spanish language acquisition
JO  - Computers in Human Behavior
VL  - 11
IS  - 3–4
SP  - 633
EP  - 647
PY  - 1995///Autumn
Y2  - 1995///Winter
T2  - 
AU  - Toro, Maria Alexandra
SN  - 0747-5632
DO  - http://dx.doi.org/10.1016/0747-5632(95)80022-Z
UR  - http://www.sciencedirect.com/science/article/pii/074756329580022Z
AB  - The underlying premise of this study has been that the acquisition of a second language can be facilitated when the student organizes information in ways that more closely parallel the organization of information in his/her mind. When learners construct personal representations of the material, they are learning.

Through the creation of HyperCard programs, students found a powerful new medium of communication and new insights into organizing and synthesizing information. Students' learning of a second language was improved by allowing the students to be the composers or creators of their own works in an attempt to communicate their understanding of the language.

Most research related to educational applications of hypermedia has focused on how teachers can use hypermedia as an authoring tool to create stacks for students to use. However, this study focused on the learners' active participation in the process of learning a second language by allowing them to create their own stacks in Spanish with the information learned in class.
ER  - 

TY  - JOUR
T1  - Nuclear muscopy — Elemental mapping using high-energy ion beam techniques
JO  - Nuclear Instruments and Methods in Physics Research Section B: Beam Interactions with Materials and Atoms
VL  - 50
IS  - 1–4
SP  - 197
EP  - 207
PY  - 1990/4/3/
T2  - 
AU  - Grime, G.W.
AU  - Watt, F.
SN  - 0168-583X
DO  - http://dx.doi.org/10.1016/0168-583X(90)90355-X
UR  - http://www.sciencedirect.com/science/article/pii/0168583X9090355X
AB  - Using a scanned, focused MeV ion beam, the techniques of ion beam analysis can be used to obtain images showing two-dimensional elemental distributions. This technique of nuclear muscopy is important in applications where the distribution of elements within a sample must be related to optical or electron images showing the structure or functional organisation of the sample. With the techniques available at present, spatial resolutions of 0.5 μm can be achieved at currents allowing PIXE analysis of trace elements at the ppm level. The simultaneous use of particle backscattering analysis and secondary-electron imaging allows the light elements and the surface topography of the sample to be determined. In some cases, nondestructive three-dimensional elemental analysis can be carried out. This paper reviews the techniques and describes two applications in semiconductor physics and microbiology carried out using the facility at Oxford.
ER  - 

TY  - JOUR
T1  - The Netherlands without engineering geology: No lands
JO  - Engineering Geology
VL  - 37
IS  - 1
SP  - 5
EP  - 14
PY  - 1994/4//
T2  - 
AU  - de Mulder, E.F.J.
SN  - 0013-7952
DO  - http://dx.doi.org/10.1016/0013-7952(94)90077-9
UR  - http://www.sciencedirect.com/science/article/pii/0013795294900779
AB  - Through the ages, The Netherlands have been struggling with encroaching water, both from the sea, from rivers and from the ground. The western part of the country, where the majority of the population is living, is situated almost entirely below sea level. Without the protection of dunes and sea dikes in the west, without the river dikes in the centre and the east, and without constant pumping. Holland would drown immediately. Because large parts of the country are composed of a thick succession of unconsolidated younger Quaternary (Holocene) deposits, almost all constructions have to be built on a foundation of piles driven down to firm Pleistocene sands to support them. These exceptional geographical, hydrological and geological conditions have prompted extensive studies in soil-mechanical engineering, and have generated special surveying techniques and special geological mapping techniques in areas where natural outcrops do not occur. In a densely populated and low-lying country with soft deposits, maintenance of the coastal defence system and foundation instability are major problems which can be mitigated by a sound knowledge of engineering geology. Some projects intended to focus attention on and to promote engineering geology in The Netherlands are described in the last section of this paper.
ER  - 

TY  - JOUR
T1  - Highly-autonomous event-driven spacecraft control
JO  - Acta Astronautica
VL  - 35, Supplement 1
IS  - 
SP  - 555
EP  - 565
PY  - 1995///
T2  - 
AU  - Aljabri, A.S.
AU  - Kia, T.
AU  - Lai, J.Y.
SN  - 0094-5765
DO  - http://dx.doi.org/10.1016/0094-5765(94)00223-9
UR  - http://www.sciencedirect.com/science/article/pii/0094576594002239
AB  - Future JPL missions will continue to be scientifically and technically more ambitious, and will demand more autonomy to accomplish complex tasks in uncertain environments and in close proximity to extraterrestrial surfaces. A prime example is small body rendezvous and sample return. In addition to mission demands, affordability is now a primary driver. The call is for smaller missions with greatly reduced cost of operation and less expensive spacecraft designs. Spacecraft with highly-autonomous, goal-directed control systems are proposed to meet these challenges. This paper discusses the plan to design and develop a proof-of-concept attitude and control subsystem (ACS) that has the ability to capture science events and enable a small body rendezvous and sample return mission while requiring only one person level-of-effort for ACS ground operation support. The technology to be developed and demonstrated includes: on-board sequence generation and execution, precision closed-loop maneuver and attitude control, target acquisition and tracking, and sensing and representation of spacecraft system state. A reference mission development scenario, complete with a representative mission, spacecraft design concept, and development process, will be used in order to incorporate all the nuances of a real mission, where experience has shown that the real problems lurk. Previously-conducted JPL studies will be used to develop the scenarios. The representative spacecraft will be small to micro and consistent with a Discovery class mission. Possible approaches for the new paradigms in system architecture, ground commanding and test and verification that will be necessary for highly-autonomous event-driven controls will be addressed.
ER  - 

TY  - JOUR
T1  - On three-element codes
JO  - Theoretical Computer Science
VL  - 40
IS  - 
SP  - 3
EP  - 11
PY  - 1985///
T2  - Eleventh International Colloquium on Automata, Languages and Programming
AU  - Karhumäki, Juhani
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/0304-3975(85)90155-0
UR  - http://www.sciencedirect.com/science/article/pii/0304397585901550
AB  - We show that three-element codes have some special properties which do not hold even for four-element codes. Firstly, for each three-element code A, if u and v are words in pref(xAω) ∩ pref(yAω), with x,y ϵ A, x ≠ y, then one of them is a prefix of the other, i.e., among the words which can be covered in two different ways from left to right there exists a unique maximal (possibly infinite) element. Secondly, each three-element code has a bounded delay in at least one direction.
ER  - 

TY  - JOUR
T1  - Many aspects of formal languages
JO  - Information Sciences
VL  - 57–58
IS  - 
SP  - 119
EP  - 129
PY  - 1991/9//
Y2  - 1991/12//
T2  - Information Sciences- Past, Present, and Future
AU  - Salomaa, Arto
SN  - 0020-0255
DO  - http://dx.doi.org/10.1016/0020-0255(91)90071-2
UR  - http://www.sciencedirect.com/science/article/pii/0020025591900712
AB  - Formal language theory is, together with automata theory, which is really inseparable from language theory, the oldest branch of theoretical computer science. Indeed, the role of language theory in computer science is analogous to that of philosophy in general science: it constitutes the stem from which the more specialized branches of knowledge emerge. A typical example is seen from the early history of complexity theory. That formal language theory is really an interdisciplinary area of science is seen, for instance, from the fact that different branches of language theory are closely connected with pure algebra, linguistics of natural languages, programming languages, compilers, computer graphics, and the description of the development of simple organisms. The strength of formal language theory has been in its ability to create new models for new investigation, rather than sticking to a specific fixed model. There is no reason to doubt this ability in the future. The purpose of this paper is to give some glimpses of the diverse investigations referred to in the preceding paragraph. Section 1 is concerned with fundamental issues; more details are contained in Salomaa (1973) [3] and Salomaa (1985) [5]. A problem going back to the beginning of this century is discussed in Section 2; the reader may consult also Salomaa (1981) [4] and Thue [8]. The final section discusses a very recent problem in cryptography; Salomaa (to be published) [6] is a general book about cryptography and data security.
ER  - 

TY  - JOUR
T1  - Various hierarchies of ω-regular sets
JO  - Theoretical Computer Science
VL  - 174
IS  - 1–2
SP  - 259
EP  - 268
PY  - 1997/3/15/
T2  - 
AU  - Takahashi, Nobuyuki
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/S0304-3975(96)00245-9
UR  - http://www.sciencedirect.com/science/article/pii/S0304397596002459
AB  - Barua (1992) studied a hierarchy Rn (n = 1,2,3,…), where Rn is a class of ω-regular sets which are decomposed into n rational Gδ sets forming a decreasing sequence. On the other hand, Kaminski (1985) defined a hierarchy Bm (m = 1,2,3,…), where Bm is a class of ω-regular sets which are decomposed into 2m rational Gδ sets not necessarily forming a decreasing sequence. We prove that R2n = Bn in spite of the difference of defining conditions.
ER  - 

TY  - JOUR
T1  - The evaluation of national performance in selected priority areas using scientometric methods
JO  - Research Policy
VL  - 25
IS  - 3
SP  - 431
EP  - 450
PY  - 1996/5//
T2  - 
AU  - Leydesdorff, Loet
AU  - Gauthier, Élaine
SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/0048-7333(95)00841-1
UR  - http://www.sciencedirect.com/science/article/pii/0048733395008411
AB  - How effectively can ‘emerging’ science-based technologies be coupled to national R&amp;D systems? Dutch and Canadian priority programs in biotechnology and advanced materials are analyzed in terms of differential increases in scientific output by using scientometric indicators and mappings. Methodological issues about using scientometric methods for science policy evaluations in the case of interdisciplinary and rapidly changing areas of ‘techno-science’ are discussed. The major finding of the paper is that Canadian researchers seem to have used the priority programs as an alternative source of funding, while their Dutch colleagues were able to use these programs to help their specialties grow above the national average, and in accordance with selected priorities. Thus, the results suggest that the national dimension has been more important for explaining differences in performance than the substantive specificity of the two priority areas.
ER  - 

TY  - JOUR
T1  - On syntactic congruences for ω-languages
JO  - Theoretical Computer Science
VL  - 183
IS  - 1
SP  - 93
EP  - 112
PY  - 1997/8/30/
T2  - Formal Language Theory
AU  - Maler, Oded
AU  - Staiger, Ludwig
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/S0304-3975(96)00312-X
UR  - http://www.sciencedirect.com/science/article/pii/S030439759600312X
AB  - In this paper we investigate several questions related to syntactic congruences and to minimal automata associated with ω-languages. In particular we investigate relationships between the so-called simple (because it is a simple translation from the usual definition in the case of finitary languages) syntactic congruence and its infinitary refinement (the iteration congruence) investigated by Arnold (Theoret. Comput. Sci. 39 (1985) 333–335). We show that in both cases not every ω-language having a finite syntactic monoid is regular and we give a characterization of those ω-languages having finite syntactic monoids.

Among the main results we derive a condition which guarantees that the simple syntactic congruence and Arnold's syntactic congruence coincide and show that all (including infinitestate) ω-languages in the Borel class Fσ∩Gδ satisfy this condition. We also show that all ω-languages in this class are accepted by their minimal-state automaton — provided they are accepted by any Muller automaton.

Finally we develop an alternative theory of recognizability of ω-languages by families of right-congruence relations, and define a canonical object (much smaller then Arnold's monoid) associated with every ω-language. Using this notion of recognizability we give a necessary and sufficient condition for a regular ω-language to be accepted by its minimal-state automaton.
ER  - 

TY  - JOUR
T1  - Monadic partition logics and finite automata
JO  - Theoretical Computer Science
VL  - 166
IS  - 1–2
SP  - 63
EP  - 81
PY  - 1996/10/20/
T2  - 
AU  - Shen, Enshao
AU  - Tian, Qijia
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/0304-3975(95)00113-1
UR  - http://www.sciencedirect.com/science/article/pii/0304397595001131
AB  - By argumenting first-order logic with monadic partition quantifiers we get a new family of extended logics. They are strictly weaker in expressive power than monadic second-order logic, have some good semantic features and offer better specification formalisms for studying finite automata and formal languages.
ER  - 

TY  - JOUR
T1  - On infinite words obtained by iterating morphisms
JO  - Theoretical Computer Science
VL  - 19
IS  - 1
SP  - 29
EP  - 38
PY  - 1982/7//
T2  - 
AU  - Culik II, Karel
AU  - Salomaa, Arto
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/0304-3975(82)90013-5
UR  - http://www.sciencedirect.com/science/article/pii/0304397582900135
AB  - The paper investigates infinite words, and sets of them, associated with DOL and DTOL systems. Main emphasis is on characterization and decidability results.
ER  - 

TY  - JOUR
T1  - Localization of the main noradrenergic neuron groups in the pons and medulla of the rabbit and the importance of cathodal lesions for prolonged survival
JO  - Journal of Neuroscience Methods
VL  - 19
IS  - 1
SP  - 11
EP  - 27
PY  - 1987/1//
T2  - 
AU  - Badoer, E.
AU  - Head, G.A.
AU  - Aberdeen, J.A.
AU  - Korner, P.I.
SN  - 0165-0270
DO  - http://dx.doi.org/10.1016/0165-0270(87)90017-3
UR  - http://www.sciencedirect.com/science/article/pii/0165027087900173
KW  - Anodal and cathodal lesions
KW  - Noradrenergic cell groups
KW  - Localization
KW  - Rabbit
AB  - Methods for stereotaxically localizing the major noradrenergic (NA) cell groups (i.e. A1, A2, A5 and A6+A7) in the rabbit are described. Using a modified Kopf head holder we used surface landmarks including the obex for making lesions of the A1 and A2 cells in the medulla. Localization of the pontine cell groups was done by mapping intracerebral structures including (1) the facial nerve for A5 and (2) the motor nucleus of the trigeminal nerve for A6 + A7. In the initial experiments we made A1 lesions by passing anodal currents through stainless steel electrodes, which was associated with pulmonary oedema, neurological complications and a high mortality. This syndrome was probably related to toxic effects of ferric ion deposition, and disappeared when cathodal currents were employed. We have now made 106 bilateral cathodal lesions in the different groups, with a 20% intraoperative mortality. But virtually all survivors remained indefinitely in clinically good condition for the 2–4 weeks duration of our experiments. In 65 of these rabbits we achieved greater than 75% of NA cell destruction (average 84%). From the cardiovascular viewpoint ‘non-specific’ damage by the lesions was relatively small, except after A2 lesions where there was some impairment in the baroreceptor-heart rate reflex, though a considerable amount of residual function remained.
ER  - 

TY  - JOUR
T1  - “Mapping the mind”: Where are the state lines?
JO  - Cognitive Development
VL  - 11
IS  - 1
SP  - 141
EP  - 155
PY  - 1996/1//
Y2  - 1996/3//
T2  - 
AU  - Miller, Patricia H.
SN  - 0885-2014
DO  - http://dx.doi.org/10.1016/S0885-2014(96)90032-5
UR  - http://www.sciencedirect.com/science/article/pii/S0885201496900325
ER  - 

TY  - JOUR
T1  - Class I gene regulation of haplotype preference may influence antiviral immunity in vivo
JO  - Cellular Immunology
VL  - 122
IS  - 2
SP  - 365
EP  - 376
PY  - 1989/9//
T2  - 
AU  - Thomsen, Allan Randrup
AU  - Marker, Ole
SN  - 0008-8749
DO  - http://dx.doi.org/10.1016/0008-8749(89)90084-1
UR  - http://www.sciencedirect.com/science/article/pii/0008874989900841
AB  - The lymphocytic choriomeningitis virus (LCMV)-specific Tc response in (C3×D2) F1 hybrids (k×d) is markedly biased in favor of the H-2d haplotype. Adoptive transfer experiments established that this haplotype preference also applied to T cell function in vivo. Using different mouse strain combinations we were unable to detect an influence of sex, non-H-2 background, maternal genotype, or route of priming on the preference pattern. In other haplotype combinations tested (k and b, b and d) no distinct haplotype preference was observed. A comparison of the LCMV-specific Tc response of (C×C3) F1 and (C-H-2dm2×C3) F1 hybrids revealed that the dominance of the H-2d haplotype was controlled by H-2Ld. The ability of this gene to down-regulate the generation of an H-2k-restricted response did not seem to reflect antigenic mimicry since H-2k-restricted LCMV-specific Tc did not lyse H-2d expressing targets. In regard to the in vivo significance of haplotype preference it was found that (C×C3) f1 mice expressed an earlier and stronger virus-specific delayed type hypersensitivity response and exerted a more efficient virus control than did (C-H-2dm2×C3) f1. Taken together these findings suggest that haplotype preference reflects a selection process favoring the restriction element associated with the most efficient immune response in vivo. The implications of this are discussed.
ER  - 

TY  - JOUR
T1  - Topographic dependence of synthetic aperture radar imagery
JO  - Computers & Geosciences
VL  - 21
IS  - 4
SP  - 521
EP  - 532
PY  - 1995/5//
T2  - 
AU  - Franklin, S.E.
AU  - Lavigne, M.B.
AU  - Hunt Jr., E.R.
AU  - Wilson, B.A.
AU  - Peddle, D.R.
AU  - McDermid, G.J.
AU  - Giles, P.T.
SN  - 0098-3004
DO  - http://dx.doi.org/10.1016/0098-3004(94)00095-C
UR  - http://www.sciencedirect.com/science/article/pii/009830049400095C
KW  - Remote sensing
KW  - Mapping
KW  - Topographic effect
KW  - Incidence values
KW  - SAR
KW  - DTM
KW  - DEM
AB  - The increasing availability of synthetic aperture radar (SAR) remote-sensing imagery for earth-science applications creates the need for reliable computer methods to improve the relationships between SAR observations and the Earth's abiotic, biotic, and cultural resources. In this paper, the topographic effect on aerial and satellite SAR imagery is quantified and corrected using software modified from an earlier normalized-cosine package written for use with optical/infrared remote-sensing imagery. The basic idea is that the incidence angle and forest canopy interactions with the radar beam can be estimated using a digital elevation model (DEM) and near-coincident observations in the red and near-infrared portions of the spectrum. Four different study areas in Canada and three different types of SAR imagery are used to illustrate the topographic dependence, and the degree of accuracy that can be expected, following the application of these relatively simple radiometric corrections.
ER  - 

TY  - JOUR
T1  - Establishing new research directions
JO  - Technological Forecasting and Social Change
VL  - 32
IS  - 3
SP  - 229
EP  - 243
PY  - 1987/11//
T2  - 
AU  - Quinn, J.J.
SN  - 0040-1625
DO  - http://dx.doi.org/10.1016/0040-1625(87)90027-8
UR  - http://www.sciencedirect.com/science/article/pii/0040162587900278
AB  - Incresingly, in the United Kingdom and other countries, government policy towards the academic sector is being guided by the principle that scientific and engineering research should be linked to the requirements of industry. Governments are selectively supporting areas of research based on their perceived industrial relevance. However, given that academic research is essentially long-term in perspective, this policy implies an ability to choose those areas of science and technology that will be important some time in the future. This paper considers the institutional structure within which this choice is currently made in the U.K. and considers some possible alternatives.
ER  - 

TY  - JOUR
T1  - The lunar prospector discovery mission: A new approach to planetary science
JO  - Acta Astronautica
VL  - 41
IS  - 4–10
SP  - 585
EP  - 597
PY  - 1997/8//
Y2  - 1997/11//
T2  - Developing Business
AU  - Hubbard, G.Scott
AU  - Binder, Alan B.
AU  - Dougherty, Thomas A.
AU  - Cox, Sylvia A.
SN  - 0094-5765
DO  - http://dx.doi.org/10.1016/S0094-5765(98)00070-8
UR  - http://www.sciencedirect.com/science/article/pii/S0094576598000708
AB  - Lunar Prospector, the first competitively selected mission in NASA's Discovery Program, will conduct a one year orbital survey of the Moon's composition and structure. To be launched in late 1997, the suite of five instruments will detect water ice to a sensitivity of 50 ppm (hydrogen), measure key elemental constituents, detect gas release events and accurately map the Moon's gravitational and magnetic fields. At a total real year cost of $63M, including launch vehicle and operations, and a development period of less than two years, the mission also demonstrates a new, rapid, cost-effective approach to planetary science investigations. As a joint effort of NASA's Ames Research Center and Lockheed Martin, Sunnyvale, Lunar Prospector is a model of government-industry cooperation.
ER  - 

TY  - JOUR
T1  - On generators of rational ω-power languages
JO  - Theoretical Computer Science
VL  - 53
IS  - 2–3
SP  - 187
EP  - 200
PY  - 1987///
T2  - 
AU  - Litovsky, I.
AU  - Timmerman, E.
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/0304-3975(87)90063-6
UR  - http://www.sciencedirect.com/science/article/pii/0304397587900636
AB  - An ‘ω-power’ language is an ω-language L of the form L=Rω for some language R called generator of L. For a given rational language R, we study the relation of inclusion in the family of the generators of Rω: 1.
(1) We first prove that the maximal generators, with respect to the inclusion, are rational, constructible and finite in number. Moreover, any generator of Rω is included in one of them.
2.
(2) Then we prove that one can test whether a generator is minimal for the inclusion.
ER  - 

TY  - JOUR
T1  - Weighted finite transducers in image processing
JO  - Discrete Applied Mathematics
VL  - 58
IS  - 3
SP  - 223
EP  - 237
PY  - 1995/4/7/
T2  - 
AU  - Culik II, Karel
AU  - Friš, Ivan
SN  - 0166-218X
DO  - http://dx.doi.org/10.1016/0166-218X(93)E0149-S
UR  - http://www.sciencedirect.com/science/article/pii/0166218X93E0149S
AB  - Culik and Karhumäki studied weighted finite automata (WFA) as devices computing real functions. The main motivation was to give specifications of graytone images as local grayness functions. Culik and Kari gave an algorithm for automatic image encoding using WFA as a basis for a practical image data compression method.

In this paper we introduce k-tape weighted finite automata. We are mainly interested in the case of 2 tapes called weighted finite transducers (WFT). We show that the most commonly used image transformations can be defined by WFTs. We also show that WFT transformations are closed under union and composition and that the family of WFA images is closed under WFT transformations.
ER  - 

TY  - JOUR
T1  - An initial semantics for the μ-calculus on trees and Rabin's complementation lemma
JO  - Theoretical Computer Science
VL  - 148
IS  - 1
SP  - 121
EP  - 132
PY  - 1995/8/21/
T2  - 
AU  - Arnold, André
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/0304-3975(95)00069-9
UR  - http://www.sciencedirect.com/science/article/pii/0304397595000699
AB  - In this paper we show that the function associated with any closed or nonclosed term of the μ-calculus on trees can be represented by a recognizable set of trees whose nodes are labeled by letters and by sets of variables. Rabin's complementation lemma is an immediate consequence of this result.
ER  - 

TY  - JOUR
T1  - On DOL systems with immigration
JO  - Theoretical Computer Science
VL  - 120
IS  - 2
SP  - 229
EP  - 245
PY  - 1993/11/22/
T2  - 
AU  - Honkala, Juha
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/0304-3975(93)90289-6
UR  - http://www.sciencedirect.com/science/article/pii/0304397593902896
AB  - We study DOL systems with immigration. We show that sequence and growth equivalence are decidable. We establish regularity and decidability results concerning degrees of ambiguity. As a consequence of results about subword complexity, we show that regularity and ω-regularity are decidable for languages generated by growing systems.
ER  - 

TY  - JOUR
T1  - Getting the best out of your medical library part 1 — The basic services and printed resources
JO  - Current Anaesthesia & Critical Care
VL  - 4
IS  - 3
SP  - 171
EP  - 177
PY  - 1993/7//
T2  - 
AU  - Ferguson, V.A.
SN  - 0953-7112
DO  - http://dx.doi.org/10.1016/0953-7112(93)90032-9
UR  - http://www.sciencedirect.com/science/article/pii/0953711293900329
AB  - A Postgraduate Medical Centre or Medical School library can play a valuable support role in the anaesthetist's clinical work and research by providing printed resources through its stock of monographs, periodicals and indexes. These are enhanced by the human resources of the library staff who can assist the clinician with additional services. In part one, the applications and use of Index Medicus, Excerpta Medica and Science Citation Index are described and the development of the individual's information-seeking methods is discussed. Part two will deal with electronic forms of information and information retrieval and copyright.
ER  - 

TY  - JOUR
T1  - Valuations of languages, with applications to fractal geometry
JO  - Theoretical Computer Science
VL  - 137
IS  - 2
SP  - 177
EP  - 217
PY  - 1995/1/23/
T2  - 
AU  - Fernau, Henning
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/0304-3975(94)00049-O
UR  - http://www.sciencedirect.com/science/article/pii/030439759400049O
AB  - Valuations — morphisms from (Σ∗, ·, λ) to ((0,∞), ·,1) — are a simple generalization of Bernoulli morphisms (distributions, measures) as introduced by Berstel and Perrin (1988), Berstel and Reutenauer (1988), Blanchard and Hansel (1984), Eilenberg (1974) and Hansel and Perrin (1983, 1989). This paper shows that valuations are useful not only within the theory of codes, but also when dealing with ambiguity, especially in context-free grammars, or for defining outer measures on the space of ω-words which are of some importance to the theory of fractals. These connections yield new formulae to determine the Hausdorff dimension of fractal sets (especially in Euclidean spaces) defined via formal languages. The class of fractals describable with context-free languages strictly includes that of MRFS fractals introduced by Čulik and Dube (1990) and Mauldin and Williams (1988).

Some of the results of this paper also appear as part of the author's Ph.D. thesis and other works (Fernau, 1992a,b, 1993).
ER  - 

TY  - JOUR
T1  - Corporate distress diagnosis: Comparisons using linear discriminant analysis and neural networks (the Italian experience)
JO  - Journal of Banking & Finance
VL  - 18
IS  - 3
SP  - 505
EP  - 529
PY  - 1994/5//
T2  - 
AU  - Altman, Edward I.
AU  - Marco, Giancarlo
AU  - Varetto, Franco
SN  - 0378-4266
DO  - http://dx.doi.org/10.1016/0378-4266(94)90007-8
UR  - http://www.sciencedirect.com/science/article/pii/0378426694900078
KW  - Distress diagnosis
KW  - Discriminant models
KW  - Neural nelworks
KW  - Corporate bankruptcy risk
KW  - Financial ratio analysis
AB  - This study analyzes the comparison between traditional statistical methodologies for distress classification and prediction, i.e., linear discriminant (LDA) or logit analyses, with an artificial intelligence algorithm known as neural networks (NN). Analyzing well over 1,000 healthy, vulnerable and unsound industrial Italian firms from 1982–1992, this study was carried out at the Centrale dei Bilanci in Turin, Italy and is now being tested in actual diagnostic situations. The results are part of a larger effort involving separate models for industrial, retailing/trading and construction firms.

The results indicate a balanced degree of accuracy and other beneficial characteristics between LDA and NN. We are particularly careful to point out the problems of the ‘black-box’ NN systems, including illogical weightings of the indicators and overfitting in the training stage both of which negatively impacts predictive accuracy. Both types of diagnoslic techniques displayed acceptable, over 90%, classificalion and holdoul sample accuracy and the study concludes that there certainly should be further studies and tests using the two lechniques and suggests a combined approach for predictive reinforcement.
ER  - 

TY  - JOUR
T1  - Intracistronic mapping of the defective site and the biochemical properties of β subunit mutants of Escherichia coli H+-ATPase: Correlation of structural domains with functions of the β subunit
JO  - Archives of Biochemistry and Biophysics
VL  - 227
IS  - 2
SP  - 596
EP  - 608
PY  - 1983/12//
T2  - 
AU  - Kanazawa, Hiroshi
AU  - Noumi, Takato
AU  - Oka, Norihiro
AU  - Futai, Masamitsu
SN  - 0003-9861
DO  - http://dx.doi.org/10.1016/0003-9861(83)90489-7
UR  - http://www.sciencedirect.com/science/article/pii/0003986183904897
AB  - Sixteen mutants of Escherichia coli defective in H+-ATPase (proton-translocating ATPase) were tested for their ability to recombine with hybrid plasmids carrying various portions of the β subunit cistron. Twelve mutations were mapped within the carboxyl half of the cistron corresponding to amino acid residues 279 to 459 (domain II), while four mutations were mapped within residues 17 to 278 (domain I). The biochemical properties of these mutants were analyzed in terms of the proton permeability of their membranes and the assembly properties of their F1F0 complex. The mutants were classified according to the properties into three types, I, II, and III. In 12 mutants of type I, proton conduction in membrane vesicles was blocked and little F1 was released from the membranes under conditions in which F1 could be released from wild-type membranes, suggesting that assembly of the F1F0 complex is structurally and functionally defective. F1 was partially purified with very low recovery from one of the type I mutants, KF16. ATPase activity was reconstituted from this F1 with the β subunit of the wild type, confirming the genetic results. Only one mutant, KF38, was classified as type II. Its membranes were partially leaky to protons and its F1 was releasable, suggesting that the interaction of its F1 and F0 was unstable. Type III mutants, KF11 and KF43, had an F1F0 complex with very low activity, in which the structure of F1 was relatively similar to that of the wild type. F1 was purified as a single complex from KF43 in this study and from KF11 previously (H. Kanazawa, Y. Horiuchi, M. Takagi, Y. Ishino, and M. Futai (1980)J. Biochem.88, 695–703). Reconstitution experiments in vitro showed that the F1's of both mutants were defective in the β subunit. The properties of the altered F1 of KF43 differed from those of F1 of KF11, suggesting that the mutation sites of KF43 and KF11 were different. From the results of mapping mutation sites and the biochemical properties of the mutants, the correlation of structural domains with function of the β subunit is discussed. Most type I and type II mutations except that of KF39 were mapped in domain II, while the type III mutations were mapped in domain I, suggesting that domain II is more important than domain I for the function of the β subunit, especially in terms of proper assembly of the F1F0 complex.
ER  - 

TY  - JOUR
T1  - Assessing basic research: Reappraisal and update of an evaluation of four radio astronomy observatories
JO  - Research Policy
VL  - 16
IS  - 2–4
SP  - 213
EP  - 227
PY  - 1987/8//
T2  - 
AU  - Irvine, John
AU  - Martin, Ben R.
AU  - Abraham, John
AU  - Peacock, Tim
SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/0048-7333(87)90031-X
UR  - http://www.sciencedirect.com/science/article/pii/004873338790031X
AB  - This paper critically reassesses the results of a previous evaluation of the research performance of four radio astronomy observatories over the period 1969–1978, completed by two of the authors in 1980. At the same time, the evaluation is updated by presenting bibliometric (publication and citation) data for the subsequent five-year period 1979–1983. While application of a more developed evaluation methodology is shown not to alter significantly the conclusions arrived at in the earlier study, there is evidence that the relative research performance of the four observatories has changed significantly since 1978.
ER  - 

TY  - JOUR
T1  - The impact of firmspecific capabilities on the amount of capital raised in an initial public offering: Evidence from the biotechnology industry
JO  - Journal of Business Venturing
VL  - 12
IS  - 1
SP  - 31
EP  - 46
PY  - 1997/1//
T2  - 
AU  - Deeds, David L.
AU  - Decarolis, Dona
AU  - Coombs, Joseph E.
SN  - 0883-9026
DO  - http://dx.doi.org/10.1016/S0883-9026(97)84970-1
UR  - http://www.sciencedirect.com/science/article/pii/S0883902697849701
AB  - Going “public” has a magical sound to most entrepreneurial managers. By going public the firm increases its legitimacy in the business community, improves access to debt financing, and creates a means of exit for major shareholders. However, by far the most important reason for going public is to infuse a significant amount of investment capital into the firm. It is well documented that small businesses frequently fail because of insufficient funding and heavy debt loads. Issuing an initial public offering (IPO) allows entrepreneurial firms to overcome these pitfalls. Clearly, if access to capital is the major goal of going public, then the success of an offering is measured by the amount of capital raised by the firm. This study presents a model of the total amount of capital raised by a firm through an IPO. The explanatory variables include several indicators of the scientific capabilities of the firm including the location of the firm, the quality of the research staff, the number of products under development, the number of patents held by the firm, and the firm's prior spending on research and development (R&amp;D). The model is empirically tested on a sample of 92 biotechnology IPOs. The results provide strong support for the hypothesized positive relationship between the total amount of capital raised by a firm's IPO and the scientific capabilities of the firm.

Our results have important implications for entrepreneurs. First, an entrepreneur needs to develop and send credible signals indicating the value of the firm's intangible assets to the market. Second, the market values as deep a product pipeline as possible given a firm's resource constraints. Third, choice of location is a key strategic decision that should not be overlooked. Fourth, the market values firm-specific capabilities and will increase the capital it is willing to invest in a firm accordingly. Finally, the amount of capital a firm raises in its IPO can be influenced by entrepreneurial managers' strategic decisions.
ER  - 

TY  - JOUR
T1  - A quantitative assessment of interdisciplinary structures in science and technology: Co-classification analysis of energy research
JO  - Research Policy
VL  - 21
IS  - 1
SP  - 27
EP  - 44
PY  - 1992/2//
T2  - 
AU  - Tijssen, Robert J.W.
SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/0048-7333(92)90025-Y
UR  - http://www.sciencedirect.com/science/article/pii/004873339290025Y
AB  - The wide diversity in subject matter and volume of research publications of large multidisciplinary areas often presents an insurmountable barrier in obtaining a comprehensive overview of its internal (“intellectual”) structure. In this article it is shown that a systematic, quantitative examination of the contents of an area's research publications offers an empirical solution for this problem. This “co-classification analysis” is based on the network of interdisciplinary links between research fields contributing to such an area, as manifest in the co-occurrence of different subject-classification headings assigned to research publications. The analysis yields quantitative measures of: (1) the level of interdisciplinarity in contributing research fields; (2) the strength of interdisciplinary relations between these fields, as well as (3) graphical representations (“maps”) of the interdisciplinary structure in single fields, as well as the area as a whole.

Capabilities and limitations of this methodology, as an aid in research policy studies, are discussed by way of a Dutch science-policy-driven application to the area of energy research. Results are presented concerning the worldwide interdisciplinary structure of energy research, and the structure in Dutch publications on research sources of renewable energy. Findings of a subsequent validation study amongst Dutch scientists, R&amp;D managers, and S&amp;T policy makers support our assertion that the method is useful for certain analytical and descriptive purposes, but also point out limits in its range of application.
ER  - 

TY  - JOUR
T1  - The knowledge pool: Measurement challenges in evaluating fundamental research programs
JO  - Evaluation and Program Planning
VL  - 20
IS  - 1
SP  - 77
EP  - 89
PY  - 1997/2//
T2  - 
AU  - Cozzens, Susan E.
SN  - 0149-7189
DO  - http://dx.doi.org/10.1016/S0149-7189(96)00038-9
UR  - http://www.sciencedirect.com/science/article/pii/S0149718996000389
AB  - The Government Performance and Results Act (GPRA) requires all U.S. federal agencies to set measurable goals and report on whether they are meeting them. These requirements force a tradeoff for research agencies. Either they focus on short-term, measurable processes in reporting their performance and neglect the long-term benefits that research produces for economy and society, or they seek relief from the measurement requirements of the law. This article reviews the state of the art in performance measures and assessment processes before GPRA was passed, and discusses the difficulties in fitting these practices into the GPRA framework. It offers a simple logic model for research programs that highlights what is measurable and what is not with regard to activities that build a national science and engineering base.
ER  - 

TY  - JOUR
T1  - On projective and separable properties
JO  - Theoretical Computer Science
VL  - 186
IS  - 1–2
SP  - 135
EP  - 156
PY  - 1997/10/30/
T2  - 
AU  - Peled, Doron
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/S0304-3975(96)00225-3
UR  - http://www.sciencedirect.com/science/article/pii/S0304397596002253
AB  - A language L over the Cartesian product of component alphabets is called projective if it is closed under projections, i.e., together with each word α ∈ L, it contains all the words that have the same projections up to stuttering as α. We prove that the projective languages are precisely the languages obtained using parallel composition and intersection from stuttering-closed component languages in each of the following classes of languages: regular, star-free regular, ω-regular and star-free ω-regular. Languages of these classes can also be seen as properties of various temporal logics which are used to specify properties of concurrent systems. In particular, the star-free ω-regular languages coincide with properties expressed using Propositional Linear Temporal Logic. Some uses of projective properties for specification and verification of programs are studied.
ER  - 

TY  - JOUR
T1  - Automaticity II: Descriptional complexity in the unary case
JO  - Theoretical Computer Science
VL  - 180
IS  - 1–2
SP  - 181
EP  - 201
PY  - 1997/6/10/
T2  - 
AU  - Pomerance, Carl
AU  - Michael Robson, John
AU  - Shallit, Jeffrey
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/S0304-3975(96)00189-2
UR  - http://www.sciencedirect.com/science/article/pii/S0304397596001892
AB  - Let Σ and Δ be finite alphabets, and let ƒ be a map from Σ∗ to Δ. Then the deterministic automaticity of ƒ, Aƒ(n), is defined to be the size of the minimum finite-state machine that correctly computes ƒ on all inputs of size &lt;/n. A similar definition applies to languages L. We denote the nondeterministic analogue (for languages L) of automaticity by nl(n).

In a previous paper, Shallit and Breitbart examined the properties of this measure of descriptional complexity in the case ¦Σ|⩾ 2. In this paper, we continue the study of automaticity, focusing on the case where ¦Σ¦= 1.

We prove that Aƒ(n)&lt;/n + 1 − [logℓn], where ℓ = ¦Δ¦. We also prove that Aƒ(n) &gt; n − 2 logℓ n − 2 logℓ logℓ n for almost all functions ƒ.

In the nondeterministic case, we show that there exists a c such that for almost all unary languages L, we have NL(n) &gt; cnlog n for all sufficiently large n. The proof is based on a new enumeration method for languages accepted by unary q-state NFAs.

If L is not a regular language, then it follows from a result of Karp that lim supn→∞ AL(n)n ⩾ 12. We conjecture that L − 0∗, then this bound can be improved to (√5 − 1)2.

Finally, we give some lower bounds for nondeterministic automaticity for nonregular languages.
ER  - 

TY  - JOUR
T1  - Verification and behavior abstraction towards a tractable verification technique for large distributed systems
JO  - Journal of Systems and Software
VL  - 33
IS  - 3
SP  - 273
EP  - 285
PY  - 1996/6//
T2  - Software Engineering for Distributed Computing
AU  - Nitsche, Ulrich
SN  - 0164-1212
DO  - http://dx.doi.org/10.1016/0164-1212(96)00026-X
UR  - http://www.sciencedirect.com/science/article/pii/016412129600026X
AB  - In this article, we present a method for coping with the complexity of verification of industrial sized distributed systems' specifications. To formally verify a specification of a distributed system, one usually constructs the complete state-space for the specification and then checks if the behavior represented by the state-space has the properties one wants it to have. Such an approach is usually limited to rather small specifications because we are confronted with what is known as the state-space explosion problem. That means that, because of interleavings, for medium or even small-sized specifications, the corresponding state-space becomes so large that usual verification techniques become intractable.

Because it is often not necessary to have present all information about the distributed system, we can calculate abstractions of the behavior of a distributed system whose state-space representation is much smaller than the state-space that represents the complete behavior. Methods exist for computing the abstracted state-space directly from the specification without having to compute the state-space for the complete behavior. We will show in this article how properties verified for an abstracted behavior can be retranslated into corresponding properties of the complete behavior. Especially for liveness properties with respect to the behavior, this is a nontrivial problem. But we will show that restrictions exist that are easily satisfied by specifications of practical interest that allow the retranslation of such liveness properties from the abstracted to the complete behavior.
ER  - 

TY  - JOUR
T1  - Repetition of subwords in DOL languages
JO  - Information and Control
VL  - 59
IS  - 1–3
SP  - 13
EP  - 35
PY  - 1983///
T2  - 
AU  - Ehrenfeucht, A.
AU  - Rozenberg, G.
SN  - 0019-9958
DO  - http://dx.doi.org/10.1016/S0019-9958(83)80028-X
UR  - http://www.sciencedirect.com/science/article/pii/S001999588380028X
AB  - A language K ⊆ Σ* is repetitive if for each positive integer n there exists a word w ∈ Σ+ such that wn is a subword of K. Language K is called strongly repetitive if there exists a word w ∈ Σ+, such that, for each positive integer n, wn is a subword of K. It is shown that it is decidable whether an arbitrary DOL language is repetitive. It is also shown that if a DOL language is repetitive then it is strongly repetitive.
ER  - 

TY  - JOUR
T1  - Finite acceptance of infinite words
JO  - Theoretical Computer Science
VL  - 174
IS  - 1–2
SP  - 1
EP  - 21
PY  - 1997/3/15/
T2  - 
AU  - Litovsky, Igor
AU  - Staiger, Ludwig
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/S0304-3975(96)00006-0
UR  - http://www.sciencedirect.com/science/article/pii/S0304397596000060
AB  - In this paper we consider the following two types of finite acceptance of infinite words by finite automata: An infinite word ξ is accepted if and only if there is a run on input ξ for which 1.
(1) an accepting state is visited at least once, or
2.
(2) an accepting state is visited at least once but only finitely often.

 The resulting classes of regular ω-languages are characterized by language-theoretic means, and they are positioned into the known hierarchies of regular ω-languages.
ER  - 

TY  - JOUR
T1  - Temporal logic can be more expressive
JO  - Information and Control
VL  - 56
IS  - 1–2
SP  - 72
EP  - 99
PY  - 1983/1//
Y2  - 1983/2//
T2  - 
AU  - Wolper, Pierre
SN  - 0019-9958
DO  - http://dx.doi.org/10.1016/S0019-9958(83)80051-5
UR  - http://www.sciencedirect.com/science/article/pii/S0019995883800515
AB  - It is first proved that there are properties of sequences that are not expressible in temporal logic, even though they are easily expressible using, for instance, regular expressions. Then, it is shown how temporal logic can be extended to express any property definable by a right-linear grammar and hence a regular expression. Finally, a complete axiomatization and a decision procedure for the extended temporal logic are given and the complexity of the extended logic is examined.
ER  - 

TY  - JOUR
T1  - Games for the μ-calculus
JO  - Theoretical Computer Science
VL  - 163
IS  - 1–2
SP  - 99
EP  - 116
PY  - 1996/8/30/
T2  - 
AU  - Niwiński, Damian
AU  - Walukiewicz, Igor
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/0304-3975(95)00136-0
UR  - http://www.sciencedirect.com/science/article/pii/0304397595001360
AB  - Given a formula of the propositional μ-calculus, we construct a tableau of the formula and define an infinite game of two players of which one wants to show that the formula is satisfiable, and the other seeks the opposite. The strategy for the first player can be further transformed into a model of the formula while the strategy for the second forms what we call a refutation of the formula. Using Martin's Determinacy Theorem, we prove that any formula has either a model or a refutation. This completeness result is a starting point for the completeness theorem for the μ-calculus to be presented elsewhere. However, we argue that refutations have some advantages of their own. They are generated by a natural system of sound logical rules and can be presented as regular trees of the size exponential in the size of a refuted formula. This last aspect completes the small model theorem for the μ-calculus established by Emerson and Jutla (1988). Thus, on a more practical side, refutations can be used as small objects testifying incorrectness of a program specification expressed by a μ-formula, we illustrate this point by an example.
ER  - 

TY  - JOUR
T1  - Real functions and numbers defined by Turing machines
JO  - Theoretical Computer Science
VL  - 23
IS  - 3
SP  - 287
EP  - 304
PY  - 1983/5//
T2  - 
AU  - Freund, Rudolf
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/0304-3975(83)90035-X
UR  - http://www.sciencedirect.com/science/article/pii/030439758390035X
AB  - Real functions and real numbers defined by deterministic or non-deterministic Turing machines are observed, using the interpretation of infinite strings of digits as real numbers. A hierarchy of such Turing functions and numbers is established, and two classes of transcedent Turing numbers are investigated.
ER  - 

TY  - CHAP
AU  - Sanford, Anthony J.
AU  - Garrod, Simon C.
T1  - Towards a Processing Account of Reference
A2  - August Flammer and Walter Kintsch
BT  - Advances in Psychology
PB  - North-Holland
PY  - 1982///
VL  - Volume 8
SP  - 100
EP  - 110
T2  - Discourse Processing
SN  - 0166-4115
DO  - http://dx.doi.org/10.1016/S0166-4115(08)62684-9
UR  - http://www.sciencedirect.com/science/article/pii/S0166411508626849
AB  - This paper is a description of a theory of text representation. In particular, the processing of referring expressions is considered. Reference is construed as memory search, and the paper contains discussions of both the structure of memory (the search domains) and the structure of the referring expressions. Pronouns, definite noun-phrases, and restrictive relative clauses are seen as processing directives to search different parts of memory, the object of the search being to append new information to existing memory structures.
ER  - 

TY  - JOUR
T1  - A patent-based cartography of technology
JO  - Research Policy
VL  - 23
IS  - 1
SP  - 1
EP  - 26
PY  - 1994/1//
T2  - 
AU  - Engelsman, E.C.
AU  - van Raan, A.F.J.
SN  - 0048-7333
DO  - http://dx.doi.org/10.1016/0048-7333(94)90024-8
UR  - http://www.sciencedirect.com/science/article/pii/0048733394900248
AB  - We use bibliometric (in particular patent-based) methods and techniques to develop a cartography of technology. Two types of maps are presented: co-word maps and co-classification maps. Both types of maps have been constructed for the entire domain of technology (the macro-level), i.e. the ensemble of all fields of technology in their mutual relations. Time series clearly illustrates the changing relations between the major clusters of technology, and in particular the changing role of fields which act as a “bridge” between clusters, or as a (declining or emerging) centre of technological activities within a specific cluster. Maps visualize relations between fields of technology. In order to have measures of the relative strength of these relations, we develop the concept of affinity between fields. A special feature of our macro-maps concerns the role of Japan in technology.

A second hierarchical level is the combination of several fields of technology (meso-level). As an example we constructed a co-word map for the emerging “crossroad” technology optomechatronics based on patents as well as on scientific publications. In this way, optomechatronics is mapped from a technological point of view, and from a research point of view.

The third hierarchical level concerns one specific field of technology (micro-level). Co-word maps have been constructed for the technology fields coating and crystal growing, optical equipment, and building materials.

An important aspect of the map is the possibility to identify centers of activity within a specifically defined field of technology. These centers of activity may indicate important innovative developments, or they may reflect important markets. Furthermore, we introduce the concept of “technological peripheries”: for a specific technology field one may identify the direct “surroundings”; i.e. the most strongly linked fields.

Also, first attempts are made to map the “science and technology interface” by a specific combination of publication and patent data.

Our general conclusion is that the mapping methods and techniques presented in this publication already offer a unique way to visualize developments in fields of technology, and within technology as a whole. We emphasize that our technology maps are intended as a support tool, and never as a replacement of experts.
ER  - 

TY  - JOUR
T1  - The static and dynamic analysis of network data using information theory
JO  - Social Networks
VL  - 13
IS  - 4
SP  - 301
EP  - 345
PY  - 1991/12//
T2  - 
AU  - Leydesdorff, Loet
SN  - 0378-8733
DO  - http://dx.doi.org/10.1016/0378-8733(91)90001-A
UR  - http://www.sciencedirect.com/science/article/pii/037887339190001A
AB  - Information theory provides us with methods for both the static and dynamic analysis of network data. Since the models are derived within one framework, the results of the multivariate analysis and the time-series analysis can be made relevant for one another. Additionally, using the static model, one can create an exact dendrogram, and determine the precise number of clusters. The algorithm is generalizable to clique analysis. Using the dynamic model, developments can be revealed which were not suggested by the comparison of results of various forms of multivariate analysis for each year separately. The question of using these methods to design research about structure/action relations is discussed.
ER  - 

TY  - JOUR
T1  - Application of model theoretic games to discrete linear orders and finite automata
JO  - Information and Control
VL  - 33
IS  - 4
SP  - 281
EP  - 303
PY  - 1977/4//
T2  - 
AU  - Ladner, Richard E.
SN  - 0019-9958
DO  - http://dx.doi.org/10.1016/S0019-9958(77)90443-0
UR  - http://www.sciencedirect.com/science/article/pii/S0019995877904430
AB  - We apply the method of model theoretic games to theories of linear order. We obtain the known “equivalence” between ω-regular sets and the monadic second-order theory of (ω, &lt;) and the known “equivalence” between the star free regular sets and the first-order theory of finite linear orders. Finally, we give a new decision procedure for the monadic second order theory of (ω, &lt;) which does not rely on a reduction to the emptiness problem for automata on ω-words.
ER  - 

TY  - JOUR
T1  - Marriage and family periodical indexes
JO  - Serials Review
VL  - 13
IS  - 1
SP  - 19
EP  - 35
PY  - 1987///Spring
T2  - 
AU  - Sammataro, Linda J.
SN  - 0098-7913
DO  - http://dx.doi.org/10.1016/0098-7913(87)90027-X
UR  - http://www.sciencedirect.com/science/article/pii/009879138790027X
ER  - 

TY  - JOUR
T1  - Synchronized rational relations of finite and infinite words
JO  - Theoretical Computer Science
VL  - 108
IS  - 1
SP  - 45
EP  - 82
PY  - 1993/2/1/
T2  - 
AU  - Frougny, Christiane
AU  - Sakarovitch, Jacques
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/0304-3975(93)90230-Q
UR  - http://www.sciencedirect.com/science/article/pii/030439759390230Q
AB  - The purpose of this paper is a comprehensive study of a family of rational relations, both of finite and infinite words, namely those that are computable by automata where the reading heads move simultaneously on the n input tapes, and that we thus propose to call synchronized rational relations.
ER  - 

TY  - JOUR
T1  - Infinite behaviour of Petri nets
JO  - Theoretical Computer Science
VL  - 25
IS  - 3
SP  - 311
EP  - 341
PY  - 1983///
T2  - 
AU  - Valk, Rüdiger
SN  - 0304-3975
DO  - http://dx.doi.org/10.1016/0304-3975(83)90115-9
UR  - http://www.sciencedirect.com/science/article/pii/0304397583901159
AB  - The infinite behaviour of a Petri net is the set of infinite, labelled or unlabelled firing sequences. For the well-known notion of i-acceptance for i ∈{1, 1',2,2',3} two hierarchies are established and their interrelation is studied.
ER  - 

TY  - JOUR
T1  - By any other name: Accounting for failure in the naming of subject categories
JO  - Library & Information Science Research
VL  - 17
IS  - 4
SP  - 347
EP  - 385
PY  - 1995///Autumn
T2  - 
AU  - Brown, Mary E.
SN  - 0740-8188
DO  - http://dx.doi.org/10.1016/0740-8188(95)90031-4
UR  - http://www.sciencedirect.com/science/article/pii/0740818895900314
AB  - Research shows 65–80% of subject search terms fail to match the appropriate subject heading and one-third to one-half of subject searches result in no references being retrieved. In a cross-sectional study, 82 students (3rd grade through college) were presented complex concepts in a naming task. Concreteness, complexity, and syndeticity contributed significantly in explaining match-failure and predicting match-success. The likelihood of match-success following an initial failure is improved by manipulating the values of these three properties. Developmental trends which worked against match-success were observed. It is suggested that match-failure is a consequence of developmental naming patterns and that these patterns can be overcome through the use of metacognitive naming skills.
ER  - 

TY  - JOUR
T1  - Meson exchange currents in nuclear weak and electromagnetic interactions
JO  - Nuclear Physics A
VL  - 163
IS  - 1
SP  - 1
EP  - 55
PY  - 1971/3/1/
T2  - 
AU  - Chemtob, M.
AU  - Rho, M.
SN  - 0375-9474
DO  - http://dx.doi.org/10.1016/0375-9474(71)90520-3
UR  - http://www.sciencedirect.com/science/article/pii/0375947471905203
AB  - Meson theory is applied to the study of the exchange magnetic moment and Gamow-Teller operators. We consider contributions due to the exchange of one pion and of vector mesons and give their detailed expressions in terms of a general classification of the operators. The one-pion-exchange process is separated into Born and non-Born parts corresponding respectively to the Born and non-Born parts in the process of weak or photoproduction of a pion by the nucleon. The results of low-energy theorems for this process enable us to reach a model-independent description of the non-Born parts. Corrections to the soft-pion limit are studied by means of simple dynamical models: a phenomenological Lagrangian for the weak current and the Chew-Low model for the e.m. current. The exchange operators due to the exchange of ρ− and ω-mesons are evaluated in the vector dominance model. The applications are concerned with the exchange effect in the isovector and isoscalar magnetic moments of 3He and3H and in the Gamow-Teller matrix element for3H β-decay. The results are obtained with the dominant S-state with a Gaussian radial function. We also discuss their dependence on short-range correlations described in terms of Jastrow factors. The exchange corrections are found to be too small for the current wave functions of the trinucleons. We discuss briefly other agencies that may account for the remaining discrepancies.
ER  - 

TY  - JOUR
T1  - Minimal Coding
JO  - Annals of Pure and Applied Logic
VL  - 41
IS  - 3
SP  - 233
EP  - 297
PY  - 1989/3/1/
T2  - 
AU  - Friedman, Sy D.
SN  - 0168-0072
DO  - http://dx.doi.org/10.1016/0168-0072(89)90002-X
UR  - http://www.sciencedirect.com/science/article/pii/016800728990002X
ER  - 
